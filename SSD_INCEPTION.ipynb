{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05c7145a930944da9277478be795fa61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3fcbfcd039a4e9f8140273d7d3169e3",
              "IPY_MODEL_9ec58dd843f54ee08bdb77eb199a3adb",
              "IPY_MODEL_37f6c39c58ac4d3c97c7911453917c3a"
            ],
            "layout": "IPY_MODEL_1646211ff0d246ccbc1f7c3d31a132bb"
          }
        },
        "b3fcbfcd039a4e9f8140273d7d3169e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e1467ea988476e94fce2f3bdb367fd",
            "placeholder": "​",
            "style": "IPY_MODEL_5644c4c02a27429981f7c4af2292105e",
            "value": "Converting train set: 100%"
          }
        },
        "9ec58dd843f54ee08bdb77eb199a3adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591d8cf6c40d40e68013eb85dfaa8dbe",
            "max": 2306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14b2fdfa7ef34725a44e32100f721805",
            "value": 2306
          }
        },
        "37f6c39c58ac4d3c97c7911453917c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae9739835b141d39536960a94416a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_8f475c7ece12483b834dfede8ca8d3ec",
            "value": " 2306/2306 [03:37&lt;00:00, 14.73it/s]"
          }
        },
        "1646211ff0d246ccbc1f7c3d31a132bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e1467ea988476e94fce2f3bdb367fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5644c4c02a27429981f7c4af2292105e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "591d8cf6c40d40e68013eb85dfaa8dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b2fdfa7ef34725a44e32100f721805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae9739835b141d39536960a94416a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f475c7ece12483b834dfede8ca8d3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3be1318ccba4823b20bbf781f7b374d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b763d91963d045b7b54ebe9b2211433c",
              "IPY_MODEL_94a8a2ff276d48ea9dcfc90e11cc9fb0",
              "IPY_MODEL_eee139eb61f6499c8767b447abfb6d42"
            ],
            "layout": "IPY_MODEL_d43ca2cb8bb64a88a40b526fc9730bb9"
          }
        },
        "b763d91963d045b7b54ebe9b2211433c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b13e902a0f04d509481cb6bad2cdf7d",
            "placeholder": "​",
            "style": "IPY_MODEL_366e751deaaf4b6c80d939b8ee41d801",
            "value": "Converting valid set: 100%"
          }
        },
        "94a8a2ff276d48ea9dcfc90e11cc9fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d8082cee9e46bd9f960baa5e3a55aa",
            "max": 493,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c3cea6be8b4b3fa29c18166585f67a",
            "value": 493
          }
        },
        "eee139eb61f6499c8767b447abfb6d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7018eea1d0d841ef879bbb57aa7569b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a8c481313b654145a3100a5cf1b8809f",
            "value": " 493/493 [00:47&lt;00:00, 17.05it/s]"
          }
        },
        "d43ca2cb8bb64a88a40b526fc9730bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b13e902a0f04d509481cb6bad2cdf7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366e751deaaf4b6c80d939b8ee41d801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3d8082cee9e46bd9f960baa5e3a55aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c3cea6be8b4b3fa29c18166585f67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7018eea1d0d841ef879bbb57aa7569b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c481313b654145a3100a5cf1b8809f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219bdc14fd56415ea3ca07881ac1f4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb8816df49054497ac3288c2b0267a5b",
              "IPY_MODEL_0975081b0cdc4b39b066d291a0eca0fe",
              "IPY_MODEL_7e34ff2e2a0e4da8855fd817b0d91608"
            ],
            "layout": "IPY_MODEL_fd9a66847caa4ec4bf92c3aefe164626"
          }
        },
        "cb8816df49054497ac3288c2b0267a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89caeeb288746389d185cfde57fabe0",
            "placeholder": "​",
            "style": "IPY_MODEL_edf7fbf254944272b529a8a4a87b601a",
            "value": "Converting test set: 100%"
          }
        },
        "0975081b0cdc4b39b066d291a0eca0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2647216747b4682b0774e2febe071f7",
            "max": 492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34f5497100db4d789b1ce4ec4b012bc7",
            "value": 492
          }
        },
        "7e34ff2e2a0e4da8855fd817b0d91608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c320ef0b502465387e2b09dd3f9b44f",
            "placeholder": "​",
            "style": "IPY_MODEL_3c436ddf5dbe4a4a8ef983c488afb6dd",
            "value": " 492/492 [00:44&lt;00:00, 15.47it/s]"
          }
        },
        "fd9a66847caa4ec4bf92c3aefe164626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89caeeb288746389d185cfde57fabe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf7fbf254944272b529a8a4a87b601a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2647216747b4682b0774e2febe071f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34f5497100db4d789b1ce4ec4b012bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c320ef0b502465387e2b09dd3f9b44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c436ddf5dbe4a4a8ef983c488afb6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17d0ac95445848bb88f13a4d9f32f63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1610f81d34c44f43b955db88bf3d68dd",
              "IPY_MODEL_c44097cfe6f04f7ea85d95e9b4b86dcf",
              "IPY_MODEL_22caaf2bc33b4d8ba20efe835a2e5128"
            ],
            "layout": "IPY_MODEL_f429d1bf2d0249699a30386890ee8e97"
          }
        },
        "1610f81d34c44f43b955db88bf3d68dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c061618aea0b44939a88b8dac49b6e7e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d8db68ad654b898ddabdf7837f9970",
            "value": "Copying files: 100%"
          }
        },
        "c44097cfe6f04f7ea85d95e9b4b86dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f351e39394e54c1b9335453f3f7a6243",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5458e9754dd7483787a35ee9173b55d7",
            "value": 75
          }
        },
        "22caaf2bc33b4d8ba20efe835a2e5128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd74c110b5b94732b5b47c9a024c6b77",
            "placeholder": "​",
            "style": "IPY_MODEL_4132b87a94854a5897df58597b1c896f",
            "value": " 75/75 [00:00&lt;00:00, 121.27it/s]"
          }
        },
        "f429d1bf2d0249699a30386890ee8e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c061618aea0b44939a88b8dac49b6e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d8db68ad654b898ddabdf7837f9970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f351e39394e54c1b9335453f3f7a6243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5458e9754dd7483787a35ee9173b55d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd74c110b5b94732b5b47c9a024c6b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4132b87a94854a5897df58597b1c896f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ssh -p 20189 root@174.88.252.15 -L 8080:localhost:8080"
      ],
      "metadata": {
        "id": "AprNKTiWtcff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awJngONoC9xQ",
        "outputId": "d8939ff9-f1c5-45df-e1aa-55ed3418161a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DATA PREP"
      ],
      "metadata": {
        "id": "TnBvTBvPfrHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import shutil\n",
        "import logging\n",
        "import argparse\n",
        "import sys\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler(\"conversion.log\")\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(\"YOLO2VOC\")\n",
        "\n",
        "\n",
        "def validate_paths(yolo_path: str, output_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validate input and output paths\n",
        "\n",
        "    Args:\n",
        "        yolo_path: Path to YOLO format dataset\n",
        "        output_path: Path to output Pascal VOC format dataset\n",
        "\n",
        "    Returns:\n",
        "        bool: True if paths are valid, False otherwise\n",
        "    \"\"\"\n",
        "    # Check if YOLO dataset path exists\n",
        "    if not os.path.exists(yolo_path):\n",
        "        logger.error(f\"YOLO dataset path does not exist: {yolo_path}\")\n",
        "        return False\n",
        "\n",
        "    # Check if data.yaml exists\n",
        "    yaml_path = os.path.join(yolo_path, \"data.yaml\")\n",
        "    if not os.path.exists(yaml_path):\n",
        "        logger.error(f\"data.yaml not found at: {yaml_path}\")\n",
        "        return False\n",
        "\n",
        "    # Check if output path parent directory exists\n",
        "    output_parent = os.path.dirname(output_path)\n",
        "    if output_parent and not os.path.exists(output_parent):\n",
        "        logger.warning(f\"Output parent directory does not exist: {output_parent}\")\n",
        "        try:\n",
        "            os.makedirs(output_parent, exist_ok=True)\n",
        "            logger.info(f\"Created output parent directory: {output_parent}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to create output directory: {e}\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def create_xml_annotation(\n",
        "    image_path: str,\n",
        "    image_width: int,\n",
        "    image_height: int,\n",
        "    boxes: List[List[int]],\n",
        "    class_ids: List[int],\n",
        "    class_names: List[str]\n",
        ") -> ET.ElementTree:\n",
        "    \"\"\"\n",
        "    Create Pascal VOC format XML annotation file\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image\n",
        "        image_width: Width of the image\n",
        "        image_height: Height of the image\n",
        "        boxes: List of bounding boxes as [x_min, y_min, x_max, y_max]\n",
        "        class_ids: List of class IDs corresponding to each box\n",
        "        class_names: List of class names\n",
        "\n",
        "    Returns:\n",
        "        ET.ElementTree: XML tree for the annotation\n",
        "    \"\"\"\n",
        "    root = ET.Element(\"annotation\")\n",
        "\n",
        "    # Add basic image information\n",
        "    folder = ET.SubElement(root, \"folder\")\n",
        "    folder.text = str(Path(image_path).parent.name)\n",
        "\n",
        "    filename = ET.SubElement(root, \"filename\")\n",
        "    filename.text = str(Path(image_path).name)\n",
        "\n",
        "    path = ET.SubElement(root, \"path\")\n",
        "    path.text = str(image_path)\n",
        "\n",
        "    source = ET.SubElement(root, \"source\")\n",
        "    database = ET.SubElement(source, \"database\")\n",
        "    database.text = \"Unknown\"\n",
        "\n",
        "    # Add size information\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    width = ET.SubElement(size, \"width\")\n",
        "    width.text = str(image_width)\n",
        "    height = ET.SubElement(size, \"height\")\n",
        "    height.text = str(image_height)\n",
        "    depth = ET.SubElement(size, \"depth\")\n",
        "    depth.text = \"3\"  # Assuming RGB images\n",
        "\n",
        "    segmented = ET.SubElement(root, \"segmented\")\n",
        "    segmented.text = \"0\"\n",
        "\n",
        "    # Add object information for each bounding box\n",
        "    for box, class_id in zip(boxes, class_ids):\n",
        "        # Ensure class_id is within range\n",
        "        if class_id < 0 or class_id >= len(class_names):\n",
        "            logger.warning(f\"Invalid class_id {class_id}, skipping this box\")\n",
        "            continue\n",
        "\n",
        "        obj = ET.SubElement(root, \"object\")\n",
        "\n",
        "        name = ET.SubElement(obj, \"name\")\n",
        "        name.text = class_names[class_id]\n",
        "\n",
        "        pose = ET.SubElement(obj, \"pose\")\n",
        "        pose.text = \"Unspecified\"\n",
        "\n",
        "        truncated = ET.SubElement(obj, \"truncated\")\n",
        "        truncated.text = \"0\"\n",
        "\n",
        "        difficult = ET.SubElement(obj, \"difficult\")\n",
        "        difficult.text = \"0\"\n",
        "\n",
        "        bndbox = ET.SubElement(obj, \"bndbox\")\n",
        "\n",
        "        xmin = ET.SubElement(bndbox, \"xmin\")\n",
        "        xmin.text = str(int(box[0]))\n",
        "\n",
        "        ymin = ET.SubElement(bndbox, \"ymin\")\n",
        "        ymin.text = str(int(box[1]))\n",
        "\n",
        "        xmax = ET.SubElement(bndbox, \"xmax\")\n",
        "        xmax.text = str(int(box[2]))\n",
        "\n",
        "        ymax = ET.SubElement(bndbox, \"ymax\")\n",
        "        ymax.text = str(int(box[3]))\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    return tree\n",
        "\n",
        "\n",
        "def process_image(\n",
        "    img_path: str,\n",
        "    split: str,\n",
        "    yolo_dataset_path: str,\n",
        "    output_path: str,\n",
        "    class_names: List[str],\n",
        "    overwrite: bool = False\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Process a single image and convert its annotations\n",
        "\n",
        "    Args:\n",
        "        img_path: Path to the image\n",
        "        split: Dataset split (train, val, test)\n",
        "        yolo_dataset_path: Path to YOLO format dataset\n",
        "        output_path: Path to output Pascal VOC format dataset\n",
        "        class_names: List of class names\n",
        "        overwrite: Whether to overwrite existing files\n",
        "\n",
        "    Returns:\n",
        "        str: Image name if successfully processed, None otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img_filename = os.path.basename(img_path)\n",
        "        img_name, img_ext = os.path.splitext(img_filename)\n",
        "        dest_img_path = os.path.join(output_path, split, 'JPEGImages', img_filename)\n",
        "        xml_path = os.path.join(output_path, split, 'Annotations', f\"{img_name}.xml\")\n",
        "\n",
        "        # Skip if files already exist and overwrite is False\n",
        "        if not overwrite and os.path.exists(dest_img_path) and os.path.exists(xml_path):\n",
        "            return img_name\n",
        "\n",
        "        # Read the image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            logger.warning(f\"Could not read image {img_path}, skipping...\")\n",
        "            return None\n",
        "\n",
        "        # Copy the image file\n",
        "        try:\n",
        "            shutil.copy(img_path, dest_img_path)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error copying image file {img_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        boxes = []\n",
        "        class_ids = []\n",
        "\n",
        "        # Process the label file\n",
        "        label_path = os.path.join(yolo_dataset_path, split, \"labels\", f\"{img_name}.txt\")\n",
        "        if os.path.exists(label_path):\n",
        "            try:\n",
        "                with open(label_path, 'r') as f:\n",
        "                    for line in f:\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) >= 5:\n",
        "                            try:\n",
        "                                class_id = int(float(parts[0]))\n",
        "                                x_center = float(parts[1])\n",
        "                                y_center = float(parts[2])\n",
        "                                width = float(parts[3])\n",
        "                                height = float(parts[4])\n",
        "\n",
        "                                # Convert YOLO to VOC format\n",
        "                                x_min = int((x_center - width/2) * img_width)\n",
        "                                y_min = int((y_center - height/2) * img_height)\n",
        "                                x_max = int((x_center + width/2) * img_width)\n",
        "                                y_max = int((y_center + height/2) * img_height)\n",
        "\n",
        "                                # Ensure coordinates are within image bounds\n",
        "                                x_min = max(0, x_min)\n",
        "                                y_min = max(0, y_min)\n",
        "                                x_max = min(img_width, x_max)\n",
        "                                y_max = min(img_height, y_max)\n",
        "\n",
        "                                # Ensure valid box dimensions\n",
        "                                if x_max <= x_min:\n",
        "                                    x_max = min(x_min + 1, img_width)\n",
        "                                if y_max <= y_min:\n",
        "                                    y_max = min(y_min + 1, img_height)\n",
        "\n",
        "                                # Skip boxes with invalid dimensions\n",
        "                                if x_max <= x_min or y_max <= y_min:\n",
        "                                    logger.warning(f\"Invalid box dimensions in {label_path}: ({x_min}, {y_min}, {x_max}, {y_max})\")\n",
        "                                    continue\n",
        "\n",
        "                                boxes.append([x_min, y_min, x_max, y_max])\n",
        "                                class_ids.append(class_id)\n",
        "                            except ValueError as e:\n",
        "                                logger.warning(f\"Error parsing line in {label_path}: {line.strip()} - {e}\")\n",
        "                                continue\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error reading label file {label_path}: {e}\")\n",
        "\n",
        "        # Create and write XML annotation\n",
        "        xml_tree = create_xml_annotation(dest_img_path, img_width, img_height, boxes, class_ids, class_names)\n",
        "        try:\n",
        "            xml_tree.write(xml_path)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error writing XML file {xml_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "        return img_name\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing image {img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def convert_yolo_to_pascal_voc(\n",
        "    yolo_dataset_path: str,\n",
        "    output_path: str,\n",
        "    splits: Tuple[str, ...] = ('train', 'valid', 'test'),\n",
        "    overwrite: bool = False,\n",
        "    num_workers: int = 4\n",
        "):\n",
        "    \"\"\"\n",
        "    Convert YOLO format dataset to Pascal VOC format for SSD training\n",
        "\n",
        "    Args:\n",
        "        yolo_dataset_path: Path to YOLO format dataset with data.yaml file\n",
        "        output_path: Path to output Pascal VOC format dataset\n",
        "        splits: Dataset splits to convert\n",
        "        overwrite: Whether to overwrite existing files\n",
        "        num_workers: Number of worker threads for parallel processing\n",
        "    \"\"\"\n",
        "    # Validate paths\n",
        "    if not validate_paths(yolo_dataset_path, output_path):\n",
        "        logger.error(\"Path validation failed. Aborting conversion.\")\n",
        "        return\n",
        "\n",
        "    # Load class names from data.yaml\n",
        "    try:\n",
        "        with open(os.path.join(yolo_dataset_path, \"data.yaml\"), 'r') as f:\n",
        "            yaml_data = yaml.safe_load(f)\n",
        "            if not yaml_data or 'names' not in yaml_data:\n",
        "                logger.error(\"Invalid data.yaml file: missing 'names' field\")\n",
        "                return\n",
        "\n",
        "            class_names = yaml_data['names']\n",
        "            logger.info(f\"Classes: {class_names}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading data.yaml: {e}\")\n",
        "        return\n",
        "\n",
        "    # Create output directories\n",
        "    try:\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "        for split in splits:\n",
        "            os.makedirs(os.path.join(output_path, split, 'JPEGImages'), exist_ok=True)\n",
        "            os.makedirs(os.path.join(output_path, split, 'Annotations'), exist_ok=True)\n",
        "            os.makedirs(os.path.join(output_path, split, 'ImageSets', 'Main'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, 'ImageSets', 'Main'), exist_ok=True)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating output directories: {e}\")\n",
        "        return\n",
        "\n",
        "    missing_splits = []\n",
        "\n",
        "    # Process each split\n",
        "    for split in splits:\n",
        "        logger.info(f\"\\nProcessing {split} split...\")\n",
        "        img_dir = os.path.join(yolo_dataset_path, split, \"images\")\n",
        "        if not os.path.exists(img_dir):\n",
        "            logger.warning(f\"{img_dir} does not exist, marking as missing...\")\n",
        "            missing_splits.append(split)\n",
        "            continue\n",
        "\n",
        "        # Find all images with supported extensions\n",
        "        img_paths = glob.glob(os.path.join(img_dir, \"*.jpg\")) + \\\n",
        "                    glob.glob(os.path.join(img_dir, \"*.png\")) + \\\n",
        "                    glob.glob(os.path.join(img_dir, \"*.jpeg\"))\n",
        "\n",
        "        if not img_paths:\n",
        "            logger.warning(f\"No images found in {img_dir}, marking as missing...\")\n",
        "            missing_splits.append(split)\n",
        "            continue\n",
        "\n",
        "        logger.info(f\"Found {len(img_paths)} images in {split} split\")\n",
        "\n",
        "        # Process images in parallel\n",
        "        successful_images = []\n",
        "\n",
        "        # Create process pool\n",
        "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "            # Create a progress bar\n",
        "            results = list(tqdm(\n",
        "                executor.map(\n",
        "                    lambda img_path: process_image(\n",
        "                        img_path, split, yolo_dataset_path, output_path, class_names, overwrite\n",
        "                    ),\n",
        "                    img_paths\n",
        "                ),\n",
        "                total=len(img_paths),\n",
        "                desc=f\"Converting {split} set\"\n",
        "            ))\n",
        "\n",
        "            # Filter out None results (failed conversions)\n",
        "            successful_images = [img_name for img_name in results if img_name]\n",
        "\n",
        "        # Write the image list file\n",
        "        if successful_images:\n",
        "            try:\n",
        "                with open(os.path.join(output_path, split, 'ImageSets', 'Main', f\"{split}.txt\"), 'w') as f:\n",
        "                    for img_name in successful_images:\n",
        "                        f.write(f\"{img_name}\\n\")\n",
        "                logger.info(f\"Successfully processed {len(successful_images)} images for {split} split\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error writing image list file for {split} split: {e}\")\n",
        "        else:\n",
        "            logger.warning(f\"No images processed for {split} split\")\n",
        "\n",
        "    # Report missing splits\n",
        "    if missing_splits:\n",
        "        logger.warning(f\"\\nThe following splits were missing or empty: {', '.join(missing_splits)}\")\n",
        "\n",
        "    # Create labelmap.txt\n",
        "    try:\n",
        "        with open(os.path.join(output_path, \"labelmap.txt\"), 'w') as f:\n",
        "            for i, class_name in enumerate(class_names):\n",
        "                f.write(f\"{i} {class_name}\\n\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error writing labelmap.txt: {e}\")\n",
        "\n",
        "    # Create trainval.txt (combined train+val list)\n",
        "    if 'train' not in missing_splits and 'val' not in missing_splits:\n",
        "        try:\n",
        "            train_list = []\n",
        "            val_list = []\n",
        "            train_file = os.path.join(output_path, 'train', 'ImageSets', 'Main', 'train.txt')\n",
        "            val_file = os.path.join(output_path, 'val', 'ImageSets', 'Main', 'val.txt')\n",
        "\n",
        "            if os.path.exists(train_file):\n",
        "                with open(train_file, 'r') as f:\n",
        "                    train_list = [line.strip() for line in f]\n",
        "            if os.path.exists(val_file):\n",
        "                with open(val_file, 'r') as f:\n",
        "                    val_list = [line.strip() for line in f]\n",
        "\n",
        "            with open(os.path.join(output_path, 'ImageSets', 'Main', 'trainval.txt'), 'w') as f:\n",
        "                for name in train_list + val_list:\n",
        "                    f.write(f\"{name}\\n\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating trainval.txt: {e}\")\n",
        "\n",
        "    # Print summary\n",
        "    logger.info(\"\\nConversion completed successfully!\")\n",
        "    logger.info(f\"Pascal VOC format dataset created at: {output_path}\")\n",
        "    logger.info(\"Directory structure:\")\n",
        "    for split in [s for s in splits if s not in missing_splits]:\n",
        "        img_count = len(glob.glob(os.path.join(output_path, split, 'JPEGImages', '*')))\n",
        "        xml_count = len(glob.glob(os.path.join(output_path, split, 'Annotations', '*.xml')))\n",
        "        logger.info(f\"  - {split}/\")\n",
        "        logger.info(f\"      - JPEGImages/ (contains {img_count} images)\")\n",
        "        logger.info(f\"      - Annotations/ (contains {xml_count} XML files)\")\n",
        "        logger.info(f\"      - ImageSets/Main/{split}.txt (contains {img_count} entries)\")\n",
        "    logger.info(f\"  - labelmap.txt (class mapping file)\")\n",
        "    if 'train' not in missing_splits and 'val' not in missing_splits:\n",
        "        logger.info(f\"  - ImageSets/Main/trainval.txt (combined train+val list)\")\n",
        "\n",
        "\n",
        "# For use in a Jupyter/Colab notebook - avoids argparse conflicts\n",
        "def run_conversion(\n",
        "    yolo_path='/content/drive/MyDrive/DATASETS/MANGO/adjusted_dataset_20250305_203807',\n",
        "    output_path='/content/ssd_dataset',\n",
        "    splits='train,valid,test',\n",
        "    overwrite=False,\n",
        "    num_workers=4,\n",
        "    log_level='INFO'\n",
        "):\n",
        "    \"\"\"\n",
        "    Run the YOLO to Pascal VOC conversion with specified parameters.\n",
        "    This function is designed to be called directly in a Jupyter notebook.\n",
        "\n",
        "    Args:\n",
        "        yolo_path: Path to YOLO format dataset\n",
        "        output_path: Path to output Pascal VOC format dataset\n",
        "        splits: Comma-separated list of dataset splits to convert\n",
        "        overwrite: Whether to overwrite existing files\n",
        "        num_workers: Number of worker threads for parallel processing\n",
        "        log_level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
        "    \"\"\"\n",
        "    # Set log level\n",
        "    logger.setLevel(getattr(logging, log_level))\n",
        "\n",
        "    # Log the parameters\n",
        "    logger.info(\"Starting conversion with parameters:\")\n",
        "    logger.info(f\"  YOLO dataset path: {yolo_path}\")\n",
        "    logger.info(f\"  Output path: {output_path}\")\n",
        "    logger.info(f\"  Splits: {splits}\")\n",
        "    logger.info(f\"  Overwrite: {overwrite}\")\n",
        "    logger.info(f\"  Num workers: {num_workers}\")\n",
        "\n",
        "    try:\n",
        "        # Split the splits string into a tuple\n",
        "        splits_tuple = tuple(splits.split(','))\n",
        "\n",
        "        # Run the conversion\n",
        "        convert_yolo_to_pascal_voc(\n",
        "            yolo_path,\n",
        "            output_path,\n",
        "            splits_tuple,\n",
        "            overwrite,\n",
        "            num_workers\n",
        "        )\n",
        "        logger.info(\"\\n=== SSD DATASET PREPARATION COMPLETE ===\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.critical(f\"Unhandled error during conversion: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "\n",
        "# This allows the script to be used both as a module and as a standalone script\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Jupyter/IPython environment\n",
        "    try:\n",
        "        # This will raise NameError if not in IPython\n",
        "        if 'IPython' in sys.modules:\n",
        "            # Set default parameters for direct execution in notebook\n",
        "            print(\"Running in Jupyter/Colab environment. Use the run_conversion function instead of command-line arguments.\")\n",
        "            print(\"Example: run_conversion(yolo_path='/path/to/yolo', output_path='/path/to/output')\")\n",
        "        else:\n",
        "            # Parse command line arguments for standalone script usage\n",
        "            parser = argparse.ArgumentParser(description='Convert YOLO format dataset to Pascal VOC format')\n",
        "            parser.add_argument('--yolo-path', type=str, default='/content/drive/MyDrive/DATASETS/MANGO/adjusted_dataset_20250305_203807',\n",
        "                                help='Path to YOLO format dataset with data.yaml file')\n",
        "            parser.add_argument('--output-path', type=str, default='/content/ssd_dataset',\n",
        "                                help='Path to output Pascal VOC format dataset')\n",
        "            parser.add_argument('--splits', type=str, default='train,valid,test',\n",
        "                                help='Dataset splits to convert (comma-separated)')\n",
        "            parser.add_argument('--overwrite', action='store_true',\n",
        "                                help='Overwrite existing files')\n",
        "            parser.add_argument('--num-workers', type=int, default=4,\n",
        "                                help='Number of worker threads for parallel processing')\n",
        "            parser.add_argument('--log-level', type=str, default='INFO',\n",
        "                                choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],\n",
        "                                help='Logging level')\n",
        "\n",
        "            args = parser.parse_args()\n",
        "\n",
        "            # Run with command line arguments\n",
        "            run_conversion(\n",
        "                args.yolo_path,\n",
        "                args.output_path,\n",
        "                args.splits,\n",
        "                args.overwrite,\n",
        "                args.num_workers,\n",
        "                args.log_level\n",
        "            )\n",
        "    except NameError:\n",
        "        # Not in IPython, but don't want to use argparse\n",
        "        print(\"Running in script mode without argument parsing.\")\n",
        "        # Run with default arguments\n",
        "        run_conversion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNBqOfyIDM5z",
        "outputId": "7f950390-f98f-4210-fe8f-93eafdea6203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Jupyter/Colab environment. Use the run_conversion function instead of command-line arguments.\n",
            "Example: run_conversion(yolo_path='/path/to/yolo', output_path='/path/to/output')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_conversion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808,
          "referenced_widgets": [
            "05c7145a930944da9277478be795fa61",
            "b3fcbfcd039a4e9f8140273d7d3169e3",
            "9ec58dd843f54ee08bdb77eb199a3adb",
            "37f6c39c58ac4d3c97c7911453917c3a",
            "1646211ff0d246ccbc1f7c3d31a132bb",
            "02e1467ea988476e94fce2f3bdb367fd",
            "5644c4c02a27429981f7c4af2292105e",
            "591d8cf6c40d40e68013eb85dfaa8dbe",
            "14b2fdfa7ef34725a44e32100f721805",
            "8ae9739835b141d39536960a94416a5c",
            "8f475c7ece12483b834dfede8ca8d3ec",
            "a3be1318ccba4823b20bbf781f7b374d",
            "b763d91963d045b7b54ebe9b2211433c",
            "94a8a2ff276d48ea9dcfc90e11cc9fb0",
            "eee139eb61f6499c8767b447abfb6d42",
            "d43ca2cb8bb64a88a40b526fc9730bb9",
            "0b13e902a0f04d509481cb6bad2cdf7d",
            "366e751deaaf4b6c80d939b8ee41d801",
            "e3d8082cee9e46bd9f960baa5e3a55aa",
            "58c3cea6be8b4b3fa29c18166585f67a",
            "7018eea1d0d841ef879bbb57aa7569b4",
            "a8c481313b654145a3100a5cf1b8809f",
            "219bdc14fd56415ea3ca07881ac1f4e1",
            "cb8816df49054497ac3288c2b0267a5b",
            "0975081b0cdc4b39b066d291a0eca0fe",
            "7e34ff2e2a0e4da8855fd817b0d91608",
            "fd9a66847caa4ec4bf92c3aefe164626",
            "d89caeeb288746389d185cfde57fabe0",
            "edf7fbf254944272b529a8a4a87b601a",
            "e2647216747b4682b0774e2febe071f7",
            "34f5497100db4d789b1ce4ec4b012bc7",
            "8c320ef0b502465387e2b09dd3f9b44f",
            "3c436ddf5dbe4a4a8ef983c488afb6dd"
          ]
        },
        "id": "Ia-eI-YzGnvl",
        "outputId": "783cccbd-a423-4e48-e0b8-4c03a4eb7174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:YOLO2VOC:Starting conversion with parameters:\n",
            "INFO:YOLO2VOC:  YOLO dataset path: /content/drive/MyDrive/DATASETS/MANGO/adjusted_dataset_20250305_203807\n",
            "INFO:YOLO2VOC:  Output path: /content/ssd_dataset\n",
            "INFO:YOLO2VOC:  Splits: train,valid,test\n",
            "INFO:YOLO2VOC:  Overwrite: False\n",
            "INFO:YOLO2VOC:  Num workers: 4\n",
            "INFO:YOLO2VOC:Classes: ['Anthracnose', 'Bacterial-Black-spot', 'Damaged-mango', 'Fruitly', 'Mechanical-damage', 'Others']\n",
            "INFO:YOLO2VOC:\n",
            "Processing train split...\n",
            "INFO:YOLO2VOC:Found 2306 images in train split\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting train set:   0%|          | 0/2306 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05c7145a930944da9277478be795fa61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:YOLO2VOC:Successfully processed 2306 images for train split\n",
            "INFO:YOLO2VOC:\n",
            "Processing valid split...\n",
            "INFO:YOLO2VOC:Found 493 images in valid split\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting valid set:   0%|          | 0/493 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3be1318ccba4823b20bbf781f7b374d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:YOLO2VOC:Successfully processed 493 images for valid split\n",
            "INFO:YOLO2VOC:\n",
            "Processing test split...\n",
            "INFO:YOLO2VOC:Found 492 images in test split\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting test set:   0%|          | 0/492 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219bdc14fd56415ea3ca07881ac1f4e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:YOLO2VOC:Successfully processed 492 images for test split\n",
            "INFO:YOLO2VOC:\n",
            "Conversion completed successfully!\n",
            "INFO:YOLO2VOC:Pascal VOC format dataset created at: /content/ssd_dataset\n",
            "INFO:YOLO2VOC:Directory structure:\n",
            "INFO:YOLO2VOC:  - train/\n",
            "INFO:YOLO2VOC:      - JPEGImages/ (contains 2306 images)\n",
            "INFO:YOLO2VOC:      - Annotations/ (contains 2306 XML files)\n",
            "INFO:YOLO2VOC:      - ImageSets/Main/train.txt (contains 2306 entries)\n",
            "INFO:YOLO2VOC:  - valid/\n",
            "INFO:YOLO2VOC:      - JPEGImages/ (contains 493 images)\n",
            "INFO:YOLO2VOC:      - Annotations/ (contains 493 XML files)\n",
            "INFO:YOLO2VOC:      - ImageSets/Main/valid.txt (contains 493 entries)\n",
            "INFO:YOLO2VOC:  - test/\n",
            "INFO:YOLO2VOC:      - JPEGImages/ (contains 492 images)\n",
            "INFO:YOLO2VOC:      - Annotations/ (contains 492 XML files)\n",
            "INFO:YOLO2VOC:      - ImageSets/Main/test.txt (contains 492 entries)\n",
            "INFO:YOLO2VOC:  - labelmap.txt (class mapping file)\n",
            "INFO:YOLO2VOC:  - ImageSets/Main/trainval.txt (combined train+val list)\n",
            "INFO:YOLO2VOC:\n",
            "=== SSD DATASET PREPARATION COMPLETE ===\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import argparse\n",
        "import shutil\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "from torchvision.models.detection.ssd import SSDHead\n",
        "from torchvision.models.detection.anchor_utils import DefaultBoxGenerator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.ops import box_iou\n",
        "import datetime\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab environment\")\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running in local environment (not Colab)\")\n",
        "\n",
        "# Set device based on availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ===========================\n",
        "# DATASET CLASS FOR PASCAL VOC\n",
        "# ===========================\n",
        "\n",
        "class PascalVOCDataset(Dataset):\n",
        "    \"\"\"Dataset for Pascal VOC format data\"\"\"\n",
        "\n",
        "    def __init__(self, root, split='train', transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root (string): Root directory of the VOC Dataset.\n",
        "            split (string): 'train', 'val', or 'test'\n",
        "            transforms (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Load class names from labelmap\n",
        "        self.classes = self._load_class_names()\n",
        "        self.num_classes = len(self.classes)\n",
        "        print(f\"Found {self.num_classes} classes: {self.classes}\")\n",
        "\n",
        "        # Map class names to indices\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Load image IDs\n",
        "        split_file = os.path.join(root, split, 'ImageSets', 'Main', f'{split}.txt')\n",
        "        if not os.path.exists(split_file):\n",
        "            raise FileNotFoundError(f\"Split file not found: {split_file}\")\n",
        "\n",
        "        with open(split_file, 'r') as f:\n",
        "            self.ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        print(f\"Loaded {len(self.ids)} images for {split} split\")\n",
        "\n",
        "    def _load_class_names(self):\n",
        "        \"\"\"Load class names from labelmap.txt file\"\"\"\n",
        "        labelmap_file = os.path.join(self.root, 'labelmap.txt')\n",
        "        if not os.path.exists(labelmap_file):\n",
        "            raise FileNotFoundError(f\"Labelmap file not found: {labelmap_file}\")\n",
        "\n",
        "        classes = []\n",
        "        with open(labelmap_file, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 2:\n",
        "                    # Format is 'index class_name'\n",
        "                    classes.append(' '.join(parts[1:]))  # Join with spaces in case class name has spaces\n",
        "\n",
        "        # Add background class as index 0\n",
        "        return ['__background__'] + classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.root, self.split, 'JPEGImages', f'{img_id}.jpg')\n",
        "        if not os.path.exists(img_path):\n",
        "            # Try PNG if JPG not found\n",
        "            img_path = os.path.join(self.root, self.split, 'JPEGImages', f'{img_id}.png')\n",
        "            if not os.path.exists(img_path):\n",
        "                raise FileNotFoundError(f\"Image not found: {img_id}\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Load annotations\n",
        "        anno_path = os.path.join(self.root, self.split, 'Annotations', f'{img_id}.xml')\n",
        "        target = self._parse_voc_xml(ET.parse(anno_path).getroot(), img_id=idx)  # Pass idx as a unique identifier\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def _parse_voc_xml(self, node, img_id):\n",
        "        \"\"\"Parse Pascal VOC XML annotation file\"\"\"\n",
        "        target = {}\n",
        "\n",
        "        # Get image size\n",
        "        size = node.find('size')\n",
        "        width = int(size.find('width').text)\n",
        "        height = int(size.find('height').text)\n",
        "\n",
        "        # Initialize empty lists for boxes, labels\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        # Process each object annotation\n",
        "        for obj in node.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "\n",
        "            if name not in self.class_to_idx:\n",
        "                print(f\"Warning: Class '{name}' not in class map, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Get bounding box coordinates\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = float(bbox.find('xmin').text)\n",
        "            ymin = float(bbox.find('ymin').text)\n",
        "            xmax = float(bbox.find('xmax').text)\n",
        "            ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "            # Validate box coordinates\n",
        "            if xmin >= xmax or ymin >= ymax:\n",
        "                print(f\"Warning: Invalid box coordinates {xmin, ymin, xmax, ymax} in {node.find('filename').text}, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Convert class name to index (add 1 since 0 is background)\n",
        "            label = self.class_to_idx[name]\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label)\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        if boxes:\n",
        "            target[\"boxes\"] = torch.tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            # Create empty tensors if no valid boxes\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
        "\n",
        "        # Use a simple integer as image_id instead of trying to parse the filename\n",
        "        target[\"image_id\"] = torch.tensor([img_id], dtype=torch.int64)\n",
        "\n",
        "        # Calculate box areas\n",
        "        target[\"area\"] = (target[\"boxes\"][:, 3] - target[\"boxes\"][:, 1]) * (target[\"boxes\"][:, 2] - target[\"boxes\"][:, 0])\n",
        "        target[\"iscrowd\"] = torch.zeros((len(target[\"boxes\"])), dtype=torch.int64)\n",
        "\n",
        "        return target\n",
        "\n",
        "# ============================\n",
        "# TRANSFORMS AND DATA LOADING\n",
        "# ============================\n",
        "\n",
        "class Compose:\n",
        "    \"\"\"Composes transforms for object detection\"\"\"\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "class ToTensor:\n",
        "    \"\"\"Convert PIL image to tensor\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        return image, target\n",
        "\n",
        "class Resize:\n",
        "    \"\"\"Resize image and adjust boxes\"\"\"\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Get original image size\n",
        "        width, height = image.size\n",
        "\n",
        "        # Resize image\n",
        "        image = transforms.Resize((self.size, self.size))(image)\n",
        "\n",
        "        # Adjust bounding boxes\n",
        "        if target[\"boxes\"].shape[0] > 0:\n",
        "            # Scale boxes\n",
        "            x_scale = self.size / width\n",
        "            y_scale = self.size / height\n",
        "\n",
        "            boxes = target[\"boxes\"].clone()\n",
        "            boxes[:, 0] *= x_scale  # xmin\n",
        "            boxes[:, 1] *= y_scale  # ymin\n",
        "            boxes[:, 2] *= x_scale  # xmax\n",
        "            boxes[:, 3] *= y_scale  # ymax\n",
        "\n",
        "            target[\"boxes\"] = boxes\n",
        "\n",
        "            # Update areas\n",
        "            target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        return image, target\n",
        "\n",
        "# Create data transforms (with NO augmentation)\n",
        "def get_transform(train, img_size=300):\n",
        "    transforms = [\n",
        "        Resize(img_size),\n",
        "        ToTensor()\n",
        "    ]\n",
        "\n",
        "    return Compose(transforms)\n",
        "\n",
        "# Custom collate function for batching\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# ============================\n",
        "# UTILITY CLASSES\n",
        "# ============================\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values\"\"\"\n",
        "    def __init__(self, window_size=20):\n",
        "        self.window_size = window_size\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.values = []\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, value):\n",
        "        self.values.append(value)\n",
        "        if len(self.values) > self.window_size:\n",
        "            self.values.pop(0)\n",
        "        self.total += value\n",
        "        self.count += 1\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        return np.median(self.values).item() if self.values else 0.0\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        return np.mean(self.values).item() if self.values else 0.0\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count if self.count > 0 else 0.0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.global_avg:.4f} ({self.avg:.4f})\"\n",
        "\n",
        "class MetricLogger:\n",
        "    \"\"\"Utility class for logging metrics during training and evaluation\"\"\"\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = {}\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if k not in self.meters:\n",
        "                self.meters[k] = SmoothedValue()\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {meter}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if header is not None:\n",
        "            print(header)\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue()\n",
        "\n",
        "        # FIX: Use string formatting that doesn't rely on format specifiers\n",
        "        space_fmt = len(str(len(iterable)))\n",
        "\n",
        "        for obj in iterable:\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                # FIX: Use a simpler string format with manual padding\n",
        "                print(\n",
        "                    f\"{header} [{i:{space_fmt}d}/{len(iterable)}]  \"\n",
        "                    f\"eta: {eta_string}  \"\n",
        "                    f\"time: {iter_time.global_avg:.4f}  \"\n",
        "                    f\"{self}\"\n",
        "                )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "# ============================\n",
        "# MODEL DEFINITION\n",
        "# ============================\n",
        "\n",
        "def create_ssd_model(num_classes, pretrained=True):\n",
        "    \"\"\"Create an SSD300 model with a VGG16 backbone\"\"\"\n",
        "    # Create SSD model with pretrained VGG backbone if requested\n",
        "    weights = None\n",
        "    if pretrained:\n",
        "        try:\n",
        "            # For newer PyTorch versions\n",
        "            from torchvision.models.detection.ssd import SSD300_VGG16_Weights\n",
        "            weights = SSD300_VGG16_Weights.DEFAULT\n",
        "        except ImportError:\n",
        "            # For older PyTorch versions\n",
        "            weights = None\n",
        "            # Will use pretrained=True instead\n",
        "\n",
        "    # Create the model\n",
        "    if weights is not None:\n",
        "        model = ssd300_vgg16(weights=weights)\n",
        "    else:\n",
        "        model = ssd300_vgg16(pretrained=pretrained)\n",
        "\n",
        "    # Replace the classifier for our number of classes\n",
        "    # For models created with newer PyTorch versions\n",
        "    if hasattr(model, 'head'):\n",
        "        # Find the number of anchors and channels\n",
        "        num_anchors = model.anchor_generator.num_anchors_per_location()\n",
        "        if hasattr(model.backbone, 'out_channels'):\n",
        "            in_channels = model.backbone.out_channels\n",
        "        else:\n",
        "            # For newer versions where out_channels is not directly accessible\n",
        "            # Typical values for SSD300 with VGG16\n",
        "            in_channels = [512, 1024, 512, 256, 256, 256]\n",
        "\n",
        "        # Create new SSD head\n",
        "        model.head = SSDHead(in_channels, num_anchors, num_classes)\n",
        "    else:\n",
        "        # For older versions\n",
        "        # Find out the number of classes in the pre-trained model\n",
        "        old_num_classes = model.roi_heads.box_predictor.cls_score.out_features\n",
        "\n",
        "        # Replace only if our number of classes is different\n",
        "        if old_num_classes != num_classes:\n",
        "            # Create a new head with the correct number of classes\n",
        "            in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "            from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "            model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    print(f\"Created SSD300 model with {'pretrained' if pretrained else 'random'} VGG16 backbone\")\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# MAIN EXECUTION\n",
        "# ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Parse arguments\n",
        "    parser = argparse.ArgumentParser(description='Train SSD model for mango disease detection (NO AUGMENTATION)')\n",
        "    parser.add_argument('--voc-path', type=str, default='/content/ssd_dataset',\n",
        "                        help='Path to Pascal VOC format dataset')\n",
        "    parser.add_argument('--output-dir', type=str, default='/content/ssd_model',\n",
        "                        help='Path to save model outputs')\n",
        "    parser.add_argument('--gdrive-dir', type=str, default='/content/drive/MyDrive/MANGO/PROJECT/mango_ssd',\n",
        "                        help='Google Drive directory to save model (for Colab users)')\n",
        "    parser.add_argument('--epochs', type=int, default=50,\n",
        "                        help='Number of epochs for training')\n",
        "    parser.add_argument('--batch-size', type=int, default=8,\n",
        "                        help='Batch size for training')\n",
        "    parser.add_argument('--lr', type=float, default=0.001,\n",
        "                        help='Learning rate')\n",
        "    parser.add_argument('--pretrained', action='store_true',\n",
        "                        help='Use pretrained VGG backbone')\n",
        "    parser.add_argument('--image-size', type=int, default=300,\n",
        "                        help='Image size for SSD300')\n",
        "    parser.add_argument('--eval-freq', type=int, default=5,\n",
        "                        help='Frequency of evaluation during training')\n",
        "    parser.add_argument('--save-freq', type=int, default=10,\n",
        "                        help='Frequency of saving model checkpoints')\n",
        "\n",
        "    # For IPython/Jupyter/Colab\n",
        "    if 'ipykernel' in sys.modules or 'IPython' in sys.modules or IN_COLAB:\n",
        "        # Default arguments for notebook mode\n",
        "        args = parser.parse_args([])\n",
        "        args.pretrained = True  # Default to using pretrained backbone in Colab\n",
        "        print(\"Running in notebook/Colab mode with default arguments\")\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "    if IN_COLAB and args.gdrive_dir:\n",
        "        os.makedirs(args.gdrive_dir, exist_ok=True)\n",
        "\n",
        "    # Verify dataset existence\n",
        "    print(\"\\n==== VERIFYING DATASET ====\")\n",
        "    if not os.path.exists(args.voc_path) or not os.path.exists(os.path.join(args.voc_path, 'labelmap.txt')):\n",
        "        print(f\"Error: Pascal VOC dataset not found at {args.voc_path}\")\n",
        "        print(\"Please ensure you have converted your YOLO dataset to Pascal VOC format.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Check if training split exists\n",
        "    train_dir = os.path.join(args.voc_path, 'train')\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(f\"Error: Training directory not found at {train_dir}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Check if validation split exists\n",
        "    valid_found = False\n",
        "    for val_name in ['val', 'valid']:\n",
        "        val_dir = os.path.join(args.voc_path, val_name)\n",
        "        if os.path.exists(val_dir):\n",
        "            valid_found = True\n",
        "            break\n",
        "\n",
        "    if not valid_found:\n",
        "        print(f\"Error: Validation directory not found at {args.voc_path}/val or {args.voc_path}/valid\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"Dataset verification completed successfully.\")\n",
        "\n",
        "    # Train the model\n",
        "    try:\n",
        "        model = train_ssd_model(args)\n",
        "        print(\"SSD model training completed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SSD model training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"\\n==== ALL STEPS COMPLETED SUCCESSFULLY ====\")\n",
        "    best_model_path = os.path.join(args.output_dir, 'best_model.pth')\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"SSD model trained and saved to {best_model_path}\")\n",
        "        if IN_COLAB and args.gdrive_dir:\n",
        "            gdrive_model_path = os.path.join(args.gdrive_dir, 'best_model.pth')\n",
        "            if os.path.exists(gdrive_model_path):\n",
        "                print(f\"Model also backed up to Google Drive at {gdrive_model_path}\")\n",
        "    else:\n",
        "        print(\"Warning: Best model file not found. Check logs for errors during training.\")\n",
        "\n",
        "# ============================\n",
        "# TRAINING FUNCTIONS\n",
        "# ============================\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f'Epoch: [{epoch}]'\n",
        "\n",
        "    for i, (images, targets) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        # Calculate total loss\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        metric_logger.update(loss=losses.item())\n",
        "\n",
        "        # Print loss values individually\n",
        "        for k, v in loss_dict.items():\n",
        "            metric_logger.update(**{k: v.item()})\n",
        "\n",
        "    return metric_logger\n",
        "\n",
        "def evaluate(model, data_loader, device, epoch):\n",
        "    \"\"\"Evaluate model on validation dataset\"\"\"\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f'Validation: [{epoch}]'\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in metric_logger.log_every(data_loader, 10, header):\n",
        "            images = list(img.to(device) for img in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Store predictions and targets for mAP calculation\n",
        "            all_predictions.extend(outputs)\n",
        "            all_targets.extend(targets)\n",
        "\n",
        "    # Calculate mAP\n",
        "    mAP = calculate_mAP(all_predictions, all_targets)\n",
        "    print(f\"Epoch {epoch}: mAP = {mAP:.4f}\")\n",
        "\n",
        "    return mAP\n",
        "\n",
        "def calculate_mAP(predictions, targets, iou_threshold=0.5):\n",
        "    \"\"\"Calculate mean Average Precision\"\"\"\n",
        "    # This is a simplified mAP calculation\n",
        "    # For production use, consider using torchvision's detection evaluation utils\n",
        "\n",
        "    # Initialize APs for each class\n",
        "    n_classes = max([max(target['labels']).item() for target in targets if len(target['labels']) > 0], default=0) + 1\n",
        "    average_precisions = [[] for _ in range(n_classes)]\n",
        "\n",
        "    # For each image in the batch\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # For each class\n",
        "        for cls in range(1, n_classes):  # Skip background class (0)\n",
        "            # Get predictions and targets for this class\n",
        "            mask_pred = pred_labels == cls\n",
        "            mask_target = target_labels == cls\n",
        "\n",
        "            if not mask_target.any():\n",
        "                # No ground truth for this class\n",
        "                continue\n",
        "\n",
        "            if not mask_pred.any():\n",
        "                # No predictions for this class\n",
        "                average_precisions[cls].append(0.0)\n",
        "                continue\n",
        "\n",
        "            # Sort predictions by score\n",
        "            pred_boxes_cls = pred_boxes[mask_pred]\n",
        "            pred_scores_cls = pred_scores[mask_pred]\n",
        "\n",
        "            # Sort by confidence score\n",
        "            indices = torch.argsort(pred_scores_cls, descending=True)\n",
        "            pred_boxes_cls = pred_boxes_cls[indices]\n",
        "\n",
        "            target_boxes_cls = target_boxes[mask_target]\n",
        "\n",
        "            # Calculate IoU between predictions and targets\n",
        "            ious = box_iou(pred_boxes_cls, target_boxes_cls)\n",
        "\n",
        "            # For each prediction, check if it matches a ground truth\n",
        "            tp = torch.zeros(len(pred_boxes_cls))\n",
        "            fp = torch.zeros(len(pred_boxes_cls))\n",
        "\n",
        "            for i in range(len(pred_boxes_cls)):\n",
        "                # Get IoUs for this prediction\n",
        "                box_ious = ious[i]\n",
        "\n",
        "                # Get the best IoU and index\n",
        "                if len(box_ious) > 0:\n",
        "                    max_iou, max_idx = torch.max(box_ious, dim=0)\n",
        "\n",
        "                    if max_iou >= iou_threshold:\n",
        "                        tp[i] = 1\n",
        "                        # Remove the matched target to prevent multiple matches\n",
        "                        ious[:, max_idx] = 0\n",
        "                    else:\n",
        "                        fp[i] = 1\n",
        "                else:\n",
        "                    fp[i] = 1\n",
        "\n",
        "            # Calculate precision and recall\n",
        "            tp_cumsum = torch.cumsum(tp, dim=0)\n",
        "            fp_cumsum = torch.cumsum(fp, dim=0)\n",
        "\n",
        "            precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
        "            recalls = tp_cumsum / len(target_boxes_cls)\n",
        "\n",
        "            # Compute average precision (area under PR curve)\n",
        "            # Add a start point (0, 1) and an end point (1, 0)\n",
        "            precisions = torch.cat([torch.tensor([1]).to(precisions.device), precisions])\n",
        "            recalls = torch.cat([torch.tensor([0]).to(recalls.device), recalls])\n",
        "\n",
        "            # Compute area under PR curve using trapezoidal rule\n",
        "            ap = torch.trapz(precisions, recalls)\n",
        "            average_precisions[cls].append(ap.item())\n",
        "\n",
        "    # Calculate mAP\n",
        "    class_aps = [np.mean(aps) if aps else 0.0 for aps in average_precisions]\n",
        "    mAP = np.mean([ap for ap in class_aps[1:] if not np.isnan(ap)])  # Skip background class\n",
        "\n",
        "    return mAP\n",
        "\n",
        "# ============================\n",
        "# VISUALIZATION FUNCTIONS\n",
        "# ============================\n",
        "\n",
        "def plot_loss_curve(train_losses, val_maps, output_dir):\n",
        "    \"\"\"Plot training loss and validation mAP curves\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, 'b-')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot mAP\n",
        "    plt.subplot(1, 2, 2)\n",
        "\n",
        "    # If val_maps are collected less frequently, create corresponding epoch indices\n",
        "    if len(val_maps) < len(train_losses):\n",
        "        eval_freq = len(train_losses) // len(val_maps)\n",
        "        eval_epochs = list(range(0, len(train_losses), eval_freq))[:len(val_maps)]\n",
        "        plt.plot(eval_epochs, val_maps, 'r-')\n",
        "    else:\n",
        "        plt.plot(val_maps, 'r-')\n",
        "\n",
        "    plt.title('Validation mAP')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'training_curves.png'))\n",
        "    plt.close()\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5, output_dir=None):\n",
        "    \"\"\"Visualize model predictions on sample images\"\"\"\n",
        "    if output_dir is None:\n",
        "        output_dir = \"predictions\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create a subplot grid for visualization\n",
        "    fig, axes = plt.subplots(num_images, 2, figsize=(12, 3*num_images))\n",
        "\n",
        "    # Randomly sample images\n",
        "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Get image and target\n",
        "        image, target = dataset[idx]\n",
        "\n",
        "        # Convert image for visualization\n",
        "        image_vis = np.array(transforms.ToPILImage()(image))\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image.to(device)])[0]\n",
        "\n",
        "        # Plot ground truth\n",
        "        axes[i, 0].imshow(image_vis)\n",
        "        axes[i, 0].set_title(\"Ground Truth\")\n",
        "\n",
        "        # Draw ground truth boxes\n",
        "        for box, label in zip(target[\"boxes\"], target[\"labels\"]):\n",
        "            box = box.cpu().numpy()\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='green', linewidth=2)\n",
        "            axes[i, 0].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label.item()]\n",
        "            axes[i, 0].text(xmin, ymin-5, class_name, color='green',\n",
        "                           backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Plot prediction\n",
        "        axes[i, 1].imshow(image_vis)\n",
        "        axes[i, 1].set_title(\"Prediction\")\n",
        "\n",
        "        # Filter predictions with confidence > 0.5\n",
        "        mask = prediction[\"scores\"] > 0.5\n",
        "        boxes = prediction[\"boxes\"][mask].cpu().numpy()\n",
        "        labels = prediction[\"labels\"][mask].cpu().numpy()\n",
        "        scores = prediction[\"scores\"][mask].cpu().numpy()\n",
        "\n",
        "        # Draw predicted boxes\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='red', linewidth=2)\n",
        "            axes[i, 1].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label]\n",
        "            axes[i, 1].text(xmin, ymin-5, f\"{class_name}: {score:.2f}\",\n",
        "                           color='red', backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Hide axis ticks\n",
        "        axes[i, 0].set_xticks([])\n",
        "        axes[i, 0].set_yticks([])\n",
        "        axes[i, 1].set_xticks([])\n",
        "        axes[i, 1].set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'sample_predictions.png'))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Prediction visualization saved to {os.path.join(output_dir, 'sample_predictions.png')}\")\n",
        "\n",
        "# ============================\n",
        "# DATA LOADERS\n",
        "# ============================\n",
        "\n",
        "def create_data_loaders(args):\n",
        "    train_dataset = PascalVOCDataset(\n",
        "        root=args.voc_path,\n",
        "        split='train',\n",
        "        transforms=get_transform(train=True, img_size=args.image_size)\n",
        "    )\n",
        "\n",
        "    # Try 'val' or 'valid' for validation set\n",
        "    val_split = 'val'\n",
        "    if not os.path.exists(os.path.join(args.voc_path, 'val')):\n",
        "        val_split = 'valid'\n",
        "\n",
        "    val_dataset = PascalVOCDataset(\n",
        "        root=args.voc_path,\n",
        "        split=val_split,\n",
        "        transforms=get_transform(train=False, img_size=args.image_size)\n",
        "    )\n",
        "\n",
        "    # Set num_workers=0 to avoid multiprocessing issues in Colab\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_dataset.num_classes\n",
        "\n",
        "# ============================\n",
        "# MAIN TRAINING FUNCTION\n",
        "# ============================\n",
        "\n",
        "def train_ssd_model(args):\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    print(\"\\n==== TRAINING SSD MODEL (NO AUGMENTATION) ====\")\n",
        "    print(f\"Dataset path: {args.voc_path}\")\n",
        "    print(f\"Output directory: {args.output_dir}\")\n",
        "    print(f\"Training for {args.epochs} epochs with batch size {args.batch_size}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    try:\n",
        "        train_loader, val_loader, num_classes = create_data_loaders(args)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data loaders: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    print(f\"Created data loaders: {len(train_loader)} training batches, {len(val_loader)} validation batches\")\n",
        "    print(f\"Number of classes (including background): {num_classes}\")\n",
        "\n",
        "    # Create model\n",
        "    try:\n",
        "        model = create_ssd_model(num_classes, pretrained=args.pretrained)\n",
        "        model.to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    print(f\"Created SSD300 model with VGG16 backbone\")\n",
        "\n",
        "    # Optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(params, lr=args.lr)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "    # Initialize training metrics\n",
        "    train_losses = []\n",
        "    val_maps = []\n",
        "    best_map = 0.0\n",
        "    best_model_path = os.path.join(args.output_dir, 'best_model.pth')\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\nStarting training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        try:\n",
        "            # Train for one epoch\n",
        "            metric_logger = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
        "\n",
        "            # Update learning rate\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            # Record training loss\n",
        "            train_losses.append(metric_logger.loss.global_avg)\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
        "                mAP = evaluate(model, val_loader, device, epoch)\n",
        "                val_maps.append(mAP)\n",
        "\n",
        "                # Save best model\n",
        "                if mAP > best_map:\n",
        "                    best_map = mAP\n",
        "                    torch.save(model.state_dict(), best_model_path)\n",
        "                    print(f\"Saved best model with mAP: {mAP:.4f}\")\n",
        "\n",
        "                    # Copy to Google Drive if in Colab\n",
        "                    if IN_COLAB and args.gdrive_dir:\n",
        "                        gdrive_best_path = os.path.join(args.gdrive_dir, 'best_model.pth')\n",
        "                        shutil.copy(best_model_path, gdrive_best_path)\n",
        "                        print(f\"Copied best model to Google Drive: {gdrive_best_path}\")\n",
        "\n",
        "            # Save checkpoint\n",
        "            if (epoch + 1) % args.save_freq == 0 or epoch == args.epochs - 1:\n",
        "                checkpoint_path = os.path.join(args.output_dir, f'checkpoint_{epoch+1}.pth')\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'best_map': best_map\n",
        "                }, checkpoint_path)\n",
        "                print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "            # Plot training curves after each evaluation\n",
        "            if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
        "                plot_loss_curve(train_losses, val_maps, args.output_dir)\n",
        "\n",
        "                # Copy visualization to Google Drive if in Colab\n",
        "                if IN_COLAB and args.gdrive_dir:\n",
        "                    curves_path = os.path.join(args.output_dir, 'training_curves.png')\n",
        "                    gdrive_curves_path = os.path.join(args.gdrive_dir, 'training_curves.png')\n",
        "                    if os.path.exists(curves_path):\n",
        "                        shutil.copy(curves_path, gdrive_curves_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in epoch {epoch}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nTraining complete in {total_time/60:.2f} minutes\")\n",
        "    print(f\"Best validation mAP: {best_map:.4f}\")\n",
        "\n",
        "    # Final model evaluation\n",
        "    try:\n",
        "        # Load the best model\n",
        "        if os.path.exists(best_model_path):\n",
        "            model.load_state_dict(torch.load(best_model_path))\n",
        "            print(\"Loaded best model for final evaluation\")\n",
        "\n",
        "            # Final validation\n",
        "            final_map = evaluate(model, val_loader, device, epoch=args.epochs)\n",
        "            print(f\"Final validation mAP: {final_map:.4f}\")\n",
        "\n",
        "            # Visualize predictions\n",
        "            print(\"Generating prediction visualizations...\")\n",
        "            val_dataset = val_loader.dataset  # Get the validation dataset\n",
        "            visualize_predictions(model, val_dataset, device,\n",
        "                                  num_images=5, output_dir=args.output_dir)\n",
        "\n",
        "            # Copy visualization to Google Drive if in Colab\n",
        "            if IN_COLAB and args.gdrive_dir:\n",
        "                pred_path = os.path.join(args.output_dir, 'sample_predictions.png')\n",
        "                gdrive_pred_path = os.path.join(args.gdrive_dir, 'sample_predictions.png')\n",
        "                if os.path.exists(pred_path):\n",
        "                    shutil.copy(pred_path, gdrive_pred_path)\n",
        "                    print(f\"Copied prediction visualization to Google Drive: {gdrive_pred_path}\")\n",
        "        else:\n",
        "            print(f\"Warning: Best model not found at {best_model_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Generate final report\n",
        "    report_path = os.path.join(args.output_dir, 'training_report.txt')\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(\"SSD Model Training Report (NO AUGMENTATION)\\n\")\n",
        "        f.write(\"=======================================\\n\\n\")\n",
        "        f.write(f\"Dataset: {args.voc_path}\\n\")\n",
        "        f.write(f\"Number of classes: {num_classes}\\n\")\n",
        "        f.write(f\"Training epochs: {args.epochs}\\n\")\n",
        "        f.write(f\"Batch size: {args.batch_size}\\n\")\n",
        "        f.write(f\"Learning rate: {args.lr}\\n\")\n",
        "        f.write(f\"Image size: {args.image_size}\\n\\n\")\n",
        "        f.write(f\"Data augmentation: None\\n\\n\")\n",
        "\n",
        "        f.write(\"Results:\\n\")\n",
        "        f.write(f\"Best validation mAP: {best_map:.4f}\\n\")\n",
        "        f.write(f\"Training time: {total_time/60:.2f} minutes\\n\\n\")\n",
        "\n",
        "        f.write(\"Training Loss:\\n\")\n",
        "        for i, loss in enumerate(train_losses):\n",
        "            f.write(f\"Epoch {i+1}: {loss:.4f}\\n\")\n",
        "\n",
        "        f.write(\"\\nValidation mAP:\\n\")\n",
        "        for i, mAP in enumerate(val_maps):\n",
        "            epoch = i * args.eval_freq + args.eval_freq\n",
        "            f.write(f\"Epoch {epoch}: {mAP:.4f}\\n\")\n",
        "\n",
        "    print(f\"Training report saved to {report_path}\")\n",
        "\n",
        "    # Copy report to Google Drive if in Colab\n",
        "    if IN_COLAB and args.gdrive_dir:\n",
        "        gdrive_report_path = os.path.join(args.gdrive_dir, 'training_report.txt')\n",
        "        shutil.copy(report_path, gdrive_report_path)\n",
        "        print(f\"Copied training report to Google Drive: {gdrive_report_path}\")\n",
        "\n",
        "    print(\"\\n==== SSD MODEL TRAINING COMPLETE ====\")\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6JAd0qsIUTq",
        "outputId": "2b6172d3-e1ca-4088-ffb5-b91cf3e6f6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab environment\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Using device: cuda\n",
            "Running in notebook/Colab mode with default arguments\n",
            "\n",
            "==== VERIFYING DATASET ====\n",
            "Dataset verification completed successfully.\n",
            "\n",
            "==== TRAINING SSD MODEL (NO AUGMENTATION) ====\n",
            "Dataset path: /content/ssd_dataset\n",
            "Output directory: /content/ssd_model\n",
            "Training for 50 epochs with batch size 8\n",
            "Found 7 classes: ['__background__', 'Anthracnose', 'Bacterial-Black-spot', 'Damaged-mango', 'Fruitly', 'Mechanical-damage', 'Others']\n",
            "Loaded 2306 images for train split\n",
            "Found 7 classes: ['__background__', 'Anthracnose', 'Bacterial-Black-spot', 'Damaged-mango', 'Fruitly', 'Mechanical-damage', 'Others']\n",
            "Loaded 493 images for valid split\n",
            "Created data loaders: 289 training batches, 62 validation batches\n",
            "Number of classes (including background): 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:01<00:00, 93.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created SSD300 model with pretrained VGG16 backbone\n",
            "Created SSD300 model with VGG16 backbone\n",
            "\n",
            "Starting training...\n",
            "Epoch: [0]\n",
            "Epoch: [0] [  0/289]  eta: 0:00:25  time: 0.0897  loss: 29.2995 (29.2995)  bbox_regression: 6.1576 (6.1576)  classification: 23.1419 (23.1419)\n",
            "Epoch: [0] [ 10/289]  eta: 0:00:23  time: 0.0845  loss: 35.3502 (35.3502)  bbox_regression: 5.7341 (5.7341)  classification: 29.6161 (29.6161)\n",
            "Epoch: [0] [ 20/289]  eta: 0:00:21  time: 0.0796  loss: 23.2520 (22.9497)  bbox_regression: 3.8103 (3.6929)  classification: 19.4418 (19.2568)\n",
            "Epoch: [0] [ 30/289]  eta: 0:00:20  time: 0.0793  loss: 18.6134 (9.4081)  bbox_regression: 3.1207 (1.6833)  classification: 15.4927 (7.7248)\n",
            "Epoch: [0] [ 40/289]  eta: 0:00:19  time: 0.0790  loss: 15.9811 (8.3467)  bbox_regression: 2.6163 (1.3627)  classification: 13.3648 (6.9840)\n",
            "Epoch: [0] [ 50/289]  eta: 0:00:18  time: 0.0793  loss: 14.4511 (7.9997)  bbox_regression: 2.3987 (1.2796)  classification: 12.0524 (6.7201)\n",
            "Epoch: [0] [ 60/289]  eta: 0:00:18  time: 0.0790  loss: 13.1993 (7.4965)  bbox_regression: 2.1611 (1.2277)  classification: 11.0382 (6.2687)\n",
            "Epoch: [0] [ 70/289]  eta: 0:00:17  time: 0.0792  loss: 12.1609 (6.3206)  bbox_regression: 1.9625 (0.8500)  classification: 10.1984 (5.4706)\n",
            "Epoch: [0] [ 80/289]  eta: 0:00:16  time: 0.0793  loss: 11.3095 (5.5457)  bbox_regression: 1.8212 (0.7848)  classification: 9.4882 (4.7608)\n",
            "Epoch: [0] [ 90/289]  eta: 0:00:15  time: 0.0795  loss: 10.6056 (5.0844)  bbox_regression: 1.7258 (0.8859)  classification: 8.8797 (4.1985)\n",
            "Epoch: [0] [100/289]  eta: 0:00:15  time: 0.0795  loss: 9.9839 (4.6152)  bbox_regression: 1.6211 (0.8104)  classification: 8.3628 (3.8048)\n",
            "Epoch: [0] [110/289]  eta: 0:00:14  time: 0.0794  loss: 9.4467 (4.1740)  bbox_regression: 1.5487 (0.7425)  classification: 7.8981 (3.4315)\n",
            "Epoch: [0] [120/289]  eta: 0:00:13  time: 0.0796  loss: 8.9704 (3.8520)  bbox_regression: 1.4874 (0.8125)  classification: 7.4829 (3.0394)\n",
            "Epoch: [0] [130/289]  eta: 0:00:12  time: 0.0799  loss: 8.5469 (3.5528)  bbox_regression: 1.4276 (0.7556)  classification: 7.1193 (2.7972)\n",
            "Epoch: [0] [140/289]  eta: 0:00:11  time: 0.0800  loss: 8.2295 (3.7471)  bbox_regression: 1.3936 (0.8260)  classification: 6.8358 (2.9211)\n",
            "Epoch: [0] [150/289]  eta: 0:00:11  time: 0.0801  loss: 7.9296 (3.8861)  bbox_regression: 1.3638 (0.9458)  classification: 6.5658 (2.9403)\n",
            "Epoch: [0] [160/289]  eta: 0:00:10  time: 0.0802  loss: 7.6733 (3.7527)  bbox_regression: 1.3339 (0.9130)  classification: 6.3394 (2.8397)\n",
            "Epoch: [0] [170/289]  eta: 0:00:09  time: 0.0803  loss: 7.4419 (3.7599)  bbox_regression: 1.3058 (0.8678)  classification: 6.1361 (2.8921)\n",
            "Epoch: [0] [180/289]  eta: 0:00:08  time: 0.0803  loss: 7.2311 (3.6713)  bbox_regression: 1.2791 (0.8380)  classification: 5.9520 (2.8333)\n",
            "Epoch: [0] [190/289]  eta: 0:00:07  time: 0.0802  loss: 7.0176 (3.3900)  bbox_regression: 1.2480 (0.7538)  classification: 5.7696 (2.6361)\n",
            "Epoch: [0] [200/289]  eta: 0:00:07  time: 0.0802  loss: 6.8279 (3.1786)  bbox_regression: 1.2178 (0.6627)  classification: 5.6101 (2.5158)\n",
            "Epoch: [0] [210/289]  eta: 0:00:06  time: 0.0800  loss: 6.6680 (3.3297)  bbox_regression: 1.1964 (0.7037)  classification: 5.4717 (2.6260)\n",
            "Epoch: [0] [220/289]  eta: 0:00:05  time: 0.0800  loss: 6.5427 (3.6766)  bbox_regression: 1.1872 (0.8797)  classification: 5.3555 (2.7969)\n",
            "Epoch: [0] [230/289]  eta: 0:00:04  time: 0.0800  loss: 6.4118 (3.7083)  bbox_regression: 1.1732 (0.9291)  classification: 5.2385 (2.7791)\n",
            "Epoch: [0] [240/289]  eta: 0:00:03  time: 0.0801  loss: 6.2877 (3.4698)  bbox_regression: 1.1569 (0.8221)  classification: 5.1308 (2.6477)\n",
            "Epoch: [0] [250/289]  eta: 0:00:03  time: 0.0800  loss: 6.1600 (3.2519)  bbox_regression: 1.1378 (0.7290)  classification: 5.0222 (2.5229)\n",
            "Epoch: [0] [260/289]  eta: 0:00:02  time: 0.0800  loss: 6.0414 (3.0730)  bbox_regression: 1.1213 (0.6922)  classification: 4.9201 (2.3808)\n",
            "Epoch: [0] [270/289]  eta: 0:00:01  time: 0.0799  loss: 5.9368 (3.1349)  bbox_regression: 1.1119 (0.7867)  classification: 4.8248 (2.3482)\n",
            "Epoch: [0] [280/289]  eta: 0:00:00  time: 0.0800  loss: 5.8451 (3.2834)  bbox_regression: 1.1008 (0.8341)  classification: 4.7442 (2.4493)\n",
            "Epoch: [0] [288/289]  eta: 0:00:00  time: 0.0801  loss: 5.7606 (3.0625)  bbox_regression: 1.0850 (0.6493)  classification: 4.6756 (2.4132)\n",
            "Epoch: [0] Time: 0:00:23 (0.0801 s / it)\n",
            "Epoch: [1]\n",
            "Epoch: [1] [  0/289]  eta: 0:00:20  time: 0.0716  loss: 1.8031 (1.8031)  bbox_regression: 0.2260 (0.2260)  classification: 1.5771 (1.5771)\n",
            "Epoch: [1] [ 10/289]  eta: 0:00:22  time: 0.0789  loss: 2.6630 (2.6630)  bbox_regression: 0.5352 (0.5352)  classification: 2.1277 (2.1277)\n",
            "Epoch: [1] [ 20/289]  eta: 0:00:21  time: 0.0801  loss: 3.0056 (3.0657)  bbox_regression: 0.6964 (0.7199)  classification: 2.3092 (2.3458)\n",
            "Epoch: [1] [ 30/289]  eta: 0:00:20  time: 0.0799  loss: 3.0097 (3.2004)  bbox_regression: 0.6869 (0.7703)  classification: 2.3228 (2.4300)\n",
            "Epoch: [1] [ 40/289]  eta: 0:00:19  time: 0.0803  loss: 2.9604 (2.9130)  bbox_regression: 0.6629 (0.6277)  classification: 2.2975 (2.2853)\n",
            "Epoch: [1] [ 50/289]  eta: 0:00:18  time: 0.0794  loss: 2.9114 (2.7590)  bbox_regression: 0.6356 (0.5560)  classification: 2.2758 (2.2030)\n",
            "Epoch: [1] [ 60/289]  eta: 0:00:17  time: 0.0786  loss: 2.8678 (2.6780)  bbox_regression: 0.6155 (0.5184)  classification: 2.2523 (2.1597)\n",
            "Epoch: [1] [ 70/289]  eta: 0:00:17  time: 0.0787  loss: 2.8724 (2.7730)  bbox_regression: 0.6182 (0.5741)  classification: 2.2542 (2.1989)\n",
            "Epoch: [1] [ 80/289]  eta: 0:00:16  time: 0.0790  loss: 2.8988 (2.9931)  bbox_regression: 0.6228 (0.6452)  classification: 2.2759 (2.3479)\n",
            "Epoch: [1] [ 90/289]  eta: 0:00:15  time: 0.0790  loss: 2.9311 (3.1394)  bbox_regression: 0.6416 (0.7244)  classification: 2.2895 (2.4151)\n",
            "Epoch: [1] [100/289]  eta: 0:00:14  time: 0.0788  loss: 2.9955 (3.3874)  bbox_regression: 0.6810 (0.9165)  classification: 2.3145 (2.4709)\n",
            "Epoch: [1] [110/289]  eta: 0:00:14  time: 0.0788  loss: 2.9887 (3.2510)  bbox_regression: 0.6822 (0.8669)  classification: 2.3066 (2.3841)\n",
            "Epoch: [1] [120/289]  eta: 0:00:13  time: 0.0790  loss: 2.9770 (2.8835)  bbox_regression: 0.6747 (0.6430)  classification: 2.3023 (2.2404)\n",
            "Epoch: [1] [130/289]  eta: 0:00:12  time: 0.0791  loss: 3.0233 (3.2150)  bbox_regression: 0.6975 (0.7828)  classification: 2.3257 (2.4323)\n",
            "Epoch: [1] [140/289]  eta: 0:00:11  time: 0.0795  loss: 3.0424 (3.4380)  bbox_regression: 0.7084 (0.9119)  classification: 2.3340 (2.5261)\n",
            "Epoch: [1] [150/289]  eta: 0:00:11  time: 0.0793  loss: 3.0199 (2.9979)  bbox_regression: 0.6999 (0.7157)  classification: 2.3200 (2.2822)\n",
            "Epoch: [1] [160/289]  eta: 0:00:10  time: 0.0795  loss: 3.0078 (2.7637)  bbox_regression: 0.6992 (0.6345)  classification: 2.3086 (2.1291)\n",
            "Epoch: [1] [170/289]  eta: 0:00:09  time: 0.0798  loss: 2.9906 (2.7694)  bbox_regression: 0.6908 (0.6220)  classification: 2.2998 (2.1474)\n",
            "Epoch: [1] [180/289]  eta: 0:00:08  time: 0.0801  loss: 2.9811 (2.7667)  bbox_regression: 0.6848 (0.5690)  classification: 2.2963 (2.1976)\n",
            "Epoch: [1] [190/289]  eta: 0:00:07  time: 0.0802  loss: 2.9957 (3.0389)  bbox_regression: 0.6932 (0.7140)  classification: 2.3024 (2.3249)\n",
            "Epoch: [1] [200/289]  eta: 0:00:07  time: 0.0801  loss: 3.0335 (3.5080)  bbox_regression: 0.7151 (0.9897)  classification: 2.3184 (2.5183)\n",
            "Epoch: [1] [210/289]  eta: 0:00:06  time: 0.0800  loss: 3.0083 (3.1288)  bbox_regression: 0.7057 (0.8246)  classification: 2.3026 (2.3042)\n",
            "Epoch: [1] [220/289]  eta: 0:00:05  time: 0.0800  loss: 2.9894 (2.5461)  bbox_regression: 0.6991 (0.5379)  classification: 2.2903 (2.0082)\n",
            "Epoch: [1] [230/289]  eta: 0:00:04  time: 0.0800  loss: 2.9921 (2.8214)  bbox_regression: 0.7033 (0.6781)  classification: 2.2888 (2.1434)\n",
            "Epoch: [1] [240/289]  eta: 0:00:03  time: 0.0800  loss: 2.9883 (2.9763)  bbox_regression: 0.7000 (0.7101)  classification: 2.2883 (2.2662)\n",
            "Epoch: [1] [250/289]  eta: 0:00:03  time: 0.0800  loss: 2.9773 (2.8067)  bbox_regression: 0.6971 (0.6251)  classification: 2.2803 (2.1816)\n",
            "Epoch: [1] [260/289]  eta: 0:00:02  time: 0.0800  loss: 2.9715 (2.7683)  bbox_regression: 0.6952 (0.6376)  classification: 2.2763 (2.1308)\n",
            "Epoch: [1] [270/289]  eta: 0:00:01  time: 0.0800  loss: 2.9801 (3.0144)  bbox_regression: 0.6986 (0.7174)  classification: 2.2815 (2.2970)\n",
            "Epoch: [1] [280/289]  eta: 0:00:00  time: 0.0799  loss: 2.9794 (3.0821)  bbox_regression: 0.6994 (0.7541)  classification: 2.2799 (2.3280)\n",
            "Epoch: [1] [288/289]  eta: 0:00:00  time: 0.0798  loss: 2.9706 (2.8872)  bbox_regression: 0.6951 (0.6492)  classification: 2.2756 (2.2380)\n",
            "Epoch: [1] Time: 0:00:23 (0.0798 s / it)\n",
            "Epoch: [2]\n",
            "Epoch: [2] [  0/289]  eta: 0:00:23  time: 0.0830  loss: 3.6650 (3.6650)  bbox_regression: 1.1801 (1.1801)  classification: 2.4849 (2.4849)\n",
            "Epoch: [2] [ 10/289]  eta: 0:00:22  time: 0.0805  loss: 2.5923 (2.5923)  bbox_regression: 0.4868 (0.4868)  classification: 2.1054 (2.1054)\n",
            "Epoch: [2] [ 20/289]  eta: 0:00:22  time: 0.0824  loss: 2.2897 (2.2210)  bbox_regression: 0.4013 (0.3624)  classification: 1.8884 (1.8586)\n",
            "Epoch: [2] [ 30/289]  eta: 0:00:21  time: 0.0825  loss: 2.4253 (2.3334)  bbox_regression: 0.4740 (0.4669)  classification: 1.9513 (1.8665)\n",
            "Epoch: [2] [ 40/289]  eta: 0:00:20  time: 0.0812  loss: 2.4057 (2.5275)  bbox_regression: 0.4488 (0.4986)  classification: 1.9569 (2.0288)\n",
            "Epoch: [2] [ 50/289]  eta: 0:00:19  time: 0.0805  loss: 2.5978 (2.8653)  bbox_regression: 0.5404 (0.6433)  classification: 2.0575 (2.2220)\n",
            "Epoch: [2] [ 60/289]  eta: 0:00:18  time: 0.0807  loss: 2.6278 (3.0832)  bbox_regression: 0.5652 (0.8040)  classification: 2.0626 (2.2793)\n",
            "Epoch: [2] [ 70/289]  eta: 0:00:17  time: 0.0808  loss: 2.6822 (2.8974)  bbox_regression: 0.5892 (0.7138)  classification: 2.0930 (2.1836)\n",
            "Epoch: [2] [ 80/289]  eta: 0:00:16  time: 0.0809  loss: 2.6805 (2.8412)  bbox_regression: 0.5856 (0.6477)  classification: 2.0949 (2.1935)\n",
            "Epoch: [2] [ 90/289]  eta: 0:00:16  time: 0.0806  loss: 2.6748 (2.6485)  bbox_regression: 0.5776 (0.5361)  classification: 2.0973 (2.1124)\n",
            "Epoch: [2] [100/289]  eta: 0:00:15  time: 0.0802  loss: 2.6341 (2.4460)  bbox_regression: 0.5652 (0.4825)  classification: 2.0689 (1.9635)\n",
            "Epoch: [2] [110/289]  eta: 0:00:14  time: 0.0802  loss: 2.6657 (2.6245)  bbox_regression: 0.5734 (0.5543)  classification: 2.0924 (2.0702)\n",
            "Epoch: [2] [120/289]  eta: 0:00:13  time: 0.0801  loss: 2.6548 (2.7593)  bbox_regression: 0.5654 (0.5666)  classification: 2.0894 (2.1927)\n",
            "Epoch: [2] [130/289]  eta: 0:00:12  time: 0.0799  loss: 2.6224 (2.3818)  bbox_regression: 0.5531 (0.4404)  classification: 2.0693 (1.9413)\n",
            "Epoch: [2] [140/289]  eta: 0:00:11  time: 0.0799  loss: 2.6404 (2.5534)  bbox_regression: 0.5584 (0.5158)  classification: 2.0820 (2.0376)\n",
            "Epoch: [2] [150/289]  eta: 0:00:11  time: 0.0799  loss: 2.6312 (2.6892)  bbox_regression: 0.5563 (0.5775)  classification: 2.0749 (2.1117)\n",
            "Epoch: [2] [160/289]  eta: 0:00:10  time: 0.0801  loss: 2.6771 (2.9354)  bbox_regression: 0.5842 (0.7664)  classification: 2.0928 (2.1690)\n",
            "Epoch: [2] [170/289]  eta: 0:00:09  time: 0.0804  loss: 2.6764 (3.0171)  bbox_regression: 0.5814 (0.7708)  classification: 2.0950 (2.2462)\n",
            "Epoch: [2] [180/289]  eta: 0:00:08  time: 0.0806  loss: 2.6747 (2.6555)  bbox_regression: 0.5828 (0.5710)  classification: 2.0919 (2.0846)\n",
            "Epoch: [2] [190/289]  eta: 0:00:07  time: 0.0804  loss: 2.6741 (2.6547)  bbox_regression: 0.5825 (0.5918)  classification: 2.0916 (2.0629)\n",
            "Epoch: [2] [200/289]  eta: 0:00:07  time: 0.0805  loss: 2.6641 (2.5687)  bbox_regression: 0.5750 (0.5044)  classification: 2.0892 (2.0643)\n",
            "Epoch: [2] [210/289]  eta: 0:00:06  time: 0.0805  loss: 2.6758 (2.6917)  bbox_regression: 0.5823 (0.5801)  classification: 2.0935 (2.1116)\n",
            "Epoch: [2] [220/289]  eta: 0:00:05  time: 0.0804  loss: 2.6773 (2.8094)  bbox_regression: 0.5829 (0.6630)  classification: 2.0943 (2.1464)\n",
            "Epoch: [2] [230/289]  eta: 0:00:04  time: 0.0805  loss: 2.6733 (2.6473)  bbox_regression: 0.5805 (0.5618)  classification: 2.0928 (2.0855)\n",
            "Epoch: [2] [240/289]  eta: 0:00:03  time: 0.0803  loss: 2.6638 (2.5150)  bbox_regression: 0.5801 (0.5483)  classification: 2.0838 (1.9667)\n",
            "Epoch: [2] [250/289]  eta: 0:00:03  time: 0.0803  loss: 2.6528 (2.4159)  bbox_regression: 0.5740 (0.4988)  classification: 2.0788 (1.9171)\n",
            "Epoch: [2] [260/289]  eta: 0:00:02  time: 0.0802  loss: 2.6301 (2.2245)  bbox_regression: 0.5634 (0.3623)  classification: 2.0668 (1.8622)\n",
            "Epoch: [2] [270/289]  eta: 0:00:01  time: 0.0801  loss: 2.6347 (2.4078)  bbox_regression: 0.5692 (0.5094)  classification: 2.0655 (1.8984)\n",
            "Epoch: [2] [280/289]  eta: 0:00:00  time: 0.0801  loss: 2.6327 (2.6659)  bbox_regression: 0.5682 (0.6312)  classification: 2.0645 (2.0347)\n",
            "Epoch: [2] [288/289]  eta: 0:00:00  time: 0.0800  loss: 2.6283 (2.4900)  bbox_regression: 0.5672 (0.5133)  classification: 2.0611 (1.9766)\n",
            "Epoch: [2] Time: 0:00:23 (0.0800 s / it)\n",
            "Epoch: [3]\n",
            "Epoch: [3] [  0/289]  eta: 0:00:22  time: 0.0769  loss: 3.1179 (3.1179)  bbox_regression: 0.8824 (0.8824)  classification: 2.2355 (2.2355)\n",
            "Epoch: [3] [ 10/289]  eta: 0:00:21  time: 0.0780  loss: 2.6049 (2.6049)  bbox_regression: 0.5535 (0.5535)  classification: 2.0514 (2.0514)\n",
            "Epoch: [3] [ 20/289]  eta: 0:00:21  time: 0.0792  loss: 2.5736 (2.5464)  bbox_regression: 0.5335 (0.5161)  classification: 2.0400 (2.0303)\n",
            "Epoch: [3] [ 30/289]  eta: 0:00:20  time: 0.0792  loss: 2.7200 (2.7833)  bbox_regression: 0.6099 (0.6409)  classification: 2.1101 (2.1423)\n",
            "Epoch: [3] [ 40/289]  eta: 0:00:19  time: 0.0792  loss: 2.6795 (2.7907)  bbox_regression: 0.6001 (0.6699)  classification: 2.0794 (2.1208)\n",
            "Epoch: [3] [ 50/289]  eta: 0:00:18  time: 0.0792  loss: 2.5708 (2.3396)  bbox_regression: 0.5522 (0.4627)  classification: 2.0186 (1.8769)\n",
            "Epoch: [3] [ 60/289]  eta: 0:00:18  time: 0.0789  loss: 2.5233 (2.2032)  bbox_regression: 0.5267 (0.3762)  classification: 1.9967 (1.8270)\n",
            "Epoch: [3] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 2.5057 (2.3398)  bbox_regression: 0.5152 (0.4207)  classification: 1.9906 (1.9190)\n",
            "Epoch: [3] [ 80/289]  eta: 0:00:16  time: 0.0788  loss: 2.4711 (2.3118)  bbox_regression: 0.5038 (0.4341)  classification: 1.9673 (1.8776)\n",
            "Epoch: [3] [ 90/289]  eta: 0:00:15  time: 0.0787  loss: 2.4763 (2.3718)  bbox_regression: 0.4963 (0.4294)  classification: 1.9800 (1.9423)\n",
            "Epoch: [3] [100/289]  eta: 0:00:14  time: 0.0787  loss: 2.4437 (2.3329)  bbox_regression: 0.4841 (0.4044)  classification: 1.9596 (1.9284)\n",
            "Epoch: [3] [110/289]  eta: 0:00:14  time: 0.0784  loss: 2.3971 (2.0366)  bbox_regression: 0.4645 (0.3199)  classification: 1.9325 (1.7167)\n",
            "Epoch: [3] [120/289]  eta: 0:00:13  time: 0.0788  loss: 2.3775 (2.0430)  bbox_regression: 0.4525 (0.2929)  classification: 1.9250 (1.7501)\n",
            "Epoch: [3] [130/289]  eta: 0:00:12  time: 0.0789  loss: 2.3939 (2.3764)  bbox_regression: 0.4603 (0.4368)  classification: 1.9336 (1.9396)\n",
            "Epoch: [3] [140/289]  eta: 0:00:11  time: 0.0792  loss: 2.4074 (2.5884)  bbox_regression: 0.4691 (0.5692)  classification: 1.9383 (2.0191)\n",
            "Epoch: [3] [150/289]  eta: 0:00:11  time: 0.0792  loss: 2.4182 (2.5776)  bbox_regression: 0.4737 (0.5613)  classification: 1.9446 (2.0162)\n",
            "Epoch: [3] [160/289]  eta: 0:00:10  time: 0.0792  loss: 2.4255 (2.5531)  bbox_regression: 0.4769 (0.5319)  classification: 1.9486 (2.0212)\n",
            "Epoch: [3] [170/289]  eta: 0:00:09  time: 0.0793  loss: 2.4133 (2.3759)  bbox_regression: 0.4684 (0.4289)  classification: 1.9449 (1.9470)\n",
            "Epoch: [3] [180/289]  eta: 0:00:08  time: 0.0793  loss: 2.4047 (2.2376)  bbox_regression: 0.4666 (0.3835)  classification: 1.9382 (1.8541)\n",
            "Epoch: [3] [190/289]  eta: 0:00:07  time: 0.0795  loss: 2.4364 (2.6343)  bbox_regression: 0.4853 (0.6296)  classification: 1.9511 (2.0047)\n",
            "Epoch: [3] [200/289]  eta: 0:00:07  time: 0.0796  loss: 2.4382 (2.7408)  bbox_regression: 0.4832 (0.6341)  classification: 1.9549 (2.1067)\n",
            "Epoch: [3] [210/289]  eta: 0:00:06  time: 0.0795  loss: 2.4108 (2.1659)  bbox_regression: 0.4720 (0.3446)  classification: 1.9388 (1.8213)\n",
            "Epoch: [3] [220/289]  eta: 0:00:05  time: 0.0793  loss: 2.3922 (1.9301)  bbox_regression: 0.4623 (0.2524)  classification: 1.9298 (1.6777)\n",
            "Epoch: [3] [230/289]  eta: 0:00:04  time: 0.0793  loss: 2.3944 (2.2213)  bbox_regression: 0.4604 (0.3377)  classification: 1.9340 (1.8836)\n",
            "Epoch: [3] [240/289]  eta: 0:00:03  time: 0.0793  loss: 2.3911 (2.3790)  bbox_regression: 0.4608 (0.4442)  classification: 1.9303 (1.9348)\n",
            "Epoch: [3] [250/289]  eta: 0:00:03  time: 0.0792  loss: 2.3880 (2.3142)  bbox_regression: 0.4602 (0.4580)  classification: 1.9278 (1.8562)\n",
            "Epoch: [3] [260/289]  eta: 0:00:02  time: 0.0792  loss: 2.3949 (2.4405)  bbox_regression: 0.4626 (0.4838)  classification: 1.9323 (1.9567)\n",
            "Epoch: [3] [270/289]  eta: 0:00:01  time: 0.0793  loss: 2.3919 (2.4406)  bbox_regression: 0.4578 (0.4282)  classification: 1.9341 (2.0124)\n",
            "Epoch: [3] [280/289]  eta: 0:00:00  time: 0.0792  loss: 2.3922 (2.3572)  bbox_regression: 0.4600 (0.4259)  classification: 1.9322 (1.9312)\n",
            "Epoch: [3] [288/289]  eta: 0:00:00  time: 0.0790  loss: 2.3834 (2.2911)  bbox_regression: 0.4559 (0.4390)  classification: 1.9275 (1.8521)\n",
            "Epoch: [3] Time: 0:00:22 (0.0791 s / it)\n",
            "Epoch: [4]\n",
            "Epoch: [4] [  0/289]  eta: 0:00:22  time: 0.0775  loss: 1.4640 (1.4640)  bbox_regression: 0.0509 (0.0509)  classification: 1.4131 (1.4131)\n",
            "Epoch: [4] [ 10/289]  eta: 0:00:21  time: 0.0784  loss: 2.6539 (2.6539)  bbox_regression: 0.5193 (0.5193)  classification: 2.1346 (2.1346)\n",
            "Epoch: [4] [ 20/289]  eta: 0:00:21  time: 0.0792  loss: 2.4363 (2.4849)  bbox_regression: 0.4297 (0.4486)  classification: 2.0065 (2.0362)\n",
            "Epoch: [4] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 2.3763 (2.2236)  bbox_regression: 0.4016 (0.3369)  classification: 1.9747 (1.8867)\n",
            "Epoch: [4] [ 40/289]  eta: 0:00:19  time: 0.0798  loss: 2.4113 (2.3851)  bbox_regression: 0.4114 (0.3922)  classification: 1.9999 (1.9929)\n",
            "Epoch: [4] [ 50/289]  eta: 0:00:19  time: 0.0805  loss: 2.3699 (2.3599)  bbox_regression: 0.4119 (0.4279)  classification: 1.9580 (1.9321)\n",
            "Epoch: [4] [ 60/289]  eta: 0:00:18  time: 0.0809  loss: 2.3918 (2.3519)  bbox_regression: 0.4329 (0.4770)  classification: 1.9589 (1.8749)\n",
            "Epoch: [4] [ 70/289]  eta: 0:00:17  time: 0.0803  loss: 2.3249 (2.2101)  bbox_regression: 0.4054 (0.3888)  classification: 1.9195 (1.8213)\n",
            "Epoch: [4] [ 80/289]  eta: 0:00:16  time: 0.0801  loss: 2.2994 (2.0177)  bbox_regression: 0.3940 (0.2752)  classification: 1.9055 (1.7426)\n",
            "Epoch: [4] [ 90/289]  eta: 0:00:15  time: 0.0800  loss: 2.2773 (2.1083)  bbox_regression: 0.3858 (0.3162)  classification: 1.8915 (1.7921)\n",
            "Epoch: [4] [100/289]  eta: 0:00:15  time: 0.0800  loss: 2.2582 (2.0910)  bbox_regression: 0.3791 (0.3190)  classification: 1.8790 (1.7720)\n",
            "Epoch: [4] [110/289]  eta: 0:00:14  time: 0.0800  loss: 2.2447 (2.0963)  bbox_regression: 0.3737 (0.3190)  classification: 1.8709 (1.7773)\n",
            "Epoch: [4] [120/289]  eta: 0:00:13  time: 0.0797  loss: 2.2373 (2.1321)  bbox_regression: 0.3706 (0.3275)  classification: 1.8667 (1.8046)\n",
            "Epoch: [4] [130/289]  eta: 0:00:12  time: 0.0796  loss: 2.2463 (2.2554)  bbox_regression: 0.3810 (0.4210)  classification: 1.8653 (1.8344)\n",
            "Epoch: [4] [140/289]  eta: 0:00:11  time: 0.0796  loss: 2.2312 (2.1944)  bbox_regression: 0.3765 (0.4123)  classification: 1.8547 (1.7822)\n",
            "Epoch: [4] [150/289]  eta: 0:00:11  time: 0.0794  loss: 2.2397 (2.1969)  bbox_regression: 0.3771 (0.3519)  classification: 1.8626 (1.8450)\n",
            "Epoch: [4] [160/289]  eta: 0:00:10  time: 0.0792  loss: 2.2394 (2.2968)  bbox_regression: 0.3774 (0.3837)  classification: 1.8620 (1.9130)\n",
            "Epoch: [4] [170/289]  eta: 0:00:09  time: 0.0791  loss: 2.2380 (2.2244)  bbox_regression: 0.3764 (0.3708)  classification: 1.8616 (1.8535)\n",
            "Epoch: [4] [180/289]  eta: 0:00:08  time: 0.0790  loss: 2.2259 (2.1173)  bbox_regression: 0.3720 (0.3283)  classification: 1.8539 (1.7890)\n",
            "Epoch: [4] [190/289]  eta: 0:00:07  time: 0.0790  loss: 2.2413 (2.2697)  bbox_regression: 0.3810 (0.4207)  classification: 1.8603 (1.8490)\n",
            "Epoch: [4] [200/289]  eta: 0:00:07  time: 0.0791  loss: 2.2561 (2.5291)  bbox_regression: 0.3873 (0.5263)  classification: 1.8687 (2.0028)\n",
            "Epoch: [4] [210/289]  eta: 0:00:06  time: 0.0792  loss: 2.2472 (2.3036)  bbox_regression: 0.3835 (0.4076)  classification: 1.8637 (1.8960)\n",
            "Epoch: [4] [220/289]  eta: 0:00:05  time: 0.0793  loss: 2.2479 (2.1664)  bbox_regression: 0.3821 (0.3294)  classification: 1.8658 (1.8370)\n",
            "Epoch: [4] [230/289]  eta: 0:00:04  time: 0.0793  loss: 2.2490 (2.2677)  bbox_regression: 0.3828 (0.3754)  classification: 1.8661 (1.8922)\n",
            "Epoch: [4] [240/289]  eta: 0:00:03  time: 0.0793  loss: 2.2469 (2.2348)  bbox_regression: 0.3837 (0.4016)  classification: 1.8631 (1.8332)\n",
            "Epoch: [4] [250/289]  eta: 0:00:03  time: 0.0793  loss: 2.2394 (2.1284)  bbox_regression: 0.3805 (0.3535)  classification: 1.8589 (1.7749)\n",
            "Epoch: [4] [260/289]  eta: 0:00:02  time: 0.0792  loss: 2.2323 (2.0567)  bbox_regression: 0.3795 (0.3284)  classification: 1.8528 (1.7283)\n",
            "Epoch: [4] [270/289]  eta: 0:00:01  time: 0.0792  loss: 2.2156 (1.9175)  bbox_regression: 0.3740 (0.2928)  classification: 1.8416 (1.6247)\n",
            "Epoch: [4] [280/289]  eta: 0:00:00  time: 0.0792  loss: 2.2081 (1.8921)  bbox_regression: 0.3693 (0.2361)  classification: 1.8388 (1.6560)\n",
            "Epoch: [4] [288/289]  eta: 0:00:00  time: 0.0791  loss: 2.2227 (2.2733)  bbox_regression: 0.3747 (0.3623)  classification: 1.8480 (1.9111)\n",
            "Epoch: [4] Time: 0:00:22 (0.0792 s / it)\n",
            "Validation: [4]\n",
            "Validation: [4] [ 0/62]  eta: 0:00:14  time: 0.2378  \n",
            "Validation: [4] [10/62]  eta: 0:00:04  time: 0.0884  \n",
            "Validation: [4] [20/62]  eta: 0:00:03  time: 0.0789  \n",
            "Validation: [4] [30/62]  eta: 0:00:02  time: 0.0755  \n",
            "Validation: [4] [40/62]  eta: 0:00:01  time: 0.0738  \n",
            "Validation: [4] [50/62]  eta: 0:00:00  time: 0.0732  \n",
            "Validation: [4] [60/62]  eta: 0:00:00  time: 0.0728  \n",
            "Validation: [4] [61/62]  eta: 0:00:00  time: 0.0730  \n",
            "Validation: [4] Time: 0:00:04 (0.0730 s / it)\n",
            "Epoch 4: mAP = 0.7307\n",
            "Saved best model with mAP: 0.7307\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/best_model.pth\n",
            "Epoch: [5]\n",
            "Epoch: [5] [  0/289]  eta: 0:00:25  time: 0.0895  loss: 2.3307 (2.3307)  bbox_regression: 0.4148 (0.4148)  classification: 1.9159 (1.9159)\n",
            "Epoch: [5] [ 10/289]  eta: 0:00:22  time: 0.0799  loss: 2.0034 (2.0034)  bbox_regression: 0.3018 (0.3018)  classification: 1.7016 (1.7016)\n",
            "Epoch: [5] [ 20/289]  eta: 0:00:21  time: 0.0797  loss: 2.0289 (2.0138)  bbox_regression: 0.2957 (0.2898)  classification: 1.7332 (1.7240)\n",
            "Epoch: [5] [ 30/289]  eta: 0:00:20  time: 0.0797  loss: 2.0601 (2.0913)  bbox_regression: 0.3099 (0.3144)  classification: 1.7502 (1.7769)\n",
            "Epoch: [5] [ 40/289]  eta: 0:00:19  time: 0.0795  loss: 2.1843 (2.3476)  bbox_regression: 0.3611 (0.4297)  classification: 1.8233 (1.9179)\n",
            "Epoch: [5] [ 50/289]  eta: 0:00:19  time: 0.0797  loss: 2.2603 (2.5705)  bbox_regression: 0.4008 (0.5416)  classification: 1.8595 (2.0289)\n",
            "Epoch: [5] [ 60/289]  eta: 0:00:18  time: 0.0798  loss: 2.2178 (2.2863)  bbox_regression: 0.3864 (0.4383)  classification: 1.8314 (1.8480)\n",
            "Epoch: [5] [ 70/289]  eta: 0:00:17  time: 0.0795  loss: 2.2333 (2.1645)  bbox_regression: 0.3974 (0.3889)  classification: 1.8359 (1.7756)\n",
            "Epoch: [5] [ 80/289]  eta: 0:00:16  time: 0.0794  loss: 2.1651 (2.0045)  bbox_regression: 0.3703 (0.3212)  classification: 1.7948 (1.6832)\n",
            "Epoch: [5] [ 90/289]  eta: 0:00:15  time: 0.0794  loss: 2.1503 (1.8556)  bbox_regression: 0.3622 (0.2369)  classification: 1.7881 (1.6187)\n",
            "Epoch: [5] [100/289]  eta: 0:00:14  time: 0.0794  loss: 2.1491 (2.0842)  bbox_regression: 0.3614 (0.3253)  classification: 1.7877 (1.7589)\n",
            "Epoch: [5] [110/289]  eta: 0:00:14  time: 0.0791  loss: 2.1338 (2.0589)  bbox_regression: 0.3498 (0.2933)  classification: 1.7841 (1.7656)\n",
            "Epoch: [5] [120/289]  eta: 0:00:13  time: 0.0794  loss: 2.1246 (2.0008)  bbox_regression: 0.3430 (0.2500)  classification: 1.7816 (1.7508)\n",
            "Epoch: [5] [130/289]  eta: 0:00:12  time: 0.0798  loss: 2.0985 (1.9021)  bbox_regression: 0.3321 (0.2340)  classification: 1.7664 (1.6682)\n",
            "Epoch: [5] [140/289]  eta: 0:00:11  time: 0.0798  loss: 2.0993 (1.9466)  bbox_regression: 0.3293 (0.2463)  classification: 1.7701 (1.7003)\n",
            "Epoch: [5] [150/289]  eta: 0:00:11  time: 0.0798  loss: 2.0993 (2.1051)  bbox_regression: 0.3262 (0.2879)  classification: 1.7731 (1.8172)\n",
            "Epoch: [5] [160/289]  eta: 0:00:10  time: 0.0796  loss: 2.0936 (2.0535)  bbox_regression: 0.3200 (0.2544)  classification: 1.7737 (1.7991)\n",
            "Epoch: [5] [170/289]  eta: 0:00:09  time: 0.0796  loss: 2.0880 (2.0027)  bbox_regression: 0.3197 (0.2706)  classification: 1.7683 (1.7321)\n",
            "Epoch: [5] [180/289]  eta: 0:00:08  time: 0.0796  loss: 2.0791 (1.9621)  bbox_regression: 0.3163 (0.2866)  classification: 1.7628 (1.6755)\n",
            "Epoch: [5] [190/289]  eta: 0:00:07  time: 0.0796  loss: 2.0687 (1.9030)  bbox_regression: 0.3121 (0.2470)  classification: 1.7566 (1.6561)\n",
            "Epoch: [5] [200/289]  eta: 0:00:07  time: 0.0795  loss: 2.0816 (2.1046)  bbox_regression: 0.3235 (0.3888)  classification: 1.7581 (1.7157)\n",
            "Epoch: [5] [210/289]  eta: 0:00:06  time: 0.0795  loss: 2.0931 (2.3271)  bbox_regression: 0.3282 (0.4817)  classification: 1.7650 (1.8454)\n",
            "Epoch: [5] [220/289]  eta: 0:00:05  time: 0.0795  loss: 2.0812 (2.0773)  bbox_regression: 0.3233 (0.3218)  classification: 1.7579 (1.7555)\n",
            "Epoch: [5] [230/289]  eta: 0:00:04  time: 0.0795  loss: 2.0837 (1.9845)  bbox_regression: 0.3227 (0.2656)  classification: 1.7610 (1.7189)\n",
            "Epoch: [5] [240/289]  eta: 0:00:03  time: 0.0799  loss: 2.0808 (2.0757)  bbox_regression: 0.3208 (0.2928)  classification: 1.7600 (1.7829)\n",
            "Epoch: [5] [250/289]  eta: 0:00:03  time: 0.0798  loss: 2.0787 (2.0201)  bbox_regression: 0.3206 (0.2960)  classification: 1.7581 (1.7241)\n",
            "Epoch: [5] [260/289]  eta: 0:00:02  time: 0.0797  loss: 2.0687 (1.9234)  bbox_regression: 0.3139 (0.2300)  classification: 1.7549 (1.6934)\n",
            "Epoch: [5] [270/289]  eta: 0:00:01  time: 0.0796  loss: 2.0615 (1.8456)  bbox_regression: 0.3129 (0.2155)  classification: 1.7486 (1.6301)\n",
            "Epoch: [5] [280/289]  eta: 0:00:00  time: 0.0797  loss: 2.0555 (1.8831)  bbox_regression: 0.3107 (0.2700)  classification: 1.7448 (1.6131)\n",
            "Epoch: [5] [288/289]  eta: 0:00:00  time: 0.0796  loss: 2.0586 (2.0032)  bbox_regression: 0.3135 (0.3197)  classification: 1.7451 (1.6835)\n",
            "Epoch: [5] Time: 0:00:23 (0.0796 s / it)\n",
            "Epoch: [6]\n",
            "Epoch: [6] [  0/289]  eta: 0:00:23  time: 0.0830  loss: 1.8214 (1.8214)  bbox_regression: 0.3020 (0.3020)  classification: 1.5194 (1.5194)\n",
            "Epoch: [6] [ 10/289]  eta: 0:00:21  time: 0.0773  loss: 1.7255 (1.7255)  bbox_regression: 0.2037 (0.2037)  classification: 1.5218 (1.5218)\n",
            "Epoch: [6] [ 20/289]  eta: 0:00:20  time: 0.0778  loss: 1.9219 (1.9269)  bbox_regression: 0.2318 (0.2283)  classification: 1.6900 (1.6985)\n",
            "Epoch: [6] [ 30/289]  eta: 0:00:20  time: 0.0798  loss: 2.1395 (2.3672)  bbox_regression: 0.3430 (0.4197)  classification: 1.7965 (1.9475)\n",
            "Epoch: [6] [ 40/289]  eta: 0:00:19  time: 0.0791  loss: 2.0297 (2.1430)  bbox_regression: 0.3095 (0.3910)  classification: 1.7202 (1.7520)\n",
            "Epoch: [6] [ 50/289]  eta: 0:00:18  time: 0.0791  loss: 2.0388 (1.8826)  bbox_regression: 0.3088 (0.2558)  classification: 1.7300 (1.6268)\n",
            "Epoch: [6] [ 60/289]  eta: 0:00:18  time: 0.0796  loss: 2.0543 (2.1046)  bbox_regression: 0.3257 (0.3590)  classification: 1.7286 (1.7457)\n",
            "Epoch: [6] [ 70/289]  eta: 0:00:17  time: 0.0797  loss: 2.0779 (2.1778)  bbox_regression: 0.3303 (0.3850)  classification: 1.7477 (1.7928)\n",
            "Epoch: [6] [ 80/289]  eta: 0:00:16  time: 0.0794  loss: 2.0433 (2.0099)  bbox_regression: 0.3150 (0.2825)  classification: 1.7283 (1.7274)\n",
            "Epoch: [6] [ 90/289]  eta: 0:00:15  time: 0.0794  loss: 2.0435 (1.9213)  bbox_regression: 0.3140 (0.2563)  classification: 1.7295 (1.6651)\n",
            "Epoch: [6] [100/289]  eta: 0:00:15  time: 0.0795  loss: 2.0373 (2.0129)  bbox_regression: 0.3077 (0.2780)  classification: 1.7296 (1.7348)\n",
            "Epoch: [6] [110/289]  eta: 0:00:14  time: 0.0795  loss: 2.0465 (2.0603)  bbox_regression: 0.3101 (0.2924)  classification: 1.7364 (1.7679)\n",
            "Epoch: [6] [120/289]  eta: 0:00:13  time: 0.0794  loss: 2.0173 (1.9165)  bbox_regression: 0.2945 (0.2276)  classification: 1.7229 (1.6889)\n",
            "Epoch: [6] [130/289]  eta: 0:00:12  time: 0.0792  loss: 2.0159 (1.8461)  bbox_regression: 0.2953 (0.2135)  classification: 1.7206 (1.6326)\n",
            "Epoch: [6] [140/289]  eta: 0:00:11  time: 0.0793  loss: 1.9934 (1.8488)  bbox_regression: 0.2863 (0.2366)  classification: 1.7072 (1.6122)\n",
            "Epoch: [6] [150/289]  eta: 0:00:11  time: 0.0792  loss: 2.0005 (1.8995)  bbox_regression: 0.2923 (0.2724)  classification: 1.7082 (1.6271)\n",
            "Epoch: [6] [160/289]  eta: 0:00:10  time: 0.0792  loss: 2.0053 (2.0887)  bbox_regression: 0.2903 (0.3187)  classification: 1.7150 (1.7700)\n",
            "Epoch: [6] [170/289]  eta: 0:00:09  time: 0.0791  loss: 2.0061 (2.0484)  bbox_regression: 0.2898 (0.2707)  classification: 1.7163 (1.7777)\n",
            "Epoch: [6] [180/289]  eta: 0:00:08  time: 0.0792  loss: 1.9960 (1.9211)  bbox_regression: 0.2863 (0.2542)  classification: 1.7097 (1.6668)\n",
            "Epoch: [6] [190/289]  eta: 0:00:07  time: 0.0791  loss: 1.9821 (1.7773)  bbox_regression: 0.2825 (0.2203)  classification: 1.6996 (1.5570)\n",
            "Epoch: [6] [200/289]  eta: 0:00:07  time: 0.0791  loss: 1.9687 (1.7220)  bbox_regression: 0.2797 (0.2197)  classification: 1.6890 (1.5023)\n",
            "Epoch: [6] [210/289]  eta: 0:00:06  time: 0.0790  loss: 1.9685 (1.8379)  bbox_regression: 0.2813 (0.2703)  classification: 1.6871 (1.5676)\n",
            "Epoch: [6] [220/289]  eta: 0:00:05  time: 0.0791  loss: 1.9680 (1.9605)  bbox_regression: 0.2825 (0.3111)  classification: 1.6854 (1.6495)\n",
            "Epoch: [6] [230/289]  eta: 0:00:04  time: 0.0791  loss: 1.9582 (1.8503)  bbox_regression: 0.2785 (0.2486)  classification: 1.6797 (1.6017)\n",
            "Epoch: [6] [240/289]  eta: 0:00:03  time: 0.0792  loss: 1.9647 (1.9289)  bbox_regression: 0.2815 (0.2703)  classification: 1.6832 (1.6586)\n",
            "Epoch: [6] [250/289]  eta: 0:00:03  time: 0.0792  loss: 1.9696 (2.1003)  bbox_regression: 0.2814 (0.3152)  classification: 1.6881 (1.7851)\n",
            "Epoch: [6] [260/289]  eta: 0:00:02  time: 0.0791  loss: 1.9629 (1.9408)  bbox_regression: 0.2799 (0.2604)  classification: 1.6830 (1.6803)\n",
            "Epoch: [6] [270/289]  eta: 0:00:01  time: 0.0789  loss: 1.9689 (1.9601)  bbox_regression: 0.2814 (0.2815)  classification: 1.6874 (1.6786)\n",
            "Epoch: [6] [280/289]  eta: 0:00:00  time: 0.0789  loss: 1.9712 (2.0793)  bbox_regression: 0.2817 (0.3055)  classification: 1.6894 (1.7737)\n",
            "Epoch: [6] [288/289]  eta: 0:00:00  time: 0.0787  loss: 1.9774 (2.1064)  bbox_regression: 0.2845 (0.3284)  classification: 1.6929 (1.7779)\n",
            "Epoch: [6] Time: 0:00:22 (0.0787 s / it)\n",
            "Epoch: [7]\n",
            "Epoch: [7] [  0/289]  eta: 0:00:21  time: 0.0759  loss: 1.2951 (1.2951)  bbox_regression: 0.0547 (0.0547)  classification: 1.2403 (1.2403)\n",
            "Epoch: [7] [ 10/289]  eta: 0:00:21  time: 0.0777  loss: 1.9568 (1.9568)  bbox_regression: 0.3044 (0.3044)  classification: 1.6524 (1.6524)\n",
            "Epoch: [7] [ 20/289]  eta: 0:00:21  time: 0.0801  loss: 2.0074 (2.0430)  bbox_regression: 0.3194 (0.3326)  classification: 1.6880 (1.7104)\n",
            "Epoch: [7] [ 30/289]  eta: 0:00:20  time: 0.0792  loss: 1.9325 (1.9191)  bbox_regression: 0.2905 (0.2829)  classification: 1.6420 (1.6363)\n",
            "Epoch: [7] [ 40/289]  eta: 0:00:19  time: 0.0783  loss: 1.8551 (1.6952)  bbox_regression: 0.2647 (0.2073)  classification: 1.5904 (1.4879)\n",
            "Epoch: [7] [ 50/289]  eta: 0:00:18  time: 0.0785  loss: 1.8671 (1.7656)  bbox_regression: 0.2710 (0.2407)  classification: 1.5961 (1.5249)\n",
            "Epoch: [7] [ 60/289]  eta: 0:00:18  time: 0.0786  loss: 1.8384 (1.8042)  bbox_regression: 0.2531 (0.2293)  classification: 1.5853 (1.5749)\n",
            "Epoch: [7] [ 70/289]  eta: 0:00:17  time: 0.0789  loss: 1.8261 (1.7218)  bbox_regression: 0.2509 (0.1996)  classification: 1.5753 (1.5222)\n",
            "Epoch: [7] [ 80/289]  eta: 0:00:16  time: 0.0786  loss: 1.8114 (1.7290)  bbox_regression: 0.2413 (0.2054)  classification: 1.5701 (1.5236)\n",
            "Epoch: [7] [ 90/289]  eta: 0:00:15  time: 0.0785  loss: 1.8550 (1.9576)  bbox_regression: 0.2543 (0.2663)  classification: 1.6008 (1.6913)\n",
            "Epoch: [7] [100/289]  eta: 0:00:14  time: 0.0785  loss: 1.8605 (2.0592)  bbox_regression: 0.2606 (0.3385)  classification: 1.5999 (1.7207)\n",
            "Epoch: [7] [110/289]  eta: 0:00:14  time: 0.0787  loss: 1.8493 (1.8232)  bbox_regression: 0.2600 (0.2858)  classification: 1.5893 (1.5374)\n",
            "Epoch: [7] [120/289]  eta: 0:00:13  time: 0.0787  loss: 1.8525 (1.8125)  bbox_regression: 0.2622 (0.2705)  classification: 1.5903 (1.5420)\n",
            "Epoch: [7] [130/289]  eta: 0:00:12  time: 0.0787  loss: 1.8443 (1.8168)  bbox_regression: 0.2574 (0.2430)  classification: 1.5870 (1.5738)\n",
            "Epoch: [7] [140/289]  eta: 0:00:11  time: 0.0787  loss: 1.8481 (1.8213)  bbox_regression: 0.2558 (0.2169)  classification: 1.5923 (1.6044)\n",
            "Epoch: [7] [150/289]  eta: 0:00:10  time: 0.0787  loss: 1.8645 (1.9968)  bbox_regression: 0.2598 (0.2757)  classification: 1.6047 (1.7211)\n",
            "Epoch: [7] [160/289]  eta: 0:00:10  time: 0.0789  loss: 1.8748 (2.0628)  bbox_regression: 0.2658 (0.3365)  classification: 1.6090 (1.7262)\n",
            "Epoch: [7] [170/289]  eta: 0:00:09  time: 0.0790  loss: 1.8712 (1.9218)  bbox_regression: 0.2645 (0.2997)  classification: 1.6068 (1.6221)\n",
            "Epoch: [7] [180/289]  eta: 0:00:08  time: 0.0792  loss: 1.8829 (1.9479)  bbox_regression: 0.2671 (0.2777)  classification: 1.6157 (1.6702)\n",
            "Epoch: [7] [190/289]  eta: 0:00:07  time: 0.0790  loss: 1.8939 (2.0881)  bbox_regression: 0.2701 (0.3181)  classification: 1.6239 (1.7700)\n",
            "Epoch: [7] [200/289]  eta: 0:00:07  time: 0.0789  loss: 1.9092 (2.1480)  bbox_regression: 0.2741 (0.3369)  classification: 1.6352 (1.8111)\n",
            "Epoch: [7] [210/289]  eta: 0:00:06  time: 0.0789  loss: 1.9169 (2.1362)  bbox_regression: 0.2761 (0.3340)  classification: 1.6408 (1.8022)\n",
            "Epoch: [7] [220/289]  eta: 0:00:05  time: 0.0790  loss: 1.9369 (2.2154)  bbox_regression: 0.2849 (0.3933)  classification: 1.6521 (1.8220)\n",
            "Epoch: [7] [230/289]  eta: 0:00:04  time: 0.0791  loss: 1.9462 (2.2558)  bbox_regression: 0.2866 (0.3972)  classification: 1.6596 (1.8586)\n",
            "Epoch: [7] [240/289]  eta: 0:00:03  time: 0.0790  loss: 1.9307 (1.8620)  bbox_regression: 0.2829 (0.2607)  classification: 1.6479 (1.6013)\n",
            "Epoch: [7] [250/289]  eta: 0:00:03  time: 0.0791  loss: 1.9194 (1.6090)  bbox_regression: 0.2800 (0.2035)  classification: 1.6394 (1.4055)\n",
            "Epoch: [7] [260/289]  eta: 0:00:02  time: 0.0791  loss: 1.9118 (1.6840)  bbox_regression: 0.2784 (0.2252)  classification: 1.6334 (1.4588)\n",
            "Epoch: [7] [270/289]  eta: 0:00:01  time: 0.0790  loss: 1.9075 (1.7585)  bbox_regression: 0.2757 (0.2219)  classification: 1.6318 (1.5367)\n",
            "Epoch: [7] [280/289]  eta: 0:00:00  time: 0.0790  loss: 1.9062 (1.8333)  bbox_regression: 0.2732 (0.2045)  classification: 1.6331 (1.6288)\n",
            "Epoch: [7] [288/289]  eta: 0:00:00  time: 0.0789  loss: 1.9033 (1.7973)  bbox_regression: 0.2716 (0.1998)  classification: 1.6317 (1.5975)\n",
            "Epoch: [7] Time: 0:00:22 (0.0789 s / it)\n",
            "Epoch: [8]\n",
            "Epoch: [8] [  0/289]  eta: 0:00:26  time: 0.0903  loss: 1.9192 (1.9192)  bbox_regression: 0.1842 (0.1842)  classification: 1.7350 (1.7350)\n",
            "Epoch: [8] [ 10/289]  eta: 0:00:22  time: 0.0789  loss: 2.1349 (2.1349)  bbox_regression: 0.3469 (0.3469)  classification: 1.7880 (1.7880)\n",
            "Epoch: [8] [ 20/289]  eta: 0:00:21  time: 0.0801  loss: 1.9947 (1.9984)  bbox_regression: 0.3129 (0.3194)  classification: 1.6817 (1.6791)\n",
            "Epoch: [8] [ 30/289]  eta: 0:00:20  time: 0.0796  loss: 1.8911 (1.7570)  bbox_regression: 0.2887 (0.2566)  classification: 1.6025 (1.5004)\n",
            "Epoch: [8] [ 40/289]  eta: 0:00:20  time: 0.0803  loss: 1.8833 (1.7663)  bbox_regression: 0.2908 (0.2675)  classification: 1.5925 (1.4988)\n",
            "Epoch: [8] [ 50/289]  eta: 0:00:19  time: 0.0800  loss: 1.9615 (2.0707)  bbox_regression: 0.3144 (0.3542)  classification: 1.6472 (1.7165)\n",
            "Epoch: [8] [ 60/289]  eta: 0:00:18  time: 0.0795  loss: 1.9969 (2.2298)  bbox_regression: 0.3314 (0.4146)  classification: 1.6655 (1.8152)\n",
            "Epoch: [8] [ 70/289]  eta: 0:00:17  time: 0.0793  loss: 1.9829 (2.0372)  bbox_regression: 0.3151 (0.3170)  classification: 1.6678 (1.7203)\n",
            "Epoch: [8] [ 80/289]  eta: 0:00:16  time: 0.0790  loss: 1.9734 (1.9017)  bbox_regression: 0.3099 (0.2445)  classification: 1.6635 (1.6573)\n",
            "Epoch: [8] [ 90/289]  eta: 0:00:15  time: 0.0793  loss: 1.9631 (1.8930)  bbox_regression: 0.3062 (0.2745)  classification: 1.6569 (1.6185)\n",
            "Epoch: [8] [100/289]  eta: 0:00:14  time: 0.0792  loss: 1.9461 (1.8355)  bbox_regression: 0.2952 (0.2358)  classification: 1.6508 (1.5997)\n",
            "Epoch: [8] [110/289]  eta: 0:00:14  time: 0.0796  loss: 1.9457 (1.8667)  bbox_regression: 0.2900 (0.2166)  classification: 1.6557 (1.6501)\n",
            "Epoch: [8] [120/289]  eta: 0:00:13  time: 0.0795  loss: 1.9234 (1.8090)  bbox_regression: 0.2812 (0.2103)  classification: 1.6422 (1.5987)\n",
            "Epoch: [8] [130/289]  eta: 0:00:12  time: 0.0792  loss: 1.8998 (1.6451)  bbox_regression: 0.2713 (0.1674)  classification: 1.6285 (1.4777)\n",
            "Epoch: [8] [140/289]  eta: 0:00:11  time: 0.0793  loss: 1.9065 (1.8042)  bbox_regression: 0.2667 (0.1793)  classification: 1.6398 (1.6249)\n",
            "Epoch: [8] [150/289]  eta: 0:00:11  time: 0.0793  loss: 1.9115 (1.9880)  bbox_regression: 0.2728 (0.2825)  classification: 1.6387 (1.7055)\n",
            "Epoch: [8] [160/289]  eta: 0:00:10  time: 0.0792  loss: 1.8814 (1.7045)  bbox_regression: 0.2606 (0.2174)  classification: 1.6208 (1.4871)\n",
            "Epoch: [8] [170/289]  eta: 0:00:09  time: 0.0791  loss: 1.8740 (1.5911)  bbox_regression: 0.2589 (0.1538)  classification: 1.6152 (1.4372)\n",
            "Epoch: [8] [180/289]  eta: 0:00:08  time: 0.0794  loss: 1.8784 (1.8538)  bbox_regression: 0.2602 (0.2571)  classification: 1.6181 (1.5967)\n",
            "Epoch: [8] [190/289]  eta: 0:00:07  time: 0.0796  loss: 1.8743 (1.8766)  bbox_regression: 0.2635 (0.3027)  classification: 1.6109 (1.5739)\n",
            "Epoch: [8] [200/289]  eta: 0:00:07  time: 0.0800  loss: 1.8768 (1.8624)  bbox_regression: 0.2649 (0.3072)  classification: 1.6119 (1.5552)\n",
            "Epoch: [8] [210/289]  eta: 0:00:06  time: 0.0800  loss: 1.8821 (1.9562)  bbox_regression: 0.2624 (0.2521)  classification: 1.6197 (1.7041)\n",
            "Epoch: [8] [220/289]  eta: 0:00:05  time: 0.0799  loss: 1.8778 (1.8881)  bbox_regression: 0.2581 (0.1899)  classification: 1.6197 (1.6982)\n",
            "Epoch: [8] [230/289]  eta: 0:00:04  time: 0.0799  loss: 1.8692 (1.7329)  bbox_regression: 0.2548 (0.1751)  classification: 1.6143 (1.5578)\n",
            "Epoch: [8] [240/289]  eta: 0:00:03  time: 0.0799  loss: 1.8598 (1.6605)  bbox_regression: 0.2536 (0.2035)  classification: 1.6062 (1.4570)\n",
            "Epoch: [8] [250/289]  eta: 0:00:03  time: 0.0798  loss: 1.8478 (1.6007)  bbox_regression: 0.2502 (0.1969)  classification: 1.5976 (1.4038)\n",
            "Epoch: [8] [260/289]  eta: 0:00:02  time: 0.0798  loss: 1.8410 (1.6146)  bbox_regression: 0.2502 (0.2095)  classification: 1.5908 (1.4051)\n",
            "Epoch: [8] [270/289]  eta: 0:00:01  time: 0.0797  loss: 1.8345 (1.6677)  bbox_regression: 0.2469 (0.2047)  classification: 1.5876 (1.4630)\n",
            "Epoch: [8] [280/289]  eta: 0:00:00  time: 0.0797  loss: 1.8333 (1.7331)  bbox_regression: 0.2447 (0.1735)  classification: 1.5886 (1.5596)\n",
            "Epoch: [8] [288/289]  eta: 0:00:00  time: 0.0796  loss: 1.8414 (1.9203)  bbox_regression: 0.2485 (0.2565)  classification: 1.5929 (1.6639)\n",
            "Epoch: [8] Time: 0:00:23 (0.0796 s / it)\n",
            "Epoch: [9]\n",
            "Epoch: [9] [  0/289]  eta: 0:00:22  time: 0.0766  loss: 1.6780 (1.6780)  bbox_regression: 0.0676 (0.0676)  classification: 1.6105 (1.6105)\n",
            "Epoch: [9] [ 10/289]  eta: 0:00:22  time: 0.0799  loss: 1.9204 (1.9204)  bbox_regression: 0.2919 (0.2919)  classification: 1.6285 (1.6285)\n",
            "Epoch: [9] [ 20/289]  eta: 0:00:21  time: 0.0798  loss: 1.8040 (1.8103)  bbox_regression: 0.2647 (0.2745)  classification: 1.5393 (1.5358)\n",
            "Epoch: [9] [ 30/289]  eta: 0:00:20  time: 0.0791  loss: 1.8132 (1.7542)  bbox_regression: 0.2530 (0.2316)  classification: 1.5602 (1.5226)\n",
            "Epoch: [9] [ 40/289]  eta: 0:00:19  time: 0.0783  loss: 1.7819 (1.7587)  bbox_regression: 0.2385 (0.2111)  classification: 1.5434 (1.5477)\n",
            "Epoch: [9] [ 50/289]  eta: 0:00:18  time: 0.0792  loss: 1.7808 (1.7306)  bbox_regression: 0.2332 (0.2025)  classification: 1.5476 (1.5281)\n",
            "Epoch: [9] [ 60/289]  eta: 0:00:18  time: 0.0795  loss: 1.7652 (1.7310)  bbox_regression: 0.2339 (0.2244)  classification: 1.5313 (1.5066)\n",
            "Epoch: [9] [ 70/289]  eta: 0:00:17  time: 0.0792  loss: 1.7388 (1.6316)  bbox_regression: 0.2247 (0.2030)  classification: 1.5141 (1.4286)\n",
            "Epoch: [9] [ 80/289]  eta: 0:00:16  time: 0.0793  loss: 1.7477 (1.6943)  bbox_regression: 0.2224 (0.1875)  classification: 1.5253 (1.5068)\n",
            "Epoch: [9] [ 90/289]  eta: 0:00:15  time: 0.0796  loss: 1.8074 (2.0511)  bbox_regression: 0.2419 (0.3029)  classification: 1.5655 (1.7483)\n",
            "Epoch: [9] [100/289]  eta: 0:00:15  time: 0.0797  loss: 1.7955 (1.9891)  bbox_regression: 0.2379 (0.3005)  classification: 1.5576 (1.6886)\n",
            "Epoch: [9] [110/289]  eta: 0:00:14  time: 0.0796  loss: 1.8120 (1.8329)  bbox_regression: 0.2468 (0.2694)  classification: 1.5652 (1.5635)\n",
            "Epoch: [9] [120/289]  eta: 0:00:13  time: 0.0795  loss: 1.7905 (1.7654)  bbox_regression: 0.2407 (0.2550)  classification: 1.5498 (1.5104)\n",
            "Epoch: [9] [130/289]  eta: 0:00:12  time: 0.0794  loss: 1.7780 (1.5889)  bbox_regression: 0.2368 (0.1808)  classification: 1.5412 (1.4081)\n",
            "Epoch: [9] [140/289]  eta: 0:00:11  time: 0.0792  loss: 1.8023 (1.8732)  bbox_regression: 0.2495 (0.3027)  classification: 1.5528 (1.5705)\n",
            "Epoch: [9] [150/289]  eta: 0:00:10  time: 0.0791  loss: 1.7853 (1.8332)  bbox_regression: 0.2449 (0.2985)  classification: 1.5403 (1.5348)\n",
            "Epoch: [9] [160/289]  eta: 0:00:10  time: 0.0791  loss: 1.7682 (1.5281)  bbox_regression: 0.2389 (0.1638)  classification: 1.5293 (1.3643)\n",
            "Epoch: [9] [170/289]  eta: 0:00:09  time: 0.0791  loss: 1.7862 (1.7935)  bbox_regression: 0.2423 (0.2223)  classification: 1.5439 (1.5712)\n",
            "Epoch: [9] [180/289]  eta: 0:00:08  time: 0.0791  loss: 1.8053 (2.1035)  bbox_regression: 0.2491 (0.3315)  classification: 1.5561 (1.7720)\n",
            "Epoch: [9] [190/289]  eta: 0:00:07  time: 0.0792  loss: 1.7898 (1.8206)  bbox_regression: 0.2445 (0.2635)  classification: 1.5453 (1.5571)\n",
            "Epoch: [9] [200/289]  eta: 0:00:07  time: 0.0794  loss: 1.7827 (1.5789)  bbox_regression: 0.2411 (0.1689)  classification: 1.5416 (1.4100)\n",
            "Epoch: [9] [210/289]  eta: 0:00:06  time: 0.0795  loss: 1.7753 (1.6362)  bbox_regression: 0.2376 (0.1720)  classification: 1.5376 (1.4642)\n",
            "Epoch: [9] [220/289]  eta: 0:00:05  time: 0.0795  loss: 1.7856 (1.8143)  bbox_regression: 0.2364 (0.1884)  classification: 1.5492 (1.6260)\n",
            "Epoch: [9] [230/289]  eta: 0:00:04  time: 0.0794  loss: 1.7809 (1.8407)  bbox_regression: 0.2336 (0.1908)  classification: 1.5474 (1.6499)\n",
            "Epoch: [9] [240/289]  eta: 0:00:03  time: 0.0793  loss: 1.7823 (1.7464)  bbox_regression: 0.2347 (0.2160)  classification: 1.5477 (1.5304)\n",
            "Epoch: [9] [250/289]  eta: 0:00:03  time: 0.0793  loss: 1.7842 (1.8220)  bbox_regression: 0.2348 (0.2492)  classification: 1.5494 (1.5728)\n",
            "Epoch: [9] [260/289]  eta: 0:00:02  time: 0.0793  loss: 1.7779 (1.7248)  bbox_regression: 0.2338 (0.2238)  classification: 1.5441 (1.5010)\n",
            "Epoch: [9] [270/289]  eta: 0:00:01  time: 0.0792  loss: 1.7873 (1.8263)  bbox_regression: 0.2351 (0.2388)  classification: 1.5522 (1.5875)\n",
            "Epoch: [9] [280/289]  eta: 0:00:00  time: 0.0792  loss: 1.7845 (1.8700)  bbox_regression: 0.2345 (0.2432)  classification: 1.5500 (1.6268)\n",
            "Epoch: [9] [288/289]  eta: 0:00:00  time: 0.0791  loss: 1.7778 (1.6058)  bbox_regression: 0.2319 (0.1760)  classification: 1.5460 (1.4297)\n",
            "Epoch: [9] Time: 0:00:22 (0.0791 s / it)\n",
            "Validation: [9]\n",
            "Validation: [9] [ 0/62]  eta: 0:00:04  time: 0.0678  \n",
            "Validation: [9] [10/62]  eta: 0:00:03  time: 0.0673  \n",
            "Validation: [9] [20/62]  eta: 0:00:02  time: 0.0671  \n",
            "Validation: [9] [30/62]  eta: 0:00:02  time: 0.0674  \n",
            "Validation: [9] [40/62]  eta: 0:00:01  time: 0.0677  \n",
            "Validation: [9] [50/62]  eta: 0:00:00  time: 0.0680  \n",
            "Validation: [9] [60/62]  eta: 0:00:00  time: 0.0691  \n",
            "Validation: [9] [61/62]  eta: 0:00:00  time: 0.0687  \n",
            "Validation: [9] Time: 0:00:04 (0.0687 s / it)\n",
            "Epoch 9: mAP = 0.7542\n",
            "Saved best model with mAP: 0.7542\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/best_model.pth\n",
            "Saved checkpoint at epoch 10\n",
            "Epoch: [10]\n",
            "Epoch: [10] [  0/289]  eta: 0:00:24  time: 0.0845  loss: 2.0607 (2.0607)  bbox_regression: 0.3445 (0.3445)  classification: 1.7162 (1.7162)\n",
            "Epoch: [10] [ 10/289]  eta: 0:00:22  time: 0.0805  loss: 1.7004 (1.7004)  bbox_regression: 0.2315 (0.2315)  classification: 1.4689 (1.4689)\n",
            "Epoch: [10] [ 20/289]  eta: 0:00:21  time: 0.0794  loss: 1.7820 (1.7681)  bbox_regression: 0.2236 (0.2176)  classification: 1.5584 (1.5505)\n",
            "Epoch: [10] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 1.6601 (1.6379)  bbox_regression: 0.1842 (0.1582)  classification: 1.4759 (1.4798)\n",
            "Epoch: [10] [ 40/289]  eta: 0:00:19  time: 0.0786  loss: 1.6752 (1.5631)  bbox_regression: 0.1918 (0.1583)  classification: 1.4835 (1.4048)\n",
            "Epoch: [10] [ 50/289]  eta: 0:00:18  time: 0.0792  loss: 1.7539 (1.8992)  bbox_regression: 0.2196 (0.2745)  classification: 1.5342 (1.6247)\n",
            "Epoch: [10] [ 60/289]  eta: 0:00:18  time: 0.0794  loss: 1.7286 (1.8381)  bbox_regression: 0.2234 (0.2883)  classification: 1.5052 (1.5498)\n",
            "Epoch: [10] [ 70/289]  eta: 0:00:17  time: 0.0794  loss: 1.7134 (1.6101)  bbox_regression: 0.2145 (0.2015)  classification: 1.4989 (1.4086)\n",
            "Epoch: [10] [ 80/289]  eta: 0:00:16  time: 0.0793  loss: 1.7186 (1.6880)  bbox_regression: 0.2225 (0.2195)  classification: 1.4961 (1.4685)\n",
            "Epoch: [10] [ 90/289]  eta: 0:00:15  time: 0.0797  loss: 1.7208 (1.7472)  bbox_regression: 0.2219 (0.2479)  classification: 1.4989 (1.4993)\n",
            "Epoch: [10] [100/289]  eta: 0:00:15  time: 0.0794  loss: 1.7110 (1.6803)  bbox_regression: 0.2187 (0.2037)  classification: 1.4923 (1.4766)\n",
            "Epoch: [10] [110/289]  eta: 0:00:14  time: 0.0791  loss: 1.7188 (1.7099)  bbox_regression: 0.2165 (0.1920)  classification: 1.5024 (1.5178)\n",
            "Epoch: [10] [120/289]  eta: 0:00:13  time: 0.0798  loss: 1.7308 (1.8309)  bbox_regression: 0.2216 (0.2359)  classification: 1.5092 (1.5949)\n",
            "Epoch: [10] [130/289]  eta: 0:00:12  time: 0.0801  loss: 1.7082 (1.6492)  bbox_regression: 0.2171 (0.2205)  classification: 1.4911 (1.4288)\n",
            "Epoch: [10] [140/289]  eta: 0:00:11  time: 0.0805  loss: 1.7332 (1.7475)  bbox_regression: 0.2337 (0.3070)  classification: 1.4995 (1.4405)\n",
            "Epoch: [10] [150/289]  eta: 0:00:11  time: 0.0803  loss: 1.7074 (1.7023)  bbox_regression: 0.2234 (0.2649)  classification: 1.4840 (1.4374)\n",
            "Epoch: [10] [160/289]  eta: 0:00:10  time: 0.0801  loss: 1.7198 (1.6256)  bbox_regression: 0.2270 (0.1800)  classification: 1.4928 (1.4456)\n",
            "Epoch: [10] [170/289]  eta: 0:00:09  time: 0.0799  loss: 1.7056 (1.6916)  bbox_regression: 0.2266 (0.2510)  classification: 1.4789 (1.4407)\n",
            "Epoch: [10] [180/289]  eta: 0:00:08  time: 0.0800  loss: 1.6994 (1.5346)  bbox_regression: 0.2239 (0.1984)  classification: 1.4755 (1.3362)\n",
            "Epoch: [10] [190/289]  eta: 0:00:07  time: 0.0799  loss: 1.6957 (1.6109)  bbox_regression: 0.2210 (0.1727)  classification: 1.4747 (1.4381)\n",
            "Epoch: [10] [200/289]  eta: 0:00:07  time: 0.0799  loss: 1.6959 (1.6641)  bbox_regression: 0.2219 (0.2038)  classification: 1.4740 (1.4603)\n",
            "Epoch: [10] [210/289]  eta: 0:00:06  time: 0.0800  loss: 1.6870 (1.6042)  bbox_regression: 0.2202 (0.2130)  classification: 1.4668 (1.3912)\n",
            "Epoch: [10] [220/289]  eta: 0:00:05  time: 0.0801  loss: 1.6832 (1.5557)  bbox_regression: 0.2198 (0.1989)  classification: 1.4634 (1.3568)\n",
            "Epoch: [10] [230/289]  eta: 0:00:04  time: 0.0800  loss: 1.6708 (1.4995)  bbox_regression: 0.2169 (0.1818)  classification: 1.4538 (1.3177)\n",
            "Epoch: [10] [240/289]  eta: 0:00:03  time: 0.0799  loss: 1.6722 (1.5514)  bbox_regression: 0.2171 (0.1877)  classification: 1.4551 (1.3636)\n",
            "Epoch: [10] [250/289]  eta: 0:00:03  time: 0.0798  loss: 1.6777 (1.7578)  bbox_regression: 0.2193 (0.2471)  classification: 1.4584 (1.5107)\n",
            "Epoch: [10] [260/289]  eta: 0:00:02  time: 0.0798  loss: 1.6796 (1.7682)  bbox_regression: 0.2182 (0.2314)  classification: 1.4614 (1.5368)\n",
            "Epoch: [10] [270/289]  eta: 0:00:01  time: 0.0797  loss: 1.6656 (1.5137)  bbox_regression: 0.2139 (0.1462)  classification: 1.4517 (1.3675)\n",
            "Epoch: [10] [280/289]  eta: 0:00:00  time: 0.0798  loss: 1.6644 (1.4662)  bbox_regression: 0.2120 (0.1315)  classification: 1.4524 (1.3347)\n",
            "Epoch: [10] [288/289]  eta: 0:00:00  time: 0.0797  loss: 1.6718 (1.7132)  bbox_regression: 0.2116 (0.1674)  classification: 1.4603 (1.5458)\n",
            "Epoch: [10] Time: 0:00:23 (0.0797 s / it)\n",
            "Epoch: [11]\n",
            "Epoch: [11] [  0/289]  eta: 0:00:26  time: 0.0925  loss: 1.1088 (1.1088)  bbox_regression: 0.1750 (0.1750)  classification: 0.9338 (0.9338)\n",
            "Epoch: [11] [ 10/289]  eta: 0:00:22  time: 0.0816  loss: 1.4060 (1.4060)  bbox_regression: 0.1616 (0.1616)  classification: 1.2444 (1.2444)\n",
            "Epoch: [11] [ 20/289]  eta: 0:00:21  time: 0.0810  loss: 1.4837 (1.5024)  bbox_regression: 0.1976 (0.1987)  classification: 1.2861 (1.3037)\n",
            "Epoch: [11] [ 30/289]  eta: 0:00:20  time: 0.0796  loss: 1.5931 (1.6960)  bbox_regression: 0.2198 (0.2518)  classification: 1.3733 (1.4442)\n",
            "Epoch: [11] [ 40/289]  eta: 0:00:19  time: 0.0796  loss: 1.5834 (1.6880)  bbox_regression: 0.2093 (0.2216)  classification: 1.3741 (1.4664)\n",
            "Epoch: [11] [ 50/289]  eta: 0:00:19  time: 0.0799  loss: 1.5986 (1.6070)  bbox_regression: 0.2075 (0.1884)  classification: 1.3911 (1.4186)\n",
            "Epoch: [11] [ 60/289]  eta: 0:00:18  time: 0.0795  loss: 1.5656 (1.5292)  bbox_regression: 0.1910 (0.1534)  classification: 1.3746 (1.3758)\n",
            "Epoch: [11] [ 70/289]  eta: 0:00:17  time: 0.0798  loss: 1.5715 (1.5026)  bbox_regression: 0.1882 (0.1390)  classification: 1.3834 (1.3637)\n",
            "Epoch: [11] [ 80/289]  eta: 0:00:16  time: 0.0799  loss: 1.5515 (1.5084)  bbox_regression: 0.1829 (0.1582)  classification: 1.3686 (1.3502)\n",
            "Epoch: [11] [ 90/289]  eta: 0:00:15  time: 0.0798  loss: 1.5700 (1.5647)  bbox_regression: 0.1945 (0.2171)  classification: 1.3755 (1.3476)\n",
            "Epoch: [11] [100/289]  eta: 0:00:15  time: 0.0797  loss: 1.5694 (1.6419)  bbox_regression: 0.1939 (0.2384)  classification: 1.3755 (1.4035)\n",
            "Epoch: [11] [110/289]  eta: 0:00:14  time: 0.0794  loss: 1.5823 (1.6381)  bbox_regression: 0.1937 (0.1897)  classification: 1.3886 (1.4483)\n",
            "Epoch: [11] [120/289]  eta: 0:00:13  time: 0.0794  loss: 1.5983 (1.7443)  bbox_regression: 0.2016 (0.2403)  classification: 1.3967 (1.5039)\n",
            "Epoch: [11] [130/289]  eta: 0:00:12  time: 0.0793  loss: 1.5856 (1.6041)  bbox_regression: 0.1931 (0.1899)  classification: 1.3925 (1.4142)\n",
            "Epoch: [11] [140/289]  eta: 0:00:11  time: 0.0793  loss: 1.6044 (1.6417)  bbox_regression: 0.1986 (0.1805)  classification: 1.4059 (1.4613)\n",
            "Epoch: [11] [150/289]  eta: 0:00:11  time: 0.0793  loss: 1.5957 (1.6618)  bbox_regression: 0.1952 (0.2092)  classification: 1.4005 (1.4526)\n",
            "Epoch: [11] [160/289]  eta: 0:00:10  time: 0.0794  loss: 1.5897 (1.4854)  bbox_regression: 0.1915 (0.1417)  classification: 1.3982 (1.3438)\n",
            "Epoch: [11] [170/289]  eta: 0:00:09  time: 0.0795  loss: 1.6047 (1.6723)  bbox_regression: 0.1969 (0.2100)  classification: 1.4077 (1.4623)\n",
            "Epoch: [11] [180/289]  eta: 0:00:08  time: 0.0795  loss: 1.6069 (1.7459)  bbox_regression: 0.1946 (0.2194)  classification: 1.4123 (1.5265)\n",
            "Epoch: [11] [190/289]  eta: 0:00:07  time: 0.0795  loss: 1.6128 (1.6826)  bbox_regression: 0.1938 (0.1668)  classification: 1.4190 (1.5158)\n",
            "Epoch: [11] [200/289]  eta: 0:00:07  time: 0.0794  loss: 1.6142 (1.6803)  bbox_regression: 0.1930 (0.1786)  classification: 1.4212 (1.5017)\n",
            "Epoch: [11] [210/289]  eta: 0:00:06  time: 0.0792  loss: 1.6137 (1.6223)  bbox_regression: 0.1932 (0.1879)  classification: 1.4205 (1.4344)\n",
            "Epoch: [11] [220/289]  eta: 0:00:05  time: 0.0792  loss: 1.6146 (1.6185)  bbox_regression: 0.1928 (0.1912)  classification: 1.4218 (1.4274)\n",
            "Epoch: [11] [230/289]  eta: 0:00:04  time: 0.0792  loss: 1.5965 (1.4151)  bbox_regression: 0.1887 (0.1414)  classification: 1.4078 (1.2737)\n",
            "Epoch: [11] [240/289]  eta: 0:00:03  time: 0.0792  loss: 1.5923 (1.3457)  bbox_regression: 0.1874 (0.1275)  classification: 1.4049 (1.2182)\n",
            "Epoch: [11] [250/289]  eta: 0:00:03  time: 0.0791  loss: 1.5979 (1.6137)  bbox_regression: 0.1886 (0.1865)  classification: 1.4093 (1.4272)\n",
            "Epoch: [11] [260/289]  eta: 0:00:02  time: 0.0791  loss: 1.5945 (1.6207)  bbox_regression: 0.1863 (0.1732)  classification: 1.4082 (1.4475)\n",
            "Epoch: [11] [270/289]  eta: 0:00:01  time: 0.0791  loss: 1.6001 (1.6275)  bbox_regression: 0.1919 (0.2344)  classification: 1.4081 (1.3932)\n",
            "Epoch: [11] [280/289]  eta: 0:00:00  time: 0.0790  loss: 1.5961 (1.6167)  bbox_regression: 0.1906 (0.2465)  classification: 1.4055 (1.3701)\n",
            "Epoch: [11] [288/289]  eta: 0:00:00  time: 0.0788  loss: 1.5865 (1.4044)  bbox_regression: 0.1873 (0.1463)  classification: 1.3992 (1.2581)\n",
            "Epoch: [11] Time: 0:00:22 (0.0789 s / it)\n",
            "Epoch: [12]\n",
            "Epoch: [12] [  0/289]  eta: 0:00:23  time: 0.0807  loss: 1.4895 (1.4895)  bbox_regression: 0.0241 (0.0241)  classification: 1.4654 (1.4654)\n",
            "Epoch: [12] [ 10/289]  eta: 0:00:22  time: 0.0807  loss: 1.6027 (1.6027)  bbox_regression: 0.1708 (0.1708)  classification: 1.4319 (1.4319)\n",
            "Epoch: [12] [ 20/289]  eta: 0:00:21  time: 0.0793  loss: 1.4397 (1.4372)  bbox_regression: 0.1439 (0.1499)  classification: 1.2957 (1.2873)\n",
            "Epoch: [12] [ 30/289]  eta: 0:00:20  time: 0.0795  loss: 1.5048 (1.4509)  bbox_regression: 0.1623 (0.1576)  classification: 1.3425 (1.2933)\n",
            "Epoch: [12] [ 40/289]  eta: 0:00:19  time: 0.0798  loss: 1.5711 (1.7091)  bbox_regression: 0.2019 (0.2628)  classification: 1.3692 (1.4464)\n",
            "Epoch: [12] [ 50/289]  eta: 0:00:19  time: 0.0799  loss: 1.5243 (1.5544)  bbox_regression: 0.1886 (0.2293)  classification: 1.3357 (1.3252)\n",
            "Epoch: [12] [ 60/289]  eta: 0:00:18  time: 0.0798  loss: 1.5029 (1.3630)  bbox_regression: 0.1836 (0.1461)  classification: 1.3193 (1.2169)\n",
            "Epoch: [12] [ 70/289]  eta: 0:00:17  time: 0.0795  loss: 1.4933 (1.4142)  bbox_regression: 0.1753 (0.1415)  classification: 1.3180 (1.2727)\n",
            "Epoch: [12] [ 80/289]  eta: 0:00:16  time: 0.0799  loss: 1.5087 (1.5262)  bbox_regression: 0.1801 (0.1696)  classification: 1.3285 (1.3567)\n",
            "Epoch: [12] [ 90/289]  eta: 0:00:15  time: 0.0795  loss: 1.5158 (1.5956)  bbox_regression: 0.1809 (0.2007)  classification: 1.3349 (1.3950)\n",
            "Epoch: [12] [100/289]  eta: 0:00:15  time: 0.0795  loss: 1.5077 (1.5040)  bbox_regression: 0.1829 (0.1938)  classification: 1.3249 (1.3102)\n",
            "Epoch: [12] [110/289]  eta: 0:00:14  time: 0.0792  loss: 1.5145 (1.5087)  bbox_regression: 0.1890 (0.2259)  classification: 1.3255 (1.2828)\n",
            "Epoch: [12] [120/289]  eta: 0:00:13  time: 0.0791  loss: 1.5071 (1.5037)  bbox_regression: 0.1889 (0.2196)  classification: 1.3181 (1.2841)\n",
            "Epoch: [12] [130/289]  eta: 0:00:12  time: 0.0791  loss: 1.5165 (1.5278)  bbox_regression: 0.1921 (0.2092)  classification: 1.3245 (1.3186)\n",
            "Epoch: [12] [140/289]  eta: 0:00:11  time: 0.0791  loss: 1.4939 (1.4144)  bbox_regression: 0.1874 (0.1781)  classification: 1.3065 (1.2363)\n",
            "Epoch: [12] [150/289]  eta: 0:00:11  time: 0.0792  loss: 1.4978 (1.3753)  bbox_regression: 0.1871 (0.1543)  classification: 1.3107 (1.2210)\n",
            "Epoch: [12] [160/289]  eta: 0:00:10  time: 0.0794  loss: 1.4909 (1.4695)  bbox_regression: 0.1818 (0.1426)  classification: 1.3091 (1.3269)\n",
            "Epoch: [12] [170/289]  eta: 0:00:09  time: 0.0796  loss: 1.4810 (1.3540)  bbox_regression: 0.1773 (0.1036)  classification: 1.3037 (1.2504)\n",
            "Epoch: [12] [180/289]  eta: 0:00:08  time: 0.0797  loss: 1.4749 (1.3465)  bbox_regression: 0.1749 (0.1190)  classification: 1.3000 (1.2275)\n",
            "Epoch: [12] [190/289]  eta: 0:00:07  time: 0.0798  loss: 1.4674 (1.3513)  bbox_regression: 0.1714 (0.1213)  classification: 1.2960 (1.2300)\n",
            "Epoch: [12] [200/289]  eta: 0:00:07  time: 0.0796  loss: 1.4690 (1.4151)  bbox_regression: 0.1694 (0.1197)  classification: 1.2996 (1.2954)\n",
            "Epoch: [12] [210/289]  eta: 0:00:06  time: 0.0795  loss: 1.4690 (1.4837)  bbox_regression: 0.1686 (0.1418)  classification: 1.3003 (1.3419)\n",
            "Epoch: [12] [220/289]  eta: 0:00:05  time: 0.0795  loss: 1.4863 (1.6600)  bbox_regression: 0.1711 (0.1886)  classification: 1.3151 (1.4714)\n",
            "Epoch: [12] [230/289]  eta: 0:00:04  time: 0.0795  loss: 1.4728 (1.5137)  bbox_regression: 0.1678 (0.1595)  classification: 1.3050 (1.3542)\n",
            "Epoch: [12] [240/289]  eta: 0:00:03  time: 0.0794  loss: 1.4814 (1.4276)  bbox_regression: 0.1705 (0.1637)  classification: 1.3109 (1.2639)\n",
            "Epoch: [12] [250/289]  eta: 0:00:03  time: 0.0793  loss: 1.4872 (1.6528)  bbox_regression: 0.1717 (0.2161)  classification: 1.3155 (1.4367)\n",
            "Epoch: [12] [260/289]  eta: 0:00:02  time: 0.0792  loss: 1.4982 (1.7005)  bbox_regression: 0.1755 (0.2353)  classification: 1.3227 (1.4652)\n",
            "Epoch: [12] [270/289]  eta: 0:00:01  time: 0.0792  loss: 1.5019 (1.6869)  bbox_regression: 0.1768 (0.2411)  classification: 1.3251 (1.4458)\n",
            "Epoch: [12] [280/289]  eta: 0:00:00  time: 0.0792  loss: 1.4993 (1.5136)  bbox_regression: 0.1757 (0.1789)  classification: 1.3236 (1.3347)\n",
            "Epoch: [12] [288/289]  eta: 0:00:00  time: 0.0790  loss: 1.4903 (1.4088)  bbox_regression: 0.1731 (0.1506)  classification: 1.3173 (1.2582)\n",
            "Epoch: [12] Time: 0:00:22 (0.0790 s / it)\n",
            "Epoch: [13]\n",
            "Epoch: [13] [  0/289]  eta: 0:00:21  time: 0.0748  loss: 1.6650 (1.6650)  bbox_regression: 0.1568 (0.1568)  classification: 1.5082 (1.5082)\n",
            "Epoch: [13] [ 10/289]  eta: 0:00:21  time: 0.0755  loss: 1.4701 (1.4701)  bbox_regression: 0.1488 (0.1488)  classification: 1.3212 (1.3212)\n",
            "Epoch: [13] [ 20/289]  eta: 0:00:20  time: 0.0777  loss: 1.4534 (1.4428)  bbox_regression: 0.1243 (0.1227)  classification: 1.3291 (1.3202)\n",
            "Epoch: [13] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 1.4064 (1.3714)  bbox_regression: 0.1180 (0.1011)  classification: 1.2884 (1.2703)\n",
            "Epoch: [13] [ 40/289]  eta: 0:00:19  time: 0.0801  loss: 1.3644 (1.2709)  bbox_regression: 0.1094 (0.0938)  classification: 1.2550 (1.1771)\n",
            "Epoch: [13] [ 50/289]  eta: 0:00:19  time: 0.0799  loss: 1.3774 (1.3325)  bbox_regression: 0.1165 (0.1141)  classification: 1.2609 (1.2184)\n",
            "Epoch: [13] [ 60/289]  eta: 0:00:18  time: 0.0795  loss: 1.3989 (1.4696)  bbox_regression: 0.1301 (0.1725)  classification: 1.2688 (1.2971)\n",
            "Epoch: [13] [ 70/289]  eta: 0:00:17  time: 0.0793  loss: 1.3980 (1.4503)  bbox_regression: 0.1335 (0.1770)  classification: 1.2644 (1.2733)\n",
            "Epoch: [13] [ 80/289]  eta: 0:00:16  time: 0.0794  loss: 1.3868 (1.3502)  bbox_regression: 0.1278 (0.1210)  classification: 1.2590 (1.2292)\n",
            "Epoch: [13] [ 90/289]  eta: 0:00:15  time: 0.0794  loss: 1.3773 (1.3037)  bbox_regression: 0.1286 (0.1112)  classification: 1.2486 (1.1926)\n",
            "Epoch: [13] [100/289]  eta: 0:00:14  time: 0.0792  loss: 1.3586 (1.2443)  bbox_regression: 0.1261 (0.1189)  classification: 1.2326 (1.1254)\n",
            "Epoch: [13] [110/289]  eta: 0:00:14  time: 0.0791  loss: 1.3803 (1.3941)  bbox_regression: 0.1351 (0.1646)  classification: 1.2452 (1.2295)\n",
            "Epoch: [13] [120/289]  eta: 0:00:13  time: 0.0789  loss: 1.3830 (1.5061)  bbox_regression: 0.1384 (0.2008)  classification: 1.2446 (1.3053)\n",
            "Epoch: [13] [130/289]  eta: 0:00:12  time: 0.0789  loss: 1.3950 (1.4763)  bbox_regression: 0.1422 (0.1819)  classification: 1.2527 (1.2945)\n",
            "Epoch: [13] [140/289]  eta: 0:00:11  time: 0.0788  loss: 1.4118 (1.5863)  bbox_regression: 0.1467 (0.1970)  classification: 1.2651 (1.3894)\n",
            "Epoch: [13] [150/289]  eta: 0:00:10  time: 0.0788  loss: 1.4102 (1.5102)  bbox_regression: 0.1484 (0.1887)  classification: 1.2618 (1.3215)\n",
            "Epoch: [13] [160/289]  eta: 0:00:10  time: 0.0787  loss: 1.4073 (1.3753)  bbox_regression: 0.1455 (0.1372)  classification: 1.2618 (1.2381)\n",
            "Epoch: [13] [170/289]  eta: 0:00:09  time: 0.0788  loss: 1.4144 (1.4460)  bbox_regression: 0.1481 (0.1459)  classification: 1.2663 (1.3001)\n",
            "Epoch: [13] [180/289]  eta: 0:00:08  time: 0.0790  loss: 1.4158 (1.4838)  bbox_regression: 0.1505 (0.1908)  classification: 1.2652 (1.2929)\n",
            "Epoch: [13] [190/289]  eta: 0:00:07  time: 0.0789  loss: 1.4242 (1.5081)  bbox_regression: 0.1487 (0.1540)  classification: 1.2755 (1.3541)\n",
            "Epoch: [13] [200/289]  eta: 0:00:07  time: 0.0791  loss: 1.4452 (1.7113)  bbox_regression: 0.1572 (0.2173)  classification: 1.2880 (1.4939)\n",
            "Epoch: [13] [210/289]  eta: 0:00:06  time: 0.0792  loss: 1.4488 (1.6839)  bbox_regression: 0.1605 (0.2733)  classification: 1.2883 (1.4106)\n",
            "Epoch: [13] [220/289]  eta: 0:00:05  time: 0.0793  loss: 1.4500 (1.4982)  bbox_regression: 0.1605 (0.1936)  classification: 1.2895 (1.3046)\n",
            "Epoch: [13] [230/289]  eta: 0:00:04  time: 0.0791  loss: 1.4456 (1.4113)  bbox_regression: 0.1587 (0.1389)  classification: 1.2869 (1.2724)\n",
            "Epoch: [13] [240/289]  eta: 0:00:03  time: 0.0793  loss: 1.4628 (1.6050)  bbox_regression: 0.1651 (0.2164)  classification: 1.2977 (1.3885)\n",
            "Epoch: [13] [250/289]  eta: 0:00:03  time: 0.0793  loss: 1.4569 (1.5873)  bbox_regression: 0.1623 (0.2044)  classification: 1.2946 (1.3829)\n",
            "Epoch: [13] [260/289]  eta: 0:00:02  time: 0.0793  loss: 1.4540 (1.3482)  bbox_regression: 0.1609 (0.1099)  classification: 1.2931 (1.2383)\n",
            "Epoch: [13] [270/289]  eta: 0:00:01  time: 0.0792  loss: 1.4460 (1.3090)  bbox_regression: 0.1593 (0.1220)  classification: 1.2866 (1.1870)\n",
            "Epoch: [13] [280/289]  eta: 0:00:00  time: 0.0792  loss: 1.4473 (1.3593)  bbox_regression: 0.1601 (0.1497)  classification: 1.2872 (1.2096)\n",
            "Epoch: [13] [288/289]  eta: 0:00:00  time: 0.0791  loss: 1.4436 (1.3939)  bbox_regression: 0.1591 (0.1460)  classification: 1.2845 (1.2479)\n",
            "Epoch: [13] Time: 0:00:22 (0.0791 s / it)\n",
            "Epoch: [14]\n",
            "Epoch: [14] [  0/289]  eta: 0:00:24  time: 0.0850  loss: 1.8152 (1.8152)  bbox_regression: 0.3393 (0.3393)  classification: 1.4760 (1.4760)\n",
            "Epoch: [14] [ 10/289]  eta: 0:00:22  time: 0.0802  loss: 1.6166 (1.6166)  bbox_regression: 0.2345 (0.2345)  classification: 1.3821 (1.3821)\n",
            "Epoch: [14] [ 20/289]  eta: 0:00:21  time: 0.0800  loss: 1.4291 (1.4098)  bbox_regression: 0.1994 (0.1924)  classification: 1.2297 (1.2174)\n",
            "Epoch: [14] [ 30/289]  eta: 0:00:20  time: 0.0799  loss: 1.3705 (1.2352)  bbox_regression: 0.1719 (0.1375)  classification: 1.1986 (1.0977)\n",
            "Epoch: [14] [ 40/289]  eta: 0:00:19  time: 0.0798  loss: 1.3862 (1.3412)  bbox_regression: 0.1758 (0.1511)  classification: 1.2104 (1.1901)\n",
            "Epoch: [14] [ 50/289]  eta: 0:00:19  time: 0.0799  loss: 1.4019 (1.4506)  bbox_regression: 0.1693 (0.1653)  classification: 1.2326 (1.2854)\n",
            "Epoch: [14] [ 60/289]  eta: 0:00:18  time: 0.0792  loss: 1.4314 (1.5241)  bbox_regression: 0.1816 (0.1934)  classification: 1.2498 (1.3307)\n",
            "Epoch: [14] [ 70/289]  eta: 0:00:17  time: 0.0794  loss: 1.4013 (1.3996)  bbox_regression: 0.1688 (0.1674)  classification: 1.2325 (1.2322)\n",
            "Epoch: [14] [ 80/289]  eta: 0:00:16  time: 0.0791  loss: 1.4088 (1.3397)  bbox_regression: 0.1652 (0.1153)  classification: 1.2435 (1.2244)\n",
            "Epoch: [14] [ 90/289]  eta: 0:00:15  time: 0.0790  loss: 1.4199 (1.4860)  bbox_regression: 0.1668 (0.1596)  classification: 1.2532 (1.3264)\n",
            "Epoch: [14] [100/289]  eta: 0:00:14  time: 0.0786  loss: 1.3927 (1.3274)  bbox_regression: 0.1597 (0.1373)  classification: 1.2330 (1.1901)\n",
            "Epoch: [14] [110/289]  eta: 0:00:14  time: 0.0787  loss: 1.3903 (1.2554)  bbox_regression: 0.1530 (0.0906)  classification: 1.2372 (1.1648)\n",
            "Epoch: [14] [120/289]  eta: 0:00:13  time: 0.0788  loss: 1.3716 (1.2654)  bbox_regression: 0.1482 (0.0899)  classification: 1.2235 (1.1755)\n",
            "Epoch: [14] [130/289]  eta: 0:00:12  time: 0.0786  loss: 1.3569 (1.1715)  bbox_regression: 0.1460 (0.1069)  classification: 1.2109 (1.0646)\n",
            "Epoch: [14] [140/289]  eta: 0:00:11  time: 0.0786  loss: 1.3634 (1.3139)  bbox_regression: 0.1469 (0.1392)  classification: 1.2166 (1.1748)\n",
            "Epoch: [14] [150/289]  eta: 0:00:10  time: 0.0786  loss: 1.3721 (1.4717)  bbox_regression: 0.1471 (0.1541)  classification: 1.2250 (1.3175)\n",
            "Epoch: [14] [160/289]  eta: 0:00:10  time: 0.0787  loss: 1.3969 (1.6331)  bbox_regression: 0.1590 (0.2441)  classification: 1.2380 (1.3890)\n",
            "Epoch: [14] [170/289]  eta: 0:00:09  time: 0.0787  loss: 1.3975 (1.5892)  bbox_regression: 0.1586 (0.2456)  classification: 1.2389 (1.3436)\n",
            "Epoch: [14] [180/289]  eta: 0:00:08  time: 0.0786  loss: 1.4088 (1.5043)  bbox_regression: 0.1592 (0.1612)  classification: 1.2496 (1.3431)\n",
            "Epoch: [14] [190/289]  eta: 0:00:07  time: 0.0786  loss: 1.4130 (1.5458)  bbox_regression: 0.1590 (0.1627)  classification: 1.2540 (1.3831)\n",
            "Epoch: [14] [200/289]  eta: 0:00:07  time: 0.0787  loss: 1.4130 (1.4512)  bbox_regression: 0.1613 (0.1803)  classification: 1.2517 (1.2709)\n",
            "Epoch: [14] [210/289]  eta: 0:00:06  time: 0.0788  loss: 1.4128 (1.4106)  bbox_regression: 0.1633 (0.2041)  classification: 1.2495 (1.2065)\n",
            "Epoch: [14] [220/289]  eta: 0:00:05  time: 0.0788  loss: 1.4189 (1.4785)  bbox_regression: 0.1618 (0.1668)  classification: 1.2571 (1.3117)\n",
            "Epoch: [14] [230/289]  eta: 0:00:04  time: 0.0787  loss: 1.4288 (1.5977)  bbox_regression: 0.1635 (0.1660)  classification: 1.2653 (1.4316)\n",
            "Epoch: [14] [240/289]  eta: 0:00:03  time: 0.0786  loss: 1.4232 (1.4701)  bbox_regression: 0.1633 (0.1803)  classification: 1.2598 (1.2898)\n",
            "Epoch: [14] [250/289]  eta: 0:00:03  time: 0.0786  loss: 1.4270 (1.4070)  bbox_regression: 0.1642 (0.1720)  classification: 1.2628 (1.2350)\n",
            "Epoch: [14] [260/289]  eta: 0:00:02  time: 0.0786  loss: 1.4248 (1.4438)  bbox_regression: 0.1630 (0.1583)  classification: 1.2618 (1.2855)\n",
            "Epoch: [14] [270/289]  eta: 0:00:01  time: 0.0786  loss: 1.4265 (1.4193)  bbox_regression: 0.1619 (0.1330)  classification: 1.2646 (1.2863)\n",
            "Epoch: [14] [280/289]  eta: 0:00:00  time: 0.0787  loss: 1.4211 (1.3733)  bbox_regression: 0.1613 (0.1400)  classification: 1.2598 (1.2333)\n",
            "Epoch: [14] [288/289]  eta: 0:00:00  time: 0.0784  loss: 1.4155 (1.2463)  bbox_regression: 0.1604 (0.1348)  classification: 1.2551 (1.1115)\n",
            "Epoch: [14] Time: 0:00:22 (0.0785 s / it)\n",
            "Validation: [14]\n",
            "Validation: [14] [ 0/62]  eta: 0:00:04  time: 0.0677  \n",
            "Validation: [14] [10/62]  eta: 0:00:03  time: 0.0669  \n",
            "Validation: [14] [20/62]  eta: 0:00:02  time: 0.0657  \n",
            "Validation: [14] [30/62]  eta: 0:00:02  time: 0.0662  \n",
            "Validation: [14] [40/62]  eta: 0:00:01  time: 0.0668  \n",
            "Validation: [14] [50/62]  eta: 0:00:00  time: 0.0672  \n",
            "Validation: [14] [60/62]  eta: 0:00:00  time: 0.0678  \n",
            "Validation: [14] [61/62]  eta: 0:00:00  time: 0.0674  \n",
            "Validation: [14] Time: 0:00:04 (0.0674 s / it)\n",
            "Epoch 14: mAP = 0.7666\n",
            "Saved best model with mAP: 0.7666\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/best_model.pth\n",
            "Epoch: [15]\n",
            "Epoch: [15] [  0/289]  eta: 0:00:25  time: 0.0869  loss: 1.3009 (1.3009)  bbox_regression: 0.1784 (0.1784)  classification: 1.1225 (1.1225)\n",
            "Epoch: [15] [ 10/289]  eta: 0:00:22  time: 0.0817  loss: 1.3498 (1.3498)  bbox_regression: 0.1303 (0.1303)  classification: 1.2195 (1.2195)\n",
            "Epoch: [15] [ 20/289]  eta: 0:00:21  time: 0.0803  loss: 1.2690 (1.2674)  bbox_regression: 0.1266 (0.1240)  classification: 1.1424 (1.1434)\n",
            "Epoch: [15] [ 30/289]  eta: 0:00:20  time: 0.0796  loss: 1.2528 (1.1994)  bbox_regression: 0.1320 (0.1330)  classification: 1.1208 (1.0665)\n",
            "Epoch: [15] [ 40/289]  eta: 0:00:19  time: 0.0791  loss: 1.2489 (1.2279)  bbox_regression: 0.1250 (0.1234)  classification: 1.1239 (1.1045)\n",
            "Epoch: [15] [ 50/289]  eta: 0:00:18  time: 0.0794  loss: 1.2976 (1.3672)  bbox_regression: 0.1392 (0.1504)  classification: 1.1584 (1.2168)\n",
            "Epoch: [15] [ 60/289]  eta: 0:00:18  time: 0.0796  loss: 1.2897 (1.3733)  bbox_regression: 0.1418 (0.1762)  classification: 1.1479 (1.1971)\n",
            "Epoch: [15] [ 70/289]  eta: 0:00:17  time: 0.0794  loss: 1.2773 (1.2255)  bbox_regression: 0.1410 (0.1456)  classification: 1.1363 (1.0799)\n",
            "Epoch: [15] [ 80/289]  eta: 0:00:16  time: 0.0790  loss: 1.2598 (1.1686)  bbox_regression: 0.1373 (0.1234)  classification: 1.1225 (1.0452)\n",
            "Epoch: [15] [ 90/289]  eta: 0:00:15  time: 0.0788  loss: 1.2619 (1.2072)  bbox_regression: 0.1340 (0.1090)  classification: 1.1279 (1.0982)\n",
            "Epoch: [15] [100/289]  eta: 0:00:14  time: 0.0789  loss: 1.2465 (1.1928)  bbox_regression: 0.1269 (0.0851)  classification: 1.1196 (1.1077)\n",
            "Epoch: [15] [110/289]  eta: 0:00:14  time: 0.0790  loss: 1.2322 (1.0971)  bbox_regression: 0.1248 (0.0830)  classification: 1.1074 (1.0141)\n",
            "Epoch: [15] [120/289]  eta: 0:00:13  time: 0.0790  loss: 1.2210 (1.0921)  bbox_regression: 0.1195 (0.0817)  classification: 1.1015 (1.0104)\n",
            "Epoch: [15] [130/289]  eta: 0:00:12  time: 0.0794  loss: 1.2030 (1.0410)  bbox_regression: 0.1172 (0.0748)  classification: 1.0859 (0.9662)\n",
            "Epoch: [15] [140/289]  eta: 0:00:11  time: 0.0799  loss: 1.1969 (1.0513)  bbox_regression: 0.1142 (0.0826)  classification: 1.0827 (0.9687)\n",
            "Epoch: [15] [150/289]  eta: 0:00:11  time: 0.0804  loss: 1.2023 (1.1975)  bbox_regression: 0.1146 (0.0981)  classification: 1.0876 (1.0994)\n",
            "Epoch: [15] [160/289]  eta: 0:00:10  time: 0.0804  loss: 1.1895 (1.1374)  bbox_regression: 0.1100 (0.0806)  classification: 1.0795 (1.0569)\n",
            "Epoch: [15] [170/289]  eta: 0:00:09  time: 0.0803  loss: 1.1823 (1.0316)  bbox_regression: 0.1073 (0.0515)  classification: 1.0751 (0.9801)\n",
            "Epoch: [15] [180/289]  eta: 0:00:08  time: 0.0802  loss: 1.1740 (1.0490)  bbox_regression: 0.1038 (0.0534)  classification: 1.0702 (0.9956)\n",
            "Epoch: [15] [190/289]  eta: 0:00:07  time: 0.0802  loss: 1.1668 (1.0337)  bbox_regression: 0.1023 (0.0598)  classification: 1.0645 (0.9739)\n",
            "Epoch: [15] [200/289]  eta: 0:00:07  time: 0.0802  loss: 1.1727 (1.1611)  bbox_regression: 0.1073 (0.1395)  classification: 1.0654 (1.0217)\n",
            "Epoch: [15] [210/289]  eta: 0:00:06  time: 0.0801  loss: 1.1716 (1.2179)  bbox_regression: 0.1068 (0.1497)  classification: 1.0648 (1.0682)\n",
            "Epoch: [15] [220/289]  eta: 0:00:05  time: 0.0801  loss: 1.1666 (1.1046)  bbox_regression: 0.1043 (0.0733)  classification: 1.0623 (1.0313)\n",
            "Epoch: [15] [230/289]  eta: 0:00:04  time: 0.0800  loss: 1.1638 (1.0819)  bbox_regression: 0.1046 (0.0817)  classification: 1.0592 (1.0002)\n",
            "Epoch: [15] [240/289]  eta: 0:00:03  time: 0.0800  loss: 1.1626 (1.1184)  bbox_regression: 0.1051 (0.1149)  classification: 1.0574 (1.0035)\n",
            "Epoch: [15] [250/289]  eta: 0:00:03  time: 0.0799  loss: 1.1544 (1.0452)  bbox_regression: 0.1030 (0.0844)  classification: 1.0514 (0.9607)\n",
            "Epoch: [15] [260/289]  eta: 0:00:02  time: 0.0799  loss: 1.1587 (1.1125)  bbox_regression: 0.1041 (0.0919)  classification: 1.0546 (1.0206)\n",
            "Epoch: [15] [270/289]  eta: 0:00:01  time: 0.0799  loss: 1.1608 (1.2416)  bbox_regression: 0.1022 (0.0927)  classification: 1.0586 (1.1489)\n",
            "Epoch: [15] [280/289]  eta: 0:00:00  time: 0.0799  loss: 1.1549 (1.1055)  bbox_regression: 0.1004 (0.0517)  classification: 1.0545 (1.0538)\n",
            "Epoch: [15] [288/289]  eta: 0:00:00  time: 0.0798  loss: 1.1556 (1.0661)  bbox_regression: 0.1013 (0.0871)  classification: 1.0543 (0.9791)\n",
            "Epoch: [15] Time: 0:00:23 (0.0798 s / it)\n",
            "Epoch: [16]\n",
            "Epoch: [16] [  0/289]  eta: 0:00:25  time: 0.0888  loss: 1.0073 (1.0073)  bbox_regression: 0.0381 (0.0381)  classification: 0.9692 (0.9692)\n",
            "Epoch: [16] [ 10/289]  eta: 0:00:23  time: 0.0837  loss: 0.9069 (0.9069)  bbox_regression: 0.0409 (0.0409)  classification: 0.8660 (0.8660)\n",
            "Epoch: [16] [ 20/289]  eta: 0:00:21  time: 0.0815  loss: 0.9700 (0.9681)  bbox_regression: 0.0491 (0.0497)  classification: 0.9208 (0.9184)\n",
            "Epoch: [16] [ 30/289]  eta: 0:00:21  time: 0.0816  loss: 0.9912 (1.0375)  bbox_regression: 0.0427 (0.0436)  classification: 0.9485 (0.9939)\n",
            "Epoch: [16] [ 40/289]  eta: 0:00:20  time: 0.0807  loss: 1.0414 (1.1164)  bbox_regression: 0.0597 (0.0709)  classification: 0.9817 (1.0455)\n",
            "Epoch: [16] [ 50/289]  eta: 0:00:19  time: 0.0802  loss: 1.0319 (1.0950)  bbox_regression: 0.0609 (0.0891)  classification: 0.9710 (1.0059)\n",
            "Epoch: [16] [ 60/289]  eta: 0:00:18  time: 0.0804  loss: 1.0246 (0.9901)  bbox_regression: 0.0654 (0.0771)  classification: 0.9591 (0.9130)\n",
            "Epoch: [16] [ 70/289]  eta: 0:00:17  time: 0.0799  loss: 1.0376 (1.0522)  bbox_regression: 0.0688 (0.0890)  classification: 0.9688 (0.9633)\n",
            "Epoch: [16] [ 80/289]  eta: 0:00:16  time: 0.0799  loss: 1.0503 (1.1290)  bbox_regression: 0.0671 (0.0722)  classification: 0.9833 (1.0569)\n",
            "Epoch: [16] [ 90/289]  eta: 0:00:15  time: 0.0797  loss: 1.0389 (1.0434)  bbox_regression: 0.0673 (0.0618)  classification: 0.9716 (0.9816)\n",
            "Epoch: [16] [100/289]  eta: 0:00:14  time: 0.0793  loss: 1.0436 (1.0161)  bbox_regression: 0.0666 (0.0645)  classification: 0.9770 (0.9516)\n",
            "Epoch: [16] [110/289]  eta: 0:00:14  time: 0.0795  loss: 1.0490 (1.0949)  bbox_regression: 0.0680 (0.0711)  classification: 0.9810 (1.0238)\n",
            "Epoch: [16] [120/289]  eta: 0:00:13  time: 0.0795  loss: 1.0652 (1.1744)  bbox_regression: 0.0724 (0.1019)  classification: 0.9928 (1.0724)\n",
            "Epoch: [16] [130/289]  eta: 0:00:12  time: 0.0794  loss: 1.0600 (1.1214)  bbox_regression: 0.0691 (0.0756)  classification: 0.9909 (1.0459)\n",
            "Epoch: [16] [140/289]  eta: 0:00:11  time: 0.0795  loss: 1.0511 (0.9659)  bbox_regression: 0.0691 (0.0492)  classification: 0.9820 (0.9167)\n",
            "Epoch: [16] [150/289]  eta: 0:00:11  time: 0.0794  loss: 1.0489 (0.9761)  bbox_regression: 0.0711 (0.0840)  classification: 0.9778 (0.8921)\n",
            "Epoch: [16] [160/289]  eta: 0:00:10  time: 0.0795  loss: 1.0528 (1.0647)  bbox_regression: 0.0728 (0.0989)  classification: 0.9800 (0.9658)\n",
            "Epoch: [16] [170/289]  eta: 0:00:09  time: 0.0793  loss: 1.0515 (1.0708)  bbox_regression: 0.0724 (0.0827)  classification: 0.9790 (0.9881)\n",
            "Epoch: [16] [180/289]  eta: 0:00:08  time: 0.0793  loss: 1.0518 (1.0437)  bbox_regression: 0.0725 (0.0696)  classification: 0.9793 (0.9741)\n",
            "Epoch: [16] [190/289]  eta: 0:00:07  time: 0.0792  loss: 1.0533 (1.0691)  bbox_regression: 0.0723 (0.0715)  classification: 0.9810 (0.9976)\n",
            "Epoch: [16] [200/289]  eta: 0:00:07  time: 0.0791  loss: 1.0505 (1.0384)  bbox_regression: 0.0728 (0.0762)  classification: 0.9776 (0.9622)\n",
            "Epoch: [16] [210/289]  eta: 0:00:06  time: 0.0790  loss: 1.0492 (1.0098)  bbox_regression: 0.0728 (0.0776)  classification: 0.9764 (0.9322)\n",
            "Epoch: [16] [220/289]  eta: 0:00:05  time: 0.0789  loss: 1.0526 (1.0742)  bbox_regression: 0.0730 (0.0743)  classification: 0.9796 (0.9999)\n",
            "Epoch: [16] [230/289]  eta: 0:00:04  time: 0.0789  loss: 1.0484 (1.0392)  bbox_regression: 0.0746 (0.0935)  classification: 0.9737 (0.9458)\n",
            "Epoch: [16] [240/289]  eta: 0:00:03  time: 0.0789  loss: 1.0487 (1.0053)  bbox_regression: 0.0749 (0.0958)  classification: 0.9738 (0.9095)\n",
            "Epoch: [16] [250/289]  eta: 0:00:03  time: 0.0789  loss: 1.0498 (1.0665)  bbox_regression: 0.0744 (0.0714)  classification: 0.9754 (0.9952)\n",
            "Epoch: [16] [260/289]  eta: 0:00:02  time: 0.0788  loss: 1.0579 (1.1691)  bbox_regression: 0.0782 (0.1182)  classification: 0.9797 (1.0508)\n",
            "Epoch: [16] [270/289]  eta: 0:00:01  time: 0.0788  loss: 1.0531 (1.0950)  bbox_regression: 0.0768 (0.1066)  classification: 0.9764 (0.9883)\n",
            "Epoch: [16] [280/289]  eta: 0:00:00  time: 0.0788  loss: 1.0562 (1.0342)  bbox_regression: 0.0782 (0.0787)  classification: 0.9780 (0.9554)\n",
            "Epoch: [16] [288/289]  eta: 0:00:00  time: 0.0786  loss: 1.0557 (1.0654)  bbox_regression: 0.0797 (0.1139)  classification: 0.9760 (0.9515)\n",
            "Epoch: [16] Time: 0:00:22 (0.0786 s / it)\n",
            "Epoch: [17]\n",
            "Epoch: [17] [  0/289]  eta: 0:00:22  time: 0.0769  loss: 0.8932 (0.8932)  bbox_regression: 0.0675 (0.0675)  classification: 0.8257 (0.8257)\n",
            "Epoch: [17] [ 10/289]  eta: 0:00:21  time: 0.0777  loss: 1.0333 (1.0333)  bbox_regression: 0.0754 (0.0754)  classification: 0.9579 (0.9579)\n",
            "Epoch: [17] [ 20/289]  eta: 0:00:20  time: 0.0773  loss: 1.0225 (1.0290)  bbox_regression: 0.0632 (0.0630)  classification: 0.9593 (0.9660)\n",
            "Epoch: [17] [ 30/289]  eta: 0:00:20  time: 0.0786  loss: 1.0160 (1.0065)  bbox_regression: 0.0617 (0.0541)  classification: 0.9544 (0.9524)\n",
            "Epoch: [17] [ 40/289]  eta: 0:00:19  time: 0.0790  loss: 0.9941 (0.9642)  bbox_regression: 0.0569 (0.0503)  classification: 0.9372 (0.9139)\n",
            "Epoch: [17] [ 50/289]  eta: 0:00:18  time: 0.0790  loss: 1.0175 (1.0199)  bbox_regression: 0.0553 (0.0456)  classification: 0.9622 (0.9743)\n",
            "Epoch: [17] [ 60/289]  eta: 0:00:18  time: 0.0790  loss: 1.0686 (1.2214)  bbox_regression: 0.0720 (0.1029)  classification: 0.9966 (1.1185)\n",
            "Epoch: [17] [ 70/289]  eta: 0:00:17  time: 0.0791  loss: 1.0555 (1.1523)  bbox_regression: 0.0675 (0.0984)  classification: 0.9880 (1.0538)\n",
            "Epoch: [17] [ 80/289]  eta: 0:00:16  time: 0.0792  loss: 1.0409 (0.9564)  bbox_regression: 0.0668 (0.0509)  classification: 0.9741 (0.9055)\n",
            "Epoch: [17] [ 90/289]  eta: 0:00:15  time: 0.0790  loss: 1.0351 (0.9628)  bbox_regression: 0.0653 (0.0574)  classification: 0.9698 (0.9054)\n",
            "Epoch: [17] [100/289]  eta: 0:00:14  time: 0.0787  loss: 1.0227 (0.9490)  bbox_regression: 0.0666 (0.0656)  classification: 0.9562 (0.8834)\n",
            "Epoch: [17] [110/289]  eta: 0:00:14  time: 0.0787  loss: 1.0149 (0.9230)  bbox_regression: 0.0657 (0.0677)  classification: 0.9492 (0.8553)\n",
            "Epoch: [17] [120/289]  eta: 0:00:13  time: 0.0787  loss: 1.0157 (0.9803)  bbox_regression: 0.0676 (0.0729)  classification: 0.9481 (0.9074)\n",
            "Epoch: [17] [130/289]  eta: 0:00:12  time: 0.0786  loss: 1.0154 (1.0179)  bbox_regression: 0.0672 (0.0756)  classification: 0.9482 (0.9423)\n",
            "Epoch: [17] [140/289]  eta: 0:00:11  time: 0.0784  loss: 1.0127 (0.9945)  bbox_regression: 0.0667 (0.0609)  classification: 0.9460 (0.9336)\n",
            "Epoch: [17] [150/289]  eta: 0:00:10  time: 0.0786  loss: 1.0087 (0.9653)  bbox_regression: 0.0666 (0.0627)  classification: 0.9421 (0.9026)\n",
            "Epoch: [17] [160/289]  eta: 0:00:10  time: 0.0785  loss: 1.0076 (0.9715)  bbox_regression: 0.0667 (0.0672)  classification: 0.9409 (0.9043)\n",
            "Epoch: [17] [170/289]  eta: 0:00:09  time: 0.0784  loss: 1.0015 (0.9465)  bbox_regression: 0.0649 (0.0522)  classification: 0.9365 (0.8943)\n",
            "Epoch: [17] [180/289]  eta: 0:00:08  time: 0.0786  loss: 1.0030 (0.9657)  bbox_regression: 0.0663 (0.0627)  classification: 0.9367 (0.9030)\n",
            "Epoch: [17] [190/289]  eta: 0:00:07  time: 0.0787  loss: 1.0018 (1.0044)  bbox_regression: 0.0660 (0.0752)  classification: 0.9358 (0.9292)\n",
            "Epoch: [17] [200/289]  eta: 0:00:07  time: 0.0787  loss: 1.0016 (0.9895)  bbox_regression: 0.0676 (0.0799)  classification: 0.9340 (0.9097)\n",
            "Epoch: [17] [210/289]  eta: 0:00:06  time: 0.0789  loss: 1.0043 (1.0281)  bbox_regression: 0.0705 (0.1129)  classification: 0.9338 (0.9151)\n",
            "Epoch: [17] [220/289]  eta: 0:00:05  time: 0.0789  loss: 1.0052 (1.0415)  bbox_regression: 0.0701 (0.0950)  classification: 0.9351 (0.9465)\n",
            "Epoch: [17] [230/289]  eta: 0:00:04  time: 0.0789  loss: 1.0053 (1.0163)  bbox_regression: 0.0716 (0.0840)  classification: 0.9337 (0.9323)\n",
            "Epoch: [17] [240/289]  eta: 0:00:03  time: 0.0789  loss: 1.0066 (1.0214)  bbox_regression: 0.0714 (0.0855)  classification: 0.9352 (0.9359)\n",
            "Epoch: [17] [250/289]  eta: 0:00:03  time: 0.0789  loss: 1.0025 (0.9694)  bbox_regression: 0.0705 (0.0571)  classification: 0.9320 (0.9123)\n",
            "Epoch: [17] [260/289]  eta: 0:00:02  time: 0.0789  loss: 1.0038 (0.9709)  bbox_regression: 0.0717 (0.0749)  classification: 0.9322 (0.8960)\n",
            "Epoch: [17] [270/289]  eta: 0:00:01  time: 0.0788  loss: 1.0036 (1.0181)  bbox_regression: 0.0708 (0.0749)  classification: 0.9328 (0.9432)\n",
            "Epoch: [17] [280/289]  eta: 0:00:00  time: 0.0789  loss: 1.0031 (0.9929)  bbox_regression: 0.0713 (0.0665)  classification: 0.9318 (0.9264)\n",
            "Epoch: [17] [288/289]  eta: 0:00:00  time: 0.0787  loss: 1.0063 (1.0564)  bbox_regression: 0.0712 (0.0813)  classification: 0.9351 (0.9751)\n",
            "Epoch: [17] Time: 0:00:22 (0.0787 s / it)\n",
            "Epoch: [18]\n",
            "Epoch: [18] [  0/289]  eta: 0:00:21  time: 0.0738  loss: 1.0767 (1.0767)  bbox_regression: 0.0276 (0.0276)  classification: 1.0491 (1.0491)\n",
            "Epoch: [18] [ 10/289]  eta: 0:00:21  time: 0.0758  loss: 0.9098 (0.9098)  bbox_regression: 0.0571 (0.0571)  classification: 0.8527 (0.8527)\n",
            "Epoch: [18] [ 20/289]  eta: 0:00:20  time: 0.0763  loss: 0.9536 (0.9474)  bbox_regression: 0.0545 (0.0559)  classification: 0.8990 (0.8915)\n",
            "Epoch: [18] [ 30/289]  eta: 0:00:20  time: 0.0776  loss: 0.9584 (0.9852)  bbox_regression: 0.0714 (0.0793)  classification: 0.8870 (0.9059)\n",
            "Epoch: [18] [ 40/289]  eta: 0:00:19  time: 0.0783  loss: 1.0028 (1.0546)  bbox_regression: 0.0772 (0.1011)  classification: 0.9256 (0.9535)\n",
            "Epoch: [18] [ 50/289]  eta: 0:00:18  time: 0.0788  loss: 0.9758 (1.0028)  bbox_regression: 0.0727 (0.0747)  classification: 0.9031 (0.9281)\n",
            "Epoch: [18] [ 60/289]  eta: 0:00:18  time: 0.0788  loss: 0.9668 (0.8928)  bbox_regression: 0.0725 (0.0627)  classification: 0.8943 (0.8301)\n",
            "Epoch: [18] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.9708 (0.9580)  bbox_regression: 0.0726 (0.0723)  classification: 0.8982 (0.8858)\n",
            "Epoch: [18] [ 80/289]  eta: 0:00:16  time: 0.0789  loss: 0.9886 (1.0554)  bbox_regression: 0.0734 (0.0761)  classification: 0.9153 (0.9793)\n",
            "Epoch: [18] [ 90/289]  eta: 0:00:15  time: 0.0789  loss: 0.9819 (1.0212)  bbox_regression: 0.0742 (0.0798)  classification: 0.9077 (0.9414)\n",
            "Epoch: [18] [100/289]  eta: 0:00:14  time: 0.0790  loss: 0.9689 (0.8891)  bbox_regression: 0.0705 (0.0590)  classification: 0.8984 (0.8301)\n",
            "Epoch: [18] [110/289]  eta: 0:00:14  time: 0.0790  loss: 0.9744 (0.9402)  bbox_regression: 0.0687 (0.0437)  classification: 0.9057 (0.8965)\n",
            "Epoch: [18] [120/289]  eta: 0:00:13  time: 0.0791  loss: 0.9772 (1.0192)  bbox_regression: 0.0690 (0.0611)  classification: 0.9083 (0.9580)\n",
            "Epoch: [18] [130/289]  eta: 0:00:12  time: 0.0792  loss: 0.9648 (0.9114)  bbox_regression: 0.0659 (0.0507)  classification: 0.8988 (0.8607)\n",
            "Epoch: [18] [140/289]  eta: 0:00:11  time: 0.0791  loss: 0.9656 (0.8951)  bbox_regression: 0.0640 (0.0340)  classification: 0.9016 (0.8611)\n",
            "Epoch: [18] [150/289]  eta: 0:00:10  time: 0.0791  loss: 0.9611 (0.9368)  bbox_regression: 0.0651 (0.0593)  classification: 0.8960 (0.8775)\n",
            "Epoch: [18] [160/289]  eta: 0:00:10  time: 0.0790  loss: 0.9575 (0.9003)  bbox_regression: 0.0659 (0.0791)  classification: 0.8916 (0.8211)\n",
            "Epoch: [18] [170/289]  eta: 0:00:09  time: 0.0791  loss: 0.9492 (0.8600)  bbox_regression: 0.0653 (0.0668)  classification: 0.8840 (0.7932)\n",
            "Epoch: [18] [180/289]  eta: 0:00:08  time: 0.0790  loss: 0.9558 (0.9420)  bbox_regression: 0.0661 (0.0680)  classification: 0.8896 (0.8740)\n",
            "Epoch: [18] [190/289]  eta: 0:00:07  time: 0.0790  loss: 0.9583 (1.0356)  bbox_regression: 0.0647 (0.0597)  classification: 0.8936 (0.9759)\n",
            "Epoch: [18] [200/289]  eta: 0:00:07  time: 0.0791  loss: 0.9536 (0.9339)  bbox_regression: 0.0632 (0.0367)  classification: 0.8904 (0.8972)\n",
            "Epoch: [18] [210/289]  eta: 0:00:06  time: 0.0792  loss: 0.9589 (0.9652)  bbox_regression: 0.0661 (0.0793)  classification: 0.8929 (0.8859)\n",
            "Epoch: [18] [220/289]  eta: 0:00:05  time: 0.0791  loss: 0.9616 (1.0418)  bbox_regression: 0.0646 (0.0788)  classification: 0.8970 (0.9630)\n",
            "Epoch: [18] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.9646 (1.0238)  bbox_regression: 0.0642 (0.0441)  classification: 0.9004 (0.9797)\n",
            "Epoch: [18] [240/289]  eta: 0:00:03  time: 0.0790  loss: 0.9696 (1.0584)  bbox_regression: 0.0674 (0.0988)  classification: 0.9022 (0.9596)\n",
            "Epoch: [18] [250/289]  eta: 0:00:03  time: 0.0791  loss: 0.9672 (0.9979)  bbox_regression: 0.0676 (0.1072)  classification: 0.8996 (0.8907)\n",
            "Epoch: [18] [260/289]  eta: 0:00:02  time: 0.0790  loss: 0.9623 (0.8744)  bbox_regression: 0.0668 (0.0596)  classification: 0.8955 (0.8148)\n",
            "Epoch: [18] [270/289]  eta: 0:00:01  time: 0.0789  loss: 0.9566 (0.8229)  bbox_regression: 0.0656 (0.0403)  classification: 0.8910 (0.7826)\n",
            "Epoch: [18] [280/289]  eta: 0:00:00  time: 0.0790  loss: 0.9573 (0.8919)  bbox_regression: 0.0660 (0.0549)  classification: 0.8913 (0.8370)\n",
            "Epoch: [18] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.9593 (0.9897)  bbox_regression: 0.0659 (0.0660)  classification: 0.8934 (0.9236)\n",
            "Epoch: [18] Time: 0:00:22 (0.0789 s / it)\n",
            "Epoch: [19]\n",
            "Epoch: [19] [  0/289]  eta: 0:00:22  time: 0.0788  loss: 0.7406 (0.7406)  bbox_regression: 0.0193 (0.0193)  classification: 0.7213 (0.7213)\n",
            "Epoch: [19] [ 10/289]  eta: 0:00:21  time: 0.0780  loss: 0.9025 (0.9025)  bbox_regression: 0.0780 (0.0780)  classification: 0.8244 (0.8244)\n",
            "Epoch: [19] [ 20/289]  eta: 0:00:21  time: 0.0798  loss: 0.9222 (0.9313)  bbox_regression: 0.0692 (0.0717)  classification: 0.8531 (0.8596)\n",
            "Epoch: [19] [ 30/289]  eta: 0:00:20  time: 0.0799  loss: 0.9273 (0.9409)  bbox_regression: 0.0650 (0.0578)  classification: 0.8623 (0.8831)\n",
            "Epoch: [19] [ 40/289]  eta: 0:00:19  time: 0.0798  loss: 0.8923 (0.8610)  bbox_regression: 0.0568 (0.0439)  classification: 0.8355 (0.8171)\n",
            "Epoch: [19] [ 50/289]  eta: 0:00:19  time: 0.0796  loss: 0.9013 (0.8610)  bbox_regression: 0.0559 (0.0418)  classification: 0.8454 (0.8193)\n",
            "Epoch: [19] [ 60/289]  eta: 0:00:18  time: 0.0801  loss: 0.8977 (0.9087)  bbox_regression: 0.0569 (0.0570)  classification: 0.8408 (0.8518)\n",
            "Epoch: [19] [ 70/289]  eta: 0:00:17  time: 0.0802  loss: 0.9205 (0.9694)  bbox_regression: 0.0671 (0.0957)  classification: 0.8534 (0.8737)\n",
            "Epoch: [19] [ 80/289]  eta: 0:00:16  time: 0.0801  loss: 0.9024 (0.9169)  bbox_regression: 0.0645 (0.0879)  classification: 0.8379 (0.8290)\n",
            "Epoch: [19] [ 90/289]  eta: 0:00:15  time: 0.0799  loss: 0.8895 (0.7794)  bbox_regression: 0.0636 (0.0510)  classification: 0.8259 (0.7284)\n",
            "Epoch: [19] [100/289]  eta: 0:00:15  time: 0.0796  loss: 0.8895 (0.8372)  bbox_regression: 0.0638 (0.0606)  classification: 0.8258 (0.7766)\n",
            "Epoch: [19] [110/289]  eta: 0:00:14  time: 0.0794  loss: 0.9058 (0.9799)  bbox_regression: 0.0645 (0.0686)  classification: 0.8413 (0.9112)\n",
            "Epoch: [19] [120/289]  eta: 0:00:13  time: 0.0792  loss: 0.9033 (0.9729)  bbox_regression: 0.0639 (0.0645)  classification: 0.8394 (0.9084)\n",
            "Epoch: [19] [130/289]  eta: 0:00:12  time: 0.0792  loss: 0.9174 (0.9817)  bbox_regression: 0.0689 (0.0933)  classification: 0.8485 (0.8884)\n",
            "Epoch: [19] [140/289]  eta: 0:00:11  time: 0.0791  loss: 0.9121 (0.9651)  bbox_regression: 0.0673 (0.0881)  classification: 0.8448 (0.8770)\n",
            "Epoch: [19] [150/289]  eta: 0:00:10  time: 0.0790  loss: 0.9076 (0.8439)  bbox_regression: 0.0662 (0.0488)  classification: 0.8414 (0.7951)\n",
            "Epoch: [19] [160/289]  eta: 0:00:10  time: 0.0789  loss: 0.9099 (0.8946)  bbox_regression: 0.0650 (0.0486)  classification: 0.8449 (0.8460)\n",
            "Epoch: [19] [170/289]  eta: 0:00:09  time: 0.0791  loss: 0.9181 (0.9975)  bbox_regression: 0.0651 (0.0564)  classification: 0.8531 (0.9410)\n",
            "Epoch: [19] [180/289]  eta: 0:00:08  time: 0.0791  loss: 0.9151 (0.9571)  bbox_regression: 0.0645 (0.0607)  classification: 0.8506 (0.8964)\n",
            "Epoch: [19] [190/289]  eta: 0:00:07  time: 0.0792  loss: 0.9186 (0.9224)  bbox_regression: 0.0639 (0.0543)  classification: 0.8546 (0.8681)\n",
            "Epoch: [19] [200/289]  eta: 0:00:07  time: 0.0797  loss: 0.9197 (0.9612)  bbox_regression: 0.0639 (0.0584)  classification: 0.8558 (0.9028)\n",
            "Epoch: [19] [210/289]  eta: 0:00:06  time: 0.0799  loss: 0.9187 (0.9195)  bbox_regression: 0.0643 (0.0675)  classification: 0.8544 (0.8520)\n",
            "Epoch: [19] [220/289]  eta: 0:00:05  time: 0.0798  loss: 0.9121 (0.8359)  bbox_regression: 0.0634 (0.0579)  classification: 0.8488 (0.7780)\n",
            "Epoch: [19] [230/289]  eta: 0:00:04  time: 0.0796  loss: 0.9099 (0.8175)  bbox_regression: 0.0619 (0.0370)  classification: 0.8480 (0.7805)\n",
            "Epoch: [19] [240/289]  eta: 0:00:03  time: 0.0795  loss: 0.9067 (0.8472)  bbox_regression: 0.0620 (0.0469)  classification: 0.8447 (0.8003)\n",
            "Epoch: [19] [250/289]  eta: 0:00:03  time: 0.0795  loss: 0.9120 (0.9357)  bbox_regression: 0.0630 (0.0754)  classification: 0.8490 (0.8603)\n",
            "Epoch: [19] [260/289]  eta: 0:00:02  time: 0.0794  loss: 0.9127 (0.9846)  bbox_regression: 0.0643 (0.0922)  classification: 0.8484 (0.8925)\n",
            "Epoch: [19] [270/289]  eta: 0:00:01  time: 0.0793  loss: 0.9187 (1.0034)  bbox_regression: 0.0648 (0.0879)  classification: 0.8539 (0.9155)\n",
            "Epoch: [19] [280/289]  eta: 0:00:00  time: 0.0792  loss: 0.9152 (0.9480)  bbox_regression: 0.0644 (0.0651)  classification: 0.8509 (0.8829)\n",
            "Epoch: [19] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.9143 (0.8803)  bbox_regression: 0.0634 (0.0538)  classification: 0.8509 (0.8265)\n",
            "Epoch: [19] Time: 0:00:22 (0.0790 s / it)\n",
            "Validation: [19]\n",
            "Validation: [19] [ 0/62]  eta: 0:00:04  time: 0.0668  \n",
            "Validation: [19] [10/62]  eta: 0:00:03  time: 0.0664  \n",
            "Validation: [19] [20/62]  eta: 0:00:02  time: 0.0657  \n",
            "Validation: [19] [30/62]  eta: 0:00:02  time: 0.0664  \n",
            "Validation: [19] [40/62]  eta: 0:00:01  time: 0.0668  \n",
            "Validation: [19] [50/62]  eta: 0:00:00  time: 0.0671  \n",
            "Validation: [19] [60/62]  eta: 0:00:00  time: 0.0674  \n",
            "Validation: [19] [61/62]  eta: 0:00:00  time: 0.0670  \n",
            "Validation: [19] Time: 0:00:04 (0.0671 s / it)\n",
            "Epoch 19: mAP = 0.7583\n",
            "Saved checkpoint at epoch 20\n",
            "Epoch: [20]\n",
            "Epoch: [20] [  0/289]  eta: 0:00:25  time: 0.0879  loss: 0.9243 (0.9243)  bbox_regression: 0.0402 (0.0402)  classification: 0.8841 (0.8841)\n",
            "Epoch: [20] [ 10/289]  eta: 0:00:24  time: 0.0872  loss: 0.7265 (0.7265)  bbox_regression: 0.0357 (0.0357)  classification: 0.6909 (0.6909)\n",
            "Epoch: [20] [ 20/289]  eta: 0:00:22  time: 0.0835  loss: 0.7974 (0.7911)  bbox_regression: 0.0474 (0.0477)  classification: 0.7500 (0.7433)\n",
            "Epoch: [20] [ 30/289]  eta: 0:00:21  time: 0.0820  loss: 0.8533 (0.9231)  bbox_regression: 0.0559 (0.0670)  classification: 0.7974 (0.8561)\n",
            "Epoch: [20] [ 40/289]  eta: 0:00:20  time: 0.0809  loss: 0.8314 (0.8672)  bbox_regression: 0.0565 (0.0660)  classification: 0.7750 (0.8012)\n",
            "Epoch: [20] [ 50/289]  eta: 0:00:19  time: 0.0801  loss: 0.8483 (0.8404)  bbox_regression: 0.0573 (0.0595)  classification: 0.7909 (0.7809)\n",
            "Epoch: [20] [ 60/289]  eta: 0:00:18  time: 0.0799  loss: 0.8838 (0.9912)  bbox_regression: 0.0658 (0.0850)  classification: 0.8180 (0.9062)\n",
            "Epoch: [20] [ 70/289]  eta: 0:00:17  time: 0.0801  loss: 0.8719 (0.9323)  bbox_regression: 0.0644 (0.0823)  classification: 0.8076 (0.8500)\n",
            "Epoch: [20] [ 80/289]  eta: 0:00:16  time: 0.0799  loss: 0.8826 (0.8790)  bbox_regression: 0.0644 (0.0602)  classification: 0.8182 (0.8188)\n",
            "Epoch: [20] [ 90/289]  eta: 0:00:15  time: 0.0798  loss: 0.8802 (0.9098)  bbox_regression: 0.0639 (0.0625)  classification: 0.8163 (0.8473)\n",
            "Epoch: [20] [100/289]  eta: 0:00:15  time: 0.0796  loss: 0.8666 (0.8018)  bbox_regression: 0.0625 (0.0550)  classification: 0.8041 (0.7469)\n",
            "Epoch: [20] [110/289]  eta: 0:00:14  time: 0.0796  loss: 0.8640 (0.7899)  bbox_regression: 0.0613 (0.0491)  classification: 0.8027 (0.7408)\n",
            "Epoch: [20] [120/289]  eta: 0:00:13  time: 0.0795  loss: 0.8586 (0.8183)  bbox_regression: 0.0623 (0.0611)  classification: 0.7963 (0.7572)\n",
            "Epoch: [20] [130/289]  eta: 0:00:12  time: 0.0796  loss: 0.8578 (0.8233)  bbox_regression: 0.0614 (0.0624)  classification: 0.7963 (0.7609)\n",
            "Epoch: [20] [140/289]  eta: 0:00:11  time: 0.0798  loss: 0.8602 (0.8699)  bbox_regression: 0.0629 (0.0665)  classification: 0.7973 (0.8035)\n",
            "Epoch: [20] [150/289]  eta: 0:00:11  time: 0.0798  loss: 0.8548 (0.8352)  bbox_regression: 0.0613 (0.0602)  classification: 0.7935 (0.7751)\n",
            "Epoch: [20] [160/289]  eta: 0:00:10  time: 0.0800  loss: 0.8543 (0.8127)  bbox_regression: 0.0611 (0.0483)  classification: 0.7932 (0.7644)\n",
            "Epoch: [20] [170/289]  eta: 0:00:09  time: 0.0800  loss: 0.8536 (0.8444)  bbox_regression: 0.0596 (0.0468)  classification: 0.7940 (0.7976)\n",
            "Epoch: [20] [180/289]  eta: 0:00:08  time: 0.0799  loss: 0.8488 (0.8046)  bbox_regression: 0.0577 (0.0308)  classification: 0.7911 (0.7738)\n",
            "Epoch: [20] [190/289]  eta: 0:00:07  time: 0.0799  loss: 0.8490 (0.8097)  bbox_regression: 0.0572 (0.0363)  classification: 0.7918 (0.7734)\n",
            "Epoch: [20] [200/289]  eta: 0:00:07  time: 0.0799  loss: 0.8526 (0.8871)  bbox_regression: 0.0576 (0.0565)  classification: 0.7950 (0.8306)\n",
            "Epoch: [20] [210/289]  eta: 0:00:06  time: 0.0797  loss: 0.8512 (0.8725)  bbox_regression: 0.0575 (0.0609)  classification: 0.7937 (0.8116)\n",
            "Epoch: [20] [220/289]  eta: 0:00:05  time: 0.0796  loss: 0.8624 (0.9600)  bbox_regression: 0.0580 (0.0619)  classification: 0.8044 (0.8981)\n",
            "Epoch: [20] [230/289]  eta: 0:00:04  time: 0.0797  loss: 0.8552 (0.8975)  bbox_regression: 0.0572 (0.0540)  classification: 0.7980 (0.8435)\n",
            "Epoch: [20] [240/289]  eta: 0:00:03  time: 0.0797  loss: 0.8586 (0.8175)  bbox_regression: 0.0604 (0.0864)  classification: 0.7983 (0.7311)\n",
            "Epoch: [20] [250/289]  eta: 0:00:03  time: 0.0798  loss: 0.8616 (0.9360)  bbox_regression: 0.0590 (0.0803)  classification: 0.8026 (0.8557)\n",
            "Epoch: [20] [260/289]  eta: 0:00:02  time: 0.0797  loss: 0.8620 (0.9029)  bbox_regression: 0.0590 (0.0433)  classification: 0.8030 (0.8597)\n",
            "Epoch: [20] [270/289]  eta: 0:00:01  time: 0.0796  loss: 0.8723 (1.0065)  bbox_regression: 0.0604 (0.0773)  classification: 0.8119 (0.9292)\n",
            "Epoch: [20] [280/289]  eta: 0:00:00  time: 0.0795  loss: 0.8686 (0.9541)  bbox_regression: 0.0602 (0.0755)  classification: 0.8084 (0.8786)\n",
            "Epoch: [20] [288/289]  eta: 0:00:00  time: 0.0793  loss: 0.8675 (0.8093)  bbox_regression: 0.0604 (0.0576)  classification: 0.8072 (0.7517)\n",
            "Epoch: [20] Time: 0:00:22 (0.0793 s / it)\n",
            "Epoch: [21]\n",
            "Epoch: [21] [  0/289]  eta: 0:00:24  time: 0.0838  loss: 0.8724 (0.8724)  bbox_regression: 0.0749 (0.0749)  classification: 0.7974 (0.7974)\n",
            "Epoch: [21] [ 10/289]  eta: 0:00:22  time: 0.0802  loss: 0.8974 (0.8974)  bbox_regression: 0.0759 (0.0759)  classification: 0.8216 (0.8216)\n",
            "Epoch: [21] [ 20/289]  eta: 0:00:21  time: 0.0795  loss: 0.7589 (0.7532)  bbox_regression: 0.0544 (0.0533)  classification: 0.7045 (0.6999)\n",
            "Epoch: [21] [ 30/289]  eta: 0:00:20  time: 0.0789  loss: 0.7827 (0.7195)  bbox_regression: 0.0559 (0.0450)  classification: 0.7267 (0.6746)\n",
            "Epoch: [21] [ 40/289]  eta: 0:00:19  time: 0.0789  loss: 0.8006 (0.8443)  bbox_regression: 0.0632 (0.0725)  classification: 0.7374 (0.7719)\n",
            "Epoch: [21] [ 50/289]  eta: 0:00:18  time: 0.0792  loss: 0.8086 (0.8489)  bbox_regression: 0.0611 (0.0690)  classification: 0.7476 (0.7799)\n",
            "Epoch: [21] [ 60/289]  eta: 0:00:18  time: 0.0790  loss: 0.7898 (0.7678)  bbox_regression: 0.0578 (0.0466)  classification: 0.7320 (0.7211)\n",
            "Epoch: [21] [ 70/289]  eta: 0:00:17  time: 0.0792  loss: 0.7978 (0.7703)  bbox_regression: 0.0556 (0.0418)  classification: 0.7422 (0.7284)\n",
            "Epoch: [21] [ 80/289]  eta: 0:00:16  time: 0.0797  loss: 0.8024 (0.8410)  bbox_regression: 0.0532 (0.0392)  classification: 0.7493 (0.8017)\n",
            "Epoch: [21] [ 90/289]  eta: 0:00:15  time: 0.0797  loss: 0.7976 (0.7967)  bbox_regression: 0.0524 (0.0411)  classification: 0.7451 (0.7556)\n",
            "Epoch: [21] [100/289]  eta: 0:00:15  time: 0.0798  loss: 0.8007 (0.7935)  bbox_regression: 0.0542 (0.0582)  classification: 0.7465 (0.7353)\n",
            "Epoch: [21] [110/289]  eta: 0:00:14  time: 0.0796  loss: 0.8127 (0.8813)  bbox_regression: 0.0604 (0.0965)  classification: 0.7523 (0.7848)\n",
            "Epoch: [21] [120/289]  eta: 0:00:13  time: 0.0794  loss: 0.8010 (0.8028)  bbox_regression: 0.0586 (0.0810)  classification: 0.7424 (0.7218)\n",
            "Epoch: [21] [130/289]  eta: 0:00:12  time: 0.0790  loss: 0.7979 (0.7160)  bbox_regression: 0.0569 (0.0377)  classification: 0.7410 (0.6783)\n",
            "Epoch: [21] [140/289]  eta: 0:00:11  time: 0.0788  loss: 0.7879 (0.7084)  bbox_regression: 0.0560 (0.0402)  classification: 0.7319 (0.6682)\n",
            "Epoch: [21] [150/289]  eta: 0:00:10  time: 0.0788  loss: 0.7992 (0.8077)  bbox_regression: 0.0554 (0.0455)  classification: 0.7438 (0.7621)\n",
            "Epoch: [21] [160/289]  eta: 0:00:10  time: 0.0788  loss: 0.8089 (0.9574)  bbox_regression: 0.0582 (0.0738)  classification: 0.7507 (0.8837)\n",
            "Epoch: [21] [170/289]  eta: 0:00:09  time: 0.0790  loss: 0.8086 (0.8795)  bbox_regression: 0.0578 (0.0754)  classification: 0.7508 (0.8041)\n",
            "Epoch: [21] [180/289]  eta: 0:00:08  time: 0.0791  loss: 0.8157 (0.8700)  bbox_regression: 0.0567 (0.0445)  classification: 0.7590 (0.8255)\n",
            "Epoch: [21] [190/289]  eta: 0:00:07  time: 0.0791  loss: 0.8183 (0.9012)  bbox_regression: 0.0567 (0.0473)  classification: 0.7616 (0.8539)\n",
            "Epoch: [21] [200/289]  eta: 0:00:07  time: 0.0790  loss: 0.8264 (0.9234)  bbox_regression: 0.0589 (0.0794)  classification: 0.7675 (0.8440)\n",
            "Epoch: [21] [210/289]  eta: 0:00:06  time: 0.0790  loss: 0.8217 (0.8546)  bbox_regression: 0.0584 (0.0752)  classification: 0.7633 (0.7794)\n",
            "Epoch: [21] [220/289]  eta: 0:00:05  time: 0.0791  loss: 0.8230 (0.7890)  bbox_regression: 0.0593 (0.0633)  classification: 0.7637 (0.7257)\n",
            "Epoch: [21] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.8298 (0.9156)  bbox_regression: 0.0590 (0.0654)  classification: 0.7708 (0.8502)\n",
            "Epoch: [21] [240/289]  eta: 0:00:03  time: 0.0789  loss: 0.8336 (0.9511)  bbox_regression: 0.0589 (0.0536)  classification: 0.7748 (0.8974)\n",
            "Epoch: [21] [250/289]  eta: 0:00:03  time: 0.0789  loss: 0.8291 (0.8200)  bbox_regression: 0.0592 (0.0615)  classification: 0.7698 (0.7584)\n",
            "Epoch: [21] [260/289]  eta: 0:00:02  time: 0.0790  loss: 0.8238 (0.7055)  bbox_regression: 0.0588 (0.0583)  classification: 0.7650 (0.6472)\n",
            "Epoch: [21] [270/289]  eta: 0:00:01  time: 0.0789  loss: 0.8194 (0.6986)  bbox_regression: 0.0586 (0.0507)  classification: 0.7608 (0.6479)\n",
            "Epoch: [21] [280/289]  eta: 0:00:00  time: 0.0788  loss: 0.8168 (0.7251)  bbox_regression: 0.0587 (0.0569)  classification: 0.7581 (0.6682)\n",
            "Epoch: [21] [288/289]  eta: 0:00:00  time: 0.0786  loss: 0.8208 (0.8356)  bbox_regression: 0.0583 (0.0544)  classification: 0.7625 (0.7812)\n",
            "Epoch: [21] Time: 0:00:22 (0.0787 s / it)\n",
            "Epoch: [22]\n",
            "Epoch: [22] [  0/289]  eta: 0:00:22  time: 0.0765  loss: 0.5531 (0.5531)  bbox_regression: 0.0136 (0.0136)  classification: 0.5395 (0.5395)\n",
            "Epoch: [22] [ 10/289]  eta: 0:00:21  time: 0.0754  loss: 0.7222 (0.7222)  bbox_regression: 0.0389 (0.0389)  classification: 0.6833 (0.6833)\n",
            "Epoch: [22] [ 20/289]  eta: 0:00:20  time: 0.0776  loss: 0.7153 (0.7234)  bbox_regression: 0.0369 (0.0381)  classification: 0.6783 (0.6853)\n",
            "Epoch: [22] [ 30/289]  eta: 0:00:20  time: 0.0785  loss: 0.7207 (0.7198)  bbox_regression: 0.0439 (0.0466)  classification: 0.6768 (0.6732)\n",
            "Epoch: [22] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 0.7170 (0.7188)  bbox_regression: 0.0470 (0.0575)  classification: 0.6700 (0.6613)\n",
            "Epoch: [22] [ 50/289]  eta: 0:00:19  time: 0.0800  loss: 0.7028 (0.6752)  bbox_regression: 0.0482 (0.0550)  classification: 0.6546 (0.6202)\n",
            "Epoch: [22] [ 60/289]  eta: 0:00:18  time: 0.0798  loss: 0.6849 (0.6189)  bbox_regression: 0.0474 (0.0484)  classification: 0.6374 (0.5706)\n",
            "Epoch: [22] [ 70/289]  eta: 0:00:17  time: 0.0799  loss: 0.6829 (0.6321)  bbox_regression: 0.0491 (0.0514)  classification: 0.6338 (0.5808)\n",
            "Epoch: [22] [ 80/289]  eta: 0:00:16  time: 0.0797  loss: 0.7116 (0.7931)  bbox_regression: 0.0554 (0.0797)  classification: 0.6562 (0.7134)\n",
            "Epoch: [22] [ 90/289]  eta: 0:00:15  time: 0.0795  loss: 0.7061 (0.7883)  bbox_regression: 0.0532 (0.0676)  classification: 0.6529 (0.7207)\n",
            "Epoch: [22] [100/289]  eta: 0:00:15  time: 0.0794  loss: 0.7059 (0.6827)  bbox_regression: 0.0523 (0.0397)  classification: 0.6536 (0.6430)\n",
            "Epoch: [22] [110/289]  eta: 0:00:14  time: 0.0794  loss: 0.7081 (0.7174)  bbox_regression: 0.0535 (0.0547)  classification: 0.6547 (0.6627)\n",
            "Epoch: [22] [120/289]  eta: 0:00:13  time: 0.0796  loss: 0.7129 (0.7485)  bbox_regression: 0.0530 (0.0568)  classification: 0.6599 (0.6917)\n",
            "Epoch: [22] [130/289]  eta: 0:00:12  time: 0.0800  loss: 0.7202 (0.7871)  bbox_regression: 0.0588 (0.0885)  classification: 0.6614 (0.6986)\n",
            "Epoch: [22] [140/289]  eta: 0:00:11  time: 0.0804  loss: 0.7189 (0.7549)  bbox_regression: 0.0576 (0.0854)  classification: 0.6612 (0.6694)\n",
            "Epoch: [22] [150/289]  eta: 0:00:11  time: 0.0803  loss: 0.7240 (0.7491)  bbox_regression: 0.0565 (0.0417)  classification: 0.6675 (0.7074)\n",
            "Epoch: [22] [160/289]  eta: 0:00:10  time: 0.0803  loss: 0.7306 (0.8134)  bbox_regression: 0.0551 (0.0373)  classification: 0.6755 (0.7760)\n",
            "Epoch: [22] [170/289]  eta: 0:00:09  time: 0.0803  loss: 0.7278 (0.7566)  bbox_regression: 0.0556 (0.0483)  classification: 0.6722 (0.7083)\n",
            "Epoch: [22] [180/289]  eta: 0:00:08  time: 0.0807  loss: 0.7411 (0.8252)  bbox_regression: 0.0565 (0.0679)  classification: 0.6845 (0.7573)\n",
            "Epoch: [22] [190/289]  eta: 0:00:07  time: 0.0808  loss: 0.7469 (0.9098)  bbox_regression: 0.0572 (0.0712)  classification: 0.6897 (0.8387)\n",
            "Epoch: [22] [200/289]  eta: 0:00:07  time: 0.0807  loss: 0.7477 (0.8074)  bbox_regression: 0.0566 (0.0571)  classification: 0.6911 (0.7504)\n",
            "Epoch: [22] [210/289]  eta: 0:00:06  time: 0.0806  loss: 0.7468 (0.7455)  bbox_regression: 0.0559 (0.0438)  classification: 0.6908 (0.7017)\n",
            "Epoch: [22] [220/289]  eta: 0:00:05  time: 0.0806  loss: 0.7483 (0.7546)  bbox_regression: 0.0564 (0.0541)  classification: 0.6919 (0.7005)\n",
            "Epoch: [22] [230/289]  eta: 0:00:04  time: 0.0805  loss: 0.7505 (0.7902)  bbox_regression: 0.0554 (0.0494)  classification: 0.6951 (0.7408)\n",
            "Epoch: [22] [240/289]  eta: 0:00:03  time: 0.0805  loss: 0.7578 (0.8633)  bbox_regression: 0.0583 (0.0794)  classification: 0.6996 (0.7839)\n",
            "Epoch: [22] [250/289]  eta: 0:00:03  time: 0.0804  loss: 0.7637 (0.9163)  bbox_regression: 0.0573 (0.0791)  classification: 0.7065 (0.8372)\n",
            "Epoch: [22] [260/289]  eta: 0:00:02  time: 0.0801  loss: 0.7686 (0.8981)  bbox_regression: 0.0568 (0.0394)  classification: 0.7118 (0.8587)\n",
            "Epoch: [22] [270/289]  eta: 0:00:01  time: 0.0800  loss: 0.7722 (0.8790)  bbox_regression: 0.0572 (0.0564)  classification: 0.7150 (0.8225)\n",
            "Epoch: [22] [280/289]  eta: 0:00:00  time: 0.0799  loss: 0.7720 (0.8169)  bbox_regression: 0.0572 (0.0622)  classification: 0.7148 (0.7548)\n",
            "Epoch: [22] [288/289]  eta: 0:00:00  time: 0.0797  loss: 0.7722 (0.7730)  bbox_regression: 0.0575 (0.0584)  classification: 0.7147 (0.7146)\n",
            "Epoch: [22] Time: 0:00:23 (0.0797 s / it)\n",
            "Epoch: [23]\n",
            "Epoch: [23] [  0/289]  eta: 0:00:27  time: 0.0935  loss: 1.3949 (1.3949)  bbox_regression: 0.0626 (0.0626)  classification: 1.3323 (1.3323)\n",
            "Epoch: [23] [ 10/289]  eta: 0:00:23  time: 0.0834  loss: 0.9311 (0.9311)  bbox_regression: 0.1064 (0.1064)  classification: 0.8247 (0.8247)\n",
            "Epoch: [23] [ 20/289]  eta: 0:00:22  time: 0.0820  loss: 0.7865 (0.7561)  bbox_regression: 0.0749 (0.0755)  classification: 0.7116 (0.6806)\n",
            "Epoch: [23] [ 30/289]  eta: 0:00:21  time: 0.0821  loss: 0.7559 (0.6596)  bbox_regression: 0.0691 (0.0485)  classification: 0.6868 (0.6110)\n",
            "Epoch: [23] [ 40/289]  eta: 0:00:20  time: 0.0834  loss: 0.7125 (0.6348)  bbox_regression: 0.0631 (0.0508)  classification: 0.6494 (0.5840)\n",
            "Epoch: [23] [ 50/289]  eta: 0:00:20  time: 0.0838  loss: 0.6938 (0.5975)  bbox_regression: 0.0591 (0.0438)  classification: 0.6346 (0.5537)\n",
            "Epoch: [23] [ 60/289]  eta: 0:00:18  time: 0.0828  loss: 0.6843 (0.6265)  bbox_regression: 0.0579 (0.0473)  classification: 0.6264 (0.5793)\n",
            "Epoch: [23] [ 70/289]  eta: 0:00:18  time: 0.0822  loss: 0.6967 (0.7040)  bbox_regression: 0.0579 (0.0548)  classification: 0.6387 (0.6492)\n",
            "Epoch: [23] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 0.6967 (0.7346)  bbox_regression: 0.0549 (0.0455)  classification: 0.6419 (0.6891)\n",
            "Epoch: [23] [ 90/289]  eta: 0:00:16  time: 0.0813  loss: 0.6929 (0.6796)  bbox_regression: 0.0543 (0.0414)  classification: 0.6386 (0.6382)\n",
            "Epoch: [23] [100/289]  eta: 0:00:15  time: 0.0813  loss: 0.7198 (0.8133)  bbox_regression: 0.0566 (0.0638)  classification: 0.6632 (0.7495)\n",
            "Epoch: [23] [110/289]  eta: 0:00:14  time: 0.0811  loss: 0.7217 (0.8527)  bbox_regression: 0.0553 (0.0600)  classification: 0.6664 (0.7928)\n",
            "Epoch: [23] [120/289]  eta: 0:00:13  time: 0.0806  loss: 0.7217 (0.7312)  bbox_regression: 0.0549 (0.0461)  classification: 0.6668 (0.6851)\n",
            "Epoch: [23] [130/289]  eta: 0:00:12  time: 0.0805  loss: 0.7202 (0.7116)  bbox_regression: 0.0554 (0.0557)  classification: 0.6648 (0.6559)\n",
            "Epoch: [23] [140/289]  eta: 0:00:11  time: 0.0805  loss: 0.7186 (0.6998)  bbox_regression: 0.0555 (0.0589)  classification: 0.6631 (0.6408)\n",
            "Epoch: [23] [150/289]  eta: 0:00:11  time: 0.0802  loss: 0.7174 (0.6992)  bbox_regression: 0.0555 (0.0564)  classification: 0.6619 (0.6428)\n",
            "Epoch: [23] [160/289]  eta: 0:00:10  time: 0.0801  loss: 0.7183 (0.7163)  bbox_regression: 0.0559 (0.0590)  classification: 0.6624 (0.6572)\n",
            "Epoch: [23] [170/289]  eta: 0:00:09  time: 0.0800  loss: 0.7230 (0.7653)  bbox_regression: 0.0565 (0.0636)  classification: 0.6665 (0.7017)\n",
            "Epoch: [23] [180/289]  eta: 0:00:08  time: 0.0801  loss: 0.7271 (0.7977)  bbox_regression: 0.0557 (0.0539)  classification: 0.6714 (0.7439)\n",
            "Epoch: [23] [190/289]  eta: 0:00:07  time: 0.0801  loss: 0.7202 (0.6965)  bbox_regression: 0.0548 (0.0407)  classification: 0.6654 (0.6558)\n",
            "Epoch: [23] [200/289]  eta: 0:00:07  time: 0.0803  loss: 0.7130 (0.5857)  bbox_regression: 0.0540 (0.0390)  classification: 0.6590 (0.5467)\n",
            "Epoch: [23] [210/289]  eta: 0:00:06  time: 0.0803  loss: 0.7147 (0.6622)  bbox_regression: 0.0535 (0.0407)  classification: 0.6612 (0.6215)\n",
            "Epoch: [23] [220/289]  eta: 0:00:05  time: 0.0801  loss: 0.7213 (0.8052)  bbox_regression: 0.0529 (0.0413)  classification: 0.6685 (0.7639)\n",
            "Epoch: [23] [230/289]  eta: 0:00:04  time: 0.0801  loss: 0.7219 (0.7973)  bbox_regression: 0.0531 (0.0492)  classification: 0.6688 (0.7481)\n",
            "Epoch: [23] [240/289]  eta: 0:00:03  time: 0.0800  loss: 0.7210 (0.7176)  bbox_regression: 0.0530 (0.0548)  classification: 0.6680 (0.6628)\n",
            "Epoch: [23] [250/289]  eta: 0:00:03  time: 0.0799  loss: 0.7233 (0.7404)  bbox_regression: 0.0520 (0.0394)  classification: 0.6713 (0.7010)\n",
            "Epoch: [23] [260/289]  eta: 0:00:02  time: 0.0797  loss: 0.7226 (0.7409)  bbox_regression: 0.0518 (0.0371)  classification: 0.6708 (0.7038)\n",
            "Epoch: [23] [270/289]  eta: 0:00:01  time: 0.0799  loss: 0.7260 (0.7594)  bbox_regression: 0.0520 (0.0521)  classification: 0.6740 (0.7073)\n",
            "Epoch: [23] [280/289]  eta: 0:00:00  time: 0.0799  loss: 0.7266 (0.7793)  bbox_regression: 0.0546 (0.0905)  classification: 0.6720 (0.6888)\n",
            "Epoch: [23] [288/289]  eta: 0:00:00  time: 0.0797  loss: 0.7238 (0.6978)  bbox_regression: 0.0558 (0.1063)  classification: 0.6680 (0.5915)\n",
            "Epoch: [23] Time: 0:00:23 (0.0797 s / it)\n",
            "Epoch: [24]\n",
            "Epoch: [24] [  0/289]  eta: 0:00:21  time: 0.0732  loss: 0.8882 (0.8882)  bbox_regression: 0.0241 (0.0241)  classification: 0.8642 (0.8642)\n",
            "Epoch: [24] [ 10/289]  eta: 0:00:22  time: 0.0798  loss: 0.6572 (0.6572)  bbox_regression: 0.0377 (0.0377)  classification: 0.6196 (0.6196)\n",
            "Epoch: [24] [ 20/289]  eta: 0:00:21  time: 0.0795  loss: 0.5860 (0.5709)  bbox_regression: 0.0379 (0.0386)  classification: 0.5481 (0.5323)\n",
            "Epoch: [24] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 0.5963 (0.5627)  bbox_regression: 0.0388 (0.0394)  classification: 0.5575 (0.5234)\n",
            "Epoch: [24] [ 40/289]  eta: 0:00:19  time: 0.0791  loss: 0.5817 (0.5772)  bbox_regression: 0.0419 (0.0461)  classification: 0.5398 (0.5311)\n",
            "Epoch: [24] [ 50/289]  eta: 0:00:18  time: 0.0787  loss: 0.5885 (0.5765)  bbox_regression: 0.0411 (0.0448)  classification: 0.5474 (0.5317)\n",
            "Epoch: [24] [ 60/289]  eta: 0:00:18  time: 0.0791  loss: 0.6266 (0.7186)  bbox_regression: 0.0395 (0.0346)  classification: 0.5871 (0.6841)\n",
            "Epoch: [24] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.6338 (0.7493)  bbox_regression: 0.0423 (0.0453)  classification: 0.5915 (0.7040)\n",
            "Epoch: [24] [ 80/289]  eta: 0:00:16  time: 0.0794  loss: 0.6319 (0.6482)  bbox_regression: 0.0416 (0.0481)  classification: 0.5903 (0.6001)\n",
            "Epoch: [24] [ 90/289]  eta: 0:00:15  time: 0.0794  loss: 0.6265 (0.6007)  bbox_regression: 0.0429 (0.0451)  classification: 0.5836 (0.5556)\n",
            "Epoch: [24] [100/289]  eta: 0:00:14  time: 0.0791  loss: 0.6249 (0.5965)  bbox_regression: 0.0425 (0.0463)  classification: 0.5824 (0.5502)\n",
            "Epoch: [24] [110/289]  eta: 0:00:14  time: 0.0790  loss: 0.6205 (0.5932)  bbox_regression: 0.0447 (0.0527)  classification: 0.5758 (0.5405)\n",
            "Epoch: [24] [120/289]  eta: 0:00:13  time: 0.0790  loss: 0.6230 (0.6131)  bbox_regression: 0.0470 (0.0694)  classification: 0.5760 (0.5437)\n",
            "Epoch: [24] [130/289]  eta: 0:00:12  time: 0.0788  loss: 0.6337 (0.7066)  bbox_regression: 0.0483 (0.0681)  classification: 0.5854 (0.6385)\n",
            "Epoch: [24] [140/289]  eta: 0:00:11  time: 0.0786  loss: 0.6337 (0.6989)  bbox_regression: 0.0490 (0.0615)  classification: 0.5847 (0.6374)\n",
            "Epoch: [24] [150/289]  eta: 0:00:10  time: 0.0786  loss: 0.6364 (0.6545)  bbox_regression: 0.0483 (0.0483)  classification: 0.5882 (0.6062)\n",
            "Epoch: [24] [160/289]  eta: 0:00:10  time: 0.0786  loss: 0.6371 (0.6608)  bbox_regression: 0.0476 (0.0372)  classification: 0.5895 (0.6235)\n",
            "Epoch: [24] [170/289]  eta: 0:00:09  time: 0.0785  loss: 0.6473 (0.7295)  bbox_regression: 0.0497 (0.0610)  classification: 0.5976 (0.6686)\n",
            "Epoch: [24] [180/289]  eta: 0:00:08  time: 0.0783  loss: 0.6536 (0.7868)  bbox_regression: 0.0538 (0.1043)  classification: 0.5998 (0.6825)\n",
            "Epoch: [24] [190/289]  eta: 0:00:07  time: 0.0785  loss: 0.6551 (0.7213)  bbox_regression: 0.0545 (0.0952)  classification: 0.6006 (0.6262)\n",
            "Epoch: [24] [200/289]  eta: 0:00:06  time: 0.0786  loss: 0.6566 (0.6839)  bbox_regression: 0.0535 (0.0508)  classification: 0.6031 (0.6331)\n",
            "Epoch: [24] [210/289]  eta: 0:00:06  time: 0.0789  loss: 0.6590 (0.6964)  bbox_regression: 0.0544 (0.0538)  classification: 0.6045 (0.6426)\n",
            "Epoch: [24] [220/289]  eta: 0:00:05  time: 0.0792  loss: 0.6617 (0.7124)  bbox_regression: 0.0553 (0.0726)  classification: 0.6064 (0.6398)\n",
            "Epoch: [24] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.6625 (0.6993)  bbox_regression: 0.0560 (0.0724)  classification: 0.6065 (0.6270)\n",
            "Epoch: [24] [240/289]  eta: 0:00:03  time: 0.0790  loss: 0.6685 (0.7440)  bbox_regression: 0.0564 (0.0696)  classification: 0.6121 (0.6744)\n",
            "Epoch: [24] [250/289]  eta: 0:00:03  time: 0.0790  loss: 0.6662 (0.7094)  bbox_regression: 0.0560 (0.0561)  classification: 0.6102 (0.6533)\n",
            "Epoch: [24] [260/289]  eta: 0:00:02  time: 0.0791  loss: 0.6671 (0.6504)  bbox_regression: 0.0558 (0.0480)  classification: 0.6113 (0.6024)\n",
            "Epoch: [24] [270/289]  eta: 0:00:01  time: 0.0792  loss: 0.6668 (0.6736)  bbox_regression: 0.0558 (0.0537)  classification: 0.6109 (0.6199)\n",
            "Epoch: [24] [280/289]  eta: 0:00:00  time: 0.0791  loss: 0.6692 (0.6962)  bbox_regression: 0.0554 (0.0501)  classification: 0.6138 (0.6462)\n",
            "Epoch: [24] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.6633 (0.6070)  bbox_regression: 0.0548 (0.0419)  classification: 0.6085 (0.5651)\n",
            "Epoch: [24] Time: 0:00:22 (0.0789 s / it)\n",
            "Validation: [24]\n",
            "Validation: [24] [ 0/62]  eta: 0:00:04  time: 0.0667  \n",
            "Validation: [24] [10/62]  eta: 0:00:03  time: 0.0665  \n",
            "Validation: [24] [20/62]  eta: 0:00:02  time: 0.0656  \n",
            "Validation: [24] [30/62]  eta: 0:00:02  time: 0.0659  \n",
            "Validation: [24] [40/62]  eta: 0:00:01  time: 0.0664  \n",
            "Validation: [24] [50/62]  eta: 0:00:00  time: 0.0667  \n",
            "Validation: [24] [60/62]  eta: 0:00:00  time: 0.0670  \n",
            "Validation: [24] [61/62]  eta: 0:00:00  time: 0.0666  \n",
            "Validation: [24] Time: 0:00:04 (0.0667 s / it)\n",
            "Epoch 24: mAP = 0.7411\n",
            "Epoch: [25]\n",
            "Epoch: [25] [  0/289]  eta: 0:00:24  time: 0.0841  loss: 0.6455 (0.6455)  bbox_regression: 0.0102 (0.0102)  classification: 0.6353 (0.6353)\n",
            "Epoch: [25] [ 10/289]  eta: 0:00:22  time: 0.0812  loss: 0.5765 (0.5765)  bbox_regression: 0.0390 (0.0390)  classification: 0.5375 (0.5375)\n",
            "Epoch: [25] [ 20/289]  eta: 0:00:22  time: 0.0820  loss: 0.5363 (0.5308)  bbox_regression: 0.0402 (0.0417)  classification: 0.4961 (0.4891)\n",
            "Epoch: [25] [ 30/289]  eta: 0:00:21  time: 0.0811  loss: 0.5444 (0.5267)  bbox_regression: 0.0478 (0.0526)  classification: 0.4966 (0.4740)\n",
            "Epoch: [25] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 0.5935 (0.6535)  bbox_regression: 0.0640 (0.0890)  classification: 0.5294 (0.5645)\n",
            "Epoch: [25] [ 50/289]  eta: 0:00:19  time: 0.0813  loss: 0.5847 (0.6471)  bbox_regression: 0.0607 (0.0806)  classification: 0.5240 (0.5665)\n",
            "Epoch: [25] [ 60/289]  eta: 0:00:18  time: 0.0810  loss: 0.6041 (0.6258)  bbox_regression: 0.0645 (0.0655)  classification: 0.5396 (0.5604)\n",
            "Epoch: [25] [ 70/289]  eta: 0:00:17  time: 0.0808  loss: 0.6072 (0.6648)  bbox_regression: 0.0602 (0.0591)  classification: 0.5470 (0.6057)\n",
            "Epoch: [25] [ 80/289]  eta: 0:00:16  time: 0.0805  loss: 0.6028 (0.5988)  bbox_regression: 0.0581 (0.0388)  classification: 0.5446 (0.5600)\n",
            "Epoch: [25] [ 90/289]  eta: 0:00:16  time: 0.0805  loss: 0.5997 (0.5729)  bbox_regression: 0.0566 (0.0436)  classification: 0.5431 (0.5292)\n",
            "Epoch: [25] [100/289]  eta: 0:00:15  time: 0.0804  loss: 0.6057 (0.6177)  bbox_regression: 0.0551 (0.0429)  classification: 0.5506 (0.5748)\n",
            "Epoch: [25] [110/289]  eta: 0:00:14  time: 0.0804  loss: 0.5997 (0.5996)  bbox_regression: 0.0533 (0.0381)  classification: 0.5464 (0.5615)\n",
            "Epoch: [25] [120/289]  eta: 0:00:13  time: 0.0804  loss: 0.6018 (0.5821)  bbox_regression: 0.0537 (0.0466)  classification: 0.5481 (0.5355)\n",
            "Epoch: [25] [130/289]  eta: 0:00:12  time: 0.0805  loss: 0.6033 (0.6238)  bbox_regression: 0.0561 (0.0721)  classification: 0.5472 (0.5516)\n",
            "Epoch: [25] [140/289]  eta: 0:00:11  time: 0.0804  loss: 0.6044 (0.6198)  bbox_regression: 0.0550 (0.0628)  classification: 0.5494 (0.5570)\n",
            "Epoch: [25] [150/289]  eta: 0:00:11  time: 0.0807  loss: 0.6084 (0.6412)  bbox_regression: 0.0543 (0.0426)  classification: 0.5540 (0.5986)\n",
            "Epoch: [25] [160/289]  eta: 0:00:10  time: 0.0806  loss: 0.6069 (0.6249)  bbox_regression: 0.0546 (0.0516)  classification: 0.5523 (0.5733)\n",
            "Epoch: [25] [170/289]  eta: 0:00:09  time: 0.0807  loss: 0.6029 (0.5618)  bbox_regression: 0.0542 (0.0530)  classification: 0.5487 (0.5087)\n",
            "Epoch: [25] [180/289]  eta: 0:00:08  time: 0.0806  loss: 0.6113 (0.6465)  bbox_regression: 0.0559 (0.0665)  classification: 0.5554 (0.5800)\n",
            "Epoch: [25] [190/289]  eta: 0:00:07  time: 0.0804  loss: 0.6139 (0.7082)  bbox_regression: 0.0572 (0.0829)  classification: 0.5567 (0.6253)\n",
            "Epoch: [25] [200/289]  eta: 0:00:07  time: 0.0802  loss: 0.6167 (0.6661)  bbox_regression: 0.0570 (0.0671)  classification: 0.5597 (0.5990)\n",
            "Epoch: [25] [210/289]  eta: 0:00:06  time: 0.0801  loss: 0.6188 (0.6650)  bbox_regression: 0.0561 (0.0455)  classification: 0.5627 (0.6195)\n",
            "Epoch: [25] [220/289]  eta: 0:00:05  time: 0.0799  loss: 0.6247 (0.7048)  bbox_regression: 0.0561 (0.0471)  classification: 0.5686 (0.6577)\n",
            "Epoch: [25] [230/289]  eta: 0:00:04  time: 0.0798  loss: 0.6273 (0.7175)  bbox_regression: 0.0558 (0.0522)  classification: 0.5716 (0.6652)\n",
            "Epoch: [25] [240/289]  eta: 0:00:03  time: 0.0797  loss: 0.6257 (0.6366)  bbox_regression: 0.0564 (0.0594)  classification: 0.5693 (0.5772)\n",
            "Epoch: [25] [250/289]  eta: 0:00:03  time: 0.0797  loss: 0.6225 (0.5671)  bbox_regression: 0.0563 (0.0622)  classification: 0.5663 (0.5049)\n",
            "Epoch: [25] [260/289]  eta: 0:00:02  time: 0.0796  loss: 0.6211 (0.5655)  bbox_regression: 0.0556 (0.0459)  classification: 0.5655 (0.5197)\n",
            "Epoch: [25] [270/289]  eta: 0:00:01  time: 0.0795  loss: 0.6170 (0.5485)  bbox_regression: 0.0549 (0.0380)  classification: 0.5621 (0.5104)\n",
            "Epoch: [25] [280/289]  eta: 0:00:00  time: 0.0794  loss: 0.6172 (0.5659)  bbox_regression: 0.0553 (0.0518)  classification: 0.5619 (0.5141)\n",
            "Epoch: [25] [288/289]  eta: 0:00:00  time: 0.0793  loss: 0.6154 (0.5800)  bbox_regression: 0.0551 (0.0580)  classification: 0.5604 (0.5220)\n",
            "Epoch: [25] Time: 0:00:22 (0.0793 s / it)\n",
            "Epoch: [26]\n",
            "Epoch: [26] [  0/289]  eta: 0:00:23  time: 0.0805  loss: 0.2924 (0.2924)  bbox_regression: 0.0396 (0.0396)  classification: 0.2529 (0.2529)\n",
            "Epoch: [26] [ 10/289]  eta: 0:00:24  time: 0.0865  loss: 0.4134 (0.4134)  bbox_regression: 0.0381 (0.0381)  classification: 0.3753 (0.3753)\n",
            "Epoch: [26] [ 20/289]  eta: 0:00:22  time: 0.0845  loss: 0.5324 (0.5444)  bbox_regression: 0.0611 (0.0622)  classification: 0.4713 (0.4823)\n",
            "Epoch: [26] [ 30/289]  eta: 0:00:21  time: 0.0831  loss: 0.5129 (0.5676)  bbox_regression: 0.0569 (0.0673)  classification: 0.4560 (0.5004)\n",
            "Epoch: [26] [ 40/289]  eta: 0:00:20  time: 0.0814  loss: 0.5220 (0.5110)  bbox_regression: 0.0518 (0.0420)  classification: 0.4702 (0.4690)\n",
            "Epoch: [26] [ 50/289]  eta: 0:00:19  time: 0.0818  loss: 0.5017 (0.4843)  bbox_regression: 0.0515 (0.0430)  classification: 0.4502 (0.4412)\n",
            "Epoch: [26] [ 60/289]  eta: 0:00:18  time: 0.0818  loss: 0.4915 (0.4292)  bbox_regression: 0.0497 (0.0454)  classification: 0.4418 (0.3837)\n",
            "Epoch: [26] [ 70/289]  eta: 0:00:17  time: 0.0813  loss: 0.5222 (0.5745)  bbox_regression: 0.0603 (0.0826)  classification: 0.4619 (0.4918)\n",
            "Epoch: [26] [ 80/289]  eta: 0:00:16  time: 0.0809  loss: 0.5096 (0.5647)  bbox_regression: 0.0573 (0.0803)  classification: 0.4523 (0.4844)\n",
            "Epoch: [26] [ 90/289]  eta: 0:00:16  time: 0.0808  loss: 0.5232 (0.5268)  bbox_regression: 0.0567 (0.0440)  classification: 0.4665 (0.4827)\n",
            "Epoch: [26] [100/289]  eta: 0:00:15  time: 0.0807  loss: 0.5306 (0.6155)  bbox_regression: 0.0559 (0.0506)  classification: 0.4746 (0.5649)\n",
            "Epoch: [26] [110/289]  eta: 0:00:14  time: 0.0808  loss: 0.5309 (0.5658)  bbox_regression: 0.0542 (0.0427)  classification: 0.4767 (0.5230)\n",
            "Epoch: [26] [120/289]  eta: 0:00:13  time: 0.0806  loss: 0.5404 (0.5902)  bbox_regression: 0.0574 (0.0645)  classification: 0.4831 (0.5257)\n",
            "Epoch: [26] [130/289]  eta: 0:00:12  time: 0.0804  loss: 0.5341 (0.5523)  bbox_regression: 0.0564 (0.0690)  classification: 0.4777 (0.4833)\n",
            "Epoch: [26] [140/289]  eta: 0:00:11  time: 0.0802  loss: 0.5272 (0.4475)  bbox_regression: 0.0562 (0.0495)  classification: 0.4710 (0.3981)\n",
            "Epoch: [26] [150/289]  eta: 0:00:11  time: 0.0800  loss: 0.5238 (0.4562)  bbox_regression: 0.0558 (0.0519)  classification: 0.4680 (0.4043)\n",
            "Epoch: [26] [160/289]  eta: 0:00:10  time: 0.0803  loss: 0.5242 (0.5029)  bbox_regression: 0.0554 (0.0498)  classification: 0.4688 (0.4531)\n",
            "Epoch: [26] [170/289]  eta: 0:00:09  time: 0.0805  loss: 0.5333 (0.6050)  bbox_regression: 0.0549 (0.0480)  classification: 0.4784 (0.5570)\n",
            "Epoch: [26] [180/289]  eta: 0:00:08  time: 0.0805  loss: 0.5450 (0.7122)  bbox_regression: 0.0541 (0.0433)  classification: 0.4909 (0.6689)\n",
            "Epoch: [26] [190/289]  eta: 0:00:07  time: 0.0805  loss: 0.5506 (0.6986)  bbox_regression: 0.0538 (0.0439)  classification: 0.4969 (0.6547)\n",
            "Epoch: [26] [200/289]  eta: 0:00:07  time: 0.0804  loss: 0.5562 (0.6577)  bbox_regression: 0.0531 (0.0444)  classification: 0.5031 (0.6133)\n",
            "Epoch: [26] [210/289]  eta: 0:00:06  time: 0.0802  loss: 0.5564 (0.6118)  bbox_regression: 0.0526 (0.0413)  classification: 0.5038 (0.5705)\n",
            "Epoch: [26] [220/289]  eta: 0:00:05  time: 0.0802  loss: 0.5589 (0.5857)  bbox_regression: 0.0521 (0.0416)  classification: 0.5068 (0.5441)\n",
            "Epoch: [26] [230/289]  eta: 0:00:04  time: 0.0801  loss: 0.5573 (0.5662)  bbox_regression: 0.0523 (0.0495)  classification: 0.5049 (0.5167)\n",
            "Epoch: [26] [240/289]  eta: 0:00:03  time: 0.0801  loss: 0.5639 (0.6190)  bbox_regression: 0.0523 (0.0544)  classification: 0.5116 (0.5646)\n",
            "Epoch: [26] [250/289]  eta: 0:00:03  time: 0.0800  loss: 0.5621 (0.6176)  bbox_regression: 0.0524 (0.0533)  classification: 0.5097 (0.5643)\n",
            "Epoch: [26] [260/289]  eta: 0:00:02  time: 0.0799  loss: 0.5659 (0.5902)  bbox_regression: 0.0541 (0.0762)  classification: 0.5118 (0.5140)\n",
            "Epoch: [26] [270/289]  eta: 0:00:01  time: 0.0798  loss: 0.5600 (0.5345)  bbox_regression: 0.0535 (0.0667)  classification: 0.5066 (0.4678)\n",
            "Epoch: [26] [280/289]  eta: 0:00:00  time: 0.0797  loss: 0.5556 (0.4213)  bbox_regression: 0.0529 (0.0370)  classification: 0.5027 (0.3843)\n",
            "Epoch: [26] [288/289]  eta: 0:00:00  time: 0.0794  loss: 0.5535 (0.4418)  bbox_regression: 0.0529 (0.0433)  classification: 0.5006 (0.3985)\n",
            "Epoch: [26] Time: 0:00:22 (0.0795 s / it)\n",
            "Epoch: [27]\n",
            "Epoch: [27] [  0/289]  eta: 0:00:22  time: 0.0784  loss: 0.4759 (0.4759)  bbox_regression: 0.0339 (0.0339)  classification: 0.4420 (0.4420)\n",
            "Epoch: [27] [ 10/289]  eta: 0:00:22  time: 0.0800  loss: 0.5062 (0.5062)  bbox_regression: 0.0318 (0.0318)  classification: 0.4744 (0.4744)\n",
            "Epoch: [27] [ 20/289]  eta: 0:00:21  time: 0.0796  loss: 0.5215 (0.5238)  bbox_regression: 0.0396 (0.0399)  classification: 0.4820 (0.4840)\n",
            "Epoch: [27] [ 30/289]  eta: 0:00:20  time: 0.0802  loss: 0.5521 (0.5773)  bbox_regression: 0.0496 (0.0595)  classification: 0.5024 (0.5178)\n",
            "Epoch: [27] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 0.5235 (0.5255)  bbox_regression: 0.0549 (0.0709)  classification: 0.4686 (0.4546)\n",
            "Epoch: [27] [ 50/289]  eta: 0:00:19  time: 0.0805  loss: 0.5329 (0.5033)  bbox_regression: 0.0571 (0.0687)  classification: 0.4758 (0.4346)\n",
            "Epoch: [27] [ 60/289]  eta: 0:00:18  time: 0.0801  loss: 0.5398 (0.5734)  bbox_regression: 0.0550 (0.0552)  classification: 0.4849 (0.5182)\n",
            "Epoch: [27] [ 70/289]  eta: 0:00:17  time: 0.0799  loss: 0.5352 (0.5408)  bbox_regression: 0.0527 (0.0415)  classification: 0.4824 (0.4993)\n",
            "Epoch: [27] [ 80/289]  eta: 0:00:16  time: 0.0800  loss: 0.5428 (0.5519)  bbox_regression: 0.0519 (0.0425)  classification: 0.4909 (0.5095)\n",
            "Epoch: [27] [ 90/289]  eta: 0:00:15  time: 0.0800  loss: 0.5335 (0.5278)  bbox_regression: 0.0521 (0.0498)  classification: 0.4815 (0.4780)\n",
            "Epoch: [27] [100/289]  eta: 0:00:15  time: 0.0800  loss: 0.5338 (0.4971)  bbox_regression: 0.0533 (0.0591)  classification: 0.4805 (0.4379)\n",
            "Epoch: [27] [110/289]  eta: 0:00:14  time: 0.0795  loss: 0.5273 (0.4988)  bbox_regression: 0.0529 (0.0567)  classification: 0.4744 (0.4422)\n",
            "Epoch: [27] [120/289]  eta: 0:00:13  time: 0.0797  loss: 0.5287 (0.5032)  bbox_regression: 0.0527 (0.0497)  classification: 0.4760 (0.4535)\n",
            "Epoch: [27] [130/289]  eta: 0:00:12  time: 0.0795  loss: 0.5216 (0.4901)  bbox_regression: 0.0506 (0.0380)  classification: 0.4710 (0.4522)\n",
            "Epoch: [27] [140/289]  eta: 0:00:11  time: 0.0794  loss: 0.5132 (0.4191)  bbox_regression: 0.0497 (0.0312)  classification: 0.4635 (0.3879)\n",
            "Epoch: [27] [150/289]  eta: 0:00:11  time: 0.0792  loss: 0.5178 (0.4927)  bbox_regression: 0.0506 (0.0507)  classification: 0.4671 (0.4420)\n",
            "Epoch: [27] [160/289]  eta: 0:00:10  time: 0.0791  loss: 0.5172 (0.5456)  bbox_regression: 0.0545 (0.0888)  classification: 0.4627 (0.4568)\n",
            "Epoch: [27] [170/289]  eta: 0:00:09  time: 0.0791  loss: 0.5173 (0.5135)  bbox_regression: 0.0549 (0.0869)  classification: 0.4624 (0.4266)\n",
            "Epoch: [27] [180/289]  eta: 0:00:08  time: 0.0791  loss: 0.5126 (0.4758)  bbox_regression: 0.0542 (0.0517)  classification: 0.4584 (0.4241)\n",
            "Epoch: [27] [190/289]  eta: 0:00:07  time: 0.0793  loss: 0.5118 (0.4651)  bbox_regression: 0.0537 (0.0437)  classification: 0.4581 (0.4214)\n",
            "Epoch: [27] [200/289]  eta: 0:00:07  time: 0.0795  loss: 0.5101 (0.4872)  bbox_regression: 0.0532 (0.0439)  classification: 0.4569 (0.4433)\n",
            "Epoch: [27] [210/289]  eta: 0:00:06  time: 0.0793  loss: 0.5120 (0.5134)  bbox_regression: 0.0529 (0.0453)  classification: 0.4591 (0.4681)\n",
            "Epoch: [27] [220/289]  eta: 0:00:05  time: 0.0793  loss: 0.5090 (0.4976)  bbox_regression: 0.0523 (0.0429)  classification: 0.4567 (0.4548)\n",
            "Epoch: [27] [230/289]  eta: 0:00:04  time: 0.0793  loss: 0.5123 (0.5155)  bbox_regression: 0.0528 (0.0517)  classification: 0.4595 (0.4638)\n",
            "Epoch: [27] [240/289]  eta: 0:00:03  time: 0.0793  loss: 0.5109 (0.5328)  bbox_regression: 0.0530 (0.0618)  classification: 0.4579 (0.4710)\n",
            "Epoch: [27] [250/289]  eta: 0:00:03  time: 0.0794  loss: 0.5137 (0.5295)  bbox_regression: 0.0534 (0.0605)  classification: 0.4602 (0.4690)\n",
            "Epoch: [27] [260/289]  eta: 0:00:02  time: 0.0793  loss: 0.5129 (0.5373)  bbox_regression: 0.0527 (0.0490)  classification: 0.4602 (0.4882)\n",
            "Epoch: [27] [270/289]  eta: 0:00:01  time: 0.0791  loss: 0.5140 (0.5182)  bbox_regression: 0.0523 (0.0376)  classification: 0.4617 (0.4806)\n",
            "Epoch: [27] [280/289]  eta: 0:00:00  time: 0.0791  loss: 0.5111 (0.4867)  bbox_regression: 0.0524 (0.0485)  classification: 0.4587 (0.4383)\n",
            "Epoch: [27] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.5171 (0.5825)  bbox_regression: 0.0525 (0.0537)  classification: 0.4646 (0.5288)\n",
            "Epoch: [27] Time: 0:00:22 (0.0790 s / it)\n",
            "Epoch: [28]\n",
            "Epoch: [28] [  0/289]  eta: 0:00:21  time: 0.0742  loss: 0.2885 (0.2885)  bbox_regression: 0.0305 (0.0305)  classification: 0.2579 (0.2579)\n",
            "Epoch: [28] [ 10/289]  eta: 0:00:21  time: 0.0782  loss: 0.4590 (0.4590)  bbox_regression: 0.0517 (0.0517)  classification: 0.4072 (0.4072)\n",
            "Epoch: [28] [ 20/289]  eta: 0:00:20  time: 0.0780  loss: 0.4604 (0.4690)  bbox_regression: 0.0563 (0.0576)  classification: 0.4041 (0.4115)\n",
            "Epoch: [28] [ 30/289]  eta: 0:00:20  time: 0.0785  loss: 0.4751 (0.4839)  bbox_regression: 0.0501 (0.0493)  classification: 0.4250 (0.4347)\n",
            "Epoch: [28] [ 40/289]  eta: 0:00:19  time: 0.0794  loss: 0.4481 (0.4352)  bbox_regression: 0.0486 (0.0404)  classification: 0.3996 (0.3948)\n",
            "Epoch: [28] [ 50/289]  eta: 0:00:18  time: 0.0793  loss: 0.4521 (0.4164)  bbox_regression: 0.0480 (0.0447)  classification: 0.4041 (0.3717)\n",
            "Epoch: [28] [ 60/289]  eta: 0:00:18  time: 0.0797  loss: 0.4427 (0.4315)  bbox_regression: 0.0451 (0.0381)  classification: 0.3976 (0.3934)\n",
            "Epoch: [28] [ 70/289]  eta: 0:00:17  time: 0.0797  loss: 0.4485 (0.4393)  bbox_regression: 0.0438 (0.0331)  classification: 0.4047 (0.4063)\n",
            "Epoch: [28] [ 80/289]  eta: 0:00:16  time: 0.0796  loss: 0.4464 (0.4577)  bbox_regression: 0.0425 (0.0344)  classification: 0.4039 (0.4232)\n",
            "Epoch: [28] [ 90/289]  eta: 0:00:15  time: 0.0796  loss: 0.4423 (0.4203)  bbox_regression: 0.0421 (0.0359)  classification: 0.4002 (0.3844)\n",
            "Epoch: [28] [100/289]  eta: 0:00:15  time: 0.0798  loss: 0.4311 (0.3691)  bbox_regression: 0.0430 (0.0449)  classification: 0.3881 (0.3242)\n",
            "Epoch: [28] [110/289]  eta: 0:00:14  time: 0.0795  loss: 0.4314 (0.3820)  bbox_regression: 0.0438 (0.0516)  classification: 0.3876 (0.3303)\n",
            "Epoch: [28] [120/289]  eta: 0:00:13  time: 0.0793  loss: 0.4308 (0.4294)  bbox_regression: 0.0449 (0.0545)  classification: 0.3859 (0.3750)\n",
            "Epoch: [28] [130/289]  eta: 0:00:12  time: 0.0792  loss: 0.4348 (0.4534)  bbox_regression: 0.0449 (0.0510)  classification: 0.3899 (0.4024)\n",
            "Epoch: [28] [140/289]  eta: 0:00:11  time: 0.0791  loss: 0.4315 (0.4356)  bbox_regression: 0.0444 (0.0415)  classification: 0.3871 (0.3942)\n",
            "Epoch: [28] [150/289]  eta: 0:00:10  time: 0.0790  loss: 0.4350 (0.4366)  bbox_regression: 0.0457 (0.0510)  classification: 0.3893 (0.3857)\n",
            "Epoch: [28] [160/289]  eta: 0:00:10  time: 0.0787  loss: 0.4344 (0.4550)  bbox_regression: 0.0457 (0.0550)  classification: 0.3887 (0.4000)\n",
            "Epoch: [28] [170/289]  eta: 0:00:09  time: 0.0787  loss: 0.4363 (0.4456)  bbox_regression: 0.0472 (0.0587)  classification: 0.3890 (0.3869)\n",
            "Epoch: [28] [180/289]  eta: 0:00:08  time: 0.0786  loss: 0.4380 (0.4672)  bbox_regression: 0.0467 (0.0544)  classification: 0.3914 (0.4129)\n",
            "Epoch: [28] [190/289]  eta: 0:00:07  time: 0.0787  loss: 0.4377 (0.4500)  bbox_regression: 0.0473 (0.0478)  classification: 0.3904 (0.4021)\n",
            "Epoch: [28] [200/289]  eta: 0:00:07  time: 0.0788  loss: 0.4393 (0.4505)  bbox_regression: 0.0478 (0.0587)  classification: 0.3914 (0.3919)\n",
            "Epoch: [28] [210/289]  eta: 0:00:06  time: 0.0788  loss: 0.4379 (0.4394)  bbox_regression: 0.0474 (0.0486)  classification: 0.3904 (0.3907)\n",
            "Epoch: [28] [220/289]  eta: 0:00:05  time: 0.0789  loss: 0.4449 (0.5017)  bbox_regression: 0.0501 (0.0732)  classification: 0.3948 (0.4285)\n",
            "Epoch: [28] [230/289]  eta: 0:00:04  time: 0.0789  loss: 0.4478 (0.5531)  bbox_regression: 0.0499 (0.0759)  classification: 0.3980 (0.4772)\n",
            "Epoch: [28] [240/289]  eta: 0:00:03  time: 0.0788  loss: 0.4488 (0.4919)  bbox_regression: 0.0497 (0.0447)  classification: 0.3991 (0.4472)\n",
            "Epoch: [28] [250/289]  eta: 0:00:03  time: 0.0787  loss: 0.4492 (0.4650)  bbox_regression: 0.0519 (0.0754)  classification: 0.3973 (0.3895)\n",
            "Epoch: [28] [260/289]  eta: 0:00:02  time: 0.0787  loss: 0.4526 (0.4975)  bbox_regression: 0.0517 (0.0757)  classification: 0.4009 (0.4218)\n",
            "Epoch: [28] [270/289]  eta: 0:00:01  time: 0.0787  loss: 0.4519 (0.4864)  bbox_regression: 0.0518 (0.0506)  classification: 0.4001 (0.4358)\n",
            "Epoch: [28] [280/289]  eta: 0:00:00  time: 0.0786  loss: 0.4536 (0.4671)  bbox_regression: 0.0512 (0.0453)  classification: 0.4024 (0.4218)\n",
            "Epoch: [28] [288/289]  eta: 0:00:00  time: 0.0785  loss: 0.4506 (0.4204)  bbox_regression: 0.0507 (0.0344)  classification: 0.3999 (0.3861)\n",
            "Epoch: [28] Time: 0:00:22 (0.0785 s / it)\n",
            "Epoch: [29]\n",
            "Epoch: [29] [  0/289]  eta: 0:00:21  time: 0.0731  loss: 0.5097 (0.5097)  bbox_regression: 0.0386 (0.0386)  classification: 0.4710 (0.4710)\n",
            "Epoch: [29] [ 10/289]  eta: 0:00:21  time: 0.0779  loss: 0.3240 (0.3240)  bbox_regression: 0.0328 (0.0328)  classification: 0.2912 (0.2912)\n",
            "Epoch: [29] [ 20/289]  eta: 0:00:21  time: 0.0790  loss: 0.3028 (0.2925)  bbox_regression: 0.0393 (0.0393)  classification: 0.2635 (0.2532)\n",
            "Epoch: [29] [ 30/289]  eta: 0:00:20  time: 0.0789  loss: 0.3310 (0.3349)  bbox_regression: 0.0423 (0.0475)  classification: 0.2888 (0.2874)\n",
            "Epoch: [29] [ 40/289]  eta: 0:00:19  time: 0.0789  loss: 0.3400 (0.3791)  bbox_regression: 0.0387 (0.0382)  classification: 0.3013 (0.3409)\n",
            "Epoch: [29] [ 50/289]  eta: 0:00:18  time: 0.0788  loss: 0.3483 (0.3751)  bbox_regression: 0.0403 (0.0373)  classification: 0.3080 (0.3377)\n",
            "Epoch: [29] [ 60/289]  eta: 0:00:18  time: 0.0787  loss: 0.3491 (0.3678)  bbox_regression: 0.0406 (0.0444)  classification: 0.3085 (0.3233)\n",
            "Epoch: [29] [ 70/289]  eta: 0:00:17  time: 0.0787  loss: 0.3559 (0.3752)  bbox_regression: 0.0421 (0.0468)  classification: 0.3137 (0.3284)\n",
            "Epoch: [29] [ 80/289]  eta: 0:00:16  time: 0.0790  loss: 0.3559 (0.3764)  bbox_regression: 0.0433 (0.0514)  classification: 0.3126 (0.3250)\n",
            "Epoch: [29] [ 90/289]  eta: 0:00:15  time: 0.0788  loss: 0.3640 (0.3928)  bbox_regression: 0.0425 (0.0438)  classification: 0.3215 (0.3490)\n",
            "Epoch: [29] [100/289]  eta: 0:00:14  time: 0.0786  loss: 0.3613 (0.3831)  bbox_regression: 0.0420 (0.0369)  classification: 0.3193 (0.3463)\n",
            "Epoch: [29] [110/289]  eta: 0:00:14  time: 0.0785  loss: 0.3558 (0.3188)  bbox_regression: 0.0420 (0.0396)  classification: 0.3139 (0.2792)\n",
            "Epoch: [29] [120/289]  eta: 0:00:13  time: 0.0783  loss: 0.3493 (0.2887)  bbox_regression: 0.0414 (0.0384)  classification: 0.3079 (0.2503)\n",
            "Epoch: [29] [130/289]  eta: 0:00:12  time: 0.0783  loss: 0.3466 (0.2956)  bbox_regression: 0.0412 (0.0367)  classification: 0.3055 (0.2589)\n",
            "Epoch: [29] [140/289]  eta: 0:00:11  time: 0.0783  loss: 0.3431 (0.3057)  bbox_regression: 0.0406 (0.0358)  classification: 0.3025 (0.2699)\n",
            "Epoch: [29] [150/289]  eta: 0:00:10  time: 0.0783  loss: 0.3500 (0.3724)  bbox_regression: 0.0411 (0.0405)  classification: 0.3090 (0.3319)\n",
            "Epoch: [29] [160/289]  eta: 0:00:10  time: 0.0786  loss: 0.3507 (0.4046)  bbox_regression: 0.0429 (0.0589)  classification: 0.3079 (0.3457)\n",
            "Epoch: [29] [170/289]  eta: 0:00:09  time: 0.0787  loss: 0.3594 (0.4300)  bbox_regression: 0.0446 (0.0715)  classification: 0.3148 (0.3585)\n",
            "Epoch: [29] [180/289]  eta: 0:00:08  time: 0.0787  loss: 0.3561 (0.3992)  bbox_regression: 0.0446 (0.0587)  classification: 0.3115 (0.3405)\n",
            "Epoch: [29] [190/289]  eta: 0:00:07  time: 0.0787  loss: 0.3565 (0.3322)  bbox_regression: 0.0444 (0.0428)  classification: 0.3121 (0.2894)\n",
            "Epoch: [29] [200/289]  eta: 0:00:07  time: 0.0787  loss: 0.3620 (0.4159)  bbox_regression: 0.0453 (0.0516)  classification: 0.3167 (0.3642)\n",
            "Epoch: [29] [210/289]  eta: 0:00:06  time: 0.0788  loss: 0.3629 (0.4234)  bbox_regression: 0.0459 (0.0597)  classification: 0.3170 (0.3637)\n",
            "Epoch: [29] [220/289]  eta: 0:00:05  time: 0.0788  loss: 0.3706 (0.4571)  bbox_regression: 0.0498 (0.0951)  classification: 0.3208 (0.3620)\n",
            "Epoch: [29] [230/289]  eta: 0:00:04  time: 0.0788  loss: 0.3699 (0.4436)  bbox_regression: 0.0510 (0.1051)  classification: 0.3189 (0.3385)\n",
            "Epoch: [29] [240/289]  eta: 0:00:03  time: 0.0788  loss: 0.3711 (0.3760)  bbox_regression: 0.0503 (0.0559)  classification: 0.3207 (0.3200)\n",
            "Epoch: [29] [250/289]  eta: 0:00:03  time: 0.0788  loss: 0.3716 (0.3914)  bbox_regression: 0.0509 (0.0495)  classification: 0.3207 (0.3419)\n",
            "Epoch: [29] [260/289]  eta: 0:00:02  time: 0.0789  loss: 0.3700 (0.3564)  bbox_regression: 0.0504 (0.0508)  classification: 0.3196 (0.3056)\n",
            "Epoch: [29] [270/289]  eta: 0:00:01  time: 0.0789  loss: 0.3756 (0.4262)  bbox_regression: 0.0506 (0.0473)  classification: 0.3250 (0.3789)\n",
            "Epoch: [29] [280/289]  eta: 0:00:00  time: 0.0788  loss: 0.3800 (0.5115)  bbox_regression: 0.0503 (0.0496)  classification: 0.3297 (0.4619)\n",
            "Epoch: [29] [288/289]  eta: 0:00:00  time: 0.0787  loss: 0.3812 (0.4517)  bbox_regression: 0.0507 (0.0499)  classification: 0.3305 (0.4017)\n",
            "Epoch: [29] Time: 0:00:22 (0.0787 s / it)\n",
            "Validation: [29]\n",
            "Validation: [29] [ 0/62]  eta: 0:00:04  time: 0.0661  \n",
            "Validation: [29] [10/62]  eta: 0:00:03  time: 0.0660  \n",
            "Validation: [29] [20/62]  eta: 0:00:02  time: 0.0652  \n",
            "Validation: [29] [30/62]  eta: 0:00:02  time: 0.0659  \n",
            "Validation: [29] [40/62]  eta: 0:00:01  time: 0.0665  \n",
            "Validation: [29] [50/62]  eta: 0:00:00  time: 0.0668  \n",
            "Validation: [29] [60/62]  eta: 0:00:00  time: 0.0670  \n",
            "Validation: [29] [61/62]  eta: 0:00:00  time: 0.0666  \n",
            "Validation: [29] Time: 0:00:04 (0.0666 s / it)\n",
            "Epoch 29: mAP = 0.7014\n",
            "Saved checkpoint at epoch 30\n",
            "Epoch: [30]\n",
            "Epoch: [30] [  0/289]  eta: 0:00:24  time: 0.0837  loss: 0.6805 (0.6805)  bbox_regression: 0.0231 (0.0231)  classification: 0.6573 (0.6573)\n",
            "Epoch: [30] [ 10/289]  eta: 0:00:22  time: 0.0800  loss: 0.4015 (0.4015)  bbox_regression: 0.0439 (0.0439)  classification: 0.3575 (0.3575)\n",
            "Epoch: [30] [ 20/289]  eta: 0:00:21  time: 0.0796  loss: 0.3676 (0.3519)  bbox_regression: 0.0406 (0.0415)  classification: 0.3269 (0.3104)\n",
            "Epoch: [30] [ 30/289]  eta: 0:00:20  time: 0.0800  loss: 0.3367 (0.3011)  bbox_regression: 0.0401 (0.0379)  classification: 0.2967 (0.2632)\n",
            "Epoch: [30] [ 40/289]  eta: 0:00:19  time: 0.0796  loss: 0.3275 (0.2855)  bbox_regression: 0.0384 (0.0361)  classification: 0.2891 (0.2494)\n",
            "Epoch: [30] [ 50/289]  eta: 0:00:19  time: 0.0796  loss: 0.3380 (0.3401)  bbox_regression: 0.0389 (0.0371)  classification: 0.2991 (0.3029)\n",
            "Epoch: [30] [ 60/289]  eta: 0:00:18  time: 0.0792  loss: 0.3583 (0.4212)  bbox_regression: 0.0402 (0.0439)  classification: 0.3180 (0.3773)\n",
            "Epoch: [30] [ 70/289]  eta: 0:00:17  time: 0.0791  loss: 0.3430 (0.3555)  bbox_regression: 0.0403 (0.0439)  classification: 0.3026 (0.3115)\n",
            "Epoch: [30] [ 80/289]  eta: 0:00:16  time: 0.0791  loss: 0.3363 (0.2692)  bbox_regression: 0.0418 (0.0467)  classification: 0.2945 (0.2225)\n",
            "Epoch: [30] [ 90/289]  eta: 0:00:15  time: 0.0789  loss: 0.3286 (0.2778)  bbox_regression: 0.0403 (0.0400)  classification: 0.2884 (0.2378)\n",
            "Epoch: [30] [100/289]  eta: 0:00:14  time: 0.0789  loss: 0.3195 (0.2516)  bbox_regression: 0.0395 (0.0299)  classification: 0.2800 (0.2216)\n",
            "Epoch: [30] [110/289]  eta: 0:00:14  time: 0.0790  loss: 0.3141 (0.2478)  bbox_regression: 0.0392 (0.0344)  classification: 0.2749 (0.2134)\n",
            "Epoch: [30] [120/289]  eta: 0:00:13  time: 0.0788  loss: 0.3124 (0.2764)  bbox_regression: 0.0381 (0.0313)  classification: 0.2743 (0.2451)\n",
            "Epoch: [30] [130/289]  eta: 0:00:12  time: 0.0788  loss: 0.3060 (0.2612)  bbox_regression: 0.0381 (0.0317)  classification: 0.2679 (0.2295)\n",
            "Epoch: [30] [140/289]  eta: 0:00:11  time: 0.0788  loss: 0.3065 (0.2711)  bbox_regression: 0.0391 (0.0449)  classification: 0.2674 (0.2262)\n",
            "Epoch: [30] [150/289]  eta: 0:00:10  time: 0.0786  loss: 0.3120 (0.3516)  bbox_regression: 0.0414 (0.0635)  classification: 0.2706 (0.2881)\n",
            "Epoch: [30] [160/289]  eta: 0:00:10  time: 0.0787  loss: 0.3093 (0.3289)  bbox_regression: 0.0416 (0.0593)  classification: 0.2677 (0.2696)\n",
            "Epoch: [30] [170/289]  eta: 0:00:09  time: 0.0790  loss: 0.3088 (0.2846)  bbox_regression: 0.0412 (0.0396)  classification: 0.2676 (0.2450)\n",
            "Epoch: [30] [180/289]  eta: 0:00:08  time: 0.0792  loss: 0.3086 (0.3032)  bbox_regression: 0.0410 (0.0358)  classification: 0.2677 (0.2673)\n",
            "Epoch: [30] [190/289]  eta: 0:00:07  time: 0.0795  loss: 0.3099 (0.3188)  bbox_regression: 0.0406 (0.0352)  classification: 0.2693 (0.2836)\n",
            "Epoch: [30] [200/289]  eta: 0:00:07  time: 0.0796  loss: 0.3065 (0.2868)  bbox_regression: 0.0403 (0.0340)  classification: 0.2662 (0.2528)\n",
            "Epoch: [30] [210/289]  eta: 0:00:06  time: 0.0795  loss: 0.3052 (0.2606)  bbox_regression: 0.0399 (0.0332)  classification: 0.2653 (0.2274)\n",
            "Epoch: [30] [220/289]  eta: 0:00:05  time: 0.0794  loss: 0.3039 (0.2777)  bbox_regression: 0.0401 (0.0382)  classification: 0.2638 (0.2395)\n",
            "Epoch: [30] [230/289]  eta: 0:00:04  time: 0.0794  loss: 0.3033 (0.2832)  bbox_regression: 0.0409 (0.0514)  classification: 0.2624 (0.2318)\n",
            "Epoch: [30] [240/289]  eta: 0:00:03  time: 0.0792  loss: 0.3025 (0.2875)  bbox_regression: 0.0408 (0.0486)  classification: 0.2617 (0.2388)\n",
            "Epoch: [30] [250/289]  eta: 0:00:03  time: 0.0792  loss: 0.3002 (0.2640)  bbox_regression: 0.0402 (0.0329)  classification: 0.2599 (0.2311)\n",
            "Epoch: [30] [260/289]  eta: 0:00:02  time: 0.0792  loss: 0.3017 (0.2915)  bbox_regression: 0.0419 (0.0550)  classification: 0.2598 (0.2365)\n",
            "Epoch: [30] [270/289]  eta: 0:00:01  time: 0.0792  loss: 0.3011 (0.3134)  bbox_regression: 0.0435 (0.0845)  classification: 0.2576 (0.2289)\n",
            "Epoch: [30] [280/289]  eta: 0:00:00  time: 0.0793  loss: 0.3018 (0.3030)  bbox_regression: 0.0431 (0.0588)  classification: 0.2587 (0.2442)\n",
            "Epoch: [30] [288/289]  eta: 0:00:00  time: 0.0791  loss: 0.2989 (0.2603)  bbox_regression: 0.0430 (0.0345)  classification: 0.2559 (0.2258)\n",
            "Epoch: [30] Time: 0:00:22 (0.0791 s / it)\n",
            "Epoch: [31]\n",
            "Epoch: [31] [  0/289]  eta: 0:00:24  time: 0.0845  loss: 0.4011 (0.4011)  bbox_regression: 0.0130 (0.0130)  classification: 0.3881 (0.3881)\n",
            "Epoch: [31] [ 10/289]  eta: 0:00:22  time: 0.0793  loss: 0.2273 (0.2273)  bbox_regression: 0.0287 (0.0287)  classification: 0.1986 (0.1986)\n",
            "Epoch: [31] [ 20/289]  eta: 0:00:21  time: 0.0791  loss: 0.2354 (0.2272)  bbox_regression: 0.0341 (0.0351)  classification: 0.2014 (0.1920)\n",
            "Epoch: [31] [ 30/289]  eta: 0:00:21  time: 0.0816  loss: 0.2642 (0.2844)  bbox_regression: 0.0415 (0.0486)  classification: 0.2227 (0.2359)\n",
            "Epoch: [31] [ 40/289]  eta: 0:00:20  time: 0.0820  loss: 0.2780 (0.3227)  bbox_regression: 0.0573 (0.0817)  classification: 0.2207 (0.2410)\n",
            "Epoch: [31] [ 50/289]  eta: 0:00:19  time: 0.0825  loss: 0.2817 (0.3088)  bbox_regression: 0.0565 (0.0797)  classification: 0.2252 (0.2291)\n",
            "Epoch: [31] [ 60/289]  eta: 0:00:18  time: 0.0825  loss: 0.2834 (0.2944)  bbox_regression: 0.0541 (0.0475)  classification: 0.2293 (0.2469)\n",
            "Epoch: [31] [ 70/289]  eta: 0:00:17  time: 0.0820  loss: 0.2829 (0.2861)  bbox_regression: 0.0509 (0.0367)  classification: 0.2320 (0.2494)\n",
            "Epoch: [31] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 0.2840 (0.2858)  bbox_regression: 0.0487 (0.0324)  classification: 0.2352 (0.2534)\n",
            "Epoch: [31] [ 90/289]  eta: 0:00:16  time: 0.0814  loss: 0.2846 (0.2904)  bbox_regression: 0.0474 (0.0348)  classification: 0.2372 (0.2556)\n",
            "Epoch: [31] [100/289]  eta: 0:00:15  time: 0.0811  loss: 0.2790 (0.2586)  bbox_regression: 0.0464 (0.0370)  classification: 0.2325 (0.2216)\n",
            "Epoch: [31] [110/289]  eta: 0:00:14  time: 0.0807  loss: 0.2716 (0.2124)  bbox_regression: 0.0456 (0.0377)  classification: 0.2259 (0.1747)\n",
            "Epoch: [31] [120/289]  eta: 0:00:13  time: 0.0804  loss: 0.2720 (0.2370)  bbox_regression: 0.0450 (0.0379)  classification: 0.2270 (0.1991)\n",
            "Epoch: [31] [130/289]  eta: 0:00:12  time: 0.0802  loss: 0.2746 (0.2916)  bbox_regression: 0.0460 (0.0477)  classification: 0.2287 (0.2439)\n",
            "Epoch: [31] [140/289]  eta: 0:00:11  time: 0.0801  loss: 0.2689 (0.2502)  bbox_regression: 0.0458 (0.0508)  classification: 0.2231 (0.1995)\n",
            "Epoch: [31] [150/289]  eta: 0:00:11  time: 0.0802  loss: 0.2735 (0.2662)  bbox_regression: 0.0449 (0.0378)  classification: 0.2286 (0.2283)\n",
            "Epoch: [31] [160/289]  eta: 0:00:10  time: 0.0802  loss: 0.2768 (0.3321)  bbox_regression: 0.0452 (0.0406)  classification: 0.2316 (0.2915)\n",
            "Epoch: [31] [170/289]  eta: 0:00:09  time: 0.0801  loss: 0.2746 (0.2828)  bbox_regression: 0.0449 (0.0452)  classification: 0.2297 (0.2376)\n",
            "Epoch: [31] [180/289]  eta: 0:00:08  time: 0.0800  loss: 0.2716 (0.2297)  bbox_regression: 0.0443 (0.0377)  classification: 0.2272 (0.1920)\n",
            "Epoch: [31] [190/289]  eta: 0:00:07  time: 0.0802  loss: 0.2714 (0.2443)  bbox_regression: 0.0450 (0.0460)  classification: 0.2264 (0.1983)\n",
            "Epoch: [31] [200/289]  eta: 0:00:07  time: 0.0802  loss: 0.2707 (0.2624)  bbox_regression: 0.0442 (0.0430)  classification: 0.2264 (0.2194)\n",
            "Epoch: [31] [210/289]  eta: 0:00:06  time: 0.0801  loss: 0.2679 (0.2338)  bbox_regression: 0.0433 (0.0265)  classification: 0.2246 (0.2073)\n",
            "Epoch: [31] [220/289]  eta: 0:00:05  time: 0.0800  loss: 0.2709 (0.2728)  bbox_regression: 0.0424 (0.0245)  classification: 0.2284 (0.2483)\n",
            "Epoch: [31] [230/289]  eta: 0:00:04  time: 0.0801  loss: 0.2697 (0.2888)  bbox_regression: 0.0422 (0.0307)  classification: 0.2275 (0.2582)\n",
            "Epoch: [31] [240/289]  eta: 0:00:03  time: 0.0800  loss: 0.2702 (0.2632)  bbox_regression: 0.0419 (0.0366)  classification: 0.2283 (0.2266)\n",
            "Epoch: [31] [250/289]  eta: 0:00:03  time: 0.0800  loss: 0.2662 (0.2264)  bbox_regression: 0.0414 (0.0329)  classification: 0.2248 (0.1935)\n",
            "Epoch: [31] [260/289]  eta: 0:00:02  time: 0.0798  loss: 0.2657 (0.2110)  bbox_regression: 0.0413 (0.0342)  classification: 0.2243 (0.1768)\n",
            "Epoch: [31] [270/289]  eta: 0:00:01  time: 0.0798  loss: 0.2688 (0.3005)  bbox_regression: 0.0413 (0.0393)  classification: 0.2275 (0.2612)\n",
            "Epoch: [31] [280/289]  eta: 0:00:00  time: 0.0797  loss: 0.2657 (0.2661)  bbox_regression: 0.0410 (0.0358)  classification: 0.2248 (0.2303)\n",
            "Epoch: [31] [288/289]  eta: 0:00:00  time: 0.0795  loss: 0.2631 (0.2073)  bbox_regression: 0.0409 (0.0370)  classification: 0.2222 (0.1703)\n",
            "Epoch: [31] Time: 0:00:22 (0.0795 s / it)\n",
            "Epoch: [32]\n",
            "Epoch: [32] [  0/289]  eta: 0:00:23  time: 0.0797  loss: 0.1517 (0.1517)  bbox_regression: 0.0371 (0.0371)  classification: 0.1146 (0.1146)\n",
            "Epoch: [32] [ 10/289]  eta: 0:00:22  time: 0.0804  loss: 0.3202 (0.3202)  bbox_regression: 0.0469 (0.0469)  classification: 0.2733 (0.2733)\n",
            "Epoch: [32] [ 20/289]  eta: 0:00:21  time: 0.0782  loss: 0.2380 (0.2423)  bbox_regression: 0.0420 (0.0423)  classification: 0.1959 (0.2000)\n",
            "Epoch: [32] [ 30/289]  eta: 0:00:20  time: 0.0776  loss: 0.2117 (0.1521)  bbox_regression: 0.0405 (0.0370)  classification: 0.1712 (0.1150)\n",
            "Epoch: [32] [ 40/289]  eta: 0:00:19  time: 0.0789  loss: 0.2210 (0.2032)  bbox_regression: 0.0427 (0.0434)  classification: 0.1783 (0.1598)\n",
            "Epoch: [32] [ 50/289]  eta: 0:00:18  time: 0.0793  loss: 0.2226 (0.2395)  bbox_regression: 0.0414 (0.0428)  classification: 0.1812 (0.1967)\n",
            "Epoch: [32] [ 60/289]  eta: 0:00:18  time: 0.0803  loss: 0.2304 (0.2496)  bbox_regression: 0.0430 (0.0436)  classification: 0.1874 (0.2060)\n",
            "Epoch: [32] [ 70/289]  eta: 0:00:17  time: 0.0802  loss: 0.2277 (0.2407)  bbox_regression: 0.0424 (0.0449)  classification: 0.1853 (0.1958)\n",
            "Epoch: [32] [ 80/289]  eta: 0:00:16  time: 0.0797  loss: 0.2248 (0.2077)  bbox_regression: 0.0412 (0.0358)  classification: 0.1836 (0.1719)\n",
            "Epoch: [32] [ 90/289]  eta: 0:00:15  time: 0.0796  loss: 0.2276 (0.2274)  bbox_regression: 0.0400 (0.0313)  classification: 0.1877 (0.1961)\n",
            "Epoch: [32] [100/289]  eta: 0:00:15  time: 0.0797  loss: 0.2260 (0.2309)  bbox_regression: 0.0394 (0.0322)  classification: 0.1866 (0.1988)\n",
            "Epoch: [32] [110/289]  eta: 0:00:14  time: 0.0797  loss: 0.2372 (0.2807)  bbox_regression: 0.0424 (0.0536)  classification: 0.1948 (0.2271)\n",
            "Epoch: [32] [120/289]  eta: 0:00:13  time: 0.0796  loss: 0.2404 (0.3134)  bbox_regression: 0.0423 (0.0569)  classification: 0.1981 (0.2565)\n",
            "Epoch: [32] [130/289]  eta: 0:00:12  time: 0.0796  loss: 0.2379 (0.2416)  bbox_regression: 0.0419 (0.0393)  classification: 0.1959 (0.2023)\n",
            "Epoch: [32] [140/289]  eta: 0:00:11  time: 0.0795  loss: 0.2397 (0.2349)  bbox_regression: 0.0421 (0.0409)  classification: 0.1975 (0.1939)\n",
            "Epoch: [32] [150/289]  eta: 0:00:11  time: 0.0794  loss: 0.2426 (0.2737)  bbox_regression: 0.0419 (0.0415)  classification: 0.2007 (0.2323)\n",
            "Epoch: [32] [160/289]  eta: 0:00:10  time: 0.0794  loss: 0.2426 (0.2633)  bbox_regression: 0.0414 (0.0361)  classification: 0.2012 (0.2272)\n",
            "Epoch: [32] [170/289]  eta: 0:00:09  time: 0.0795  loss: 0.2428 (0.2442)  bbox_regression: 0.0418 (0.0408)  classification: 0.2010 (0.2034)\n",
            "Epoch: [32] [180/289]  eta: 0:00:08  time: 0.0793  loss: 0.2397 (0.2165)  bbox_regression: 0.0409 (0.0374)  classification: 0.1988 (0.1791)\n",
            "Epoch: [32] [190/289]  eta: 0:00:07  time: 0.0793  loss: 0.2388 (0.2042)  bbox_regression: 0.0410 (0.0343)  classification: 0.1978 (0.1700)\n",
            "Epoch: [32] [200/289]  eta: 0:00:07  time: 0.0795  loss: 0.2435 (0.2776)  bbox_regression: 0.0433 (0.0650)  classification: 0.2002 (0.2126)\n",
            "Epoch: [32] [210/289]  eta: 0:00:06  time: 0.0796  loss: 0.2439 (0.2932)  bbox_regression: 0.0438 (0.0705)  classification: 0.2001 (0.2227)\n",
            "Epoch: [32] [220/289]  eta: 0:00:05  time: 0.0797  loss: 0.2438 (0.2473)  bbox_regression: 0.0433 (0.0431)  classification: 0.2005 (0.2042)\n",
            "Epoch: [32] [230/289]  eta: 0:00:04  time: 0.0797  loss: 0.2467 (0.2761)  bbox_regression: 0.0438 (0.0446)  classification: 0.2029 (0.2314)\n",
            "Epoch: [32] [240/289]  eta: 0:00:03  time: 0.0795  loss: 0.2475 (0.2879)  bbox_regression: 0.0434 (0.0448)  classification: 0.2041 (0.2432)\n",
            "Epoch: [32] [250/289]  eta: 0:00:03  time: 0.0795  loss: 0.2477 (0.2590)  bbox_regression: 0.0429 (0.0316)  classification: 0.2048 (0.2274)\n",
            "Epoch: [32] [260/289]  eta: 0:00:02  time: 0.0795  loss: 0.2466 (0.2364)  bbox_regression: 0.0423 (0.0291)  classification: 0.2043 (0.2073)\n",
            "Epoch: [32] [270/289]  eta: 0:00:01  time: 0.0794  loss: 0.2485 (0.2587)  bbox_regression: 0.0419 (0.0297)  classification: 0.2066 (0.2290)\n",
            "Epoch: [32] [280/289]  eta: 0:00:00  time: 0.0793  loss: 0.2468 (0.2488)  bbox_regression: 0.0416 (0.0323)  classification: 0.2052 (0.2165)\n",
            "Epoch: [32] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.2475 (0.2418)  bbox_regression: 0.0412 (0.0300)  classification: 0.2063 (0.2118)\n",
            "Epoch: [32] Time: 0:00:22 (0.0791 s / it)\n",
            "Epoch: [33]\n",
            "Epoch: [33] [  0/289]  eta: 0:00:21  time: 0.0740  loss: 0.0915 (0.0915)  bbox_regression: 0.0206 (0.0206)  classification: 0.0709 (0.0709)\n",
            "Epoch: [33] [ 10/289]  eta: 0:00:21  time: 0.0766  loss: 0.2667 (0.2667)  bbox_regression: 0.0375 (0.0375)  classification: 0.2292 (0.2292)\n",
            "Epoch: [33] [ 20/289]  eta: 0:00:20  time: 0.0778  loss: 0.2427 (0.2502)  bbox_regression: 0.0329 (0.0335)  classification: 0.2097 (0.2167)\n",
            "Epoch: [33] [ 30/289]  eta: 0:00:20  time: 0.0783  loss: 0.2209 (0.1957)  bbox_regression: 0.0328 (0.0302)  classification: 0.1881 (0.1655)\n",
            "Epoch: [33] [ 40/289]  eta: 0:00:19  time: 0.0782  loss: 0.2194 (0.1949)  bbox_regression: 0.0338 (0.0346)  classification: 0.1856 (0.1603)\n",
            "Epoch: [33] [ 50/289]  eta: 0:00:18  time: 0.0791  loss: 0.2265 (0.2352)  bbox_regression: 0.0338 (0.0354)  classification: 0.1927 (0.1999)\n",
            "Epoch: [33] [ 60/289]  eta: 0:00:18  time: 0.0792  loss: 0.2360 (0.2701)  bbox_regression: 0.0350 (0.0376)  classification: 0.2010 (0.2325)\n",
            "Epoch: [33] [ 70/289]  eta: 0:00:17  time: 0.0792  loss: 0.2410 (0.2780)  bbox_regression: 0.0370 (0.0452)  classification: 0.2040 (0.2328)\n",
            "Epoch: [33] [ 80/289]  eta: 0:00:16  time: 0.0792  loss: 0.2423 (0.2614)  bbox_regression: 0.0370 (0.0431)  classification: 0.2053 (0.2183)\n",
            "Epoch: [33] [ 90/289]  eta: 0:00:15  time: 0.0792  loss: 0.2379 (0.2267)  bbox_regression: 0.0365 (0.0345)  classification: 0.2014 (0.1922)\n",
            "Epoch: [33] [100/289]  eta: 0:00:14  time: 0.0789  loss: 0.2381 (0.2211)  bbox_regression: 0.0382 (0.0430)  classification: 0.1999 (0.1782)\n",
            "Epoch: [33] [110/289]  eta: 0:00:14  time: 0.0789  loss: 0.2388 (0.2430)  bbox_regression: 0.0380 (0.0447)  classification: 0.2008 (0.1983)\n",
            "Epoch: [33] [120/289]  eta: 0:00:13  time: 0.0787  loss: 0.2350 (0.2191)  bbox_regression: 0.0386 (0.0406)  classification: 0.1963 (0.1784)\n",
            "Epoch: [33] [130/289]  eta: 0:00:12  time: 0.0786  loss: 0.2327 (0.1991)  bbox_regression: 0.0380 (0.0385)  classification: 0.1947 (0.1606)\n",
            "Epoch: [33] [140/289]  eta: 0:00:11  time: 0.0787  loss: 0.2323 (0.2160)  bbox_regression: 0.0376 (0.0313)  classification: 0.1947 (0.1847)\n",
            "Epoch: [33] [150/289]  eta: 0:00:10  time: 0.0785  loss: 0.2313 (0.2216)  bbox_regression: 0.0368 (0.0289)  classification: 0.1944 (0.1927)\n",
            "Epoch: [33] [160/289]  eta: 0:00:10  time: 0.0785  loss: 0.2331 (0.2393)  bbox_regression: 0.0371 (0.0342)  classification: 0.1960 (0.2051)\n",
            "Epoch: [33] [170/289]  eta: 0:00:09  time: 0.0788  loss: 0.2355 (0.2676)  bbox_regression: 0.0381 (0.0481)  classification: 0.1974 (0.2195)\n",
            "Epoch: [33] [180/289]  eta: 0:00:08  time: 0.0790  loss: 0.2314 (0.2177)  bbox_regression: 0.0381 (0.0461)  classification: 0.1933 (0.1716)\n",
            "Epoch: [33] [190/289]  eta: 0:00:07  time: 0.0790  loss: 0.2300 (0.1833)  bbox_regression: 0.0391 (0.0470)  classification: 0.1910 (0.1364)\n",
            "Epoch: [33] [200/289]  eta: 0:00:07  time: 0.0790  loss: 0.2313 (0.2299)  bbox_regression: 0.0394 (0.0509)  classification: 0.1919 (0.1790)\n",
            "Epoch: [33] [210/289]  eta: 0:00:06  time: 0.0789  loss: 0.2309 (0.2392)  bbox_regression: 0.0399 (0.0477)  classification: 0.1910 (0.1915)\n",
            "Epoch: [33] [220/289]  eta: 0:00:05  time: 0.0789  loss: 0.2355 (0.2785)  bbox_regression: 0.0397 (0.0427)  classification: 0.1958 (0.2358)\n",
            "Epoch: [33] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.2353 (0.2817)  bbox_regression: 0.0395 (0.0360)  classification: 0.1958 (0.2457)\n",
            "Epoch: [33] [240/289]  eta: 0:00:03  time: 0.0789  loss: 0.2356 (0.2358)  bbox_regression: 0.0394 (0.0362)  classification: 0.1962 (0.1996)\n",
            "Epoch: [33] [250/289]  eta: 0:00:03  time: 0.0790  loss: 0.2338 (0.2160)  bbox_regression: 0.0400 (0.0456)  classification: 0.1937 (0.1704)\n",
            "Epoch: [33] [260/289]  eta: 0:00:02  time: 0.0790  loss: 0.2333 (0.2066)  bbox_regression: 0.0399 (0.0463)  classification: 0.1934 (0.1603)\n",
            "Epoch: [33] [270/289]  eta: 0:00:01  time: 0.0789  loss: 0.2324 (0.2158)  bbox_regression: 0.0396 (0.0345)  classification: 0.1928 (0.1813)\n",
            "Epoch: [33] [280/289]  eta: 0:00:00  time: 0.0789  loss: 0.2365 (0.2783)  bbox_regression: 0.0415 (0.0618)  classification: 0.1950 (0.2165)\n",
            "Epoch: [33] [288/289]  eta: 0:00:00  time: 0.0787  loss: 0.2364 (0.2872)  bbox_regression: 0.0411 (0.0618)  classification: 0.1953 (0.2254)\n",
            "Epoch: [33] Time: 0:00:22 (0.0787 s / it)\n",
            "Epoch: [34]\n",
            "Epoch: [34] [  0/289]  eta: 0:00:22  time: 0.0783  loss: 0.1171 (0.1171)  bbox_regression: 0.0210 (0.0210)  classification: 0.0961 (0.0961)\n",
            "Epoch: [34] [ 10/289]  eta: 0:00:21  time: 0.0779  loss: 0.2483 (0.2483)  bbox_regression: 0.0347 (0.0347)  classification: 0.2135 (0.2135)\n",
            "Epoch: [34] [ 20/289]  eta: 0:00:21  time: 0.0783  loss: 0.2272 (0.2327)  bbox_regression: 0.0311 (0.0316)  classification: 0.1961 (0.2011)\n",
            "Epoch: [34] [ 30/289]  eta: 0:00:20  time: 0.0784  loss: 0.2274 (0.2160)  bbox_regression: 0.0312 (0.0293)  classification: 0.1962 (0.1867)\n",
            "Epoch: [34] [ 40/289]  eta: 0:00:19  time: 0.0779  loss: 0.2374 (0.2481)  bbox_regression: 0.0338 (0.0367)  classification: 0.2036 (0.2114)\n",
            "Epoch: [34] [ 50/289]  eta: 0:00:18  time: 0.0780  loss: 0.2207 (0.2102)  bbox_regression: 0.0316 (0.0321)  classification: 0.1891 (0.1781)\n",
            "Epoch: [34] [ 60/289]  eta: 0:00:17  time: 0.0781  loss: 0.2382 (0.2397)  bbox_regression: 0.0397 (0.0518)  classification: 0.1984 (0.1879)\n",
            "Epoch: [34] [ 70/289]  eta: 0:00:17  time: 0.0782  loss: 0.2390 (0.2856)  bbox_regression: 0.0400 (0.0614)  classification: 0.1990 (0.2243)\n",
            "Epoch: [34] [ 80/289]  eta: 0:00:16  time: 0.0784  loss: 0.2367 (0.2321)  bbox_regression: 0.0388 (0.0361)  classification: 0.1978 (0.1960)\n",
            "Epoch: [34] [ 90/289]  eta: 0:00:15  time: 0.0785  loss: 0.2262 (0.1808)  bbox_regression: 0.0377 (0.0298)  classification: 0.1884 (0.1510)\n",
            "Epoch: [34] [100/289]  eta: 0:00:14  time: 0.0793  loss: 0.2337 (0.2214)  bbox_regression: 0.0398 (0.0438)  classification: 0.1938 (0.1777)\n",
            "Epoch: [34] [110/289]  eta: 0:00:14  time: 0.0790  loss: 0.2326 (0.2616)  bbox_regression: 0.0399 (0.0499)  classification: 0.1926 (0.2117)\n",
            "Epoch: [34] [120/289]  eta: 0:00:13  time: 0.0792  loss: 0.2291 (0.2062)  bbox_regression: 0.0396 (0.0386)  classification: 0.1895 (0.1676)\n",
            "Epoch: [34] [130/289]  eta: 0:00:12  time: 0.0792  loss: 0.2328 (0.2343)  bbox_regression: 0.0405 (0.0439)  classification: 0.1923 (0.1904)\n",
            "Epoch: [34] [140/289]  eta: 0:00:11  time: 0.0789  loss: 0.2321 (0.2499)  bbox_regression: 0.0396 (0.0392)  classification: 0.1925 (0.2107)\n",
            "Epoch: [34] [150/289]  eta: 0:00:10  time: 0.0790  loss: 0.2299 (0.2112)  bbox_regression: 0.0391 (0.0298)  classification: 0.1908 (0.1813)\n",
            "Epoch: [34] [160/289]  eta: 0:00:10  time: 0.0788  loss: 0.2323 (0.2336)  bbox_regression: 0.0421 (0.0597)  classification: 0.1902 (0.1739)\n",
            "Epoch: [34] [170/289]  eta: 0:00:09  time: 0.0789  loss: 0.2310 (0.2386)  bbox_regression: 0.0423 (0.0664)  classification: 0.1887 (0.1722)\n",
            "Epoch: [34] [180/289]  eta: 0:00:08  time: 0.0788  loss: 0.2259 (0.1743)  bbox_regression: 0.0416 (0.0376)  classification: 0.1843 (0.1367)\n",
            "Epoch: [34] [190/289]  eta: 0:00:07  time: 0.0790  loss: 0.2246 (0.1704)  bbox_regression: 0.0417 (0.0370)  classification: 0.1829 (0.1334)\n",
            "Epoch: [34] [200/289]  eta: 0:00:07  time: 0.0791  loss: 0.2281 (0.2489)  bbox_regression: 0.0419 (0.0450)  classification: 0.1862 (0.2039)\n",
            "Epoch: [34] [210/289]  eta: 0:00:06  time: 0.0791  loss: 0.2247 (0.2254)  bbox_regression: 0.0413 (0.0374)  classification: 0.1834 (0.1879)\n",
            "Epoch: [34] [220/289]  eta: 0:00:05  time: 0.0791  loss: 0.2272 (0.2181)  bbox_regression: 0.0414 (0.0363)  classification: 0.1858 (0.1818)\n",
            "Epoch: [34] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.2228 (0.2031)  bbox_regression: 0.0407 (0.0341)  classification: 0.1821 (0.1690)\n",
            "Epoch: [34] [240/289]  eta: 0:00:03  time: 0.0790  loss: 0.2266 (0.2198)  bbox_regression: 0.0406 (0.0317)  classification: 0.1860 (0.1881)\n",
            "Epoch: [34] [250/289]  eta: 0:00:03  time: 0.0791  loss: 0.2232 (0.2278)  bbox_regression: 0.0401 (0.0331)  classification: 0.1831 (0.1948)\n",
            "Epoch: [34] [260/289]  eta: 0:00:02  time: 0.0791  loss: 0.2242 (0.1945)  bbox_regression: 0.0408 (0.0431)  classification: 0.1834 (0.1514)\n",
            "Epoch: [34] [270/289]  eta: 0:00:01  time: 0.0791  loss: 0.2234 (0.2256)  bbox_regression: 0.0410 (0.0526)  classification: 0.1824 (0.1730)\n",
            "Epoch: [34] [280/289]  eta: 0:00:00  time: 0.0792  loss: 0.2251 (0.2367)  bbox_regression: 0.0407 (0.0396)  classification: 0.1844 (0.1971)\n",
            "Epoch: [34] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.2253 (0.2603)  bbox_regression: 0.0403 (0.0392)  classification: 0.1851 (0.2211)\n",
            "Epoch: [34] Time: 0:00:22 (0.0790 s / it)\n",
            "Validation: [34]\n",
            "Validation: [34] [ 0/62]  eta: 0:00:04  time: 0.0673  \n",
            "Validation: [34] [10/62]  eta: 0:00:03  time: 0.0661  \n",
            "Validation: [34] [20/62]  eta: 0:00:02  time: 0.0649  \n",
            "Validation: [34] [30/62]  eta: 0:00:02  time: 0.0651  \n",
            "Validation: [34] [40/62]  eta: 0:00:01  time: 0.0656  \n",
            "Validation: [34] [50/62]  eta: 0:00:00  time: 0.0660  \n",
            "Validation: [34] [60/62]  eta: 0:00:00  time: 0.0664  \n",
            "Validation: [34] [61/62]  eta: 0:00:00  time: 0.0660  \n",
            "Validation: [34] Time: 0:00:04 (0.0660 s / it)\n",
            "Epoch 34: mAP = 0.6928\n",
            "Epoch: [35]\n",
            "Epoch: [35] [  0/289]  eta: 0:00:23  time: 0.0818  loss: 0.1952 (0.1952)  bbox_regression: 0.0425 (0.0425)  classification: 0.1527 (0.1527)\n",
            "Epoch: [35] [ 10/289]  eta: 0:00:22  time: 0.0792  loss: 0.2012 (0.2012)  bbox_regression: 0.0382 (0.0382)  classification: 0.1630 (0.1630)\n",
            "Epoch: [35] [ 20/289]  eta: 0:00:21  time: 0.0789  loss: 0.2399 (0.2422)  bbox_regression: 0.0476 (0.0478)  classification: 0.1924 (0.1943)\n",
            "Epoch: [35] [ 30/289]  eta: 0:00:20  time: 0.0806  loss: 0.2332 (0.2508)  bbox_regression: 0.0434 (0.0462)  classification: 0.1898 (0.2045)\n",
            "Epoch: [35] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 0.2295 (0.2186)  bbox_regression: 0.0434 (0.0390)  classification: 0.1861 (0.1796)\n",
            "Epoch: [35] [ 50/289]  eta: 0:00:19  time: 0.0808  loss: 0.2219 (0.2043)  bbox_regression: 0.0417 (0.0392)  classification: 0.1801 (0.1652)\n",
            "Epoch: [35] [ 60/289]  eta: 0:00:18  time: 0.0804  loss: 0.2194 (0.1987)  bbox_regression: 0.0395 (0.0316)  classification: 0.1799 (0.1671)\n",
            "Epoch: [35] [ 70/289]  eta: 0:00:17  time: 0.0805  loss: 0.2178 (0.2074)  bbox_regression: 0.0385 (0.0302)  classification: 0.1793 (0.1772)\n",
            "Epoch: [35] [ 80/289]  eta: 0:00:16  time: 0.0807  loss: 0.2142 (0.1982)  bbox_regression: 0.0370 (0.0294)  classification: 0.1771 (0.1688)\n",
            "Epoch: [35] [ 90/289]  eta: 0:00:16  time: 0.0805  loss: 0.2165 (0.2120)  bbox_regression: 0.0367 (0.0303)  classification: 0.1798 (0.1817)\n",
            "Epoch: [35] [100/289]  eta: 0:00:15  time: 0.0803  loss: 0.2252 (0.2697)  bbox_regression: 0.0381 (0.0426)  classification: 0.1870 (0.2271)\n",
            "Epoch: [35] [110/289]  eta: 0:00:14  time: 0.0800  loss: 0.2189 (0.2297)  bbox_regression: 0.0373 (0.0399)  classification: 0.1816 (0.1898)\n",
            "Epoch: [35] [120/289]  eta: 0:00:13  time: 0.0801  loss: 0.2219 (0.2054)  bbox_regression: 0.0403 (0.0514)  classification: 0.1816 (0.1540)\n",
            "Epoch: [35] [130/289]  eta: 0:00:12  time: 0.0801  loss: 0.2149 (0.1927)  bbox_regression: 0.0397 (0.0531)  classification: 0.1752 (0.1396)\n",
            "Epoch: [35] [140/289]  eta: 0:00:11  time: 0.0800  loss: 0.2128 (0.1578)  bbox_regression: 0.0401 (0.0386)  classification: 0.1727 (0.1192)\n",
            "Epoch: [35] [150/289]  eta: 0:00:11  time: 0.0798  loss: 0.2098 (0.1762)  bbox_regression: 0.0394 (0.0378)  classification: 0.1703 (0.1384)\n",
            "Epoch: [35] [160/289]  eta: 0:00:10  time: 0.0798  loss: 0.2045 (0.1458)  bbox_regression: 0.0388 (0.0297)  classification: 0.1657 (0.1160)\n",
            "Epoch: [35] [170/289]  eta: 0:00:09  time: 0.0797  loss: 0.2077 (0.1921)  bbox_regression: 0.0392 (0.0373)  classification: 0.1685 (0.1548)\n",
            "Epoch: [35] [180/289]  eta: 0:00:08  time: 0.0801  loss: 0.2075 (0.2317)  bbox_regression: 0.0384 (0.0353)  classification: 0.1691 (0.1964)\n",
            "Epoch: [35] [190/289]  eta: 0:00:07  time: 0.0801  loss: 0.2091 (0.2206)  bbox_regression: 0.0383 (0.0306)  classification: 0.1708 (0.1900)\n",
            "Epoch: [35] [200/289]  eta: 0:00:07  time: 0.0803  loss: 0.2121 (0.2538)  bbox_regression: 0.0379 (0.0338)  classification: 0.1742 (0.2200)\n",
            "Epoch: [35] [210/289]  eta: 0:00:06  time: 0.0803  loss: 0.2140 (0.2607)  bbox_regression: 0.0391 (0.0471)  classification: 0.1748 (0.2137)\n",
            "Epoch: [35] [220/289]  eta: 0:00:05  time: 0.0804  loss: 0.2163 (0.2583)  bbox_regression: 0.0395 (0.0549)  classification: 0.1768 (0.2034)\n",
            "Epoch: [35] [230/289]  eta: 0:00:04  time: 0.0802  loss: 0.2161 (0.2388)  bbox_regression: 0.0395 (0.0438)  classification: 0.1766 (0.1949)\n",
            "Epoch: [35] [240/289]  eta: 0:00:03  time: 0.0801  loss: 0.2158 (0.2100)  bbox_regression: 0.0391 (0.0352)  classification: 0.1766 (0.1748)\n",
            "Epoch: [35] [250/289]  eta: 0:00:03  time: 0.0801  loss: 0.2144 (0.1952)  bbox_regression: 0.0396 (0.0403)  classification: 0.1748 (0.1549)\n",
            "Epoch: [35] [260/289]  eta: 0:00:02  time: 0.0800  loss: 0.2138 (0.1905)  bbox_regression: 0.0395 (0.0436)  classification: 0.1744 (0.1469)\n",
            "Epoch: [35] [270/289]  eta: 0:00:01  time: 0.0798  loss: 0.2210 (0.3038)  bbox_regression: 0.0419 (0.0709)  classification: 0.1791 (0.2329)\n",
            "Epoch: [35] [280/289]  eta: 0:00:00  time: 0.0797  loss: 0.2196 (0.2945)  bbox_regression: 0.0416 (0.0687)  classification: 0.1780 (0.2258)\n",
            "Epoch: [35] [288/289]  eta: 0:00:00  time: 0.0795  loss: 0.2176 (0.2245)  bbox_regression: 0.0411 (0.0575)  classification: 0.1765 (0.1670)\n",
            "Epoch: [35] Time: 0:00:22 (0.0795 s / it)\n",
            "Epoch: [36]\n",
            "Epoch: [36] [  0/289]  eta: 0:00:22  time: 0.0764  loss: 0.0656 (0.0656)  bbox_regression: 0.0240 (0.0240)  classification: 0.0416 (0.0416)\n",
            "Epoch: [36] [ 10/289]  eta: 0:00:20  time: 0.0752  loss: 0.2001 (0.2001)  bbox_regression: 0.0441 (0.0441)  classification: 0.1560 (0.1560)\n",
            "Epoch: [36] [ 20/289]  eta: 0:00:20  time: 0.0761  loss: 0.1978 (0.2044)  bbox_regression: 0.0465 (0.0476)  classification: 0.1513 (0.1568)\n",
            "Epoch: [36] [ 30/289]  eta: 0:00:19  time: 0.0767  loss: 0.2004 (0.2006)  bbox_regression: 0.0456 (0.0464)  classification: 0.1549 (0.1542)\n",
            "Epoch: [36] [ 40/289]  eta: 0:00:19  time: 0.0768  loss: 0.1850 (0.1715)  bbox_regression: 0.0421 (0.0374)  classification: 0.1429 (0.1341)\n",
            "Epoch: [36] [ 50/289]  eta: 0:00:18  time: 0.0775  loss: 0.1826 (0.1550)  bbox_regression: 0.0397 (0.0305)  classification: 0.1429 (0.1244)\n",
            "Epoch: [36] [ 60/289]  eta: 0:00:17  time: 0.0782  loss: 0.1890 (0.1971)  bbox_regression: 0.0387 (0.0319)  classification: 0.1503 (0.1653)\n",
            "Epoch: [36] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.1881 (0.2020)  bbox_regression: 0.0387 (0.0362)  classification: 0.1494 (0.1659)\n",
            "Epoch: [36] [ 80/289]  eta: 0:00:16  time: 0.0793  loss: 0.1857 (0.1758)  bbox_regression: 0.0376 (0.0341)  classification: 0.1481 (0.1417)\n",
            "Epoch: [36] [ 90/289]  eta: 0:00:15  time: 0.0792  loss: 0.1858 (0.1777)  bbox_regression: 0.0371 (0.0316)  classification: 0.1487 (0.1461)\n",
            "Epoch: [36] [100/289]  eta: 0:00:15  time: 0.0794  loss: 0.1849 (0.1815)  bbox_regression: 0.0359 (0.0291)  classification: 0.1490 (0.1524)\n",
            "Epoch: [36] [110/289]  eta: 0:00:14  time: 0.0790  loss: 0.1929 (0.2253)  bbox_regression: 0.0385 (0.0446)  classification: 0.1544 (0.1807)\n",
            "Epoch: [36] [120/289]  eta: 0:00:13  time: 0.0788  loss: 0.2028 (0.2934)  bbox_regression: 0.0394 (0.0571)  classification: 0.1634 (0.2363)\n",
            "Epoch: [36] [130/289]  eta: 0:00:12  time: 0.0789  loss: 0.2052 (0.2735)  bbox_regression: 0.0394 (0.0445)  classification: 0.1658 (0.2290)\n",
            "Epoch: [36] [140/289]  eta: 0:00:11  time: 0.0788  loss: 0.2019 (0.1963)  bbox_regression: 0.0390 (0.0367)  classification: 0.1629 (0.1595)\n",
            "Epoch: [36] [150/289]  eta: 0:00:10  time: 0.0788  loss: 0.2045 (0.1999)  bbox_regression: 0.0395 (0.0405)  classification: 0.1650 (0.1594)\n",
            "Epoch: [36] [160/289]  eta: 0:00:10  time: 0.0788  loss: 0.2021 (0.2038)  bbox_regression: 0.0390 (0.0388)  classification: 0.1631 (0.1650)\n",
            "Epoch: [36] [170/289]  eta: 0:00:09  time: 0.0790  loss: 0.2020 (0.1832)  bbox_regression: 0.0390 (0.0352)  classification: 0.1630 (0.1480)\n",
            "Epoch: [36] [180/289]  eta: 0:00:08  time: 0.0790  loss: 0.2056 (0.2334)  bbox_regression: 0.0388 (0.0376)  classification: 0.1667 (0.1958)\n",
            "Epoch: [36] [190/289]  eta: 0:00:07  time: 0.0791  loss: 0.2043 (0.2242)  bbox_regression: 0.0388 (0.0372)  classification: 0.1655 (0.1870)\n",
            "Epoch: [36] [200/289]  eta: 0:00:07  time: 0.0792  loss: 0.2094 (0.2438)  bbox_regression: 0.0393 (0.0435)  classification: 0.1701 (0.2003)\n",
            "Epoch: [36] [210/289]  eta: 0:00:06  time: 0.0795  loss: 0.2060 (0.2215)  bbox_regression: 0.0394 (0.0452)  classification: 0.1665 (0.1763)\n",
            "Epoch: [36] [220/289]  eta: 0:00:05  time: 0.0797  loss: 0.2053 (0.1642)  bbox_regression: 0.0399 (0.0455)  classification: 0.1654 (0.1187)\n",
            "Epoch: [36] [230/289]  eta: 0:00:04  time: 0.0797  loss: 0.2039 (0.1823)  bbox_regression: 0.0398 (0.0439)  classification: 0.1641 (0.1384)\n",
            "Epoch: [36] [240/289]  eta: 0:00:03  time: 0.0797  loss: 0.2038 (0.1871)  bbox_regression: 0.0399 (0.0398)  classification: 0.1639 (0.1473)\n",
            "Epoch: [36] [250/289]  eta: 0:00:03  time: 0.0797  loss: 0.2038 (0.2026)  bbox_regression: 0.0394 (0.0349)  classification: 0.1644 (0.1677)\n",
            "Epoch: [36] [260/289]  eta: 0:00:02  time: 0.0796  loss: 0.2023 (0.1844)  bbox_regression: 0.0390 (0.0282)  classification: 0.1633 (0.1561)\n",
            "Epoch: [36] [270/289]  eta: 0:00:01  time: 0.0796  loss: 0.2015 (0.1730)  bbox_regression: 0.0386 (0.0283)  classification: 0.1629 (0.1447)\n",
            "Epoch: [36] [280/289]  eta: 0:00:00  time: 0.0795  loss: 0.2027 (0.2080)  bbox_regression: 0.0386 (0.0334)  classification: 0.1641 (0.1746)\n",
            "Epoch: [36] [288/289]  eta: 0:00:00  time: 0.0793  loss: 0.2081 (0.2940)  bbox_regression: 0.0408 (0.0674)  classification: 0.1673 (0.2266)\n",
            "Epoch: [36] Time: 0:00:22 (0.0793 s / it)\n",
            "Epoch: [37]\n",
            "Epoch: [37] [  0/289]  eta: 0:00:20  time: 0.0698  loss: 0.2720 (0.2720)  bbox_regression: 0.0343 (0.0343)  classification: 0.2377 (0.2377)\n",
            "Epoch: [37] [ 10/289]  eta: 0:00:21  time: 0.0787  loss: 0.2197 (0.2197)  bbox_regression: 0.0432 (0.0432)  classification: 0.1765 (0.1765)\n",
            "Epoch: [37] [ 20/289]  eta: 0:00:21  time: 0.0790  loss: 0.2685 (0.2683)  bbox_regression: 0.0499 (0.0507)  classification: 0.2186 (0.2176)\n",
            "Epoch: [37] [ 30/289]  eta: 0:00:20  time: 0.0789  loss: 0.2300 (0.2356)  bbox_regression: 0.0424 (0.0419)  classification: 0.1876 (0.1937)\n",
            "Epoch: [37] [ 40/289]  eta: 0:00:19  time: 0.0791  loss: 0.2149 (0.1586)  bbox_regression: 0.0394 (0.0283)  classification: 0.1755 (0.1303)\n",
            "Epoch: [37] [ 50/289]  eta: 0:00:18  time: 0.0789  loss: 0.2224 (0.2107)  bbox_regression: 0.0434 (0.0451)  classification: 0.1790 (0.1656)\n",
            "Epoch: [37] [ 60/289]  eta: 0:00:18  time: 0.0791  loss: 0.2185 (0.2259)  bbox_regression: 0.0415 (0.0458)  classification: 0.1770 (0.1801)\n",
            "Epoch: [37] [ 70/289]  eta: 0:00:17  time: 0.0801  loss: 0.2197 (0.2129)  bbox_regression: 0.0404 (0.0326)  classification: 0.1793 (0.1803)\n",
            "Epoch: [37] [ 80/289]  eta: 0:00:16  time: 0.0802  loss: 0.2329 (0.2770)  bbox_regression: 0.0493 (0.0732)  classification: 0.1836 (0.2038)\n",
            "Epoch: [37] [ 90/289]  eta: 0:00:15  time: 0.0802  loss: 0.2313 (0.2722)  bbox_regression: 0.0483 (0.0766)  classification: 0.1829 (0.1957)\n",
            "Epoch: [37] [100/289]  eta: 0:00:15  time: 0.0801  loss: 0.2237 (0.1862)  bbox_regression: 0.0481 (0.0434)  classification: 0.1755 (0.1428)\n",
            "Epoch: [37] [110/289]  eta: 0:00:14  time: 0.0802  loss: 0.2173 (0.1536)  bbox_regression: 0.0482 (0.0474)  classification: 0.1691 (0.1062)\n",
            "Epoch: [37] [120/289]  eta: 0:00:13  time: 0.0801  loss: 0.2159 (0.1769)  bbox_regression: 0.0476 (0.0450)  classification: 0.1683 (0.1319)\n",
            "Epoch: [37] [130/289]  eta: 0:00:12  time: 0.0800  loss: 0.2193 (0.2308)  bbox_regression: 0.0476 (0.0446)  classification: 0.1717 (0.1862)\n",
            "Epoch: [37] [140/289]  eta: 0:00:11  time: 0.0799  loss: 0.2163 (0.2188)  bbox_regression: 0.0464 (0.0389)  classification: 0.1700 (0.1799)\n",
            "Epoch: [37] [150/289]  eta: 0:00:11  time: 0.0798  loss: 0.2137 (0.1771)  bbox_regression: 0.0456 (0.0327)  classification: 0.1681 (0.1445)\n",
            "Epoch: [37] [160/289]  eta: 0:00:10  time: 0.0795  loss: 0.2085 (0.1532)  bbox_regression: 0.0447 (0.0330)  classification: 0.1638 (0.1202)\n",
            "Epoch: [37] [170/289]  eta: 0:00:09  time: 0.0793  loss: 0.2074 (0.1591)  bbox_regression: 0.0441 (0.0328)  classification: 0.1632 (0.1263)\n",
            "Epoch: [37] [180/289]  eta: 0:00:08  time: 0.0792  loss: 0.2029 (0.1574)  bbox_regression: 0.0434 (0.0331)  classification: 0.1594 (0.1243)\n",
            "Epoch: [37] [190/289]  eta: 0:00:07  time: 0.0791  loss: 0.2069 (0.2030)  bbox_regression: 0.0437 (0.0397)  classification: 0.1632 (0.1633)\n",
            "Epoch: [37] [200/289]  eta: 0:00:07  time: 0.0791  loss: 0.2085 (0.2591)  bbox_regression: 0.0430 (0.0393)  classification: 0.1654 (0.2199)\n",
            "Epoch: [37] [210/289]  eta: 0:00:06  time: 0.0792  loss: 0.2076 (0.2144)  bbox_regression: 0.0423 (0.0291)  classification: 0.1653 (0.1853)\n",
            "Epoch: [37] [220/289]  eta: 0:00:05  time: 0.0792  loss: 0.2094 (0.2191)  bbox_regression: 0.0419 (0.0308)  classification: 0.1675 (0.1883)\n",
            "Epoch: [37] [230/289]  eta: 0:00:04  time: 0.0793  loss: 0.2098 (0.2335)  bbox_regression: 0.0422 (0.0414)  classification: 0.1676 (0.1921)\n",
            "Epoch: [37] [240/289]  eta: 0:00:03  time: 0.0793  loss: 0.2077 (0.1885)  bbox_regression: 0.0419 (0.0419)  classification: 0.1658 (0.1466)\n",
            "Epoch: [37] [250/289]  eta: 0:00:03  time: 0.0792  loss: 0.2060 (0.1614)  bbox_regression: 0.0421 (0.0407)  classification: 0.1639 (0.1207)\n",
            "Epoch: [37] [260/289]  eta: 0:00:02  time: 0.0791  loss: 0.2042 (0.1625)  bbox_regression: 0.0415 (0.0365)  classification: 0.1627 (0.1260)\n",
            "Epoch: [37] [270/289]  eta: 0:00:01  time: 0.0791  loss: 0.2037 (0.1755)  bbox_regression: 0.0413 (0.0314)  classification: 0.1624 (0.1441)\n",
            "Epoch: [37] [280/289]  eta: 0:00:00  time: 0.0791  loss: 0.2022 (0.1756)  bbox_regression: 0.0407 (0.0297)  classification: 0.1615 (0.1460)\n",
            "Epoch: [37] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.2009 (0.1717)  bbox_regression: 0.0402 (0.0260)  classification: 0.1608 (0.1457)\n",
            "Epoch: [37] Time: 0:00:22 (0.0790 s / it)\n",
            "Epoch: [38]\n",
            "Epoch: [38] [  0/289]  eta: 0:00:22  time: 0.0789  loss: 0.1152 (0.1152)  bbox_regression: 0.0320 (0.0320)  classification: 0.0831 (0.0831)\n",
            "Epoch: [38] [ 10/289]  eta: 0:00:21  time: 0.0780  loss: 0.2410 (0.2410)  bbox_regression: 0.0350 (0.0350)  classification: 0.2060 (0.2060)\n",
            "Epoch: [38] [ 20/289]  eta: 0:00:21  time: 0.0787  loss: 0.1848 (0.1883)  bbox_regression: 0.0328 (0.0328)  classification: 0.1521 (0.1555)\n",
            "Epoch: [38] [ 30/289]  eta: 0:00:20  time: 0.0784  loss: 0.2047 (0.1848)  bbox_regression: 0.0390 (0.0412)  classification: 0.1657 (0.1436)\n",
            "Epoch: [38] [ 40/289]  eta: 0:00:19  time: 0.0784  loss: 0.1969 (0.2096)  bbox_regression: 0.0359 (0.0393)  classification: 0.1610 (0.1703)\n",
            "Epoch: [38] [ 50/289]  eta: 0:00:18  time: 0.0785  loss: 0.2026 (0.1993)  bbox_regression: 0.0383 (0.0372)  classification: 0.1643 (0.1621)\n",
            "Epoch: [38] [ 60/289]  eta: 0:00:17  time: 0.0782  loss: 0.1930 (0.1850)  bbox_regression: 0.0366 (0.0380)  classification: 0.1564 (0.1469)\n",
            "Epoch: [38] [ 70/289]  eta: 0:00:17  time: 0.0782  loss: 0.2074 (0.2196)  bbox_regression: 0.0434 (0.0565)  classification: 0.1640 (0.1631)\n",
            "Epoch: [38] [ 80/289]  eta: 0:00:16  time: 0.0780  loss: 0.2013 (0.2266)  bbox_regression: 0.0420 (0.0586)  classification: 0.1592 (0.1680)\n",
            "Epoch: [38] [ 90/289]  eta: 0:00:15  time: 0.0778  loss: 0.1994 (0.1710)  bbox_regression: 0.0425 (0.0391)  classification: 0.1569 (0.1319)\n",
            "Epoch: [38] [100/289]  eta: 0:00:14  time: 0.0781  loss: 0.2016 (0.2029)  bbox_regression: 0.0422 (0.0428)  classification: 0.1594 (0.1601)\n",
            "Epoch: [38] [110/289]  eta: 0:00:13  time: 0.0782  loss: 0.1998 (0.2019)  bbox_regression: 0.0409 (0.0337)  classification: 0.1590 (0.1683)\n",
            "Epoch: [38] [120/289]  eta: 0:00:13  time: 0.0784  loss: 0.2053 (0.2239)  bbox_regression: 0.0420 (0.0409)  classification: 0.1633 (0.1830)\n",
            "Epoch: [38] [130/289]  eta: 0:00:12  time: 0.0786  loss: 0.2077 (0.2512)  bbox_regression: 0.0421 (0.0490)  classification: 0.1656 (0.2023)\n",
            "Epoch: [38] [140/289]  eta: 0:00:11  time: 0.0784  loss: 0.2104 (0.2413)  bbox_regression: 0.0431 (0.0499)  classification: 0.1673 (0.1914)\n",
            "Epoch: [38] [150/289]  eta: 0:00:10  time: 0.0784  loss: 0.2063 (0.1968)  bbox_regression: 0.0424 (0.0442)  classification: 0.1639 (0.1527)\n",
            "Epoch: [38] [160/289]  eta: 0:00:10  time: 0.0785  loss: 0.2053 (0.1694)  bbox_regression: 0.0420 (0.0339)  classification: 0.1633 (0.1354)\n",
            "Epoch: [38] [170/289]  eta: 0:00:09  time: 0.0786  loss: 0.1984 (0.1390)  bbox_regression: 0.0411 (0.0314)  classification: 0.1573 (0.1076)\n",
            "Epoch: [38] [180/289]  eta: 0:00:08  time: 0.0787  loss: 0.1996 (0.1541)  bbox_regression: 0.0408 (0.0313)  classification: 0.1589 (0.1228)\n",
            "Epoch: [38] [190/289]  eta: 0:00:07  time: 0.0787  loss: 0.1963 (0.1789)  bbox_regression: 0.0403 (0.0332)  classification: 0.1561 (0.1456)\n",
            "Epoch: [38] [200/289]  eta: 0:00:07  time: 0.0788  loss: 0.1955 (0.1580)  bbox_regression: 0.0399 (0.0314)  classification: 0.1556 (0.1266)\n",
            "Epoch: [38] [210/289]  eta: 0:00:06  time: 0.0788  loss: 0.1923 (0.1535)  bbox_regression: 0.0392 (0.0291)  classification: 0.1531 (0.1244)\n",
            "Epoch: [38] [220/289]  eta: 0:00:05  time: 0.0789  loss: 0.1910 (0.1459)  bbox_regression: 0.0396 (0.0370)  classification: 0.1514 (0.1089)\n",
            "Epoch: [38] [230/289]  eta: 0:00:04  time: 0.0790  loss: 0.1917 (0.1850)  bbox_regression: 0.0404 (0.0531)  classification: 0.1512 (0.1319)\n",
            "Epoch: [38] [240/289]  eta: 0:00:03  time: 0.0790  loss: 0.1914 (0.1960)  bbox_regression: 0.0403 (0.0476)  classification: 0.1512 (0.1483)\n",
            "Epoch: [38] [250/289]  eta: 0:00:03  time: 0.0790  loss: 0.1947 (0.2296)  bbox_regression: 0.0412 (0.0496)  classification: 0.1535 (0.1800)\n",
            "Epoch: [38] [260/289]  eta: 0:00:02  time: 0.0790  loss: 0.1931 (0.2130)  bbox_regression: 0.0411 (0.0513)  classification: 0.1520 (0.1617)\n",
            "Epoch: [38] [270/289]  eta: 0:00:01  time: 0.0790  loss: 0.1941 (0.1873)  bbox_regression: 0.0412 (0.0417)  classification: 0.1529 (0.1456)\n",
            "Epoch: [38] [280/289]  eta: 0:00:00  time: 0.0790  loss: 0.1961 (0.2362)  bbox_regression: 0.0412 (0.0419)  classification: 0.1550 (0.1942)\n",
            "Epoch: [38] [288/289]  eta: 0:00:00  time: 0.0788  loss: 0.1961 (0.2185)  bbox_regression: 0.0411 (0.0391)  classification: 0.1550 (0.1794)\n",
            "Epoch: [38] Time: 0:00:22 (0.0788 s / it)\n",
            "Epoch: [39]\n",
            "Epoch: [39] [  0/289]  eta: 0:00:24  time: 0.0850  loss: 0.0843 (0.0843)  bbox_regression: 0.0250 (0.0250)  classification: 0.0593 (0.0593)\n",
            "Epoch: [39] [ 10/289]  eta: 0:00:21  time: 0.0761  loss: 0.1578 (0.1578)  bbox_regression: 0.0367 (0.0367)  classification: 0.1211 (0.1211)\n",
            "Epoch: [39] [ 20/289]  eta: 0:00:20  time: 0.0770  loss: 0.2010 (0.2069)  bbox_regression: 0.0383 (0.0390)  classification: 0.1627 (0.1679)\n",
            "Epoch: [39] [ 30/289]  eta: 0:00:20  time: 0.0772  loss: 0.1955 (0.2163)  bbox_regression: 0.0399 (0.0417)  classification: 0.1556 (0.1746)\n",
            "Epoch: [39] [ 40/289]  eta: 0:00:19  time: 0.0768  loss: 0.1864 (0.1710)  bbox_regression: 0.0368 (0.0351)  classification: 0.1496 (0.1358)\n",
            "Epoch: [39] [ 50/289]  eta: 0:00:18  time: 0.0777  loss: 0.1800 (0.1560)  bbox_regression: 0.0364 (0.0309)  classification: 0.1437 (0.1251)\n",
            "Epoch: [39] [ 60/289]  eta: 0:00:17  time: 0.0779  loss: 0.1935 (0.2081)  bbox_regression: 0.0414 (0.0510)  classification: 0.1521 (0.1571)\n",
            "Epoch: [39] [ 70/289]  eta: 0:00:17  time: 0.0780  loss: 0.1863 (0.2021)  bbox_regression: 0.0390 (0.0458)  classification: 0.1472 (0.1564)\n",
            "Epoch: [39] [ 80/289]  eta: 0:00:16  time: 0.0780  loss: 0.1857 (0.1619)  bbox_regression: 0.0394 (0.0334)  classification: 0.1463 (0.1285)\n",
            "Epoch: [39] [ 90/289]  eta: 0:00:15  time: 0.0784  loss: 0.1873 (0.1909)  bbox_regression: 0.0399 (0.0428)  classification: 0.1474 (0.1481)\n",
            "Epoch: [39] [100/289]  eta: 0:00:14  time: 0.0791  loss: 0.1829 (0.1718)  bbox_regression: 0.0393 (0.0387)  classification: 0.1436 (0.1330)\n",
            "Epoch: [39] [110/289]  eta: 0:00:14  time: 0.0795  loss: 0.1882 (0.1924)  bbox_regression: 0.0398 (0.0398)  classification: 0.1484 (0.1526)\n",
            "Epoch: [39] [120/289]  eta: 0:00:13  time: 0.0800  loss: 0.1932 (0.2450)  bbox_regression: 0.0409 (0.0489)  classification: 0.1523 (0.1961)\n",
            "Epoch: [39] [130/289]  eta: 0:00:12  time: 0.0799  loss: 0.1952 (0.2342)  bbox_regression: 0.0424 (0.0563)  classification: 0.1529 (0.1779)\n",
            "Epoch: [39] [140/289]  eta: 0:00:11  time: 0.0801  loss: 0.1971 (0.2209)  bbox_regression: 0.0417 (0.0465)  classification: 0.1554 (0.1743)\n",
            "Epoch: [39] [150/289]  eta: 0:00:11  time: 0.0798  loss: 0.1942 (0.1878)  bbox_regression: 0.0410 (0.0324)  classification: 0.1532 (0.1554)\n",
            "Epoch: [39] [160/289]  eta: 0:00:10  time: 0.0796  loss: 0.1922 (0.1574)  bbox_regression: 0.0409 (0.0351)  classification: 0.1513 (0.1224)\n",
            "Epoch: [39] [170/289]  eta: 0:00:09  time: 0.0795  loss: 0.1920 (0.1753)  bbox_regression: 0.0410 (0.0408)  classification: 0.1510 (0.1345)\n",
            "Epoch: [39] [180/289]  eta: 0:00:08  time: 0.0796  loss: 0.1868 (0.1438)  bbox_regression: 0.0401 (0.0343)  classification: 0.1467 (0.1095)\n",
            "Epoch: [39] [190/289]  eta: 0:00:07  time: 0.0796  loss: 0.1870 (0.1440)  bbox_regression: 0.0397 (0.0287)  classification: 0.1473 (0.1153)\n",
            "Epoch: [39] [200/289]  eta: 0:00:07  time: 0.0795  loss: 0.1855 (0.1731)  bbox_regression: 0.0396 (0.0345)  classification: 0.1459 (0.1386)\n",
            "Epoch: [39] [210/289]  eta: 0:00:06  time: 0.0793  loss: 0.1833 (0.1477)  bbox_regression: 0.0391 (0.0333)  classification: 0.1442 (0.1143)\n",
            "Epoch: [39] [220/289]  eta: 0:00:05  time: 0.0792  loss: 0.1874 (0.2063)  bbox_regression: 0.0400 (0.0447)  classification: 0.1473 (0.1617)\n",
            "Epoch: [39] [230/289]  eta: 0:00:04  time: 0.0793  loss: 0.1886 (0.2454)  bbox_regression: 0.0405 (0.0556)  classification: 0.1481 (0.1898)\n",
            "Epoch: [39] [240/289]  eta: 0:00:03  time: 0.0791  loss: 0.1876 (0.1899)  bbox_regression: 0.0401 (0.0413)  classification: 0.1474 (0.1486)\n",
            "Epoch: [39] [250/289]  eta: 0:00:03  time: 0.0792  loss: 0.1902 (0.2087)  bbox_regression: 0.0422 (0.0611)  classification: 0.1481 (0.1476)\n",
            "Epoch: [39] [260/289]  eta: 0:00:02  time: 0.0793  loss: 0.1915 (0.2387)  bbox_regression: 0.0418 (0.0623)  classification: 0.1497 (0.1764)\n",
            "Epoch: [39] [270/289]  eta: 0:00:01  time: 0.0795  loss: 0.1908 (0.1979)  bbox_regression: 0.0415 (0.0331)  classification: 0.1493 (0.1648)\n",
            "Epoch: [39] [280/289]  eta: 0:00:00  time: 0.0795  loss: 0.1905 (0.1773)  bbox_regression: 0.0410 (0.0300)  classification: 0.1495 (0.1474)\n",
            "Epoch: [39] [288/289]  eta: 0:00:00  time: 0.0792  loss: 0.1897 (0.1704)  bbox_regression: 0.0407 (0.0290)  classification: 0.1491 (0.1414)\n",
            "Epoch: [39] Time: 0:00:22 (0.0793 s / it)\n",
            "Validation: [39]\n",
            "Validation: [39] [ 0/62]  eta: 0:00:04  time: 0.0658  \n",
            "Validation: [39] [10/62]  eta: 0:00:03  time: 0.0656  \n",
            "Validation: [39] [20/62]  eta: 0:00:02  time: 0.0647  \n",
            "Validation: [39] [30/62]  eta: 0:00:02  time: 0.0651  \n",
            "Validation: [39] [40/62]  eta: 0:00:01  time: 0.0657  \n",
            "Validation: [39] [50/62]  eta: 0:00:00  time: 0.0662  \n",
            "Validation: [39] [60/62]  eta: 0:00:00  time: 0.0665  \n",
            "Validation: [39] [61/62]  eta: 0:00:00  time: 0.0661  \n",
            "Validation: [39] Time: 0:00:04 (0.0661 s / it)\n",
            "Epoch 39: mAP = 0.6817\n",
            "Saved checkpoint at epoch 40\n",
            "Epoch: [40]\n",
            "Epoch: [40] [  0/289]  eta: 0:00:24  time: 0.0840  loss: 0.2041 (0.2041)  bbox_regression: 0.0264 (0.0264)  classification: 0.1777 (0.1777)\n",
            "Epoch: [40] [ 10/289]  eta: 0:00:23  time: 0.0857  loss: 0.1796 (0.1796)  bbox_regression: 0.0447 (0.0447)  classification: 0.1349 (0.1349)\n",
            "Epoch: [40] [ 20/289]  eta: 0:00:22  time: 0.0841  loss: 0.1844 (0.1834)  bbox_regression: 0.0363 (0.0368)  classification: 0.1481 (0.1466)\n",
            "Epoch: [40] [ 30/289]  eta: 0:00:21  time: 0.0819  loss: 0.1775 (0.1764)  bbox_regression: 0.0337 (0.0276)  classification: 0.1439 (0.1488)\n",
            "Epoch: [40] [ 40/289]  eta: 0:00:20  time: 0.0811  loss: 0.1749 (0.1648)  bbox_regression: 0.0331 (0.0297)  classification: 0.1418 (0.1351)\n",
            "Epoch: [40] [ 50/289]  eta: 0:00:19  time: 0.0810  loss: 0.1712 (0.1613)  bbox_regression: 0.0344 (0.0355)  classification: 0.1368 (0.1258)\n",
            "Epoch: [40] [ 60/289]  eta: 0:00:18  time: 0.0803  loss: 0.1659 (0.1476)  bbox_regression: 0.0334 (0.0341)  classification: 0.1325 (0.1135)\n",
            "Epoch: [40] [ 70/289]  eta: 0:00:17  time: 0.0799  loss: 0.1864 (0.2251)  bbox_regression: 0.0379 (0.0467)  classification: 0.1485 (0.1784)\n",
            "Epoch: [40] [ 80/289]  eta: 0:00:16  time: 0.0796  loss: 0.1996 (0.3022)  bbox_regression: 0.0393 (0.0573)  classification: 0.1602 (0.2449)\n",
            "Epoch: [40] [ 90/289]  eta: 0:00:15  time: 0.0797  loss: 0.1933 (0.2180)  bbox_regression: 0.0385 (0.0408)  classification: 0.1548 (0.1772)\n",
            "Epoch: [40] [100/289]  eta: 0:00:15  time: 0.0799  loss: 0.1854 (0.1280)  bbox_regression: 0.0374 (0.0295)  classification: 0.1480 (0.0985)\n",
            "Epoch: [40] [110/289]  eta: 0:00:14  time: 0.0797  loss: 0.1820 (0.1307)  bbox_regression: 0.0365 (0.0271)  classification: 0.1456 (0.1037)\n",
            "Epoch: [40] [120/289]  eta: 0:00:13  time: 0.0796  loss: 0.1794 (0.1489)  bbox_regression: 0.0359 (0.0284)  classification: 0.1435 (0.1205)\n",
            "Epoch: [40] [130/289]  eta: 0:00:12  time: 0.0795  loss: 0.1768 (0.1478)  bbox_regression: 0.0355 (0.0300)  classification: 0.1413 (0.1177)\n",
            "Epoch: [40] [140/289]  eta: 0:00:11  time: 0.0795  loss: 0.1750 (0.1483)  bbox_regression: 0.0350 (0.0293)  classification: 0.1400 (0.1191)\n",
            "Epoch: [40] [150/289]  eta: 0:00:11  time: 0.0794  loss: 0.1780 (0.1860)  bbox_regression: 0.0351 (0.0324)  classification: 0.1430 (0.1536)\n",
            "Epoch: [40] [160/289]  eta: 0:00:10  time: 0.0795  loss: 0.1848 (0.2543)  bbox_regression: 0.0359 (0.0428)  classification: 0.1489 (0.2115)\n",
            "Epoch: [40] [170/289]  eta: 0:00:09  time: 0.0794  loss: 0.1825 (0.2159)  bbox_regression: 0.0358 (0.0410)  classification: 0.1467 (0.1749)\n",
            "Epoch: [40] [180/289]  eta: 0:00:08  time: 0.0794  loss: 0.1799 (0.1406)  bbox_regression: 0.0360 (0.0367)  classification: 0.1439 (0.1039)\n",
            "Epoch: [40] [190/289]  eta: 0:00:07  time: 0.0797  loss: 0.1808 (0.1668)  bbox_regression: 0.0360 (0.0379)  classification: 0.1448 (0.1289)\n",
            "Epoch: [40] [200/289]  eta: 0:00:07  time: 0.0800  loss: 0.1810 (0.1905)  bbox_regression: 0.0368 (0.0437)  classification: 0.1442 (0.1468)\n",
            "Epoch: [40] [210/289]  eta: 0:00:06  time: 0.0801  loss: 0.1810 (0.1828)  bbox_regression: 0.0372 (0.0485)  classification: 0.1438 (0.1343)\n",
            "Epoch: [40] [220/289]  eta: 0:00:05  time: 0.0801  loss: 0.1836 (0.2094)  bbox_regression: 0.0380 (0.0505)  classification: 0.1455 (0.1589)\n",
            "Epoch: [40] [230/289]  eta: 0:00:04  time: 0.0799  loss: 0.1821 (0.1930)  bbox_regression: 0.0379 (0.0455)  classification: 0.1442 (0.1475)\n",
            "Epoch: [40] [240/289]  eta: 0:00:03  time: 0.0800  loss: 0.1854 (0.2061)  bbox_regression: 0.0401 (0.0627)  classification: 0.1454 (0.1434)\n",
            "Epoch: [40] [250/289]  eta: 0:00:03  time: 0.0800  loss: 0.1841 (0.2081)  bbox_regression: 0.0401 (0.0654)  classification: 0.1440 (0.1426)\n",
            "Epoch: [40] [260/289]  eta: 0:00:02  time: 0.0799  loss: 0.1838 (0.1645)  bbox_regression: 0.0403 (0.0428)  classification: 0.1435 (0.1217)\n",
            "Epoch: [40] [270/289]  eta: 0:00:01  time: 0.0797  loss: 0.1835 (0.1753)  bbox_regression: 0.0404 (0.0438)  classification: 0.1431 (0.1315)\n",
            "Epoch: [40] [280/289]  eta: 0:00:00  time: 0.0797  loss: 0.1838 (0.1833)  bbox_regression: 0.0407 (0.0465)  classification: 0.1431 (0.1368)\n",
            "Epoch: [40] [288/289]  eta: 0:00:00  time: 0.0795  loss: 0.1835 (0.2025)  bbox_regression: 0.0406 (0.0487)  classification: 0.1429 (0.1537)\n",
            "Epoch: [40] Time: 0:00:22 (0.0795 s / it)\n",
            "Epoch: [41]\n",
            "Epoch: [41] [  0/289]  eta: 0:00:23  time: 0.0813  loss: 0.0646 (0.0646)  bbox_regression: 0.0228 (0.0228)  classification: 0.0418 (0.0418)\n",
            "Epoch: [41] [ 10/289]  eta: 0:00:21  time: 0.0775  loss: 0.1707 (0.1707)  bbox_regression: 0.0719 (0.0719)  classification: 0.0989 (0.0989)\n",
            "Epoch: [41] [ 20/289]  eta: 0:00:21  time: 0.0799  loss: 0.1686 (0.1739)  bbox_regression: 0.0549 (0.0565)  classification: 0.1138 (0.1174)\n",
            "Epoch: [41] [ 30/289]  eta: 0:00:20  time: 0.0793  loss: 0.1711 (0.1713)  bbox_regression: 0.0495 (0.0371)  classification: 0.1217 (0.1342)\n",
            "Epoch: [41] [ 40/289]  eta: 0:00:19  time: 0.0791  loss: 0.1610 (0.1530)  bbox_regression: 0.0445 (0.0336)  classification: 0.1165 (0.1194)\n",
            "Epoch: [41] [ 50/289]  eta: 0:00:18  time: 0.0790  loss: 0.1507 (0.1191)  bbox_regression: 0.0411 (0.0283)  classification: 0.1096 (0.0908)\n",
            "Epoch: [41] [ 60/289]  eta: 0:00:18  time: 0.0793  loss: 0.1485 (0.1229)  bbox_regression: 0.0386 (0.0263)  classification: 0.1099 (0.0965)\n",
            "Epoch: [41] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.1524 (0.1567)  bbox_regression: 0.0389 (0.0333)  classification: 0.1135 (0.1234)\n",
            "Epoch: [41] [ 80/289]  eta: 0:00:16  time: 0.0792  loss: 0.1580 (0.1870)  bbox_regression: 0.0394 (0.0420)  classification: 0.1186 (0.1451)\n",
            "Epoch: [41] [ 90/289]  eta: 0:00:15  time: 0.0792  loss: 0.1591 (0.1827)  bbox_regression: 0.0389 (0.0390)  classification: 0.1201 (0.1437)\n",
            "Epoch: [41] [100/289]  eta: 0:00:14  time: 0.0791  loss: 0.1661 (0.1987)  bbox_regression: 0.0398 (0.0413)  classification: 0.1263 (0.1574)\n",
            "Epoch: [41] [110/289]  eta: 0:00:14  time: 0.0792  loss: 0.1641 (0.1870)  bbox_regression: 0.0395 (0.0418)  classification: 0.1246 (0.1452)\n",
            "Epoch: [41] [120/289]  eta: 0:00:13  time: 0.0792  loss: 0.1626 (0.1452)  bbox_regression: 0.0389 (0.0346)  classification: 0.1237 (0.1106)\n",
            "Epoch: [41] [130/289]  eta: 0:00:12  time: 0.0790  loss: 0.1580 (0.1246)  bbox_regression: 0.0382 (0.0309)  classification: 0.1199 (0.0936)\n",
            "Epoch: [41] [140/289]  eta: 0:00:11  time: 0.0789  loss: 0.1643 (0.1742)  bbox_regression: 0.0380 (0.0327)  classification: 0.1262 (0.1415)\n",
            "Epoch: [41] [150/289]  eta: 0:00:10  time: 0.0788  loss: 0.1685 (0.2372)  bbox_regression: 0.0384 (0.0399)  classification: 0.1301 (0.1973)\n",
            "Epoch: [41] [160/289]  eta: 0:00:10  time: 0.0788  loss: 0.1684 (0.1978)  bbox_regression: 0.0381 (0.0389)  classification: 0.1303 (0.1589)\n",
            "Epoch: [41] [170/289]  eta: 0:00:09  time: 0.0788  loss: 0.1676 (0.1608)  bbox_regression: 0.0378 (0.0336)  classification: 0.1298 (0.1272)\n",
            "Epoch: [41] [180/289]  eta: 0:00:08  time: 0.0788  loss: 0.1675 (0.1596)  bbox_regression: 0.0374 (0.0314)  classification: 0.1301 (0.1282)\n",
            "Epoch: [41] [190/289]  eta: 0:00:07  time: 0.0787  loss: 0.1653 (0.1451)  bbox_regression: 0.0369 (0.0286)  classification: 0.1284 (0.1165)\n",
            "Epoch: [41] [200/289]  eta: 0:00:06  time: 0.0786  loss: 0.1672 (0.1650)  bbox_regression: 0.0382 (0.0454)  classification: 0.1290 (0.1196)\n",
            "Epoch: [41] [210/289]  eta: 0:00:06  time: 0.0787  loss: 0.1674 (0.1880)  bbox_regression: 0.0388 (0.0569)  classification: 0.1287 (0.1310)\n",
            "Epoch: [41] [220/289]  eta: 0:00:05  time: 0.0786  loss: 0.1679 (0.1748)  bbox_regression: 0.0398 (0.0559)  classification: 0.1281 (0.1189)\n",
            "Epoch: [41] [230/289]  eta: 0:00:04  time: 0.0789  loss: 0.1717 (0.2171)  bbox_regression: 0.0399 (0.0524)  classification: 0.1318 (0.1647)\n",
            "Epoch: [41] [240/289]  eta: 0:00:03  time: 0.0789  loss: 0.1700 (0.1929)  bbox_regression: 0.0395 (0.0357)  classification: 0.1305 (0.1572)\n",
            "Epoch: [41] [250/289]  eta: 0:00:03  time: 0.0788  loss: 0.1721 (0.1767)  bbox_regression: 0.0395 (0.0339)  classification: 0.1327 (0.1429)\n",
            "Epoch: [41] [260/289]  eta: 0:00:02  time: 0.0788  loss: 0.1734 (0.2147)  bbox_regression: 0.0398 (0.0438)  classification: 0.1336 (0.1710)\n",
            "Epoch: [41] [270/289]  eta: 0:00:01  time: 0.0788  loss: 0.1749 (0.2100)  bbox_regression: 0.0396 (0.0409)  classification: 0.1354 (0.1692)\n",
            "Epoch: [41] [280/289]  eta: 0:00:00  time: 0.0788  loss: 0.1745 (0.1888)  bbox_regression: 0.0400 (0.0424)  classification: 0.1345 (0.1464)\n",
            "Epoch: [41] [288/289]  eta: 0:00:00  time: 0.0786  loss: 0.1766 (0.2068)  bbox_regression: 0.0402 (0.0487)  classification: 0.1364 (0.1581)\n",
            "Epoch: [41] Time: 0:00:22 (0.0786 s / it)\n",
            "Epoch: [42]\n",
            "Epoch: [42] [  0/289]  eta: 0:00:25  time: 0.0867  loss: 0.2921 (0.2921)  bbox_regression: 0.0458 (0.0458)  classification: 0.2462 (0.2462)\n",
            "Epoch: [42] [ 10/289]  eta: 0:00:22  time: 0.0790  loss: 0.2382 (0.2382)  bbox_regression: 0.0356 (0.0356)  classification: 0.2026 (0.2026)\n",
            "Epoch: [42] [ 20/289]  eta: 0:00:21  time: 0.0794  loss: 0.2262 (0.2229)  bbox_regression: 0.0418 (0.0416)  classification: 0.1844 (0.1813)\n",
            "Epoch: [42] [ 30/289]  eta: 0:00:20  time: 0.0786  loss: 0.1898 (0.1632)  bbox_regression: 0.0368 (0.0374)  classification: 0.1531 (0.1258)\n",
            "Epoch: [42] [ 40/289]  eta: 0:00:19  time: 0.0782  loss: 0.1729 (0.1170)  bbox_regression: 0.0354 (0.0288)  classification: 0.1375 (0.0882)\n",
            "Epoch: [42] [ 50/289]  eta: 0:00:18  time: 0.0779  loss: 0.1690 (0.1367)  bbox_regression: 0.0369 (0.0370)  classification: 0.1321 (0.0996)\n",
            "Epoch: [42] [ 60/289]  eta: 0:00:17  time: 0.0781  loss: 0.1671 (0.1552)  bbox_regression: 0.0368 (0.0395)  classification: 0.1303 (0.1156)\n",
            "Epoch: [42] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.1726 (0.1817)  bbox_regression: 0.0367 (0.0364)  classification: 0.1358 (0.1453)\n",
            "Epoch: [42] [ 80/289]  eta: 0:00:16  time: 0.0795  loss: 0.1753 (0.2005)  bbox_regression: 0.0363 (0.0350)  classification: 0.1390 (0.1655)\n",
            "Epoch: [42] [ 90/289]  eta: 0:00:15  time: 0.0801  loss: 0.1667 (0.1458)  bbox_regression: 0.0352 (0.0297)  classification: 0.1315 (0.1161)\n",
            "Epoch: [42] [100/289]  eta: 0:00:15  time: 0.0802  loss: 0.1725 (0.1612)  bbox_regression: 0.0359 (0.0340)  classification: 0.1367 (0.1272)\n",
            "Epoch: [42] [110/289]  eta: 0:00:14  time: 0.0801  loss: 0.1671 (0.1687)  bbox_regression: 0.0357 (0.0377)  classification: 0.1314 (0.1310)\n",
            "Epoch: [42] [120/289]  eta: 0:00:13  time: 0.0798  loss: 0.1646 (0.1242)  bbox_regression: 0.0365 (0.0398)  classification: 0.1280 (0.0844)\n",
            "Epoch: [42] [130/289]  eta: 0:00:12  time: 0.0798  loss: 0.1654 (0.1565)  bbox_regression: 0.0370 (0.0447)  classification: 0.1284 (0.1118)\n",
            "Epoch: [42] [140/289]  eta: 0:00:11  time: 0.0799  loss: 0.1616 (0.1439)  bbox_regression: 0.0365 (0.0361)  classification: 0.1252 (0.1078)\n",
            "Epoch: [42] [150/289]  eta: 0:00:11  time: 0.0799  loss: 0.1604 (0.1271)  bbox_regression: 0.0360 (0.0289)  classification: 0.1244 (0.0982)\n",
            "Epoch: [42] [160/289]  eta: 0:00:10  time: 0.0797  loss: 0.1634 (0.1763)  bbox_regression: 0.0365 (0.0371)  classification: 0.1269 (0.1392)\n",
            "Epoch: [42] [170/289]  eta: 0:00:09  time: 0.0799  loss: 0.1622 (0.1763)  bbox_regression: 0.0366 (0.0412)  classification: 0.1257 (0.1351)\n",
            "Epoch: [42] [180/289]  eta: 0:00:08  time: 0.0797  loss: 0.1663 (0.1890)  bbox_regression: 0.0393 (0.0617)  classification: 0.1269 (0.1273)\n",
            "Epoch: [42] [190/289]  eta: 0:00:07  time: 0.0795  loss: 0.1649 (0.1879)  bbox_regression: 0.0390 (0.0598)  classification: 0.1259 (0.1281)\n",
            "Epoch: [42] [200/289]  eta: 0:00:07  time: 0.0795  loss: 0.1682 (0.1855)  bbox_regression: 0.0400 (0.0461)  classification: 0.1282 (0.1394)\n",
            "Epoch: [42] [210/289]  eta: 0:00:06  time: 0.0794  loss: 0.1661 (0.1769)  bbox_regression: 0.0394 (0.0433)  classification: 0.1266 (0.1336)\n",
            "Epoch: [42] [220/289]  eta: 0:00:05  time: 0.0794  loss: 0.1672 (0.1575)  bbox_regression: 0.0395 (0.0348)  classification: 0.1277 (0.1227)\n",
            "Epoch: [42] [230/289]  eta: 0:00:04  time: 0.0794  loss: 0.1673 (0.1802)  bbox_regression: 0.0393 (0.0384)  classification: 0.1280 (0.1418)\n",
            "Epoch: [42] [240/289]  eta: 0:00:03  time: 0.0794  loss: 0.1682 (0.1794)  bbox_regression: 0.0399 (0.0437)  classification: 0.1284 (0.1357)\n",
            "Epoch: [42] [250/289]  eta: 0:00:03  time: 0.0794  loss: 0.1690 (0.1892)  bbox_regression: 0.0401 (0.0487)  classification: 0.1290 (0.1405)\n",
            "Epoch: [42] [260/289]  eta: 0:00:02  time: 0.0795  loss: 0.1685 (0.1713)  bbox_regression: 0.0404 (0.0465)  classification: 0.1281 (0.1247)\n",
            "Epoch: [42] [270/289]  eta: 0:00:01  time: 0.0796  loss: 0.1692 (0.1714)  bbox_regression: 0.0402 (0.0424)  classification: 0.1290 (0.1290)\n",
            "Epoch: [42] [280/289]  eta: 0:00:00  time: 0.0795  loss: 0.1716 (0.2125)  bbox_regression: 0.0401 (0.0367)  classification: 0.1315 (0.1758)\n",
            "Epoch: [42] [288/289]  eta: 0:00:00  time: 0.0792  loss: 0.1714 (0.2154)  bbox_regression: 0.0402 (0.0403)  classification: 0.1312 (0.1750)\n",
            "Epoch: [42] Time: 0:00:22 (0.0793 s / it)\n",
            "Epoch: [43]\n",
            "Epoch: [43] [  0/289]  eta: 0:00:25  time: 0.0882  loss: 0.3344 (0.3344)  bbox_regression: 0.0445 (0.0445)  classification: 0.2900 (0.2900)\n",
            "Epoch: [43] [ 10/289]  eta: 0:00:22  time: 0.0793  loss: 0.1779 (0.1779)  bbox_regression: 0.0465 (0.0465)  classification: 0.1314 (0.1314)\n",
            "Epoch: [43] [ 20/289]  eta: 0:00:21  time: 0.0783  loss: 0.1732 (0.1652)  bbox_regression: 0.0556 (0.0562)  classification: 0.1176 (0.1090)\n",
            "Epoch: [43] [ 30/289]  eta: 0:00:20  time: 0.0783  loss: 0.1646 (0.1573)  bbox_regression: 0.0462 (0.0460)  classification: 0.1184 (0.1113)\n",
            "Epoch: [43] [ 40/289]  eta: 0:00:19  time: 0.0780  loss: 0.1585 (0.1429)  bbox_regression: 0.0431 (0.0301)  classification: 0.1153 (0.1129)\n",
            "Epoch: [43] [ 50/289]  eta: 0:00:18  time: 0.0781  loss: 0.1677 (0.1724)  bbox_regression: 0.0414 (0.0341)  classification: 0.1262 (0.1383)\n",
            "Epoch: [43] [ 60/289]  eta: 0:00:17  time: 0.0782  loss: 0.1640 (0.1752)  bbox_regression: 0.0398 (0.0331)  classification: 0.1241 (0.1422)\n",
            "Epoch: [43] [ 70/289]  eta: 0:00:17  time: 0.0780  loss: 0.1579 (0.1332)  bbox_regression: 0.0377 (0.0284)  classification: 0.1202 (0.1048)\n",
            "Epoch: [43] [ 80/289]  eta: 0:00:16  time: 0.0777  loss: 0.1590 (0.1437)  bbox_regression: 0.0373 (0.0296)  classification: 0.1217 (0.1141)\n",
            "Epoch: [43] [ 90/289]  eta: 0:00:15  time: 0.0779  loss: 0.1543 (0.1415)  bbox_regression: 0.0373 (0.0358)  classification: 0.1170 (0.1057)\n",
            "Epoch: [43] [100/289]  eta: 0:00:14  time: 0.0781  loss: 0.1550 (0.1391)  bbox_regression: 0.0374 (0.0378)  classification: 0.1176 (0.1013)\n",
            "Epoch: [43] [110/289]  eta: 0:00:14  time: 0.0785  loss: 0.1557 (0.1617)  bbox_regression: 0.0371 (0.0359)  classification: 0.1186 (0.1258)\n",
            "Epoch: [43] [120/289]  eta: 0:00:13  time: 0.0785  loss: 0.1522 (0.1378)  bbox_regression: 0.0371 (0.0354)  classification: 0.1151 (0.1024)\n",
            "Epoch: [43] [130/289]  eta: 0:00:12  time: 0.0784  loss: 0.1496 (0.1162)  bbox_regression: 0.0366 (0.0341)  classification: 0.1130 (0.0821)\n",
            "Epoch: [43] [140/289]  eta: 0:00:11  time: 0.0785  loss: 0.1475 (0.1191)  bbox_regression: 0.0364 (0.0321)  classification: 0.1111 (0.0870)\n",
            "Epoch: [43] [150/289]  eta: 0:00:10  time: 0.0786  loss: 0.1483 (0.1395)  bbox_regression: 0.0365 (0.0355)  classification: 0.1118 (0.1039)\n",
            "Epoch: [43] [160/289]  eta: 0:00:10  time: 0.0786  loss: 0.1529 (0.1907)  bbox_regression: 0.0371 (0.0418)  classification: 0.1158 (0.1489)\n",
            "Epoch: [43] [170/289]  eta: 0:00:09  time: 0.0785  loss: 0.1554 (0.2090)  bbox_regression: 0.0370 (0.0408)  classification: 0.1184 (0.1682)\n",
            "Epoch: [43] [180/289]  eta: 0:00:08  time: 0.0785  loss: 0.1528 (0.1525)  bbox_regression: 0.0365 (0.0322)  classification: 0.1163 (0.1203)\n",
            "Epoch: [43] [190/289]  eta: 0:00:07  time: 0.0786  loss: 0.1548 (0.1500)  bbox_regression: 0.0368 (0.0349)  classification: 0.1181 (0.1152)\n",
            "Epoch: [43] [200/289]  eta: 0:00:07  time: 0.0788  loss: 0.1541 (0.1660)  bbox_regression: 0.0364 (0.0353)  classification: 0.1177 (0.1308)\n",
            "Epoch: [43] [210/289]  eta: 0:00:06  time: 0.0788  loss: 0.1572 (0.1801)  bbox_regression: 0.0372 (0.0417)  classification: 0.1200 (0.1383)\n",
            "Epoch: [43] [220/289]  eta: 0:00:05  time: 0.0787  loss: 0.1582 (0.1995)  bbox_regression: 0.0377 (0.0503)  classification: 0.1206 (0.1492)\n",
            "Epoch: [43] [230/289]  eta: 0:00:04  time: 0.0786  loss: 0.1591 (0.1790)  bbox_regression: 0.0387 (0.0543)  classification: 0.1204 (0.1247)\n",
            "Epoch: [43] [240/289]  eta: 0:00:03  time: 0.0787  loss: 0.1578 (0.1524)  bbox_regression: 0.0383 (0.0456)  classification: 0.1194 (0.1068)\n",
            "Epoch: [43] [250/289]  eta: 0:00:03  time: 0.0788  loss: 0.1605 (0.1761)  bbox_regression: 0.0387 (0.0388)  classification: 0.1218 (0.1374)\n",
            "Epoch: [43] [260/289]  eta: 0:00:02  time: 0.0790  loss: 0.1616 (0.2079)  bbox_regression: 0.0387 (0.0430)  classification: 0.1229 (0.1649)\n",
            "Epoch: [43] [270/289]  eta: 0:00:01  time: 0.0792  loss: 0.1613 (0.1717)  bbox_regression: 0.0384 (0.0351)  classification: 0.1229 (0.1366)\n",
            "Epoch: [43] [280/289]  eta: 0:00:00  time: 0.0791  loss: 0.1660 (0.2238)  bbox_regression: 0.0401 (0.0592)  classification: 0.1259 (0.1645)\n",
            "Epoch: [43] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.1656 (0.2193)  bbox_regression: 0.0399 (0.0588)  classification: 0.1257 (0.1605)\n",
            "Epoch: [43] Time: 0:00:22 (0.0789 s / it)\n",
            "Epoch: [44]\n",
            "Epoch: [44] [  0/289]  eta: 0:00:20  time: 0.0696  loss: 0.3410 (0.3410)  bbox_regression: 0.1012 (0.1012)  classification: 0.2398 (0.2398)\n",
            "Epoch: [44] [ 10/289]  eta: 0:00:21  time: 0.0781  loss: 0.1580 (0.1580)  bbox_regression: 0.0429 (0.0429)  classification: 0.1151 (0.1151)\n",
            "Epoch: [44] [ 20/289]  eta: 0:00:21  time: 0.0796  loss: 0.1531 (0.1437)  bbox_regression: 0.0467 (0.0440)  classification: 0.1064 (0.0997)\n",
            "Epoch: [44] [ 30/289]  eta: 0:00:20  time: 0.0785  loss: 0.1409 (0.1314)  bbox_regression: 0.0396 (0.0377)  classification: 0.1013 (0.0937)\n",
            "Epoch: [44] [ 40/289]  eta: 0:00:19  time: 0.0785  loss: 0.1345 (0.1149)  bbox_regression: 0.0365 (0.0258)  classification: 0.0979 (0.0891)\n",
            "Epoch: [44] [ 50/289]  eta: 0:00:18  time: 0.0787  loss: 0.1261 (0.1033)  bbox_regression: 0.0347 (0.0271)  classification: 0.0915 (0.0763)\n",
            "Epoch: [44] [ 60/289]  eta: 0:00:17  time: 0.0783  loss: 0.1312 (0.1246)  bbox_regression: 0.0341 (0.0291)  classification: 0.0971 (0.0955)\n",
            "Epoch: [44] [ 70/289]  eta: 0:00:17  time: 0.0784  loss: 0.1357 (0.1600)  bbox_regression: 0.0334 (0.0302)  classification: 0.1023 (0.1298)\n",
            "Epoch: [44] [ 80/289]  eta: 0:00:16  time: 0.0784  loss: 0.1412 (0.1716)  bbox_regression: 0.0350 (0.0378)  classification: 0.1062 (0.1338)\n",
            "Epoch: [44] [ 90/289]  eta: 0:00:15  time: 0.0784  loss: 0.1428 (0.1680)  bbox_regression: 0.0361 (0.0459)  classification: 0.1066 (0.1221)\n",
            "Epoch: [44] [100/289]  eta: 0:00:14  time: 0.0785  loss: 0.1512 (0.1918)  bbox_regression: 0.0361 (0.0406)  classification: 0.1151 (0.1512)\n",
            "Epoch: [44] [110/289]  eta: 0:00:14  time: 0.0785  loss: 0.1521 (0.1945)  bbox_regression: 0.0361 (0.0360)  classification: 0.1160 (0.1585)\n",
            "Epoch: [44] [120/289]  eta: 0:00:13  time: 0.0788  loss: 0.1505 (0.1471)  bbox_regression: 0.0364 (0.0380)  classification: 0.1141 (0.1091)\n",
            "Epoch: [44] [130/289]  eta: 0:00:12  time: 0.0792  loss: 0.1483 (0.1273)  bbox_regression: 0.0358 (0.0342)  classification: 0.1125 (0.0931)\n",
            "Epoch: [44] [140/289]  eta: 0:00:11  time: 0.0793  loss: 0.1446 (0.1084)  bbox_regression: 0.0352 (0.0280)  classification: 0.1093 (0.0804)\n",
            "Epoch: [44] [150/289]  eta: 0:00:10  time: 0.0791  loss: 0.1513 (0.1712)  bbox_regression: 0.0379 (0.0517)  classification: 0.1134 (0.1195)\n",
            "Epoch: [44] [160/289]  eta: 0:00:10  time: 0.0791  loss: 0.1551 (0.2292)  bbox_regression: 0.0383 (0.0602)  classification: 0.1167 (0.1690)\n",
            "Epoch: [44] [170/289]  eta: 0:00:09  time: 0.0791  loss: 0.1565 (0.1953)  bbox_regression: 0.0383 (0.0414)  classification: 0.1182 (0.1539)\n",
            "Epoch: [44] [180/289]  eta: 0:00:08  time: 0.0789  loss: 0.1544 (0.1487)  bbox_regression: 0.0382 (0.0376)  classification: 0.1161 (0.1111)\n",
            "Epoch: [44] [190/289]  eta: 0:00:07  time: 0.0789  loss: 0.1581 (0.1721)  bbox_regression: 0.0400 (0.0538)  classification: 0.1182 (0.1183)\n",
            "Epoch: [44] [200/289]  eta: 0:00:07  time: 0.0788  loss: 0.1578 (0.1885)  bbox_regression: 0.0398 (0.0542)  classification: 0.1179 (0.1343)\n",
            "Epoch: [44] [210/289]  eta: 0:00:06  time: 0.0787  loss: 0.1580 (0.1569)  bbox_regression: 0.0394 (0.0341)  classification: 0.1186 (0.1228)\n",
            "Epoch: [44] [220/289]  eta: 0:00:05  time: 0.0787  loss: 0.1605 (0.1874)  bbox_regression: 0.0390 (0.0307)  classification: 0.1214 (0.1567)\n",
            "Epoch: [44] [230/289]  eta: 0:00:04  time: 0.0787  loss: 0.1644 (0.2320)  bbox_regression: 0.0390 (0.0347)  classification: 0.1254 (0.1973)\n",
            "Epoch: [44] [240/289]  eta: 0:00:03  time: 0.0788  loss: 0.1629 (0.1897)  bbox_regression: 0.0395 (0.0450)  classification: 0.1234 (0.1447)\n",
            "Epoch: [44] [250/289]  eta: 0:00:03  time: 0.0788  loss: 0.1609 (0.1201)  bbox_regression: 0.0391 (0.0404)  classification: 0.1218 (0.0798)\n",
            "Epoch: [44] [260/289]  eta: 0:00:02  time: 0.0789  loss: 0.1588 (0.1102)  bbox_regression: 0.0387 (0.0284)  classification: 0.1202 (0.0818)\n",
            "Epoch: [44] [270/289]  eta: 0:00:01  time: 0.0790  loss: 0.1596 (0.1433)  bbox_regression: 0.0385 (0.0313)  classification: 0.1211 (0.1121)\n",
            "Epoch: [44] [280/289]  eta: 0:00:00  time: 0.0791  loss: 0.1580 (0.1472)  bbox_regression: 0.0382 (0.0324)  classification: 0.1198 (0.1148)\n",
            "Epoch: [44] [288/289]  eta: 0:00:00  time: 0.0789  loss: 0.1602 (0.1624)  bbox_regression: 0.0394 (0.0498)  classification: 0.1209 (0.1126)\n",
            "Epoch: [44] Time: 0:00:22 (0.0790 s / it)\n",
            "Validation: [44]\n",
            "Validation: [44] [ 0/62]  eta: 0:00:04  time: 0.0668  \n",
            "Validation: [44] [10/62]  eta: 0:00:03  time: 0.0665  \n",
            "Validation: [44] [20/62]  eta: 0:00:02  time: 0.0655  \n",
            "Validation: [44] [30/62]  eta: 0:00:02  time: 0.0658  \n",
            "Validation: [44] [40/62]  eta: 0:00:01  time: 0.0664  \n",
            "Validation: [44] [50/62]  eta: 0:00:00  time: 0.0667  \n",
            "Validation: [44] [60/62]  eta: 0:00:00  time: 0.0669  \n",
            "Validation: [44] [61/62]  eta: 0:00:00  time: 0.0665  \n",
            "Validation: [44] Time: 0:00:04 (0.0665 s / it)\n",
            "Epoch 44: mAP = 0.6711\n",
            "Epoch: [45]\n",
            "Epoch: [45] [  0/289]  eta: 0:00:23  time: 0.0812  loss: 0.0824 (0.0824)  bbox_regression: 0.0285 (0.0285)  classification: 0.0539 (0.0539)\n",
            "Epoch: [45] [ 10/289]  eta: 0:00:21  time: 0.0783  loss: 0.1256 (0.1256)  bbox_regression: 0.0291 (0.0291)  classification: 0.0965 (0.0965)\n",
            "Epoch: [45] [ 20/289]  eta: 0:00:20  time: 0.0773  loss: 0.1310 (0.1334)  bbox_regression: 0.0271 (0.0271)  classification: 0.1039 (0.1064)\n",
            "Epoch: [45] [ 30/289]  eta: 0:00:20  time: 0.0781  loss: 0.1260 (0.1262)  bbox_regression: 0.0289 (0.0288)  classification: 0.0971 (0.0974)\n",
            "Epoch: [45] [ 40/289]  eta: 0:00:19  time: 0.0795  loss: 0.1376 (0.1446)  bbox_regression: 0.0363 (0.0460)  classification: 0.1013 (0.0986)\n",
            "Epoch: [45] [ 50/289]  eta: 0:00:18  time: 0.0793  loss: 0.1359 (0.1513)  bbox_regression: 0.0359 (0.0468)  classification: 0.1000 (0.1046)\n",
            "Epoch: [45] [ 60/289]  eta: 0:00:18  time: 0.0792  loss: 0.1353 (0.1305)  bbox_regression: 0.0378 (0.0407)  classification: 0.0975 (0.0898)\n",
            "Epoch: [45] [ 70/289]  eta: 0:00:17  time: 0.0794  loss: 0.1357 (0.1353)  bbox_regression: 0.0369 (0.0392)  classification: 0.0989 (0.0960)\n",
            "Epoch: [45] [ 80/289]  eta: 0:00:16  time: 0.0793  loss: 0.1311 (0.1185)  bbox_regression: 0.0373 (0.0358)  classification: 0.0939 (0.0827)\n",
            "Epoch: [45] [ 90/289]  eta: 0:00:15  time: 0.0796  loss: 0.1295 (0.1075)  bbox_regression: 0.0366 (0.0356)  classification: 0.0930 (0.0719)\n",
            "Epoch: [45] [100/289]  eta: 0:00:15  time: 0.0798  loss: 0.1369 (0.1602)  bbox_regression: 0.0361 (0.0311)  classification: 0.1008 (0.1291)\n",
            "Epoch: [45] [110/289]  eta: 0:00:14  time: 0.0798  loss: 0.1439 (0.2093)  bbox_regression: 0.0376 (0.0421)  classification: 0.1063 (0.1672)\n",
            "Epoch: [45] [120/289]  eta: 0:00:13  time: 0.0797  loss: 0.1458 (0.1908)  bbox_regression: 0.0374 (0.0439)  classification: 0.1084 (0.1468)\n",
            "Epoch: [45] [130/289]  eta: 0:00:12  time: 0.0795  loss: 0.1518 (0.1954)  bbox_regression: 0.0400 (0.0533)  classification: 0.1118 (0.1421)\n",
            "Epoch: [45] [140/289]  eta: 0:00:11  time: 0.0795  loss: 0.1526 (0.1935)  bbox_regression: 0.0405 (0.0594)  classification: 0.1121 (0.1341)\n",
            "Epoch: [45] [150/289]  eta: 0:00:11  time: 0.0797  loss: 0.1516 (0.1509)  bbox_regression: 0.0399 (0.0393)  classification: 0.1118 (0.1116)\n",
            "Epoch: [45] [160/289]  eta: 0:00:10  time: 0.0796  loss: 0.1503 (0.1346)  bbox_regression: 0.0392 (0.0303)  classification: 0.1111 (0.1043)\n",
            "Epoch: [45] [170/289]  eta: 0:00:09  time: 0.0795  loss: 0.1484 (0.1236)  bbox_regression: 0.0385 (0.0281)  classification: 0.1099 (0.0956)\n",
            "Epoch: [45] [180/289]  eta: 0:00:08  time: 0.0796  loss: 0.1466 (0.1165)  bbox_regression: 0.0377 (0.0255)  classification: 0.1089 (0.0910)\n",
            "Epoch: [45] [190/289]  eta: 0:00:07  time: 0.0795  loss: 0.1566 (0.2269)  bbox_regression: 0.0407 (0.0593)  classification: 0.1159 (0.1676)\n",
            "Epoch: [45] [200/289]  eta: 0:00:07  time: 0.0793  loss: 0.1562 (0.2429)  bbox_regression: 0.0402 (0.0633)  classification: 0.1159 (0.1796)\n",
            "Epoch: [45] [210/289]  eta: 0:00:06  time: 0.0793  loss: 0.1556 (0.1457)  bbox_regression: 0.0399 (0.0323)  classification: 0.1157 (0.1134)\n",
            "Epoch: [45] [220/289]  eta: 0:00:05  time: 0.0795  loss: 0.1543 (0.1352)  bbox_regression: 0.0395 (0.0322)  classification: 0.1148 (0.1030)\n",
            "Epoch: [45] [230/289]  eta: 0:00:04  time: 0.0795  loss: 0.1556 (0.1565)  bbox_regression: 0.0399 (0.0395)  classification: 0.1158 (0.1170)\n",
            "Epoch: [45] [240/289]  eta: 0:00:03  time: 0.0794  loss: 0.1533 (0.1430)  bbox_regression: 0.0392 (0.0356)  classification: 0.1142 (0.1075)\n",
            "Epoch: [45] [250/289]  eta: 0:00:03  time: 0.0793  loss: 0.1536 (0.1301)  bbox_regression: 0.0389 (0.0273)  classification: 0.1147 (0.1028)\n",
            "Epoch: [45] [260/289]  eta: 0:00:02  time: 0.0792  loss: 0.1528 (0.1457)  bbox_regression: 0.0385 (0.0296)  classification: 0.1143 (0.1162)\n",
            "Epoch: [45] [270/289]  eta: 0:00:01  time: 0.0792  loss: 0.1536 (0.1540)  bbox_regression: 0.0388 (0.0387)  classification: 0.1148 (0.1153)\n",
            "Epoch: [45] [280/289]  eta: 0:00:00  time: 0.0792  loss: 0.1543 (0.1749)  bbox_regression: 0.0389 (0.0444)  classification: 0.1155 (0.1305)\n",
            "Epoch: [45] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.1535 (0.1512)  bbox_regression: 0.0386 (0.0351)  classification: 0.1148 (0.1161)\n",
            "Epoch: [45] Time: 0:00:22 (0.0791 s / it)\n",
            "Epoch: [46]\n",
            "Epoch: [46] [  0/289]  eta: 0:00:24  time: 0.0861  loss: 0.0412 (0.0412)  bbox_regression: 0.0304 (0.0304)  classification: 0.0108 (0.0108)\n",
            "Epoch: [46] [ 10/289]  eta: 0:00:21  time: 0.0779  loss: 0.1533 (0.1533)  bbox_regression: 0.0323 (0.0323)  classification: 0.1210 (0.1210)\n",
            "Epoch: [46] [ 20/289]  eta: 0:00:20  time: 0.0780  loss: 0.1340 (0.1386)  bbox_regression: 0.0298 (0.0298)  classification: 0.1042 (0.1088)\n",
            "Epoch: [46] [ 30/289]  eta: 0:00:20  time: 0.0778  loss: 0.1366 (0.1274)  bbox_regression: 0.0364 (0.0386)  classification: 0.1003 (0.0888)\n",
            "Epoch: [46] [ 40/289]  eta: 0:00:19  time: 0.0786  loss: 0.1476 (0.1619)  bbox_regression: 0.0355 (0.0415)  classification: 0.1121 (0.1204)\n",
            "Epoch: [46] [ 50/289]  eta: 0:00:18  time: 0.0785  loss: 0.1453 (0.1587)  bbox_regression: 0.0341 (0.0305)  classification: 0.1112 (0.1282)\n",
            "Epoch: [46] [ 60/289]  eta: 0:00:17  time: 0.0782  loss: 0.1474 (0.1471)  bbox_regression: 0.0342 (0.0317)  classification: 0.1132 (0.1155)\n",
            "Epoch: [46] [ 70/289]  eta: 0:00:17  time: 0.0782  loss: 0.1510 (0.1658)  bbox_regression: 0.0369 (0.0442)  classification: 0.1141 (0.1216)\n",
            "Epoch: [46] [ 80/289]  eta: 0:00:16  time: 0.0780  loss: 0.1553 (0.1793)  bbox_regression: 0.0369 (0.0449)  classification: 0.1184 (0.1343)\n",
            "Epoch: [46] [ 90/289]  eta: 0:00:15  time: 0.0783  loss: 0.1582 (0.1838)  bbox_regression: 0.0382 (0.0428)  classification: 0.1200 (0.1410)\n",
            "Epoch: [46] [100/289]  eta: 0:00:14  time: 0.0789  loss: 0.1524 (0.1406)  bbox_regression: 0.0368 (0.0363)  classification: 0.1156 (0.1043)\n",
            "Epoch: [46] [110/289]  eta: 0:00:14  time: 0.0792  loss: 0.1535 (0.1320)  bbox_regression: 0.0371 (0.0320)  classification: 0.1164 (0.1000)\n",
            "Epoch: [46] [120/289]  eta: 0:00:13  time: 0.0789  loss: 0.1501 (0.1385)  bbox_regression: 0.0362 (0.0335)  classification: 0.1139 (0.1051)\n",
            "Epoch: [46] [130/289]  eta: 0:00:12  time: 0.0788  loss: 0.1507 (0.1353)  bbox_regression: 0.0361 (0.0306)  classification: 0.1146 (0.1047)\n",
            "Epoch: [46] [140/289]  eta: 0:00:11  time: 0.0786  loss: 0.1517 (0.1616)  bbox_regression: 0.0361 (0.0352)  classification: 0.1157 (0.1265)\n",
            "Epoch: [46] [150/289]  eta: 0:00:10  time: 0.0787  loss: 0.1507 (0.1505)  bbox_regression: 0.0365 (0.0389)  classification: 0.1142 (0.1116)\n",
            "Epoch: [46] [160/289]  eta: 0:00:10  time: 0.0785  loss: 0.1480 (0.1218)  bbox_regression: 0.0359 (0.0344)  classification: 0.1121 (0.0873)\n",
            "Epoch: [46] [170/289]  eta: 0:00:09  time: 0.0785  loss: 0.1564 (0.1996)  bbox_regression: 0.0399 (0.0657)  classification: 0.1165 (0.1339)\n",
            "Epoch: [46] [180/289]  eta: 0:00:08  time: 0.0785  loss: 0.1570 (0.2297)  bbox_regression: 0.0401 (0.0738)  classification: 0.1170 (0.1559)\n",
            "Epoch: [46] [190/289]  eta: 0:00:07  time: 0.0784  loss: 0.1595 (0.1858)  bbox_regression: 0.0407 (0.0481)  classification: 0.1188 (0.1377)\n",
            "Epoch: [46] [200/289]  eta: 0:00:06  time: 0.0785  loss: 0.1557 (0.1435)  bbox_regression: 0.0401 (0.0403)  classification: 0.1156 (0.1031)\n",
            "Epoch: [46] [210/289]  eta: 0:00:06  time: 0.0786  loss: 0.1534 (0.0947)  bbox_regression: 0.0399 (0.0316)  classification: 0.1135 (0.0631)\n",
            "Epoch: [46] [220/289]  eta: 0:00:05  time: 0.0786  loss: 0.1517 (0.1111)  bbox_regression: 0.0400 (0.0394)  classification: 0.1116 (0.0717)\n",
            "Epoch: [46] [230/289]  eta: 0:00:04  time: 0.0787  loss: 0.1523 (0.1411)  bbox_regression: 0.0397 (0.0374)  classification: 0.1126 (0.1037)\n",
            "Epoch: [46] [240/289]  eta: 0:00:03  time: 0.0789  loss: 0.1498 (0.1291)  bbox_regression: 0.0392 (0.0305)  classification: 0.1105 (0.0986)\n",
            "Epoch: [46] [250/289]  eta: 0:00:03  time: 0.0791  loss: 0.1522 (0.1511)  bbox_regression: 0.0391 (0.0327)  classification: 0.1131 (0.1184)\n",
            "Epoch: [46] [260/289]  eta: 0:00:02  time: 0.0791  loss: 0.1525 (0.1856)  bbox_regression: 0.0391 (0.0370)  classification: 0.1135 (0.1486)\n",
            "Epoch: [46] [270/289]  eta: 0:00:01  time: 0.0793  loss: 0.1520 (0.1500)  bbox_regression: 0.0386 (0.0328)  classification: 0.1134 (0.1172)\n",
            "Epoch: [46] [280/289]  eta: 0:00:00  time: 0.0792  loss: 0.1508 (0.1280)  bbox_regression: 0.0382 (0.0276)  classification: 0.1125 (0.1004)\n",
            "Epoch: [46] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.1514 (0.1381)  bbox_regression: 0.0380 (0.0275)  classification: 0.1135 (0.1106)\n",
            "Epoch: [46] Time: 0:00:22 (0.0790 s / it)\n",
            "Epoch: [47]\n",
            "Epoch: [47] [  0/289]  eta: 0:00:22  time: 0.0770  loss: 0.0529 (0.0529)  bbox_regression: 0.0170 (0.0170)  classification: 0.0360 (0.0360)\n",
            "Epoch: [47] [ 10/289]  eta: 0:00:21  time: 0.0770  loss: 0.1069 (0.1069)  bbox_regression: 0.0285 (0.0285)  classification: 0.0784 (0.0784)\n",
            "Epoch: [47] [ 20/289]  eta: 0:00:20  time: 0.0771  loss: 0.0920 (0.0939)  bbox_regression: 0.0270 (0.0275)  classification: 0.0650 (0.0664)\n",
            "Epoch: [47] [ 30/289]  eta: 0:00:20  time: 0.0773  loss: 0.1135 (0.1171)  bbox_regression: 0.0299 (0.0307)  classification: 0.0836 (0.0865)\n",
            "Epoch: [47] [ 40/289]  eta: 0:00:19  time: 0.0778  loss: 0.1340 (0.1781)  bbox_regression: 0.0352 (0.0437)  classification: 0.0988 (0.1344)\n",
            "Epoch: [47] [ 50/289]  eta: 0:00:18  time: 0.0781  loss: 0.1436 (0.1903)  bbox_regression: 0.0370 (0.0479)  classification: 0.1066 (0.1424)\n",
            "Epoch: [47] [ 60/289]  eta: 0:00:17  time: 0.0780  loss: 0.1531 (0.1924)  bbox_regression: 0.0444 (0.0632)  classification: 0.1088 (0.1292)\n",
            "Epoch: [47] [ 70/289]  eta: 0:00:17  time: 0.0790  loss: 0.1617 (0.2080)  bbox_regression: 0.0442 (0.0625)  classification: 0.1176 (0.1454)\n",
            "Epoch: [47] [ 80/289]  eta: 0:00:16  time: 0.0791  loss: 0.1625 (0.1909)  bbox_regression: 0.0436 (0.0413)  classification: 0.1189 (0.1496)\n",
            "Epoch: [47] [ 90/289]  eta: 0:00:15  time: 0.0789  loss: 0.1619 (0.1625)  bbox_regression: 0.0427 (0.0376)  classification: 0.1192 (0.1249)\n",
            "Epoch: [47] [100/289]  eta: 0:00:14  time: 0.0789  loss: 0.1597 (0.1487)  bbox_regression: 0.0430 (0.0405)  classification: 0.1167 (0.1082)\n",
            "Epoch: [47] [110/289]  eta: 0:00:14  time: 0.0787  loss: 0.1555 (0.1264)  bbox_regression: 0.0415 (0.0356)  classification: 0.1140 (0.0907)\n",
            "Epoch: [47] [120/289]  eta: 0:00:13  time: 0.0789  loss: 0.1534 (0.1214)  bbox_regression: 0.0403 (0.0265)  classification: 0.1131 (0.0949)\n",
            "Epoch: [47] [130/289]  eta: 0:00:12  time: 0.0788  loss: 0.1521 (0.1333)  bbox_regression: 0.0404 (0.0345)  classification: 0.1117 (0.0988)\n",
            "Epoch: [47] [140/289]  eta: 0:00:11  time: 0.0789  loss: 0.1556 (0.1689)  bbox_regression: 0.0409 (0.0447)  classification: 0.1147 (0.1241)\n",
            "Epoch: [47] [150/289]  eta: 0:00:10  time: 0.0790  loss: 0.1567 (0.1869)  bbox_regression: 0.0405 (0.0413)  classification: 0.1162 (0.1455)\n",
            "Epoch: [47] [160/289]  eta: 0:00:10  time: 0.0789  loss: 0.1569 (0.1661)  bbox_regression: 0.0405 (0.0379)  classification: 0.1164 (0.1282)\n",
            "Epoch: [47] [170/289]  eta: 0:00:09  time: 0.0788  loss: 0.1542 (0.1351)  bbox_regression: 0.0397 (0.0339)  classification: 0.1144 (0.1012)\n",
            "Epoch: [47] [180/289]  eta: 0:00:08  time: 0.0789  loss: 0.1554 (0.1429)  bbox_regression: 0.0398 (0.0339)  classification: 0.1156 (0.1090)\n",
            "Epoch: [47] [190/289]  eta: 0:00:07  time: 0.0789  loss: 0.1532 (0.1449)  bbox_regression: 0.0392 (0.0342)  classification: 0.1140 (0.1107)\n",
            "Epoch: [47] [200/289]  eta: 0:00:07  time: 0.0788  loss: 0.1540 (0.1422)  bbox_regression: 0.0386 (0.0280)  classification: 0.1154 (0.1142)\n",
            "Epoch: [47] [210/289]  eta: 0:00:06  time: 0.0787  loss: 0.1516 (0.1360)  bbox_regression: 0.0383 (0.0302)  classification: 0.1133 (0.1058)\n",
            "Epoch: [47] [220/289]  eta: 0:00:05  time: 0.0786  loss: 0.1503 (0.1130)  bbox_regression: 0.0381 (0.0324)  classification: 0.1123 (0.0806)\n",
            "Epoch: [47] [230/289]  eta: 0:00:04  time: 0.0786  loss: 0.1523 (0.1596)  bbox_regression: 0.0385 (0.0403)  classification: 0.1138 (0.1193)\n",
            "Epoch: [47] [240/289]  eta: 0:00:03  time: 0.0787  loss: 0.1522 (0.1735)  bbox_regression: 0.0385 (0.0440)  classification: 0.1137 (0.1295)\n",
            "Epoch: [47] [250/289]  eta: 0:00:03  time: 0.0788  loss: 0.1506 (0.1315)  bbox_regression: 0.0384 (0.0371)  classification: 0.1122 (0.0944)\n",
            "Epoch: [47] [260/289]  eta: 0:00:02  time: 0.0788  loss: 0.1508 (0.1335)  bbox_regression: 0.0381 (0.0330)  classification: 0.1127 (0.1005)\n",
            "Epoch: [47] [270/289]  eta: 0:00:01  time: 0.0790  loss: 0.1512 (0.1584)  bbox_regression: 0.0388 (0.0437)  classification: 0.1124 (0.1147)\n",
            "Epoch: [47] [280/289]  eta: 0:00:00  time: 0.0790  loss: 0.1512 (0.1559)  bbox_regression: 0.0386 (0.0446)  classification: 0.1126 (0.1112)\n",
            "Epoch: [47] [288/289]  eta: 0:00:00  time: 0.0787  loss: 0.1501 (0.1448)  bbox_regression: 0.0384 (0.0429)  classification: 0.1117 (0.1019)\n",
            "Epoch: [47] Time: 0:00:22 (0.0787 s / it)\n",
            "Epoch: [48]\n",
            "Epoch: [48] [  0/289]  eta: 0:00:21  time: 0.0734  loss: 0.0609 (0.0609)  bbox_regression: 0.0171 (0.0171)  classification: 0.0439 (0.0439)\n",
            "Epoch: [48] [ 10/289]  eta: 0:00:21  time: 0.0766  loss: 0.1927 (0.1927)  bbox_regression: 0.0380 (0.0380)  classification: 0.1547 (0.1547)\n",
            "Epoch: [48] [ 20/289]  eta: 0:00:21  time: 0.0783  loss: 0.1686 (0.1740)  bbox_regression: 0.0337 (0.0346)  classification: 0.1349 (0.1394)\n",
            "Epoch: [48] [ 30/289]  eta: 0:00:20  time: 0.0786  loss: 0.1606 (0.1430)  bbox_regression: 0.0406 (0.0421)  classification: 0.1200 (0.1009)\n",
            "Epoch: [48] [ 40/289]  eta: 0:00:19  time: 0.0782  loss: 0.1616 (0.1542)  bbox_regression: 0.0421 (0.0509)  classification: 0.1194 (0.1032)\n",
            "Epoch: [48] [ 50/289]  eta: 0:00:18  time: 0.0786  loss: 0.1567 (0.1505)  bbox_regression: 0.0398 (0.0385)  classification: 0.1169 (0.1120)\n",
            "Epoch: [48] [ 60/289]  eta: 0:00:17  time: 0.0785  loss: 0.1534 (0.1367)  bbox_regression: 0.0387 (0.0317)  classification: 0.1147 (0.1049)\n",
            "Epoch: [48] [ 70/289]  eta: 0:00:17  time: 0.0789  loss: 0.1602 (0.1693)  bbox_regression: 0.0391 (0.0372)  classification: 0.1211 (0.1320)\n",
            "Epoch: [48] [ 80/289]  eta: 0:00:16  time: 0.0785  loss: 0.1501 (0.1402)  bbox_regression: 0.0373 (0.0328)  classification: 0.1129 (0.1074)\n",
            "Epoch: [48] [ 90/289]  eta: 0:00:15  time: 0.0785  loss: 0.1508 (0.1175)  bbox_regression: 0.0361 (0.0255)  classification: 0.1147 (0.0920)\n",
            "Epoch: [48] [100/289]  eta: 0:00:14  time: 0.0787  loss: 0.1488 (0.1434)  bbox_regression: 0.0362 (0.0319)  classification: 0.1126 (0.1115)\n",
            "Epoch: [48] [110/289]  eta: 0:00:14  time: 0.0787  loss: 0.1445 (0.1155)  bbox_regression: 0.0352 (0.0312)  classification: 0.1093 (0.0843)\n",
            "Epoch: [48] [120/289]  eta: 0:00:13  time: 0.0787  loss: 0.1500 (0.1558)  bbox_regression: 0.0395 (0.0561)  classification: 0.1105 (0.0997)\n",
            "Epoch: [48] [130/289]  eta: 0:00:12  time: 0.0788  loss: 0.1494 (0.1767)  bbox_regression: 0.0400 (0.0669)  classification: 0.1094 (0.1099)\n",
            "Epoch: [48] [140/289]  eta: 0:00:11  time: 0.0787  loss: 0.1501 (0.1513)  bbox_regression: 0.0396 (0.0399)  classification: 0.1106 (0.1114)\n",
            "Epoch: [48] [150/289]  eta: 0:00:10  time: 0.0787  loss: 0.1519 (0.1680)  bbox_regression: 0.0393 (0.0348)  classification: 0.1125 (0.1332)\n",
            "Epoch: [48] [160/289]  eta: 0:00:10  time: 0.0789  loss: 0.1509 (0.1559)  bbox_regression: 0.0386 (0.0315)  classification: 0.1123 (0.1244)\n",
            "Epoch: [48] [170/289]  eta: 0:00:09  time: 0.0790  loss: 0.1492 (0.1293)  bbox_regression: 0.0389 (0.0354)  classification: 0.1103 (0.0939)\n",
            "Epoch: [48] [180/289]  eta: 0:00:08  time: 0.0789  loss: 0.1507 (0.1494)  bbox_regression: 0.0385 (0.0378)  classification: 0.1122 (0.1116)\n",
            "Epoch: [48] [190/289]  eta: 0:00:07  time: 0.0788  loss: 0.1493 (0.1497)  bbox_regression: 0.0381 (0.0313)  classification: 0.1112 (0.1184)\n",
            "Epoch: [48] [200/289]  eta: 0:00:06  time: 0.0786  loss: 0.1481 (0.1246)  bbox_regression: 0.0377 (0.0312)  classification: 0.1104 (0.0934)\n",
            "Epoch: [48] [210/289]  eta: 0:00:06  time: 0.0786  loss: 0.1475 (0.1301)  bbox_regression: 0.0374 (0.0306)  classification: 0.1101 (0.0995)\n",
            "Epoch: [48] [220/289]  eta: 0:00:05  time: 0.0787  loss: 0.1474 (0.1403)  bbox_regression: 0.0377 (0.0372)  classification: 0.1097 (0.1032)\n",
            "Epoch: [48] [230/289]  eta: 0:00:04  time: 0.0787  loss: 0.1478 (0.1513)  bbox_regression: 0.0384 (0.0485)  classification: 0.1094 (0.1028)\n",
            "Epoch: [48] [240/289]  eta: 0:00:03  time: 0.0788  loss: 0.1475 (0.1483)  bbox_regression: 0.0385 (0.0468)  classification: 0.1090 (0.1014)\n",
            "Epoch: [48] [250/289]  eta: 0:00:03  time: 0.0787  loss: 0.1466 (0.1334)  bbox_regression: 0.0381 (0.0353)  classification: 0.1085 (0.0981)\n",
            "Epoch: [48] [260/289]  eta: 0:00:02  time: 0.0786  loss: 0.1486 (0.1625)  bbox_regression: 0.0381 (0.0340)  classification: 0.1105 (0.1286)\n",
            "Epoch: [48] [270/289]  eta: 0:00:01  time: 0.0786  loss: 0.1515 (0.2130)  bbox_regression: 0.0384 (0.0425)  classification: 0.1131 (0.1705)\n",
            "Epoch: [48] [280/289]  eta: 0:00:00  time: 0.0786  loss: 0.1500 (0.1680)  bbox_regression: 0.0383 (0.0403)  classification: 0.1117 (0.1277)\n",
            "Epoch: [48] [288/289]  eta: 0:00:00  time: 0.0786  loss: 0.1501 (0.1512)  bbox_regression: 0.0385 (0.0459)  classification: 0.1116 (0.1054)\n",
            "Epoch: [48] Time: 0:00:22 (0.0786 s / it)\n",
            "Epoch: [49]\n",
            "Epoch: [49] [  0/289]  eta: 0:00:22  time: 0.0774  loss: 0.2767 (0.2767)  bbox_regression: 0.0355 (0.0355)  classification: 0.2412 (0.2412)\n",
            "Epoch: [49] [ 10/289]  eta: 0:00:23  time: 0.0841  loss: 0.1789 (0.1789)  bbox_regression: 0.0364 (0.0364)  classification: 0.1426 (0.1426)\n",
            "Epoch: [49] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.1530 (0.1468)  bbox_regression: 0.0313 (0.0310)  classification: 0.1217 (0.1157)\n",
            "Epoch: [49] [ 30/289]  eta: 0:00:21  time: 0.0812  loss: 0.1376 (0.1149)  bbox_regression: 0.0304 (0.0272)  classification: 0.1072 (0.0877)\n",
            "Epoch: [49] [ 40/289]  eta: 0:00:19  time: 0.0803  loss: 0.1339 (0.1138)  bbox_regression: 0.0310 (0.0307)  classification: 0.1029 (0.0831)\n",
            "Epoch: [49] [ 50/289]  eta: 0:00:19  time: 0.0799  loss: 0.1389 (0.1410)  bbox_regression: 0.0323 (0.0352)  classification: 0.1067 (0.1058)\n",
            "Epoch: [49] [ 60/289]  eta: 0:00:18  time: 0.0804  loss: 0.1346 (0.1361)  bbox_regression: 0.0319 (0.0337)  classification: 0.1027 (0.1023)\n",
            "Epoch: [49] [ 70/289]  eta: 0:00:17  time: 0.0805  loss: 0.1316 (0.1129)  bbox_regression: 0.0331 (0.0350)  classification: 0.0986 (0.0779)\n",
            "Epoch: [49] [ 80/289]  eta: 0:00:16  time: 0.0806  loss: 0.1350 (0.1363)  bbox_regression: 0.0332 (0.0370)  classification: 0.1019 (0.0993)\n",
            "Epoch: [49] [ 90/289]  eta: 0:00:15  time: 0.0804  loss: 0.1325 (0.1356)  bbox_regression: 0.0327 (0.0317)  classification: 0.0997 (0.1039)\n",
            "Epoch: [49] [100/289]  eta: 0:00:15  time: 0.0802  loss: 0.1455 (0.1879)  bbox_regression: 0.0350 (0.0423)  classification: 0.1105 (0.1456)\n",
            "Epoch: [49] [110/289]  eta: 0:00:14  time: 0.0800  loss: 0.1405 (0.1771)  bbox_regression: 0.0344 (0.0421)  classification: 0.1061 (0.1350)\n",
            "Epoch: [49] [120/289]  eta: 0:00:13  time: 0.0801  loss: 0.1541 (0.1974)  bbox_regression: 0.0392 (0.0607)  classification: 0.1149 (0.1367)\n",
            "Epoch: [49] [130/289]  eta: 0:00:12  time: 0.0801  loss: 0.1491 (0.1967)  bbox_regression: 0.0381 (0.0581)  classification: 0.1111 (0.1385)\n",
            "Epoch: [49] [140/289]  eta: 0:00:11  time: 0.0800  loss: 0.1491 (0.1189)  bbox_regression: 0.0373 (0.0254)  classification: 0.1118 (0.0935)\n",
            "Epoch: [49] [150/289]  eta: 0:00:11  time: 0.0798  loss: 0.1470 (0.1336)  bbox_regression: 0.0368 (0.0289)  classification: 0.1102 (0.1046)\n",
            "Epoch: [49] [160/289]  eta: 0:00:10  time: 0.0798  loss: 0.1502 (0.1583)  bbox_regression: 0.0367 (0.0326)  classification: 0.1136 (0.1257)\n",
            "Epoch: [49] [170/289]  eta: 0:00:09  time: 0.0797  loss: 0.1503 (0.1747)  bbox_regression: 0.0368 (0.0367)  classification: 0.1134 (0.1379)\n",
            "Epoch: [49] [180/289]  eta: 0:00:08  time: 0.0796  loss: 0.1505 (0.1527)  bbox_regression: 0.0368 (0.0373)  classification: 0.1138 (0.1154)\n",
            "Epoch: [49] [190/289]  eta: 0:00:07  time: 0.0796  loss: 0.1496 (0.1441)  bbox_regression: 0.0371 (0.0391)  classification: 0.1126 (0.1049)\n",
            "Epoch: [49] [200/289]  eta: 0:00:07  time: 0.0796  loss: 0.1484 (0.1291)  bbox_regression: 0.0366 (0.0357)  classification: 0.1117 (0.0935)\n",
            "Epoch: [49] [210/289]  eta: 0:00:06  time: 0.0797  loss: 0.1459 (0.1100)  bbox_regression: 0.0360 (0.0262)  classification: 0.1098 (0.0838)\n",
            "Epoch: [49] [220/289]  eta: 0:00:05  time: 0.0796  loss: 0.1479 (0.1436)  bbox_regression: 0.0369 (0.0390)  classification: 0.1111 (0.1046)\n",
            "Epoch: [49] [230/289]  eta: 0:00:04  time: 0.0795  loss: 0.1477 (0.1666)  bbox_regression: 0.0370 (0.0469)  classification: 0.1107 (0.1196)\n",
            "Epoch: [49] [240/289]  eta: 0:00:03  time: 0.0794  loss: 0.1479 (0.1476)  bbox_regression: 0.0369 (0.0376)  classification: 0.1110 (0.1100)\n",
            "Epoch: [49] [250/289]  eta: 0:00:03  time: 0.0793  loss: 0.1478 (0.1498)  bbox_regression: 0.0367 (0.0332)  classification: 0.1112 (0.1166)\n",
            "Epoch: [49] [260/289]  eta: 0:00:02  time: 0.0792  loss: 0.1482 (0.1520)  bbox_regression: 0.0372 (0.0402)  classification: 0.1111 (0.1118)\n",
            "Epoch: [49] [270/289]  eta: 0:00:01  time: 0.0792  loss: 0.1477 (0.1461)  bbox_regression: 0.0371 (0.0419)  classification: 0.1106 (0.1042)\n",
            "Epoch: [49] [280/289]  eta: 0:00:00  time: 0.0792  loss: 0.1490 (0.1593)  bbox_regression: 0.0379 (0.0475)  classification: 0.1111 (0.1118)\n",
            "Epoch: [49] [288/289]  eta: 0:00:00  time: 0.0790  loss: 0.1500 (0.1822)  bbox_regression: 0.0384 (0.0548)  classification: 0.1116 (0.1274)\n",
            "Epoch: [49] Time: 0:00:22 (0.0790 s / it)\n",
            "Validation: [49]\n",
            "Validation: [49] [ 0/62]  eta: 0:00:04  time: 0.0667  \n",
            "Validation: [49] [10/62]  eta: 0:00:03  time: 0.0674  \n",
            "Validation: [49] [20/62]  eta: 0:00:02  time: 0.0679  \n",
            "Validation: [49] [30/62]  eta: 0:00:02  time: 0.0674  \n",
            "Validation: [49] [40/62]  eta: 0:00:01  time: 0.0675  \n",
            "Validation: [49] [50/62]  eta: 0:00:00  time: 0.0676  \n",
            "Validation: [49] [60/62]  eta: 0:00:00  time: 0.0676  \n",
            "Validation: [49] [61/62]  eta: 0:00:00  time: 0.0671  \n",
            "Validation: [49] Time: 0:00:04 (0.0672 s / it)\n",
            "Epoch 49: mAP = 0.6712\n",
            "Saved checkpoint at epoch 50\n",
            "\n",
            "Training complete in 20.00 minutes\n",
            "Best validation mAP: 0.7666\n",
            "Loaded best model for final evaluation\n",
            "Validation: [50]\n",
            "Validation: [50] [ 0/62]  eta: 0:00:04  time: 0.0744  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-04ce9e00a17b>:813: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [50] [10/62]  eta: 0:00:03  time: 0.0696  \n",
            "Validation: [50] [20/62]  eta: 0:00:02  time: 0.0685  \n",
            "Validation: [50] [30/62]  eta: 0:00:02  time: 0.0685  \n",
            "Validation: [50] [40/62]  eta: 0:00:01  time: 0.0686  \n",
            "Validation: [50] [50/62]  eta: 0:00:00  time: 0.0686  \n",
            "Validation: [50] [60/62]  eta: 0:00:00  time: 0.0686  \n",
            "Validation: [50] [61/62]  eta: 0:00:00  time: 0.0681  \n",
            "Validation: [50] Time: 0:00:04 (0.0682 s / it)\n",
            "Epoch 50: mAP = 0.7666\n",
            "Final validation mAP: 0.7666\n",
            "Generating prediction visualizations...\n",
            "Prediction visualization saved to /content/ssd_model/sample_predictions.png\n",
            "Copied prediction visualization to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/sample_predictions.png\n",
            "Training report saved to /content/ssd_model/training_report.txt\n",
            "Copied training report to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/training_report.txt\n",
            "\n",
            "==== SSD MODEL TRAINING COMPLETE ====\n",
            "SSD model training completed successfully.\n",
            "\n",
            "==== ALL STEPS COMPLETED SUCCESSFULLY ====\n",
            "SSD model trained and saved to /content/ssd_model/best_model.pth\n",
            "Model also backed up to Google Drive at /content/drive/MyDrive/MANGO/PROJECT/mango_ssd/best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import argparse\n",
        "import shutil\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "from torchvision.models.detection.ssd import SSDHead\n",
        "from torchvision.models.detection.anchor_utils import DefaultBoxGenerator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.ops import box_iou\n",
        "import datetime\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab environment\")\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running in local environment (not Colab)\")\n",
        "\n",
        "# Set device based on availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ===========================\n",
        "# DATASET CLASS FOR PASCAL VOC\n",
        "# ===========================\n",
        "\n",
        "class PascalVOCDataset(Dataset):\n",
        "    \"\"\"Dataset for Pascal VOC format data\"\"\"\n",
        "\n",
        "    def __init__(self, root, split='train', transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root (string): Root directory of the VOC Dataset.\n",
        "            split (string): 'train', 'val', or 'test'\n",
        "            transforms (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Load class names from labelmap\n",
        "        self.classes = self._load_class_names()\n",
        "        self.num_classes = len(self.classes)\n",
        "        print(f\"Found {self.num_classes} classes: {self.classes}\")\n",
        "\n",
        "        # Map class names to indices\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Load image IDs\n",
        "        split_file = os.path.join(root, split, 'ImageSets', 'Main', f'{split}.txt')\n",
        "        if not os.path.exists(split_file):\n",
        "            raise FileNotFoundError(f\"Split file not found: {split_file}\")\n",
        "\n",
        "        with open(split_file, 'r') as f:\n",
        "            self.ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        print(f\"Loaded {len(self.ids)} images for {split} split\")\n",
        "\n",
        "    def _load_class_names(self):\n",
        "        \"\"\"Load class names from labelmap.txt file\"\"\"\n",
        "        labelmap_file = os.path.join(self.root, 'labelmap.txt')\n",
        "        if not os.path.exists(labelmap_file):\n",
        "            raise FileNotFoundError(f\"Labelmap file not found: {labelmap_file}\")\n",
        "\n",
        "        classes = []\n",
        "        with open(labelmap_file, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 2:\n",
        "                    # Format is 'index class_name'\n",
        "                    classes.append(' '.join(parts[1:]))  # Join with spaces in case class name has spaces\n",
        "\n",
        "        # Add background class as index 0\n",
        "        return ['__background__'] + classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.root, self.split, 'JPEGImages', f'{img_id}.jpg')\n",
        "        if not os.path.exists(img_path):\n",
        "            # Try PNG if JPG not found\n",
        "            img_path = os.path.join(self.root, self.split, 'JPEGImages', f'{img_id}.png')\n",
        "            if not os.path.exists(img_path):\n",
        "                raise FileNotFoundError(f\"Image not found: {img_id}\")\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Load annotations\n",
        "        anno_path = os.path.join(self.root, self.split, 'Annotations', f'{img_id}.xml')\n",
        "        target = self._parse_voc_xml(ET.parse(anno_path).getroot(), img_id=idx)  # Pass idx as a unique identifier\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def _parse_voc_xml(self, node, img_id):\n",
        "        \"\"\"Parse Pascal VOC XML annotation file\"\"\"\n",
        "        target = {}\n",
        "\n",
        "        # Get image size\n",
        "        size = node.find('size')\n",
        "        width = int(size.find('width').text)\n",
        "        height = int(size.find('height').text)\n",
        "\n",
        "        # Initialize empty lists for boxes, labels\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        # Process each object annotation\n",
        "        for obj in node.findall('object'):\n",
        "            name = obj.find('name').text\n",
        "\n",
        "            if name not in self.class_to_idx:\n",
        "                print(f\"Warning: Class '{name}' not in class map, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Get bounding box coordinates\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = float(bbox.find('xmin').text)\n",
        "            ymin = float(bbox.find('ymin').text)\n",
        "            xmax = float(bbox.find('xmax').text)\n",
        "            ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "            # Validate box coordinates\n",
        "            if xmin >= xmax or ymin >= ymax:\n",
        "                print(f\"Warning: Invalid box coordinates {xmin, ymin, xmax, ymax} in {node.find('filename').text}, skipping\")\n",
        "                continue\n",
        "\n",
        "            # Convert class name to index (add 1 since 0 is background)\n",
        "            label = self.class_to_idx[name]\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label)\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        if boxes:\n",
        "            target[\"boxes\"] = torch.tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            # Create empty tensors if no valid boxes\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
        "\n",
        "        # Use a simple integer as image_id instead of trying to parse the filename\n",
        "        target[\"image_id\"] = torch.tensor([img_id], dtype=torch.int64)\n",
        "\n",
        "        # Calculate box areas\n",
        "        target[\"area\"] = (target[\"boxes\"][:, 3] - target[\"boxes\"][:, 1]) * (target[\"boxes\"][:, 2] - target[\"boxes\"][:, 0])\n",
        "        target[\"iscrowd\"] = torch.zeros((len(target[\"boxes\"])), dtype=torch.int64)\n",
        "\n",
        "        return target\n",
        "\n",
        "# ============================\n",
        "# TRANSFORMS AND DATA LOADING\n",
        "# ============================\n",
        "\n",
        "class Compose:\n",
        "    \"\"\"Composes transforms for object detection\"\"\"\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "class ToTensor:\n",
        "    \"\"\"Convert PIL image to tensor\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        return image, target\n",
        "\n",
        "class Resize:\n",
        "    \"\"\"Resize image and adjust boxes\"\"\"\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Get original image size\n",
        "        width, height = image.size\n",
        "\n",
        "        # Resize image\n",
        "        image = transforms.Resize((self.size, self.size))(image)\n",
        "\n",
        "        # Adjust bounding boxes\n",
        "        if target[\"boxes\"].shape[0] > 0:\n",
        "            # Scale boxes\n",
        "            x_scale = self.size / width\n",
        "            y_scale = self.size / height\n",
        "\n",
        "            boxes = target[\"boxes\"].clone()\n",
        "            boxes[:, 0] *= x_scale  # xmin\n",
        "            boxes[:, 1] *= y_scale  # ymin\n",
        "            boxes[:, 2] *= x_scale  # xmax\n",
        "            boxes[:, 3] *= y_scale  # ymax\n",
        "\n",
        "            target[\"boxes\"] = boxes\n",
        "\n",
        "            # Update areas\n",
        "            target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        return image, target\n",
        "\n",
        "# Create data transforms (with NO augmentation)\n",
        "def get_transform(train, img_size=300):\n",
        "    transforms = [\n",
        "        Resize(img_size),\n",
        "        ToTensor()\n",
        "    ]\n",
        "\n",
        "    return Compose(transforms)\n",
        "\n",
        "# Custom collate function for batching\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# ============================\n",
        "# UTILITY CLASSES\n",
        "# ============================\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values\"\"\"\n",
        "    def __init__(self, window_size=20):\n",
        "        self.window_size = window_size\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.values = []\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, value):\n",
        "        self.values.append(value)\n",
        "        if len(self.values) > self.window_size:\n",
        "            self.values.pop(0)\n",
        "        self.total += value\n",
        "        self.count += 1\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        return np.median(self.values).item() if self.values else 0.0\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        return np.mean(self.values).item() if self.values else 0.0\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count if self.count > 0 else 0.0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.global_avg:.4f} ({self.avg:.4f})\"\n",
        "\n",
        "class MetricLogger:\n",
        "    \"\"\"Utility class for logging metrics during training and evaluation\"\"\"\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = {}\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if k not in self.meters:\n",
        "                self.meters[k] = SmoothedValue()\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {meter}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if header is not None:\n",
        "            print(header)\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue()\n",
        "\n",
        "        # FIX: Use string formatting that doesn't rely on format specifiers\n",
        "        space_fmt = len(str(len(iterable)))\n",
        "\n",
        "        for obj in iterable:\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                # FIX: Use a simpler string format with manual padding\n",
        "                print(\n",
        "                    f\"{header} [{i:{space_fmt}d}/{len(iterable)}]  \"\n",
        "                    f\"eta: {eta_string}  \"\n",
        "                    f\"time: {iter_time.global_avg:.4f}  \"\n",
        "                    f\"{self}\"\n",
        "                )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "# ============================\n",
        "# MODEL DEFINITION\n",
        "# ============================\n",
        "\n",
        "def create_ssd_model(num_classes, pretrained=True):\n",
        "    \"\"\"Create an SSD300 model with a VGG16 backbone\"\"\"\n",
        "    # Create SSD model with pretrained VGG backbone if requested\n",
        "    weights = None\n",
        "    if pretrained:\n",
        "        try:\n",
        "            # For newer PyTorch versions\n",
        "            from torchvision.models.detection.ssd import SSD300_VGG16_Weights\n",
        "            weights = SSD300_VGG16_Weights.DEFAULT\n",
        "        except ImportError:\n",
        "            # For older PyTorch versions\n",
        "            weights = None\n",
        "            # Will use pretrained=True instead\n",
        "\n",
        "    # Create the model\n",
        "    if weights is not None:\n",
        "        model = ssd300_vgg16(weights=weights)\n",
        "    else:\n",
        "        model = ssd300_vgg16(pretrained=pretrained)\n",
        "\n",
        "    # Replace the classifier for our number of classes\n",
        "    # For models created with newer PyTorch versions\n",
        "    if hasattr(model, 'head'):\n",
        "        # Find the number of anchors and channels\n",
        "        num_anchors = model.anchor_generator.num_anchors_per_location()\n",
        "        if hasattr(model.backbone, 'out_channels'):\n",
        "            in_channels = model.backbone.out_channels\n",
        "        else:\n",
        "            # For newer versions where out_channels is not directly accessible\n",
        "            # Typical values for SSD300 with VGG16\n",
        "            in_channels = [512, 1024, 512, 256, 256, 256]\n",
        "\n",
        "        # Create new SSD head\n",
        "        model.head = SSDHead(in_channels, num_anchors, num_classes)\n",
        "    else:\n",
        "        # For older versions\n",
        "        # Find out the number of classes in the pre-trained model\n",
        "        old_num_classes = model.roi_heads.box_predictor.cls_score.out_features\n",
        "\n",
        "        # Replace only if our number of classes is different\n",
        "        if old_num_classes != num_classes:\n",
        "            # Create a new head with the correct number of classes\n",
        "            in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "            from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "            model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    print(f\"Created SSD300 model with {'pretrained' if pretrained else 'random'} VGG16 backbone\")\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# TRAINING FUNCTIONS\n",
        "# ============================\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f'Epoch: [{epoch}]'\n",
        "\n",
        "    for i, (images, targets) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        # Calculate total loss\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        metric_logger.update(loss=losses.item())\n",
        "\n",
        "        # Print loss values individually\n",
        "        for k, v in loss_dict.items():\n",
        "            metric_logger.update(**{k: v.item()})\n",
        "\n",
        "    return metric_logger\n",
        "\n",
        "# ============================\n",
        "# ENHANCED EVALUATION FUNCTIONS\n",
        "# ============================\n",
        "\n",
        "def calculate_mAP(predictions, targets, iou_threshold=0.5, confidence_threshold=0.5, return_per_class=False):\n",
        "    \"\"\"Calculate mean Average Precision with confidence threshold\"\"\"\n",
        "    # Initialize APs for each class\n",
        "    n_classes = max([max(target['labels']).item() for target in targets if len(target['labels']) > 0], default=0) + 1\n",
        "    average_precisions = [[] for _ in range(n_classes)]\n",
        "\n",
        "    # For each image in the batch\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        # Apply confidence threshold\n",
        "        mask = pred_scores >= confidence_threshold\n",
        "        pred_boxes = pred_boxes[mask]\n",
        "        pred_scores = pred_scores[mask]\n",
        "        pred_labels = pred_labels[mask]\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # For each class\n",
        "        for cls in range(1, n_classes):  # Skip background class (0)\n",
        "            # Get predictions and targets for this class\n",
        "            mask_pred = pred_labels == cls\n",
        "            mask_target = target_labels == cls\n",
        "\n",
        "            if not mask_target.any():\n",
        "                # No ground truth for this class\n",
        "                continue\n",
        "\n",
        "            if not mask_pred.any():\n",
        "                # No predictions for this class\n",
        "                average_precisions[cls].append(0.0)\n",
        "                continue\n",
        "\n",
        "            # Sort predictions by score\n",
        "            pred_boxes_cls = pred_boxes[mask_pred]\n",
        "            pred_scores_cls = pred_scores[mask_pred]\n",
        "\n",
        "            # Sort by confidence score\n",
        "            indices = torch.argsort(pred_scores_cls, descending=True)\n",
        "            pred_boxes_cls = pred_boxes_cls[indices]\n",
        "\n",
        "            target_boxes_cls = target_boxes[mask_target]\n",
        "\n",
        "            # Calculate IoU between predictions and targets\n",
        "            ious = box_iou(pred_boxes_cls, target_boxes_cls)\n",
        "\n",
        "            # For each prediction, check if it matches a ground truth\n",
        "            tp = torch.zeros(len(pred_boxes_cls))\n",
        "            fp = torch.zeros(len(pred_boxes_cls))\n",
        "\n",
        "            for i in range(len(pred_boxes_cls)):\n",
        "                # Get IoUs for this prediction\n",
        "                box_ious = ious[i]\n",
        "\n",
        "                # Get the best IoU and index\n",
        "                if len(box_ious) > 0:\n",
        "                    max_iou, max_idx = torch.max(box_ious, dim=0)\n",
        "\n",
        "                    if max_iou >= iou_threshold:\n",
        "                        tp[i] = 1\n",
        "                        # Remove the matched target to prevent multiple matches\n",
        "                        ious[:, max_idx] = 0\n",
        "                    else:\n",
        "                        fp[i] = 1\n",
        "                else:\n",
        "                    fp[i] = 1\n",
        "\n",
        "            # Calculate precision and recall\n",
        "            tp_cumsum = torch.cumsum(tp, dim=0)\n",
        "            fp_cumsum = torch.cumsum(fp, dim=0)\n",
        "\n",
        "            precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)\n",
        "            recalls = tp_cumsum / len(target_boxes_cls)\n",
        "\n",
        "            # Compute average precision (area under PR curve)\n",
        "            # Add a start point (0, 1) and an end point (1, 0)\n",
        "            precisions = torch.cat([torch.tensor([1]).to(precisions.device), precisions])\n",
        "            recalls = torch.cat([torch.tensor([0]).to(recalls.device), recalls])\n",
        "\n",
        "            # Compute area under PR curve using trapezoidal rule\n",
        "            ap = torch.trapz(precisions, recalls)\n",
        "            average_precisions[cls].append(ap.item())\n",
        "\n",
        "    # Calculate per-class AP\n",
        "    class_aps = [np.mean(aps) if aps else 0.0 for aps in average_precisions]\n",
        "\n",
        "    # Calculate mAP\n",
        "    mAP = np.mean([ap for ap in class_aps[1:] if not np.isnan(ap)])  # Skip background class\n",
        "\n",
        "    if return_per_class:\n",
        "        return mAP, class_aps\n",
        "    return mAP\n",
        "\n",
        "def calculate_pr_curves(predictions, targets, num_classes, iou_threshold=0.5):\n",
        "    \"\"\"Calculate precision-recall curves for each class\"\"\"\n",
        "    # Initialize precision-recall data for each class\n",
        "    pr_curves = []\n",
        "    for cls in range(1, num_classes):  # Skip background class\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        # For each image\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            pred_boxes = pred['boxes'].cpu().numpy()\n",
        "            pred_scores = pred['scores'].cpu().numpy()\n",
        "            pred_labels = pred['labels'].cpu().numpy()\n",
        "\n",
        "            target_boxes = target['boxes'].cpu().numpy()\n",
        "            target_labels = target['labels'].cpu().numpy()\n",
        "\n",
        "            # Get predictions for this class\n",
        "            cls_pred_indices = np.where(pred_labels == cls)[0]\n",
        "            cls_pred_boxes = pred_boxes[cls_pred_indices] if len(cls_pred_indices) > 0 else np.empty((0, 4))\n",
        "            cls_pred_scores = pred_scores[cls_pred_indices] if len(cls_pred_indices) > 0 else np.empty(0)\n",
        "\n",
        "            # Get targets for this class\n",
        "            cls_target_indices = np.where(target_labels == cls)[0]\n",
        "            cls_target_boxes = target_boxes[cls_target_indices] if len(cls_target_indices) > 0 else np.empty((0, 4))\n",
        "\n",
        "            all_predictions.append((cls_pred_boxes, cls_pred_scores))\n",
        "            all_targets.append(cls_target_boxes)\n",
        "\n",
        "        # Compute precision and recall at different score thresholds\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        scores = []\n",
        "\n",
        "        # Flatten predictions across all images\n",
        "        all_boxes = []\n",
        "        all_scores = []\n",
        "        for boxes, scores in all_predictions:\n",
        "            if len(boxes) > 0:\n",
        "                all_boxes.append(boxes)\n",
        "                all_scores.append(scores)\n",
        "\n",
        "        if all_boxes and all_scores:\n",
        "            all_boxes = np.vstack(all_boxes)\n",
        "            all_scores = np.concatenate(all_scores)\n",
        "\n",
        "            # Count total ground truth objects\n",
        "            total_gt = sum(len(t) for t in all_targets)\n",
        "\n",
        "            if total_gt > 0:\n",
        "                # Sort by score\n",
        "                indices = np.argsort(-all_scores)\n",
        "                all_boxes = all_boxes[indices]\n",
        "                all_scores = all_scores[indices]\n",
        "\n",
        "                # Iterate through score thresholds\n",
        "                tp = np.zeros(len(all_boxes))\n",
        "                fp = np.zeros(len(all_boxes))\n",
        "\n",
        "                # Make a copy of targets to mark used ones\n",
        "                used_targets = [np.zeros(len(t), dtype=bool) for t in all_targets]\n",
        "\n",
        "                # For each prediction\n",
        "                for i, (box, score) in enumerate(zip(all_boxes, all_scores)):\n",
        "                    matched = False\n",
        "\n",
        "                    # For each image\n",
        "                    for img_idx, target_boxes in enumerate(all_targets):\n",
        "                        if len(target_boxes) == 0:\n",
        "                            continue\n",
        "\n",
        "                        # Calculate IoU with all targets in this image\n",
        "                        ious = calculate_iou_numpy(box, target_boxes)\n",
        "\n",
        "                        # Find best match\n",
        "                        max_iou = np.max(ious) if len(ious) > 0 else 0\n",
        "                        max_idx = np.argmax(ious) if len(ious) > 0 else -1\n",
        "\n",
        "                        if max_iou >= iou_threshold and not used_targets[img_idx][max_idx]:\n",
        "                            matched = True\n",
        "                            used_targets[img_idx][max_idx] = True\n",
        "                            break\n",
        "\n",
        "                    if matched:\n",
        "                        tp[i] = 1\n",
        "                    else:\n",
        "                        fp[i] = 1\n",
        "\n",
        "                # Calculate precision and recall at each threshold\n",
        "                cumsum_tp = np.cumsum(tp)\n",
        "                cumsum_fp = np.cumsum(fp)\n",
        "                rec = cumsum_tp / total_gt\n",
        "                prec = cumsum_tp / (cumsum_tp + cumsum_fp)\n",
        "\n",
        "                # Add sentinel values\n",
        "                rec = np.concatenate([[0], rec, [1]])\n",
        "                prec = np.concatenate([[1], prec, [0]])\n",
        "                scores = np.concatenate([[1], all_scores, [0]])\n",
        "\n",
        "                # Ensure precision is decreasing\n",
        "                for i in range(len(prec) - 2, -1, -1):\n",
        "                    prec[i] = max(prec[i], prec[i + 1])\n",
        "\n",
        "                precisions = prec\n",
        "                recalls = rec\n",
        "\n",
        "        pr_curves.append((precisions, recalls))\n",
        "\n",
        "    return pr_curves\n",
        "\n",
        "def calculate_iou_numpy(box, boxes):\n",
        "    \"\"\"Calculate IoU between a box and a list of boxes using numpy\"\"\"\n",
        "    # Expand box to shape [1, 4]\n",
        "    box = box.reshape(1, 4)\n",
        "\n",
        "    # Calculate intersection area\n",
        "    ixmin = np.maximum(boxes[:, 0], box[0, 0])\n",
        "    iymin = np.maximum(boxes[:, 1], box[0, 1])\n",
        "    ixmax = np.minimum(boxes[:, 2], box[0, 2])\n",
        "    iymax = np.minimum(boxes[:, 3], box[0, 3])\n",
        "\n",
        "    iw = np.maximum(ixmax - ixmin, 0)\n",
        "    ih = np.maximum(iymax - iymin, 0)\n",
        "\n",
        "    # Intersection area\n",
        "    inters = iw * ih\n",
        "\n",
        "    # Union area\n",
        "    box_area = (box[0, 2] - box[0, 0]) * (box[0, 3] - box[0, 1])\n",
        "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
        "    union = box_area + boxes_area - inters\n",
        "\n",
        "    # IoU\n",
        "    iou = inters / (union + 1e-6)\n",
        "\n",
        "    return iou\n",
        "\n",
        "def calculate_confusion_matrix(predictions, targets, num_classes, iou_threshold=0.5, confidence_threshold=0.5):\n",
        "    \"\"\"Calculate confusion matrix for object detection\"\"\"\n",
        "    # Initialize confusion matrix\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
        "\n",
        "    # For each image\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        # Filter by confidence threshold\n",
        "        mask = pred_scores >= confidence_threshold\n",
        "        pred_boxes = pred_boxes[mask]\n",
        "        pred_labels = pred_labels[mask]\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # Calculate IoU between all predictions and targets\n",
        "        if len(pred_boxes) > 0 and len(target_boxes) > 0:\n",
        "            ious = box_iou(pred_boxes, target_boxes)\n",
        "\n",
        "            # Track which targets have been matched\n",
        "            matched_targets = torch.zeros(len(target_labels), dtype=torch.bool)\n",
        "\n",
        "            # For each prediction, find the best matching target\n",
        "            for i, pred_label in enumerate(pred_labels):\n",
        "                if len(ious[i]) > 0:\n",
        "                    max_iou, max_idx = torch.max(ious[i], dim=0)\n",
        "\n",
        "                    if max_iou >= iou_threshold and not matched_targets[max_idx]:\n",
        "                        # This is a match, increment confusion matrix\n",
        "                        gt_label = target_labels[max_idx]\n",
        "                        confusion_matrix[gt_label, pred_label] += 1\n",
        "                        matched_targets[max_idx] = True\n",
        "\n",
        "                        # Remove this target from consideration for other predictions\n",
        "                        ious[:, max_idx] = 0\n",
        "                    else:\n",
        "                        # False positive (wrong class or low IoU)\n",
        "                        confusion_matrix[0, pred_label] += 1\n",
        "                else:\n",
        "                    # False positive (no target)\n",
        "                    confusion_matrix[0, pred_label] += 1\n",
        "\n",
        "            # Count false negatives (unmatched targets)\n",
        "            for i, is_matched in enumerate(matched_targets):\n",
        "                if not is_matched:\n",
        "                    gt_label = target_labels[i]\n",
        "                    confusion_matrix[gt_label, 0] += 1\n",
        "        else:\n",
        "            # All predictions are false positives or all targets are false negatives\n",
        "            for pred_label in pred_labels:\n",
        "                confusion_matrix[0, pred_label] += 1\n",
        "\n",
        "            for gt_label in target_labels:\n",
        "                confusion_matrix[gt_label, 0] += 1\n",
        "\n",
        "    return confusion_matrix\n",
        "\n",
        "def enhanced_evaluate(model, data_loader, device, epoch, confidence_thresholds=[0.5, 0.6, 0.7, 0.8, 0.9], output_dir=None):\n",
        "    \"\"\"Evaluate model on validation dataset with enhanced metrics\"\"\"\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f'Validation: [{epoch}]'\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in metric_logger.log_every(data_loader, 10, header):\n",
        "            images = list(img.to(device) for img in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Store predictions and targets for metric calculation\n",
        "            all_predictions.extend(outputs)\n",
        "            all_targets.extend(targets)\n",
        "\n",
        "    # Get dataset class names\n",
        "    class_names = data_loader.dataset.classes\n",
        "\n",
        "    # Calculate mAP for different confidence thresholds\n",
        "    mAP_by_threshold = {}\n",
        "    for threshold in confidence_thresholds:\n",
        "        mAP, class_ap = calculate_mAP(all_predictions, all_targets, iou_threshold=0.5,\n",
        "                                     confidence_threshold=threshold, return_per_class=True)\n",
        "        mAP_by_threshold[threshold] = (mAP, class_ap)\n",
        "\n",
        "    # Calculate PR curves for each class\n",
        "    pr_curves = calculate_pr_curves(all_predictions, all_targets, len(class_names))\n",
        "\n",
        "    # Save evaluation results\n",
        "    if output_dir:\n",
        "        # Save mAP by threshold\n",
        "        save_mAP_threshold_results(mAP_by_threshold, class_names, output_dir, epoch)\n",
        "\n",
        "        # Plot and save PR curves\n",
        "        plot_pr_curves(pr_curves, class_names, output_dir, epoch)\n",
        "\n",
        "        # Plot per-class performance\n",
        "        plot_per_class_metrics(mAP_by_threshold[0.5][1], class_names, output_dir, epoch)\n",
        "\n",
        "        # Create confusion matrix if possible\n",
        "        try:\n",
        "            conf_matrix = calculate_confusion_matrix(all_predictions, all_targets, len(class_names))\n",
        "            plot_confusion_matrix(conf_matrix, class_names, output_dir, epoch)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not create confusion matrix: {e}\")\n",
        "\n",
        "    # Return mAP at standard threshold of 0.5\n",
        "    mAP = mAP_by_threshold[0.5][0]\n",
        "    print(f\"Epoch {epoch}: mAP@0.5 = {mAP:.4f}\")\n",
        "\n",
        "    # Print per-class mAP\n",
        "    print(\"\\nPer-class Average Precision:\")\n",
        "    for i, ap in enumerate(mAP_by_threshold[0.5][1]):\n",
        "        if i == 0:  # Skip background class\n",
        "            continue\n",
        "        print(f\"  {class_names[i]}: {ap:.4f}\")\n",
        "\n",
        "    return mAP, mAP_by_threshold, pr_curves\n",
        "\n",
        "# ============================\n",
        "# ENHANCED VISUALIZATION FUNCTIONS\n",
        "# ============================\n",
        "\n",
        "def plot_loss_curve(train_losses, val_maps, output_dir):\n",
        "    \"\"\"Plot training loss and validation mAP curves\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, 'b-')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot mAP\n",
        "    plt.subplot(1, 2, 2)\n",
        "\n",
        "    # If val_maps are collected less frequently, create corresponding epoch indices\n",
        "    if len(val_maps) < len(train_losses):\n",
        "        eval_freq = len(train_losses) // len(val_maps)\n",
        "        eval_epochs = list(range(0, len(train_losses), eval_freq))[:len(val_maps)]\n",
        "        plt.plot(eval_epochs, val_maps, 'r-')\n",
        "    else:\n",
        "        plt.plot(val_maps, 'r-')\n",
        "\n",
        "    plt.title('Validation mAP')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'training_curves.png'))\n",
        "    plt.close()\n",
        "\n",
        "def plot_pr_curves(pr_curves, class_names, output_dir, epoch):\n",
        "    \"\"\"Plot precision-recall curves for each class\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Skip background class (index 0)\n",
        "    for cls_idx, (precisions, recalls) in enumerate(pr_curves, 1):\n",
        "        if len(precisions) > 1:  # Only if we have valid data\n",
        "            plt.step(recalls, precisions, where='post', label=class_names[cls_idx])\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(f'Precision-Recall Curves (Epoch {epoch})')\n",
        "    plt.xlim([0.0, 1.05])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.legend(loc='lower left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(output_dir, f'pr_curves_epoch_{epoch}.png')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved PR curves to {save_path}\")\n",
        "\n",
        "def save_mAP_threshold_results(mAP_by_threshold, class_names, output_dir, epoch):\n",
        "    \"\"\"Save mAP results for different confidence thresholds\"\"\"\n",
        "    # Create figure for mAP vs threshold\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    thresholds = sorted(list(mAP_by_threshold.keys()))\n",
        "    mAPs = [mAP_by_threshold[t][0] for t in thresholds]\n",
        "\n",
        "    plt.plot(thresholds, mAPs, 'o-', linewidth=2)\n",
        "    plt.xlabel('Confidence Threshold')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.title(f'mAP vs Confidence Threshold (Epoch {epoch})')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(output_dir, f'mAP_vs_threshold_epoch_{epoch}.png')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved mAP vs threshold plot to {save_path}\")\n",
        "\n",
        "    # Save data as CSV\n",
        "    csv_path = os.path.join(output_dir, f'mAP_vs_threshold_epoch_{epoch}.csv')\n",
        "    with open(csv_path, 'w') as f:\n",
        "        f.write(\"threshold,mAP\\n\")\n",
        "        for thresh, mAP in zip(thresholds, mAPs):\n",
        "            f.write(f\"{thresh},{mAP}\\n\")\n",
        "\n",
        "    # Save per-class mAP at 0.5 threshold\n",
        "    per_class_path = os.path.join(output_dir, f'per_class_mAP_epoch_{epoch}.csv')\n",
        "    with open(per_class_path, 'w') as f:\n",
        "        f.write(\"class,AP\\n\")\n",
        "        for i, ap in enumerate(mAP_by_threshold[0.5][1]):\n",
        "            if i == 0:  # Skip background\n",
        "                continue\n",
        "            f.write(f\"{class_names[i]},{ap}\\n\")\n",
        "\n",
        "def plot_per_class_metrics(class_aps, class_names, output_dir, epoch):\n",
        "    \"\"\"Plot per-class performance metrics\"\"\"\n",
        "    # Skip background class (index 0)\n",
        "    indices = list(range(1, len(class_aps)))\n",
        "    aps = [class_aps[i] for i in indices]\n",
        "    names = [class_names[i] for i in indices]\n",
        "\n",
        "    # Sort by AP value\n",
        "    sorted_indices = np.argsort(aps)\n",
        "    sorted_aps = [aps[i] for i in sorted_indices]\n",
        "    sorted_names = [names[i] for i in sorted_indices]\n",
        "\n",
        "    plt.figure(figsize=(10, max(6, len(indices) * 0.4)))\n",
        "    plt.barh(range(len(sorted_names)), sorted_aps, align='center')\n",
        "    plt.yticks(range(len(sorted_names)), sorted_names)\n",
        "    plt.xlabel('Average Precision')\n",
        "    plt.title(f'Per-Class Average Precision (Epoch {epoch})')\n",
        "    plt.grid(True, axis='x')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(output_dir, f'per_class_ap_epoch_{epoch}.png')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved per-class AP plot to {save_path}\")\n",
        "\n",
        "def plot_confusion_matrix(confusion_matrix, class_names, output_dir, epoch):\n",
        "    \"\"\"Plot confusion matrix\"\"\"\n",
        "    try:\n",
        "        import seaborn as sns\n",
        "    except ImportError:\n",
        "        print(\"seaborn not available, installing...\")\n",
        "        import pip\n",
        "        pip.main(['install', 'seaborn'])\n",
        "        import seaborn as sns\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Use only the first 20 classes if there are too many\n",
        "    if len(class_names) > 20:\n",
        "        confusion_matrix = confusion_matrix[:20, :20]\n",
        "        display_names = class_names[:20]\n",
        "    else:\n",
        "        display_names = class_names\n",
        "\n",
        "    # Create heatmap\n",
        "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=display_names, yticklabels=display_names)\n",
        "\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('Ground Truth Label')\n",
        "    plt.title(f'Confusion Matrix (Epoch {epoch})')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(output_dir, f'confusion_matrix_epoch_{epoch}.png')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved confusion matrix to {save_path}\")\n",
        "\n",
        "def plot_mAP_threshold_curves(val_maps_by_threshold, eval_freq, output_dir):\n",
        "    \"\"\"Plot mAP vs confidence threshold curves across training\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Extract all confidence thresholds (from the first evaluation)\n",
        "    thresholds = sorted(list(val_maps_by_threshold[0].keys()))\n",
        "\n",
        "    # Plot a line for each evaluation\n",
        "    for i, mAP_by_threshold in enumerate(val_maps_by_threshold):\n",
        "        epoch = (i + 1) * eval_freq\n",
        "        mAPs = [mAP_by_threshold[t][0] for t in thresholds]\n",
        "        plt.plot(thresholds, mAPs, 'o-', linewidth=2, label=f'Epoch {epoch}')\n",
        "\n",
        "    plt.xlabel('Confidence Threshold')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.title('mAP vs Confidence Threshold Across Training')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(output_dir, 'mAP_threshold_curves.png')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved mAP threshold curves to {save_path}\")\n",
        "\n",
        "def enhanced_visualize_predictions(model, dataset, device, num_images=8, confidence_threshold=0.5, output_dir=None):\n",
        "    \"\"\"Visualize model predictions on sample images with detailed information\"\"\"\n",
        "    if output_dir is None:\n",
        "        output_dir = \"predictions\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create a subplot grid for visualization\n",
        "    fig, axes = plt.subplots(num_images, 2, figsize=(16, 4*num_images))\n",
        "\n",
        "    # Randomly sample images\n",
        "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
        "\n",
        "    # Track per-class detections for metrics calculation\n",
        "    class_metrics = {}\n",
        "    for cls_name in dataset.classes[1:]:  # Skip background\n",
        "        class_metrics[cls_name] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Get image and target\n",
        "        image, target = dataset[idx]\n",
        "\n",
        "        # Convert image for visualization\n",
        "        image_vis = np.array(transforms.ToPILImage()(image))\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image.to(device)])[0]\n",
        "\n",
        "        # Plot ground truth\n",
        "        axes[i, 0].imshow(image_vis)\n",
        "        axes[i, 0].set_title(\"Ground Truth\")\n",
        "\n",
        "        # Draw ground truth boxes\n",
        "        for box, label in zip(target[\"boxes\"], target[\"labels\"]):\n",
        "            box = box.cpu().numpy()\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='green', linewidth=2)\n",
        "            axes[i, 0].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label.item()]\n",
        "            axes[i, 0].text(xmin, ymin-5, class_name, color='green',\n",
        "                           backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Plot prediction\n",
        "        axes[i, 1].imshow(image_vis)\n",
        "        axes[i, 1].set_title(f\"Prediction (conf >= {confidence_threshold})\")\n",
        "\n",
        "        # Filter predictions with confidence > threshold\n",
        "        mask = prediction[\"scores\"] > confidence_threshold\n",
        "        boxes = prediction[\"boxes\"][mask].cpu().numpy()\n",
        "        labels = prediction[\"labels\"][mask].cpu().numpy()\n",
        "        scores = prediction[\"scores\"][mask].cpu().numpy()\n",
        "\n",
        "        # Draw predicted boxes\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='red', linewidth=2)\n",
        "            axes[i, 1].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label]\n",
        "            axes[i, 1].text(xmin, ymin-5, f\"{class_name}: {score:.2f}\",\n",
        "                           color='red', backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Hide axis ticks\n",
        "        axes[i, 0].set_xticks([])\n",
        "        axes[i, 0].set_yticks([])\n",
        "        axes[i, 1].set_xticks([])\n",
        "        axes[i, 1].set_yticks([])\n",
        "\n",
        "        # Calculate metrics for this image\n",
        "        pred_boxes = prediction[\"boxes\"].cpu()\n",
        "        pred_scores = prediction[\"scores\"].cpu()\n",
        "        pred_labels = prediction[\"labels\"].cpu()\n",
        "\n",
        "        gt_boxes = target[\"boxes\"].cpu()\n",
        "        gt_labels = target[\"labels\"].cpu()\n",
        "\n",
        "        # Apply confidence threshold\n",
        "        mask = pred_scores > confidence_threshold\n",
        "        pred_boxes = pred_boxes[mask]\n",
        "        pred_labels = pred_labels[mask]\n",
        "\n",
        "        # Calculate IoU for all predictions with all ground truth\n",
        "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
        "            ious = box_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "            # Keep track of matched ground truth\n",
        "            matched_gt = set()\n",
        "\n",
        "            # For each prediction\n",
        "            for j, pred_label in enumerate(pred_labels):\n",
        "                pred_cls = dataset.classes[pred_label.item()]\n",
        "\n",
        "                # Find best matching ground truth\n",
        "                if len(ious[j]) > 0:\n",
        "                    max_iou, max_idx = torch.max(ious[j], dim=0)\n",
        "\n",
        "                    if max_iou >= 0.5:\n",
        "                        gt_label = gt_labels[max_idx].item()\n",
        "                        gt_cls = dataset.classes[gt_label]\n",
        "\n",
        "                        # True positive if class matches\n",
        "                        if pred_label.item() == gt_label:\n",
        "                            class_metrics[gt_cls]['TP'] += 1\n",
        "                            matched_gt.add(max_idx.item())\n",
        "                        else:\n",
        "                            # Wrong class prediction\n",
        "                            class_metrics[pred_cls]['FP'] += 1\n",
        "                    else:\n",
        "                        # No matching ground truth with sufficient IoU\n",
        "                        class_metrics[pred_cls]['FP'] += 1\n",
        "                else:\n",
        "                    # No ground truth to match with\n",
        "                    class_metrics[pred_cls]['FP'] += 1\n",
        "\n",
        "            # Count false negatives (unmatched ground truth)\n",
        "            for j, gt_label in enumerate(gt_labels):\n",
        "                if j not in matched_gt:\n",
        "                    gt_cls = dataset.classes[gt_label.item()]\n",
        "                    class_metrics[gt_cls]['FN'] += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'enhanced_predictions.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Create per-class metrics summary\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Calculate precision, recall, F1 for each class\n",
        "    class_names = []\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1_score = []\n",
        "\n",
        "    for cls_name, metrics in class_metrics.items():\n",
        "        tp = metrics['TP']\n",
        "        fp = metrics['FP']\n",
        "        fn = metrics['FN']\n",
        "\n",
        "        # Calculate metrics\n",
        "        cls_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        cls_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        cls_f1 = 2 * cls_precision * cls_recall / (cls_precision + cls_recall) if (cls_precision + cls_recall) > 0 else 0\n",
        "\n",
        "        class_names.append(cls_name)\n",
        "        precision.append(cls_precision)\n",
        "        recall.append(cls_recall)\n",
        "        f1_score.append(cls_f1)\n",
        "\n",
        "    # Sort by F1 score\n",
        "    sorted_indices = np.argsort(f1_score)\n",
        "    sorted_names = [class_names[i] for i in sorted_indices]\n",
        "    sorted_precision = [precision[i] for i in sorted_indices]\n",
        "    sorted_recall = [recall[i] for i in sorted_indices]\n",
        "    sorted_f1 = [f1_score[i] for i in sorted_indices]\n",
        "\n",
        "    # Plot barplot\n",
        "    x = np.arange(len(sorted_names))\n",
        "    width = 0.25\n",
        "\n",
        "    plt.bar(x - width, sorted_precision, width, label='Precision')\n",
        "    plt.bar(x, sorted_recall, width, label='Recall')\n",
        "    plt.bar(x + width, sorted_f1, width, label='F1 Score')\n",
        "\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Per-Class Detection Metrics')\n",
        "    plt.xticks(x, sorted_names, rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'per_class_metrics.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Save metrics as CSV\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Class': class_names,\n",
        "        'TP': [class_metrics[cls]['TP'] for cls in class_names],\n",
        "        'FP': [class_metrics[cls]['FP'] for cls in class_names],\n",
        "        'FN': [class_metrics[cls]['FN'] for cls in class_names],\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1': f1_score\n",
        "    })\n",
        "\n",
        "    metrics_df.to_csv(os.path.join(output_dir, 'detection_metrics.csv'), index=False)\n",
        "\n",
        "    print(f\"Enhanced prediction visualization and metrics saved to {output_dir}\")\n",
        "\n",
        "def save_to_google_drive(local_dir, gdrive_dir, IN_COLAB):\n",
        "    \"\"\"Copy all results to Google Drive\"\"\"\n",
        "    if not IN_COLAB or not gdrive_dir:\n",
        "        return\n",
        "\n",
        "    os.makedirs(gdrive_dir, exist_ok=True)\n",
        "\n",
        "    # List all files in local directory\n",
        "    files = glob.glob(os.path.join(local_dir, '*'))\n",
        "\n",
        "    # Copy each file to Google Drive\n",
        "    for file_path in files:\n",
        "        if os.path.isfile(file_path):\n",
        "            filename = os.path.basename(file_path)\n",
        "            gdrive_path = os.path.join(gdrive_dir, filename)\n",
        "            shutil.copy(file_path, gdrive_path)\n",
        "            print(f\"Copied {filename} to Google Drive: {gdrive_path}\")\n",
        "        elif os.path.isdir(file_path):\n",
        "            # Recursively handle subdirectories\n",
        "            subdir_name = os.path.basename(file_path)\n",
        "            gdrive_subdir = os.path.join(gdrive_dir, subdir_name)\n",
        "            os.makedirs(gdrive_subdir, exist_ok=True)\n",
        "            save_to_google_drive(file_path, gdrive_subdir, IN_COLAB)\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5, output_dir=None):\n",
        "    \"\"\"Visualize model predictions on sample images\"\"\"\n",
        "    if output_dir is None:\n",
        "        output_dir = \"predictions\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create a subplot grid for visualization\n",
        "    fig, axes = plt.subplots(num_images, 2, figsize=(12, 3*num_images))\n",
        "\n",
        "    # Randomly sample images\n",
        "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Get image and target\n",
        "        image, target = dataset[idx]\n",
        "\n",
        "        # Convert image for visualization\n",
        "        image_vis = np.array(transforms.ToPILImage()(image))\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image.to(device)])[0]\n",
        "\n",
        "        # Plot ground truth\n",
        "        axes[i, 0].imshow(image_vis)\n",
        "        axes[i, 0].set_title(\"Ground Truth\")\n",
        "\n",
        "        # Draw ground truth boxes\n",
        "        for box, label in zip(target[\"boxes\"], target[\"labels\"]):\n",
        "            box = box.cpu().numpy()\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='green', linewidth=2)\n",
        "            axes[i, 0].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label.item()]\n",
        "            axes[i, 0].text(xmin, ymin-5, class_name, color='green',\n",
        "                           backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Plot prediction\n",
        "        axes[i, 1].imshow(image_vis)\n",
        "        axes[i, 1].set_title(\"Prediction\")\n",
        "\n",
        "        # Filter predictions with confidence > 0.5\n",
        "        mask = prediction[\"scores\"] > 0.5\n",
        "        boxes = prediction[\"boxes\"][mask].cpu().numpy()\n",
        "        labels = prediction[\"labels\"][mask].cpu().numpy()\n",
        "        scores = prediction[\"scores\"][mask].cpu().numpy()\n",
        "\n",
        "        # Draw predicted boxes\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 fill=False, edgecolor='red', linewidth=2)\n",
        "            axes[i, 1].add_patch(rect)\n",
        "\n",
        "            class_name = dataset.classes[label]\n",
        "            axes[i, 1].text(xmin, ymin-5, f\"{class_name}: {score:.2f}\",\n",
        "                           color='red', backgroundcolor='white', fontsize=8)\n",
        "\n",
        "        # Hide axis ticks\n",
        "        axes[i, 0].set_xticks([])\n",
        "        axes[i, 0].set_yticks([])\n",
        "        axes[i, 1].set_xticks([])\n",
        "        axes[i, 1].set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'sample_predictions.png'))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Prediction visualization saved to {os.path.join(output_dir, 'sample_predictions.png')}\")\n",
        "\n",
        "# ============================\n",
        "# DATA LOADERS\n",
        "# ============================\n",
        "\n",
        "def create_data_loaders(args):\n",
        "    train_dataset = PascalVOCDataset(\n",
        "        root=args.voc_path,\n",
        "        split='train',\n",
        "        transforms=get_transform(train=True, img_size=args.image_size)\n",
        "    )\n",
        "\n",
        "    # Try 'val' or 'valid' for validation set\n",
        "    val_split = 'val'\n",
        "    if not os.path.exists(os.path.join(args.voc_path, 'val')):\n",
        "        val_split = 'valid'\n",
        "\n",
        "    val_dataset = PascalVOCDataset(\n",
        "        root=args.voc_path,\n",
        "        split=val_split,\n",
        "        transforms=get_transform(train=False, img_size=args.image_size)\n",
        "    )\n",
        "\n",
        "    # Set num_workers=0 to avoid multiprocessing issues in Colab\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_dataset.num_classes\n",
        "\n",
        "# ============================\n",
        "# MAIN TRAINING FUNCTION\n",
        "# ============================\n",
        "\n",
        "def train_ssd_model(args):\n",
        "    \"\"\"Main training function with enhanced evaluation and visualization\"\"\"\n",
        "    print(\"\\n==== TRAINING SSD MODEL WITH ENHANCED EVALUATION ====\")\n",
        "    print(f\"Dataset path: {args.voc_path}\")\n",
        "    print(f\"Output directory: {args.output_dir}\")\n",
        "    print(f\"Training for {args.epochs} epochs with batch size {args.batch_size}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    try:\n",
        "        train_loader, val_loader, num_classes = create_data_loaders(args)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data loaders: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    print(f\"Created data loaders: {len(train_loader)} training batches, {len(val_loader)} validation batches\")\n",
        "    print(f\"Number of classes (including background): {num_classes}\")\n",
        "\n",
        "    # Create model\n",
        "    try:\n",
        "        model = create_ssd_model(num_classes, pretrained=args.pretrained)\n",
        "        model.to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    print(f\"Created SSD300 model with VGG16 backbone\")\n",
        "\n",
        "    # Optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(params, lr=args.lr)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "\n",
        "    # Initialize training metrics\n",
        "    train_losses = []\n",
        "    val_maps = []\n",
        "    val_maps_by_threshold = []\n",
        "    best_map = 0.0\n",
        "    best_model_path = os.path.join(args.output_dir, 'best_model.pth')\n",
        "\n",
        "    # Create evaluation subdirectory\n",
        "    eval_dir = os.path.join(args.output_dir, 'evaluation')\n",
        "    os.makedirs(eval_dir, exist_ok=True)\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\nStarting training...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        try:\n",
        "            # Train for one epoch\n",
        "            metric_logger = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10)\n",
        "\n",
        "            # Update learning rate\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            # Record training loss\n",
        "            train_losses.append(metric_logger.loss.global_avg)\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
        "                # Create epoch-specific evaluation directory\n",
        "                epoch_eval_dir = os.path.join(eval_dir, f'epoch_{epoch+1}')\n",
        "                os.makedirs(epoch_eval_dir, exist_ok=True)\n",
        "\n",
        "                # Enhanced evaluation\n",
        "                mAP, mAP_by_threshold, pr_curves = enhanced_evaluate(\n",
        "                    model, val_loader, device, epoch,\n",
        "                    confidence_thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "                    output_dir=epoch_eval_dir\n",
        "                )\n",
        "\n",
        "                val_maps.append(mAP)\n",
        "                val_maps_by_threshold.append(mAP_by_threshold)\n",
        "\n",
        "                # Save best model\n",
        "                if mAP > best_map:\n",
        "                    best_map = mAP\n",
        "                    torch.save(model.state_dict(), best_model_path)\n",
        "                    print(f\"Saved best model with mAP: {mAP:.4f}\")\n",
        "\n",
        "                    # Copy to Google Drive if in Colab\n",
        "                    if IN_COLAB and args.gdrive_dir:\n",
        "                        gdrive_best_path = os.path.join(args.gdrive_dir, 'best_model.pth')\n",
        "                        shutil.copy(best_model_path, gdrive_best_path)\n",
        "                        print(f\"Copied best model to Google Drive: {gdrive_best_path}\")\n",
        "\n",
        "                # Copy evaluation results to Google Drive\n",
        "                if IN_COLAB and args.gdrive_dir:\n",
        "                    gdrive_eval_dir = os.path.join(args.gdrive_dir, 'evaluation', f'epoch_{epoch+1}')\n",
        "                    save_to_google_drive(epoch_eval_dir, gdrive_eval_dir, IN_COLAB)\n",
        "\n",
        "            # Save checkpoint\n",
        "            if (epoch + 1) % args.save_freq == 0 or epoch == args.epochs - 1:\n",
        "                checkpoint_path = os.path.join(args.output_dir, f'checkpoint_{epoch+1}.pth')\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'best_map': best_map\n",
        "                }, checkpoint_path)\n",
        "                print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "            # Plot training curves after each evaluation\n",
        "            if (epoch + 1) % args.eval_freq == 0 or epoch == args.epochs - 1:\n",
        "                plot_loss_curve(train_losses, val_maps, args.output_dir)\n",
        "\n",
        "                # Enhanced plots for mAP vs threshold\n",
        "                if len(val_maps_by_threshold) > 0:\n",
        "                    plot_mAP_threshold_curves(val_maps_by_threshold, args.eval_freq, args.output_dir)\n",
        "\n",
        "                # Copy visualization to Google Drive if in Colab\n",
        "                if IN_COLAB and args.gdrive_dir:\n",
        "                    curves_path = os.path.join(args.output_dir, 'training_curves.png')\n",
        "                    gdrive_curves_path = os.path.join(args.gdrive_dir, 'training_curves.png')\n",
        "                    if os.path.exists(curves_path):\n",
        "                        shutil.copy(curves_path, gdrive_curves_path)\n",
        "\n",
        "                    threshold_curves_path = os.path.join(args.output_dir, 'mAP_threshold_curves.png')\n",
        "                    gdrive_threshold_path = os.path.join(args.gdrive_dir, 'mAP_threshold_curves.png')\n",
        "                    if os.path.exists(threshold_curves_path):\n",
        "                        shutil.copy(threshold_curves_path, gdrive_threshold_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in epoch {epoch}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nTraining complete in {total_time/60:.2f} minutes\")\n",
        "    print(f\"Best validation mAP: {best_map:.4f}\")\n",
        "\n",
        "    # Final model evaluation\n",
        "    try:\n",
        "        # Load the best model\n",
        "        if os.path.exists(best_model_path):\n",
        "            model.load_state_dict(torch.load(best_model_path))\n",
        "            print(\"Loaded best model for final evaluation\")\n",
        "\n",
        "            # Final evaluation directory\n",
        "            final_eval_dir = os.path.join(eval_dir, 'final')\n",
        "            os.makedirs(final_eval_dir, exist_ok=True)\n",
        "\n",
        "            # Final validation with enhanced metrics\n",
        "            final_map, final_maps_by_threshold, final_pr_curves = enhanced_evaluate(\n",
        "                model, val_loader, device, epoch=args.epochs, output_dir=final_eval_dir\n",
        "            )\n",
        "            print(f\"Final validation mAP: {final_map:.4f}\")\n",
        "\n",
        "            # Visualize predictions with enhanced visualization\n",
        "            print(\"Generating enhanced prediction visualizations...\")\n",
        "            val_dataset = val_loader.dataset  # Get the validation dataset\n",
        "\n",
        "            # Create different visualizations for multiple confidence thresholds\n",
        "            for threshold in [0.3, 0.5, 0.7]:\n",
        "                threshold_dir = os.path.join(final_eval_dir, f'conf_{threshold}')\n",
        "                os.makedirs(threshold_dir, exist_ok=True)\n",
        "\n",
        "                enhanced_visualize_predictions(\n",
        "                    model, val_dataset, device, num_images=8,\n",
        "                    confidence_threshold=threshold, output_dir=threshold_dir\n",
        "                )\n",
        "\n",
        "            # Copy final evaluation to Google Drive\n",
        "            if IN_COLAB and args.gdrive_dir:\n",
        "                gdrive_final_eval_dir = os.path.join(args.gdrive_dir, 'evaluation', 'final')\n",
        "                save_to_google_drive(final_eval_dir, gdrive_final_eval_dir, IN_COLAB)\n",
        "        else:\n",
        "            print(f\"Warning: Best model not found at {best_model_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Generate final report with enhanced metrics\n",
        "    report_path = os.path.join(args.output_dir, 'training_report.txt')\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(\"SSD Model Training Report with Enhanced Evaluation\\n\")\n",
        "        f.write(\"===============================================\\n\\n\")\n",
        "        f.write(f\"Dataset: {args.voc_path}\\n\")\n",
        "        f.write(f\"Number of classes: {num_classes}\\n\")\n",
        "        f.write(f\"Training epochs: {args.epochs}\\n\")\n",
        "        f.write(f\"Batch size: {args.batch_size}\\n\")\n",
        "        f.write(f\"Learning rate: {args.lr}\\n\")\n",
        "        f.write(f\"Image size: {args.image_size}\\n\\n\")\n",
        "        f.write(f\"Data augmentation: None\\n\\n\")\n",
        "\n",
        "        f.write(\"Results:\\n\")\n",
        "        f.write(f\"Best validation mAP@0.5: {best_map:.4f}\\n\")\n",
        "        f.write(f\"Training time: {total_time/60:.2f} minutes\\n\\n\")\n",
        "\n",
        "        f.write(\"Training Loss:\\n\")\n",
        "        for i, loss in enumerate(train_losses):\n",
        "            f.write(f\"Epoch {i+1}: {loss:.4f}\\n\")\n",
        "\n",
        "        f.write(\"\\nValidation mAP@0.5:\\n\")\n",
        "        for i, mAP in enumerate(val_maps):\n",
        "            epoch = i * args.eval_freq + args.eval_freq\n",
        "            f.write(f\"Epoch {epoch}: {mAP:.4f}\\n\")\n",
        "\n",
        "        # Add per-class metrics if available\n",
        "        if 'final_maps_by_threshold' in locals() and final_maps_by_threshold:\n",
        "            f.write(\"\\nPer-Class AP@0.5 for Final Model:\\n\")\n",
        "            class_aps = final_maps_by_threshold[0.5][1]\n",
        "            for i, ap in enumerate(class_aps):\n",
        "                if i == 0:  # Skip background\n",
        "                    continue\n",
        "                class_name = val_loader.dataset.classes[i]\n",
        "                f.write(f\"{class_name}: {ap:.4f}\\n\")\n",
        "\n",
        "            f.write(\"\\nmAP at Different Confidence Thresholds for Final Model:\\n\")\n",
        "            for threshold in sorted(final_maps_by_threshold.keys()):\n",
        "                f.write(f\"Threshold {threshold}: {final_maps_by_threshold[threshold][0]:.4f}\\n\")\n",
        "\n",
        "    print(f\"Enhanced training report saved to {report_path}\")\n",
        "    # Copy report to Google Drive if in Colab\n",
        "    if IN_COLAB and args.gdrive_dir:\n",
        "        gdrive_report_path = os.path.join(args.gdrive_dir, 'training_report.txt')\n",
        "        shutil.copy(report_path, gdrive_report_path)\n",
        "        print(f\"Copied training report to Google Drive: {gdrive_report_path}\")\n",
        "\n",
        "        # Save all output dir to Google Drive\n",
        "        save_to_google_drive(args.output_dir, args.gdrive_dir, IN_COLAB)\n",
        "\n",
        "    print(\"\\n==== SSD MODEL TRAINING WITH ENHANCED EVALUATION COMPLETE ====\")\n",
        "    return model\n",
        "\n",
        "# ============================\n",
        "# MAIN EXECUTION\n",
        "# ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Parse arguments\n",
        "    parser = argparse.ArgumentParser(description='Train SSD model for mango disease detection with ENHANCED EVALUATION')\n",
        "    parser.add_argument('--voc-path', type=str, default='/content/ssd_dataset',\n",
        "                        help='Path to Pascal VOC format dataset')\n",
        "    parser.add_argument('--output-dir', type=str, default='/content/ssd_model',\n",
        "                        help='Path to save model outputs')\n",
        "    parser.add_argument('--gdrive-dir', type=str, default='/content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced',\n",
        "                        help='Google Drive directory to save model (for Colab users)')\n",
        "    parser.add_argument('--epochs', type=int, default=50,\n",
        "                        help='Number of epochs for training')\n",
        "    parser.add_argument('--batch-size', type=int, default=8,\n",
        "                        help='Batch size for training')\n",
        "    parser.add_argument('--lr', type=float, default=0.001,\n",
        "                        help='Learning rate')\n",
        "    parser.add_argument('--pretrained', action='store_true',\n",
        "                        help='Use pretrained VGG backbone')\n",
        "    parser.add_argument('--image-size', type=int, default=300,\n",
        "                        help='Image size for SSD300')\n",
        "    parser.add_argument('--eval-freq', type=int, default=5,\n",
        "                        help='Frequency of evaluation during training')\n",
        "    parser.add_argument('--save-freq', type=int, default=10,\n",
        "                        help='Frequency of saving model checkpoints')\n",
        "\n",
        "    # For IPython/Jupyter/Colab\n",
        "    if 'ipykernel' in sys.modules or 'IPython' in sys.modules or IN_COLAB:\n",
        "        # Default arguments for notebook mode\n",
        "        args = parser.parse_args([])\n",
        "        args.pretrained = True  # Default to using pretrained backbone in Colab\n",
        "        print(\"Running in notebook/Colab mode with default arguments\")\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "    if IN_COLAB and args.gdrive_dir:\n",
        "        os.makedirs(args.gdrive_dir, exist_ok=True)\n",
        "\n",
        "    # Verify dataset existence\n",
        "    print(\"\\n==== VERIFYING DATASET ====\")\n",
        "    if not os.path.exists(args.voc_path) or not os.path.exists(os.path.join(args.voc_path, 'labelmap.txt')):\n",
        "        print(f\"Error: Pascal VOC dataset not found at {args.voc_path}\")\n",
        "        print(\"Please ensure you have converted your YOLO dataset to Pascal VOC format.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Check if training split exists\n",
        "    train_dir = os.path.join(args.voc_path, 'train')\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(f\"Error: Training directory not found at {train_dir}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Check if validation split exists\n",
        "    valid_found = False\n",
        "    for val_name in ['val', 'valid']:\n",
        "        val_dir = os.path.join(args.voc_path, val_name)\n",
        "        if os.path.exists(val_dir):\n",
        "            valid_found = True\n",
        "            break\n",
        "\n",
        "    if not valid_found:\n",
        "        print(f\"Error: Validation directory not found at {args.voc_path}/val or {args.voc_path}/valid\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"Dataset verification completed successfully.\")\n",
        "\n",
        "    # Train the model\n",
        "    try:\n",
        "        model = train_ssd_model(args)\n",
        "        print(\"SSD model training completed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SSD model training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"\\n==== ALL STEPS COMPLETED SUCCESSFULLY ====\")\n",
        "    best_model_path = os.path.join(args.output_dir, 'best_model.pth')\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"SSD model trained and saved to {best_model_path}\")\n",
        "        if IN_COLAB and args.gdrive_dir:\n",
        "            gdrive_model_path = os.path.join(args.gdrive_dir, 'best_model.pth')\n",
        "            if os.path.exists(gdrive_model_path):\n",
        "                print(f\"Model also backed up to Google Drive at {gdrive_model_path}\")\n",
        "    else:\n",
        "        print(\"Warning: Best model file not found. Check logs for errors during training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVRgiNMKs2aY",
        "outputId": "4d3772bc-e2ff-457c-a15d-e29546724d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab environment\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Using device: cuda\n",
            "Running in notebook/Colab mode with default arguments\n",
            "\n",
            "==== VERIFYING DATASET ====\n",
            "Dataset verification completed successfully.\n",
            "\n",
            "==== TRAINING SSD MODEL WITH ENHANCED EVALUATION ====\n",
            "Dataset path: /content/ssd_dataset\n",
            "Output directory: /content/ssd_model\n",
            "Training for 50 epochs with batch size 8\n",
            "Found 7 classes: ['__background__', 'Anthracnose', 'Bacterial-Black-spot', 'Damaged-mango', 'Fruitly', 'Mechanical-damage', 'Others']\n",
            "Loaded 2306 images for train split\n",
            "Found 7 classes: ['__background__', 'Anthracnose', 'Bacterial-Black-spot', 'Damaged-mango', 'Fruitly', 'Mechanical-damage', 'Others']\n",
            "Loaded 493 images for valid split\n",
            "Created data loaders: 289 training batches, 62 validation batches\n",
            "Number of classes (including background): 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:12<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created SSD300 model with pretrained VGG16 backbone\n",
            "Created SSD300 model with VGG16 backbone\n",
            "\n",
            "Starting training...\n",
            "Epoch: [0]\n",
            "Epoch: [0] [  0/289]  eta: 0:11:39  time: 2.4206  loss: 29.2995 (29.2995)  bbox_regression: 6.1576 (6.1576)  classification: 23.1419 (23.1419)\n",
            "Epoch: [0] [ 10/289]  eta: 0:01:23  time: 0.2979  loss: 35.3502 (35.3502)  bbox_regression: 5.7341 (5.7341)  classification: 29.6161 (29.6161)\n",
            "Epoch: [0] [ 20/289]  eta: 0:00:52  time: 0.1938  loss: 23.2482 (22.9456)  bbox_regression: 3.8086 (3.6911)  classification: 19.4396 (19.2545)\n",
            "Epoch: [0] [ 30/289]  eta: 0:00:40  time: 0.1574  loss: 18.5814 (9.3586)  bbox_regression: 3.1084 (1.6642)  classification: 15.4731 (7.6944)\n",
            "Epoch: [0] [ 40/289]  eta: 0:00:34  time: 0.1389  loss: 15.8900 (8.1639)  bbox_regression: 2.5711 (1.2718)  classification: 13.3189 (6.8921)\n",
            "Epoch: [0] [ 50/289]  eta: 0:00:30  time: 0.1272  loss: 14.0374 (6.9941)  bbox_regression: 2.2056 (0.8064)  classification: 11.8317 (6.1877)\n",
            "Epoch: [0] [ 60/289]  eta: 0:00:27  time: 0.1190  loss: 12.6846 (6.1137)  bbox_regression: 1.9827 (0.7765)  classification: 10.7019 (5.3373)\n",
            "Epoch: [0] [ 70/289]  eta: 0:00:24  time: 0.1136  loss: 11.6257 (5.4760)  bbox_regression: 1.8111 (0.8048)  classification: 9.8147 (4.6712)\n",
            "Epoch: [0] [ 80/289]  eta: 0:00:22  time: 0.1094  loss: 10.7514 (4.8551)  bbox_regression: 1.6854 (0.7784)  classification: 9.0661 (4.0767)\n",
            "Epoch: [0] [ 90/289]  eta: 0:00:21  time: 0.1063  loss: 10.0535 (4.4721)  bbox_regression: 1.6065 (0.8801)  classification: 8.4471 (3.5920)\n",
            "Epoch: [0] [100/289]  eta: 0:00:19  time: 0.1037  loss: 9.4521 (4.1901)  bbox_regression: 1.5154 (0.8272)  classification: 7.9367 (3.3629)\n",
            "Epoch: [0] [110/289]  eta: 0:00:18  time: 0.1015  loss: 8.9384 (3.8647)  bbox_regression: 1.4522 (0.7505)  classification: 7.4862 (3.1143)\n",
            "Epoch: [0] [120/289]  eta: 0:00:16  time: 0.0998  loss: 8.4890 (3.6253)  bbox_regression: 1.4000 (0.8174)  classification: 7.0890 (2.8078)\n",
            "Epoch: [0] [130/289]  eta: 0:00:15  time: 0.0984  loss: 8.0861 (3.3556)  bbox_regression: 1.3471 (0.7638)  classification: 6.7390 (2.5919)\n",
            "Epoch: [0] [140/289]  eta: 0:00:14  time: 0.0972  loss: 7.7860 (3.5326)  bbox_regression: 1.3170 (0.8143)  classification: 6.4690 (2.7183)\n",
            "Epoch: [0] [150/289]  eta: 0:00:13  time: 0.0961  loss: 7.5118 (3.7500)  bbox_regression: 1.2921 (0.9318)  classification: 6.2197 (2.8182)\n",
            "Epoch: [0] [160/289]  eta: 0:00:12  time: 0.0952  loss: 7.2677 (3.6138)  bbox_regression: 1.2646 (0.8955)  classification: 6.0031 (2.7182)\n",
            "Epoch: [0] [170/289]  eta: 0:00:11  time: 0.0945  loss: 7.0404 (3.4813)  bbox_regression: 1.2371 (0.8220)  classification: 5.8032 (2.6593)\n",
            "Epoch: [0] [180/289]  eta: 0:00:10  time: 0.0936  loss: 6.8402 (3.3990)  bbox_regression: 1.2112 (0.7812)  classification: 5.6290 (2.6178)\n",
            "Epoch: [0] [190/289]  eta: 0:00:09  time: 0.0930  loss: 6.6411 (3.2271)  bbox_regression: 1.1845 (0.7347)  classification: 5.4566 (2.4925)\n",
            "Epoch: [0] [200/289]  eta: 0:00:08  time: 0.0924  loss: 6.4582 (3.0013)  bbox_regression: 1.1557 (0.6538)  classification: 5.3025 (2.3474)\n",
            "Epoch: [0] [210/289]  eta: 0:00:07  time: 0.0918  loss: 6.3067 (3.1132)  bbox_regression: 1.1350 (0.6621)  classification: 5.1717 (2.4511)\n",
            "Epoch: [0] [220/289]  eta: 0:00:06  time: 0.0912  loss: 6.1879 (3.4712)  bbox_regression: 1.1264 (0.8313)  classification: 5.0615 (2.6399)\n",
            "Epoch: [0] [230/289]  eta: 0:00:05  time: 0.0908  loss: 6.0746 (3.6258)  bbox_regression: 1.1170 (0.9277)  classification: 4.9575 (2.6982)\n",
            "Epoch: [0] [240/289]  eta: 0:00:04  time: 0.0904  loss: 5.9699 (3.5606)  bbox_regression: 1.1043 (0.8601)  classification: 4.8656 (2.7004)\n",
            "Epoch: [0] [250/289]  eta: 0:00:03  time: 0.0899  loss: 5.8612 (3.3969)  bbox_regression: 1.0897 (0.7743)  classification: 4.7715 (2.6226)\n",
            "Epoch: [0] [260/289]  eta: 0:00:02  time: 0.0895  loss: 5.7536 (3.1471)  bbox_regression: 1.0743 (0.7129)  classification: 4.6793 (2.4343)\n",
            "Epoch: [0] [270/289]  eta: 0:00:01  time: 0.0891  loss: 5.6578 (3.1046)  bbox_regression: 1.0649 (0.7528)  classification: 4.5929 (2.3517)\n",
            "Epoch: [0] [280/289]  eta: 0:00:00  time: 0.0888  loss: 5.5740 (3.2303)  bbox_regression: 1.0550 (0.8036)  classification: 4.5190 (2.4267)\n",
            "Epoch: [0] [288/289]  eta: 0:00:00  time: 0.0887  loss: 5.4947 (2.9957)  bbox_regression: 1.0398 (0.6345)  classification: 4.4549 (2.3612)\n",
            "Epoch: [0] Time: 0:00:25 (0.0887 s / it)\n",
            "Epoch: [1]\n",
            "Epoch: [1] [  0/289]  eta: 0:00:20  time: 0.0716  loss: 1.7204 (1.7204)  bbox_regression: 0.2032 (0.2032)  classification: 1.5172 (1.5172)\n",
            "Epoch: [1] [ 10/289]  eta: 0:00:21  time: 0.0783  loss: 2.6150 (2.6150)  bbox_regression: 0.5091 (0.5091)  classification: 2.1059 (2.1059)\n",
            "Epoch: [1] [ 20/289]  eta: 0:00:21  time: 0.0802  loss: 2.9309 (2.9914)  bbox_regression: 0.6694 (0.6927)  classification: 2.2615 (2.2987)\n",
            "Epoch: [1] [ 30/289]  eta: 0:00:21  time: 0.0815  loss: 2.9354 (3.1116)  bbox_regression: 0.6691 (0.7572)  classification: 2.2663 (2.3545)\n",
            "Epoch: [1] [ 40/289]  eta: 0:00:20  time: 0.0829  loss: 2.8813 (2.8291)  bbox_regression: 0.6432 (0.6157)  classification: 2.2380 (2.2134)\n",
            "Epoch: [1] [ 50/289]  eta: 0:00:19  time: 0.0821  loss: 2.8254 (2.6550)  bbox_regression: 0.6157 (0.5329)  classification: 2.2097 (2.1221)\n",
            "Epoch: [1] [ 60/289]  eta: 0:00:18  time: 0.0809  loss: 2.7830 (2.5817)  bbox_regression: 0.5956 (0.4979)  classification: 2.1875 (2.0838)\n",
            "Epoch: [1] [ 70/289]  eta: 0:00:17  time: 0.0806  loss: 2.7917 (2.7056)  bbox_regression: 0.5939 (0.5383)  classification: 2.1978 (2.1673)\n",
            "Epoch: [1] [ 80/289]  eta: 0:00:16  time: 0.0808  loss: 2.8208 (2.9358)  bbox_regression: 0.5983 (0.6065)  classification: 2.2225 (2.3293)\n",
            "Epoch: [1] [ 90/289]  eta: 0:00:16  time: 0.0806  loss: 2.8509 (3.0610)  bbox_regression: 0.6183 (0.7052)  classification: 2.2325 (2.3558)\n",
            "Epoch: [1] [100/289]  eta: 0:00:15  time: 0.0803  loss: 2.9157 (3.3003)  bbox_regression: 0.6578 (0.8990)  classification: 2.2579 (2.4013)\n",
            "Epoch: [1] [110/289]  eta: 0:00:14  time: 0.0801  loss: 2.9114 (3.1866)  bbox_regression: 0.6581 (0.8392)  classification: 2.2532 (2.3474)\n",
            "Epoch: [1] [120/289]  eta: 0:00:13  time: 0.0802  loss: 2.9022 (2.8341)  bbox_regression: 0.6520 (0.6225)  classification: 2.2502 (2.2116)\n",
            "Epoch: [1] [130/289]  eta: 0:00:12  time: 0.0808  loss: 2.9364 (3.0752)  bbox_regression: 0.6704 (0.7384)  classification: 2.2660 (2.3369)\n",
            "Epoch: [1] [140/289]  eta: 0:00:12  time: 0.0810  loss: 2.9522 (3.2541)  bbox_regression: 0.6794 (0.8451)  classification: 2.2728 (2.4090)\n",
            "Epoch: [1] [150/289]  eta: 0:00:11  time: 0.0807  loss: 2.9301 (2.8888)  bbox_regression: 0.6719 (0.6816)  classification: 2.2582 (2.2072)\n",
            "Epoch: [1] [160/289]  eta: 0:00:10  time: 0.0805  loss: 2.9211 (2.7023)  bbox_regression: 0.6709 (0.6110)  classification: 2.2502 (2.0913)\n",
            "Epoch: [1] [170/289]  eta: 0:00:09  time: 0.0806  loss: 2.9068 (2.7311)  bbox_regression: 0.6641 (0.6054)  classification: 2.2427 (2.1257)\n",
            "Epoch: [1] [180/289]  eta: 0:00:08  time: 0.0808  loss: 2.9054 (2.7785)  bbox_regression: 0.6615 (0.5855)  classification: 2.2439 (2.1930)\n",
            "Epoch: [1] [190/289]  eta: 0:00:08  time: 0.0809  loss: 2.9214 (3.0467)  bbox_regression: 0.6700 (0.7207)  classification: 2.2514 (2.3259)\n",
            "Epoch: [1] [200/289]  eta: 0:00:07  time: 0.0809  loss: 2.9536 (3.3898)  bbox_regression: 0.6886 (0.9342)  classification: 2.2650 (2.4556)\n",
            "Epoch: [1] [210/289]  eta: 0:00:06  time: 0.0808  loss: 2.9255 (2.9644)  bbox_regression: 0.6791 (0.7657)  classification: 2.2464 (2.1987)\n",
            "Epoch: [1] [220/289]  eta: 0:00:05  time: 0.0808  loss: 2.9038 (2.4035)  bbox_regression: 0.6709 (0.4935)  classification: 2.2328 (1.9100)\n",
            "Epoch: [1] [230/289]  eta: 0:00:04  time: 0.0808  loss: 2.9059 (2.6986)  bbox_regression: 0.6740 (0.6199)  classification: 2.2319 (2.0787)\n",
            "Epoch: [1] [240/289]  eta: 0:00:03  time: 0.0807  loss: 2.9006 (2.8652)  bbox_regression: 0.6693 (0.6506)  classification: 2.2313 (2.2145)\n",
            "Epoch: [1] [250/289]  eta: 0:00:03  time: 0.0806  loss: 2.8916 (2.7263)  bbox_regression: 0.6657 (0.5703)  classification: 2.2259 (2.1560)\n",
            "Epoch: [1] [260/289]  eta: 0:00:02  time: 0.0806  loss: 2.8866 (2.7184)  bbox_regression: 0.6640 (0.6012)  classification: 2.2226 (2.1172)\n",
            "Epoch: [1] [270/289]  eta: 0:00:01  time: 0.0805  loss: 2.8939 (2.9230)  bbox_regression: 0.6675 (0.6899)  classification: 2.2264 (2.2330)\n",
            "Epoch: [1] [280/289]  eta: 0:00:00  time: 0.0804  loss: 2.8889 (2.9188)  bbox_regression: 0.6659 (0.6905)  classification: 2.2230 (2.2283)\n",
            "Epoch: [1] [288/289]  eta: 0:00:00  time: 0.0803  loss: 2.8831 (2.7371)  bbox_regression: 0.6621 (0.5780)  classification: 2.2210 (2.1591)\n",
            "Epoch: [1] Time: 0:00:23 (0.0803 s / it)\n",
            "Epoch: [2]\n",
            "Epoch: [2] [  0/289]  eta: 0:00:22  time: 0.0792  loss: 3.4878 (3.4878)  bbox_regression: 1.1369 (1.1369)  classification: 2.3509 (2.3509)\n",
            "Epoch: [2] [ 10/289]  eta: 0:00:22  time: 0.0791  loss: 2.5449 (2.5449)  bbox_regression: 0.4770 (0.4770)  classification: 2.0679 (2.0679)\n",
            "Epoch: [2] [ 20/289]  eta: 0:00:21  time: 0.0807  loss: 2.2559 (2.1943)  bbox_regression: 0.3921 (0.3548)  classification: 1.8639 (1.8395)\n",
            "Epoch: [2] [ 30/289]  eta: 0:00:20  time: 0.0809  loss: 2.3834 (2.2946)  bbox_regression: 0.4431 (0.4244)  classification: 1.9404 (1.8702)\n",
            "Epoch: [2] [ 40/289]  eta: 0:00:20  time: 0.0809  loss: 2.3573 (2.4637)  bbox_regression: 0.4232 (0.4560)  classification: 1.9340 (2.0077)\n",
            "Epoch: [2] [ 50/289]  eta: 0:00:19  time: 0.0810  loss: 2.5335 (2.7661)  bbox_regression: 0.5069 (0.6058)  classification: 2.0266 (2.1603)\n",
            "Epoch: [2] [ 60/289]  eta: 0:00:18  time: 0.0819  loss: 2.5765 (3.0260)  bbox_regression: 0.5363 (0.7682)  classification: 2.0402 (2.2577)\n",
            "Epoch: [2] [ 70/289]  eta: 0:00:17  time: 0.0819  loss: 2.6110 (2.8086)  bbox_regression: 0.5499 (0.6594)  classification: 2.0612 (2.1492)\n",
            "Epoch: [2] [ 80/289]  eta: 0:00:17  time: 0.0817  loss: 2.5908 (2.6346)  bbox_regression: 0.5346 (0.5293)  classification: 2.0562 (2.1053)\n",
            "Epoch: [2] [ 90/289]  eta: 0:00:16  time: 0.0812  loss: 2.5839 (2.4875)  bbox_regression: 0.5273 (0.4473)  classification: 2.0566 (2.0402)\n",
            "Epoch: [2] [100/289]  eta: 0:00:15  time: 0.0806  loss: 2.5426 (2.3470)  bbox_regression: 0.5158 (0.4398)  classification: 2.0267 (1.9073)\n",
            "Epoch: [2] [110/289]  eta: 0:00:14  time: 0.0804  loss: 2.5684 (2.4979)  bbox_regression: 0.5254 (0.5168)  classification: 2.0430 (1.9811)\n",
            "Epoch: [2] [120/289]  eta: 0:00:13  time: 0.0803  loss: 2.5621 (2.6605)  bbox_regression: 0.5203 (0.5426)  classification: 2.0418 (2.1178)\n",
            "Epoch: [2] [130/289]  eta: 0:00:12  time: 0.0803  loss: 2.5334 (2.3393)  bbox_regression: 0.5076 (0.4090)  classification: 2.0258 (1.9303)\n",
            "Epoch: [2] [140/289]  eta: 0:00:11  time: 0.0803  loss: 2.5421 (2.4214)  bbox_regression: 0.5092 (0.4421)  classification: 2.0329 (1.9794)\n",
            "Epoch: [2] [150/289]  eta: 0:00:11  time: 0.0802  loss: 2.5286 (2.4973)  bbox_regression: 0.5067 (0.5006)  classification: 2.0219 (1.9967)\n",
            "Epoch: [2] [160/289]  eta: 0:00:10  time: 0.0802  loss: 2.5727 (2.7887)  bbox_regression: 0.5333 (0.7034)  classification: 2.0395 (2.0853)\n",
            "Epoch: [2] [170/289]  eta: 0:00:09  time: 0.0802  loss: 2.5692 (2.8759)  bbox_regression: 0.5286 (0.6941)  classification: 2.0406 (2.1817)\n",
            "Epoch: [2] [180/289]  eta: 0:00:08  time: 0.0802  loss: 2.5637 (2.4909)  bbox_regression: 0.5273 (0.4788)  classification: 2.0364 (2.0121)\n",
            "Epoch: [2] [190/289]  eta: 0:00:07  time: 0.0801  loss: 2.5611 (2.4916)  bbox_regression: 0.5259 (0.5022)  classification: 2.0352 (1.9894)\n",
            "Epoch: [2] [200/289]  eta: 0:00:07  time: 0.0802  loss: 2.5477 (2.4025)  bbox_regression: 0.5169 (0.4226)  classification: 2.0308 (1.9800)\n",
            "Epoch: [2] [210/289]  eta: 0:00:06  time: 0.0804  loss: 2.5565 (2.5124)  bbox_regression: 0.5237 (0.5033)  classification: 2.0328 (2.0091)\n",
            "Epoch: [2] [220/289]  eta: 0:00:05  time: 0.0803  loss: 2.5556 (2.6349)  bbox_regression: 0.5239 (0.5943)  classification: 2.0317 (2.0406)\n",
            "Epoch: [2] [230/289]  eta: 0:00:04  time: 0.0804  loss: 2.5517 (2.5006)  bbox_regression: 0.5204 (0.4857)  classification: 2.0312 (2.0150)\n",
            "Epoch: [2] [240/289]  eta: 0:00:03  time: 0.0802  loss: 2.5402 (2.3706)  bbox_regression: 0.5197 (0.4737)  classification: 2.0205 (1.8969)\n",
            "Epoch: [2] [250/289]  eta: 0:00:03  time: 0.0802  loss: 2.5271 (2.2437)  bbox_regression: 0.5120 (0.4149)  classification: 2.0151 (1.8288)\n",
            "Epoch: [2] [260/289]  eta: 0:00:02  time: 0.0801  loss: 2.5052 (2.0828)  bbox_regression: 0.5018 (0.2856)  classification: 2.0034 (1.7972)\n",
            "Epoch: [2] [270/289]  eta: 0:00:01  time: 0.0801  loss: 2.5077 (2.2644)  bbox_regression: 0.5062 (0.4326)  classification: 2.0016 (1.8318)\n",
            "Epoch: [2] [280/289]  eta: 0:00:00  time: 0.0800  loss: 2.5020 (2.4603)  bbox_regression: 0.5051 (0.5488)  classification: 1.9969 (1.9115)\n",
            "Epoch: [2] [288/289]  eta: 0:00:00  time: 0.0799  loss: 2.4956 (2.2845)  bbox_regression: 0.5030 (0.4370)  classification: 1.9926 (1.8475)\n",
            "Epoch: [2] Time: 0:00:23 (0.0799 s / it)\n",
            "Epoch: [3]\n",
            "Epoch: [3] [  0/289]  eta: 0:00:21  time: 0.0753  loss: 3.0865 (3.0865)  bbox_regression: 0.8072 (0.8072)  classification: 2.2793 (2.2793)\n",
            "Epoch: [3] [ 10/289]  eta: 0:00:21  time: 0.0774  loss: 2.4902 (2.4902)  bbox_regression: 0.5063 (0.5063)  classification: 1.9839 (1.9839)\n",
            "Epoch: [3] [ 20/289]  eta: 0:00:20  time: 0.0772  loss: 2.4153 (2.3817)  bbox_regression: 0.4785 (0.4621)  classification: 1.9368 (1.9197)\n",
            "Epoch: [3] [ 30/289]  eta: 0:00:19  time: 0.0762  loss: 2.5776 (2.6256)  bbox_regression: 0.5637 (0.5952)  classification: 2.0139 (2.0304)\n",
            "Epoch: [3] [ 40/289]  eta: 0:00:19  time: 0.0765  loss: 2.5366 (2.6640)  bbox_regression: 0.5544 (0.6340)  classification: 1.9823 (2.0300)\n",
            "Epoch: [3] [ 50/289]  eta: 0:00:18  time: 0.0772  loss: 2.4373 (2.2199)  bbox_regression: 0.5081 (0.4218)  classification: 1.9293 (1.7981)\n",
            "Epoch: [3] [ 60/289]  eta: 0:00:17  time: 0.0780  loss: 2.3807 (2.0612)  bbox_regression: 0.4790 (0.3244)  classification: 1.9018 (1.7368)\n",
            "Epoch: [3] [ 70/289]  eta: 0:00:17  time: 0.0789  loss: 2.3854 (2.2531)  bbox_regression: 0.4669 (0.3620)  classification: 1.9185 (1.8911)\n",
            "Epoch: [3] [ 80/289]  eta: 0:00:16  time: 0.0794  loss: 2.3593 (2.2937)  bbox_regression: 0.4557 (0.3848)  classification: 1.9035 (1.9089)\n",
            "Epoch: [3] [ 90/289]  eta: 0:00:15  time: 0.0796  loss: 2.3805 (2.3629)  bbox_regression: 0.4559 (0.4166)  classification: 1.9246 (1.9463)\n",
            "Epoch: [3] [100/289]  eta: 0:00:15  time: 0.0796  loss: 2.3635 (2.3805)  bbox_regression: 0.4495 (0.4245)  classification: 1.9139 (1.9561)\n",
            "Epoch: [3] [110/289]  eta: 0:00:14  time: 0.0793  loss: 2.3295 (2.0977)  bbox_regression: 0.4337 (0.3330)  classification: 1.8958 (1.7646)\n",
            "Epoch: [3] [120/289]  eta: 0:00:13  time: 0.0796  loss: 2.3221 (2.1130)  bbox_regression: 0.4270 (0.3133)  classification: 1.8951 (1.7997)\n",
            "Epoch: [3] [130/289]  eta: 0:00:12  time: 0.0797  loss: 2.3443 (2.4260)  bbox_regression: 0.4361 (0.4494)  classification: 1.9081 (1.9766)\n",
            "Epoch: [3] [140/289]  eta: 0:00:11  time: 0.0800  loss: 2.3578 (2.5739)  bbox_regression: 0.4437 (0.5446)  classification: 1.9141 (2.0293)\n",
            "Epoch: [3] [150/289]  eta: 0:00:11  time: 0.0800  loss: 2.3622 (2.4800)  bbox_regression: 0.4434 (0.4910)  classification: 1.9188 (1.9890)\n",
            "Epoch: [3] [160/289]  eta: 0:00:10  time: 0.0800  loss: 2.3673 (2.4347)  bbox_regression: 0.4463 (0.4650)  classification: 1.9210 (1.9697)\n",
            "Epoch: [3] [170/289]  eta: 0:00:09  time: 0.0800  loss: 2.3546 (2.2969)  bbox_regression: 0.4370 (0.3891)  classification: 1.9176 (1.9078)\n",
            "Epoch: [3] [180/289]  eta: 0:00:08  time: 0.0799  loss: 2.3428 (2.1453)  bbox_regression: 0.4320 (0.3164)  classification: 1.9108 (1.8289)\n",
            "Epoch: [3] [190/289]  eta: 0:00:07  time: 0.0799  loss: 2.3721 (2.5218)  bbox_regression: 0.4514 (0.5737)  classification: 1.9208 (1.9481)\n",
            "Epoch: [3] [200/289]  eta: 0:00:07  time: 0.0799  loss: 2.3795 (2.7112)  bbox_regression: 0.4529 (0.6418)  classification: 1.9266 (2.0694)\n",
            "Epoch: [3] [210/289]  eta: 0:00:06  time: 0.0799  loss: 2.3562 (2.2048)  bbox_regression: 0.4428 (0.3609)  classification: 1.9135 (1.8438)\n",
            "Epoch: [3] [220/289]  eta: 0:00:05  time: 0.0798  loss: 2.3380 (1.9213)  bbox_regression: 0.4334 (0.2374)  classification: 1.9046 (1.6839)\n",
            "Epoch: [3] [230/289]  eta: 0:00:04  time: 0.0799  loss: 2.3400 (2.1690)  bbox_regression: 0.4307 (0.3031)  classification: 1.9093 (1.8659)\n",
            "Epoch: [3] [240/289]  eta: 0:00:03  time: 0.0799  loss: 2.3387 (2.3468)  bbox_regression: 0.4318 (0.4148)  classification: 1.9069 (1.9319)\n",
            "Epoch: [3] [250/289]  eta: 0:00:03  time: 0.0798  loss: 2.3367 (2.2980)  bbox_regression: 0.4312 (0.4366)  classification: 1.9055 (1.8614)\n",
            "Epoch: [3] [260/289]  eta: 0:00:02  time: 0.0798  loss: 2.3432 (2.3965)  bbox_regression: 0.4325 (0.4412)  classification: 1.9106 (1.9553)\n",
            "Epoch: [3] [270/289]  eta: 0:00:01  time: 0.0799  loss: 2.3393 (2.3719)  bbox_regression: 0.4274 (0.3795)  classification: 1.9119 (1.9924)\n",
            "Epoch: [3] [280/289]  eta: 0:00:00  time: 0.0798  loss: 2.3368 (2.2540)  bbox_regression: 0.4288 (0.3800)  classification: 1.9080 (1.8740)\n",
            "Epoch: [3] [288/289]  eta: 0:00:00  time: 0.0797  loss: 2.3249 (2.1310)  bbox_regression: 0.4244 (0.3773)  classification: 1.9005 (1.7536)\n",
            "Epoch: [3] Time: 0:00:23 (0.0797 s / it)\n",
            "Epoch: [4]\n",
            "Epoch: [4] [  0/289]  eta: 0:00:22  time: 0.0782  loss: 1.4441 (1.4441)  bbox_regression: 0.0561 (0.0561)  classification: 1.3879 (1.3879)\n",
            "Epoch: [4] [ 10/289]  eta: 0:00:22  time: 0.0793  loss: 2.4434 (2.4434)  bbox_regression: 0.4554 (0.4554)  classification: 1.9880 (1.9880)\n",
            "Epoch: [4] [ 20/289]  eta: 0:00:21  time: 0.0797  loss: 2.2065 (2.2447)  bbox_regression: 0.3643 (0.3797)  classification: 1.8422 (1.8650)\n",
            "Epoch: [4] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 2.1622 (2.0076)  bbox_regression: 0.3422 (0.2800)  classification: 1.8200 (1.7275)\n",
            "Epoch: [4] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 2.1925 (2.1777)  bbox_regression: 0.3445 (0.3237)  classification: 1.8480 (1.8540)\n",
            "Epoch: [4] [ 50/289]  eta: 0:00:19  time: 0.0801  loss: 2.1612 (2.1597)  bbox_regression: 0.3483 (0.3578)  classification: 1.8129 (1.8020)\n",
            "Epoch: [4] [ 60/289]  eta: 0:00:18  time: 0.0804  loss: 2.1957 (2.2023)  bbox_regression: 0.3731 (0.4316)  classification: 1.8226 (1.7707)\n",
            "Epoch: [4] [ 70/289]  eta: 0:00:17  time: 0.0801  loss: 2.1604 (2.1583)  bbox_regression: 0.3548 (0.3712)  classification: 1.8056 (1.7872)\n",
            "Epoch: [4] [ 80/289]  eta: 0:00:16  time: 0.0804  loss: 2.1500 (2.0108)  bbox_regression: 0.3478 (0.2705)  classification: 1.8023 (1.7403)\n",
            "Epoch: [4] [ 90/289]  eta: 0:00:16  time: 0.0808  loss: 2.1405 (2.0697)  bbox_regression: 0.3401 (0.2879)  classification: 1.8004 (1.7817)\n",
            "Epoch: [4] [100/289]  eta: 0:00:15  time: 0.0809  loss: 2.1368 (2.0830)  bbox_regression: 0.3393 (0.3048)  classification: 1.7975 (1.7781)\n",
            "Epoch: [4] [110/289]  eta: 0:00:14  time: 0.0808  loss: 2.1336 (2.1025)  bbox_regression: 0.3389 (0.3335)  classification: 1.7948 (1.7691)\n",
            "Epoch: [4] [120/289]  eta: 0:00:13  time: 0.0806  loss: 2.1299 (2.0950)  bbox_regression: 0.3352 (0.3148)  classification: 1.7947 (1.7803)\n",
            "Epoch: [4] [130/289]  eta: 0:00:12  time: 0.0806  loss: 2.1408 (2.1807)  bbox_regression: 0.3472 (0.3930)  classification: 1.7937 (1.7877)\n",
            "Epoch: [4] [140/289]  eta: 0:00:12  time: 0.0807  loss: 2.1273 (2.1117)  bbox_regression: 0.3426 (0.3873)  classification: 1.7847 (1.7244)\n",
            "Epoch: [4] [150/289]  eta: 0:00:11  time: 0.0805  loss: 2.1339 (2.0886)  bbox_regression: 0.3431 (0.3166)  classification: 1.7908 (1.7721)\n",
            "Epoch: [4] [160/289]  eta: 0:00:10  time: 0.0804  loss: 2.1325 (2.1695)  bbox_regression: 0.3424 (0.3413)  classification: 1.7901 (1.8282)\n",
            "Epoch: [4] [170/289]  eta: 0:00:09  time: 0.0803  loss: 2.1308 (2.1070)  bbox_regression: 0.3408 (0.3231)  classification: 1.7900 (1.7839)\n",
            "Epoch: [4] [180/289]  eta: 0:00:08  time: 0.0803  loss: 2.1227 (2.0432)  bbox_regression: 0.3369 (0.2920)  classification: 1.7858 (1.7511)\n",
            "Epoch: [4] [190/289]  eta: 0:00:07  time: 0.0803  loss: 2.1417 (2.2349)  bbox_regression: 0.3467 (0.3973)  classification: 1.7950 (1.8376)\n",
            "Epoch: [4] [200/289]  eta: 0:00:07  time: 0.0803  loss: 2.1543 (2.4405)  bbox_regression: 0.3527 (0.4957)  classification: 1.8016 (1.9448)\n",
            "Epoch: [4] [210/289]  eta: 0:00:06  time: 0.0803  loss: 2.1461 (2.1884)  bbox_regression: 0.3487 (0.3674)  classification: 1.7975 (1.8210)\n",
            "Epoch: [4] [220/289]  eta: 0:00:05  time: 0.0803  loss: 2.1512 (2.1199)  bbox_regression: 0.3476 (0.2963)  classification: 1.8036 (1.8236)\n",
            "Epoch: [4] [230/289]  eta: 0:00:04  time: 0.0803  loss: 2.1582 (2.2857)  bbox_regression: 0.3485 (0.3471)  classification: 1.8097 (1.9386)\n",
            "Epoch: [4] [240/289]  eta: 0:00:03  time: 0.0804  loss: 2.1626 (2.2886)  bbox_regression: 0.3510 (0.3889)  classification: 1.8116 (1.8997)\n",
            "Epoch: [4] [250/289]  eta: 0:00:03  time: 0.0804  loss: 2.1559 (2.1297)  bbox_regression: 0.3477 (0.3385)  classification: 1.8082 (1.7912)\n",
            "Epoch: [4] [260/289]  eta: 0:00:02  time: 0.0803  loss: 2.1494 (1.9911)  bbox_regression: 0.3465 (0.2922)  classification: 1.8029 (1.6989)\n",
            "Epoch: [4] [270/289]  eta: 0:00:01  time: 0.0802  loss: 2.1340 (1.8592)  bbox_regression: 0.3411 (0.2581)  classification: 1.7929 (1.6010)\n",
            "Epoch: [4] [280/289]  eta: 0:00:00  time: 0.0801  loss: 2.1265 (1.8274)  bbox_regression: 0.3361 (0.2004)  classification: 1.7904 (1.6271)\n",
            "Epoch: [4] [288/289]  eta: 0:00:00  time: 0.0800  loss: 2.1405 (2.1901)  bbox_regression: 0.3411 (0.3230)  classification: 1.7995 (1.8670)\n",
            "Epoch: [4] Time: 0:00:23 (0.0800 s / it)\n",
            "Validation: [4]\n",
            "Validation: [4] [ 0/62]  eta: 0:00:12  time: 0.2028  \n",
            "Validation: [4] [10/62]  eta: 0:00:04  time: 0.0795  \n",
            "Validation: [4] [20/62]  eta: 0:00:03  time: 0.0738  \n",
            "Validation: [4] [30/62]  eta: 0:00:02  time: 0.0726  \n",
            "Validation: [4] [40/62]  eta: 0:00:01  time: 0.0720  \n",
            "Validation: [4] [50/62]  eta: 0:00:00  time: 0.0717  \n",
            "Validation: [4] [60/62]  eta: 0:00:00  time: 0.0714  \n",
            "Validation: [4] [61/62]  eta: 0:00:00  time: 0.0716  \n",
            "Validation: [4] Time: 0:00:04 (0.0716 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_5/mAP_vs_threshold_epoch_4.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_5/pr_curves_epoch_4.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_5/per_class_ap_epoch_4.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_5/confusion_matrix_epoch_4.png\n",
            "Epoch 4: mAP@0.5 = 0.0612\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.0000\n",
            "  Bacterial-Black-spot: 0.0000\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.0000\n",
            "  Mechanical-damage: 0.3143\n",
            "  Others: 0.0526\n",
            "Saved best model with mAP: 0.0612\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied mAP_vs_threshold_epoch_4.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/mAP_vs_threshold_epoch_4.csv\n",
            "Copied per_class_ap_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/per_class_ap_epoch_4.png\n",
            "Copied confusion_matrix_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/confusion_matrix_epoch_4.png\n",
            "Copied mAP_vs_threshold_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/mAP_vs_threshold_epoch_4.png\n",
            "Copied pr_curves_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/pr_curves_epoch_4.png\n",
            "Copied per_class_mAP_epoch_4.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/per_class_mAP_epoch_4.csv\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [5]\n",
            "Epoch: [5] [  0/289]  eta: 0:00:27  time: 0.0940  loss: 2.2505 (2.2505)  bbox_regression: 0.3695 (0.3695)  classification: 1.8810 (1.8810)\n",
            "Epoch: [5] [ 10/289]  eta: 0:00:23  time: 0.0849  loss: 1.9666 (1.9666)  bbox_regression: 0.2926 (0.2926)  classification: 1.6740 (1.6740)\n",
            "Epoch: [5] [ 20/289]  eta: 0:00:22  time: 0.0842  loss: 1.9889 (1.9758)  bbox_regression: 0.2995 (0.2960)  classification: 1.6894 (1.6798)\n",
            "Epoch: [5] [ 30/289]  eta: 0:00:21  time: 0.0837  loss: 1.9746 (1.9791)  bbox_regression: 0.3008 (0.3052)  classification: 1.6739 (1.6738)\n",
            "Epoch: [5] [ 40/289]  eta: 0:00:20  time: 0.0833  loss: 2.1264 (2.2708)  bbox_regression: 0.3525 (0.4081)  classification: 1.7739 (1.8627)\n",
            "Epoch: [5] [ 50/289]  eta: 0:00:19  time: 0.0830  loss: 2.1919 (2.5286)  bbox_regression: 0.3875 (0.5219)  classification: 1.8044 (2.0067)\n",
            "Epoch: [5] [ 60/289]  eta: 0:00:19  time: 0.0831  loss: 2.1669 (2.2499)  bbox_regression: 0.3759 (0.4238)  classification: 1.7910 (1.8261)\n",
            "Epoch: [5] [ 70/289]  eta: 0:00:18  time: 0.0827  loss: 2.1762 (2.1361)  bbox_regression: 0.3749 (0.3429)  classification: 1.8012 (1.7932)\n",
            "Epoch: [5] [ 80/289]  eta: 0:00:17  time: 0.0824  loss: 2.1174 (1.9666)  bbox_regression: 0.3521 (0.2794)  classification: 1.7654 (1.6872)\n",
            "Epoch: [5] [ 90/289]  eta: 0:00:16  time: 0.0823  loss: 2.1157 (1.9013)  bbox_regression: 0.3460 (0.2433)  classification: 1.7698 (1.6580)\n",
            "Epoch: [5] [100/289]  eta: 0:00:15  time: 0.0822  loss: 2.1160 (2.1101)  bbox_regression: 0.3446 (0.3144)  classification: 1.7714 (1.7957)\n",
            "Epoch: [5] [110/289]  eta: 0:00:14  time: 0.0820  loss: 2.1001 (2.0291)  bbox_regression: 0.3320 (0.2681)  classification: 1.7682 (1.7610)\n",
            "Epoch: [5] [120/289]  eta: 0:00:13  time: 0.0824  loss: 2.0962 (1.9964)  bbox_regression: 0.3290 (0.2501)  classification: 1.7672 (1.7463)\n",
            "Epoch: [5] [130/289]  eta: 0:00:13  time: 0.0828  loss: 2.0750 (1.9353)  bbox_regression: 0.3187 (0.2450)  classification: 1.7563 (1.6903)\n",
            "Epoch: [5] [140/289]  eta: 0:00:12  time: 0.0827  loss: 2.0759 (1.9532)  bbox_regression: 0.3176 (0.2489)  classification: 1.7583 (1.7042)\n",
            "Epoch: [5] [150/289]  eta: 0:00:11  time: 0.0826  loss: 2.0755 (2.0787)  bbox_regression: 0.3146 (0.2880)  classification: 1.7608 (1.7907)\n",
            "Epoch: [5] [160/289]  eta: 0:00:10  time: 0.0823  loss: 2.0651 (1.9886)  bbox_regression: 0.3068 (0.2302)  classification: 1.7583 (1.7584)\n",
            "Epoch: [5] [170/289]  eta: 0:00:09  time: 0.0822  loss: 2.0626 (1.9654)  bbox_regression: 0.3075 (0.2533)  classification: 1.7551 (1.7121)\n",
            "Epoch: [5] [180/289]  eta: 0:00:08  time: 0.0822  loss: 2.0534 (1.9590)  bbox_regression: 0.3043 (0.2845)  classification: 1.7491 (1.6746)\n",
            "Epoch: [5] [190/289]  eta: 0:00:08  time: 0.0822  loss: 2.0481 (1.9244)  bbox_regression: 0.3016 (0.2516)  classification: 1.7465 (1.6728)\n",
            "Epoch: [5] [200/289]  eta: 0:00:07  time: 0.0821  loss: 2.0644 (2.1646)  bbox_regression: 0.3127 (0.3884)  classification: 1.7518 (1.7762)\n",
            "Epoch: [5] [210/289]  eta: 0:00:06  time: 0.0823  loss: 2.0710 (2.2893)  bbox_regression: 0.3157 (0.4499)  classification: 1.7553 (1.8394)\n",
            "Epoch: [5] [220/289]  eta: 0:00:05  time: 0.0822  loss: 2.0586 (1.9996)  bbox_regression: 0.3105 (0.2887)  classification: 1.7481 (1.7109)\n",
            "Epoch: [5] [230/289]  eta: 0:00:04  time: 0.0821  loss: 2.0590 (1.9323)  bbox_regression: 0.3092 (0.2414)  classification: 1.7497 (1.6909)\n",
            "Epoch: [5] [240/289]  eta: 0:00:04  time: 0.0819  loss: 2.0528 (1.9895)  bbox_regression: 0.3062 (0.2589)  classification: 1.7466 (1.7306)\n",
            "Epoch: [5] [250/289]  eta: 0:00:03  time: 0.0818  loss: 2.0473 (1.9120)  bbox_regression: 0.3043 (0.2479)  classification: 1.7429 (1.6641)\n",
            "Epoch: [5] [260/289]  eta: 0:00:02  time: 0.0818  loss: 2.0351 (1.8213)  bbox_regression: 0.2983 (0.2027)  classification: 1.7368 (1.6186)\n",
            "Epoch: [5] [270/289]  eta: 0:00:01  time: 0.0817  loss: 2.0255 (1.7529)  bbox_regression: 0.2969 (0.2036)  classification: 1.7286 (1.5493)\n",
            "Epoch: [5] [280/289]  eta: 0:00:00  time: 0.0817  loss: 2.0205 (1.8304)  bbox_regression: 0.2946 (0.2470)  classification: 1.7259 (1.5834)\n",
            "Epoch: [5] [288/289]  eta: 0:00:00  time: 0.0816  loss: 2.0186 (1.8861)  bbox_regression: 0.2953 (0.2710)  classification: 1.7233 (1.6151)\n",
            "Epoch: [5] Time: 0:00:23 (0.0816 s / it)\n",
            "Epoch: [6]\n",
            "Epoch: [6] [  0/289]  eta: 0:00:23  time: 0.0818  loss: 1.5904 (1.5904)  bbox_regression: 0.2025 (0.2025)  classification: 1.3879 (1.3879)\n",
            "Epoch: [6] [ 10/289]  eta: 0:00:22  time: 0.0793  loss: 1.6329 (1.6329)  bbox_regression: 0.1790 (0.1790)  classification: 1.4539 (1.4539)\n",
            "Epoch: [6] [ 20/289]  eta: 0:00:21  time: 0.0794  loss: 1.8402 (1.8527)  bbox_regression: 0.2243 (0.2254)  classification: 1.6159 (1.6274)\n",
            "Epoch: [6] [ 30/289]  eta: 0:00:21  time: 0.0816  loss: 2.0450 (2.2717)  bbox_regression: 0.3294 (0.4120)  classification: 1.7157 (1.8596)\n",
            "Epoch: [6] [ 40/289]  eta: 0:00:20  time: 0.0811  loss: 1.9444 (2.0539)  bbox_regression: 0.2934 (0.3659)  classification: 1.6511 (1.6879)\n",
            "Epoch: [6] [ 50/289]  eta: 0:00:19  time: 0.0819  loss: 1.9455 (1.7913)  bbox_regression: 0.2863 (0.2196)  classification: 1.6592 (1.5717)\n",
            "Epoch: [6] [ 60/289]  eta: 0:00:19  time: 0.0830  loss: 1.9649 (2.0069)  bbox_regression: 0.3048 (0.3284)  classification: 1.6601 (1.6785)\n",
            "Epoch: [6] [ 70/289]  eta: 0:00:18  time: 0.0829  loss: 1.9998 (2.1384)  bbox_regression: 0.3121 (0.3777)  classification: 1.6878 (1.7607)\n",
            "Epoch: [6] [ 80/289]  eta: 0:00:17  time: 0.0828  loss: 1.9740 (2.0017)  bbox_regression: 0.2998 (0.2845)  classification: 1.6742 (1.7172)\n",
            "Epoch: [6] [ 90/289]  eta: 0:00:16  time: 0.0827  loss: 1.9747 (1.8853)  bbox_regression: 0.2980 (0.2481)  classification: 1.6767 (1.6372)\n",
            "Epoch: [6] [100/289]  eta: 0:00:15  time: 0.0826  loss: 1.9773 (1.9909)  bbox_regression: 0.2969 (0.2852)  classification: 1.6804 (1.7057)\n",
            "Epoch: [6] [110/289]  eta: 0:00:14  time: 0.0825  loss: 1.9839 (2.0259)  bbox_regression: 0.2978 (0.2972)  classification: 1.6860 (1.7287)\n",
            "Epoch: [6] [120/289]  eta: 0:00:13  time: 0.0824  loss: 1.9494 (1.8080)  bbox_regression: 0.2816 (0.2041)  classification: 1.6678 (1.6039)\n",
            "Epoch: [6] [130/289]  eta: 0:00:13  time: 0.0821  loss: 1.9399 (1.6959)  bbox_regression: 0.2786 (0.1720)  classification: 1.6613 (1.5240)\n",
            "Epoch: [6] [140/289]  eta: 0:00:12  time: 0.0820  loss: 1.9114 (1.6816)  bbox_regression: 0.2690 (0.1926)  classification: 1.6424 (1.4890)\n",
            "Epoch: [6] [150/289]  eta: 0:00:11  time: 0.0817  loss: 1.9177 (1.7722)  bbox_regression: 0.2737 (0.2412)  classification: 1.6440 (1.5309)\n",
            "Epoch: [6] [160/289]  eta: 0:00:10  time: 0.0816  loss: 1.9164 (1.9518)  bbox_regression: 0.2715 (0.2894)  classification: 1.6449 (1.6623)\n",
            "Epoch: [6] [170/289]  eta: 0:00:09  time: 0.0814  loss: 1.9141 (1.8868)  bbox_regression: 0.2697 (0.2396)  classification: 1.6444 (1.6473)\n",
            "Epoch: [6] [180/289]  eta: 0:00:08  time: 0.0815  loss: 1.9052 (1.8155)  bbox_regression: 0.2669 (0.2299)  classification: 1.6383 (1.5856)\n",
            "Epoch: [6] [190/289]  eta: 0:00:08  time: 0.0814  loss: 1.8957 (1.7383)  bbox_regression: 0.2650 (0.2251)  classification: 1.6307 (1.5132)\n",
            "Epoch: [6] [200/289]  eta: 0:00:07  time: 0.0814  loss: 1.8898 (1.7495)  bbox_regression: 0.2647 (0.2445)  classification: 1.6251 (1.5050)\n",
            "Epoch: [6] [210/289]  eta: 0:00:06  time: 0.0812  loss: 1.8878 (1.8130)  bbox_regression: 0.2654 (0.2688)  classification: 1.6225 (1.5441)\n",
            "Epoch: [6] [220/289]  eta: 0:00:05  time: 0.0815  loss: 1.8830 (1.8151)  bbox_regression: 0.2649 (0.2669)  classification: 1.6181 (1.5481)\n",
            "Epoch: [6] [230/289]  eta: 0:00:04  time: 0.0814  loss: 1.8725 (1.7102)  bbox_regression: 0.2594 (0.1968)  classification: 1.6130 (1.5134)\n",
            "Epoch: [6] [240/289]  eta: 0:00:03  time: 0.0814  loss: 1.8819 (1.8700)  bbox_regression: 0.2623 (0.2338)  classification: 1.6196 (1.6362)\n",
            "Epoch: [6] [250/289]  eta: 0:00:03  time: 0.0814  loss: 1.8867 (2.0516)  bbox_regression: 0.2610 (0.2789)  classification: 1.6257 (1.7727)\n",
            "Epoch: [6] [260/289]  eta: 0:00:02  time: 0.0813  loss: 1.8817 (1.8794)  bbox_regression: 0.2586 (0.2135)  classification: 1.6232 (1.6659)\n",
            "Epoch: [6] [270/289]  eta: 0:00:01  time: 0.0811  loss: 1.8847 (1.8591)  bbox_regression: 0.2593 (0.2386)  classification: 1.6254 (1.6205)\n",
            "Epoch: [6] [280/289]  eta: 0:00:00  time: 0.0811  loss: 1.8860 (1.9413)  bbox_regression: 0.2588 (0.2619)  classification: 1.6272 (1.6794)\n",
            "Epoch: [6] [288/289]  eta: 0:00:00  time: 0.0808  loss: 1.8942 (2.0527)  bbox_regression: 0.2619 (0.3011)  classification: 1.6323 (1.7515)\n",
            "Epoch: [6] Time: 0:00:23 (0.0809 s / it)\n",
            "Epoch: [7]\n",
            "Epoch: [7] [  0/289]  eta: 0:00:22  time: 0.0776  loss: 1.3505 (1.3505)  bbox_regression: 0.0639 (0.0639)  classification: 1.2866 (1.2866)\n",
            "Epoch: [7] [ 10/289]  eta: 0:00:21  time: 0.0777  loss: 2.0125 (2.0125)  bbox_regression: 0.3151 (0.3151)  classification: 1.6974 (1.6974)\n",
            "Epoch: [7] [ 20/289]  eta: 0:00:21  time: 0.0802  loss: 1.9945 (2.0267)  bbox_regression: 0.3031 (0.3151)  classification: 1.6914 (1.7116)\n",
            "Epoch: [7] [ 30/289]  eta: 0:00:20  time: 0.0797  loss: 1.9019 (1.8411)  bbox_regression: 0.2773 (0.2565)  classification: 1.6246 (1.5845)\n",
            "Epoch: [7] [ 40/289]  eta: 0:00:19  time: 0.0792  loss: 1.8382 (1.6740)  bbox_regression: 0.2539 (0.2022)  classification: 1.5842 (1.4717)\n",
            "Epoch: [7] [ 50/289]  eta: 0:00:19  time: 0.0796  loss: 1.8557 (1.7842)  bbox_regression: 0.2601 (0.2334)  classification: 1.5956 (1.5508)\n",
            "Epoch: [7] [ 60/289]  eta: 0:00:18  time: 0.0816  loss: 1.8225 (1.7903)  bbox_regression: 0.2431 (0.2208)  classification: 1.5794 (1.5696)\n",
            "Epoch: [7] [ 70/289]  eta: 0:00:17  time: 0.0819  loss: 1.7996 (1.6565)  bbox_regression: 0.2376 (0.1802)  classification: 1.5620 (1.4762)\n",
            "Epoch: [7] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 1.7815 (1.6567)  bbox_regression: 0.2250 (0.1699)  classification: 1.5565 (1.4867)\n",
            "Epoch: [7] [ 90/289]  eta: 0:00:16  time: 0.0819  loss: 1.8131 (1.8610)  bbox_regression: 0.2343 (0.2227)  classification: 1.5788 (1.6383)\n",
            "Epoch: [7] [100/289]  eta: 0:00:15  time: 0.0818  loss: 1.8156 (1.9533)  bbox_regression: 0.2385 (0.2932)  classification: 1.5770 (1.6601)\n",
            "Epoch: [7] [110/289]  eta: 0:00:14  time: 0.0818  loss: 1.8063 (1.7752)  bbox_regression: 0.2354 (0.2401)  classification: 1.5709 (1.5351)\n",
            "Epoch: [7] [120/289]  eta: 0:00:13  time: 0.0816  loss: 1.8046 (1.7492)  bbox_regression: 0.2358 (0.2222)  classification: 1.5688 (1.5270)\n",
            "Epoch: [7] [130/289]  eta: 0:00:12  time: 0.0816  loss: 1.7927 (1.7176)  bbox_regression: 0.2300 (0.2002)  classification: 1.5627 (1.5173)\n",
            "Epoch: [7] [140/289]  eta: 0:00:12  time: 0.0815  loss: 1.7984 (1.7612)  bbox_regression: 0.2296 (0.1916)  classification: 1.5689 (1.5696)\n",
            "Epoch: [7] [150/289]  eta: 0:00:11  time: 0.0814  loss: 1.8150 (1.9609)  bbox_regression: 0.2310 (0.2375)  classification: 1.5840 (1.7234)\n",
            "Epoch: [7] [160/289]  eta: 0:00:10  time: 0.0814  loss: 1.8142 (1.9257)  bbox_regression: 0.2336 (0.2624)  classification: 1.5806 (1.6633)\n",
            "Epoch: [7] [170/289]  eta: 0:00:09  time: 0.0815  loss: 1.8076 (1.7516)  bbox_regression: 0.2295 (0.2186)  classification: 1.5780 (1.5330)\n",
            "Epoch: [7] [180/289]  eta: 0:00:08  time: 0.0814  loss: 1.8136 (1.8080)  bbox_regression: 0.2322 (0.2206)  classification: 1.5814 (1.5875)\n",
            "Epoch: [7] [190/289]  eta: 0:00:08  time: 0.0812  loss: 1.8218 (1.9432)  bbox_regression: 0.2359 (0.2902)  classification: 1.5859 (1.6530)\n",
            "Epoch: [7] [200/289]  eta: 0:00:07  time: 0.0812  loss: 1.8419 (2.0984)  bbox_regression: 0.2408 (0.3187)  classification: 1.6011 (1.7798)\n",
            "Epoch: [7] [210/289]  eta: 0:00:06  time: 0.0812  loss: 1.8537 (2.1580)  bbox_regression: 0.2441 (0.3225)  classification: 1.6096 (1.8355)\n",
            "Epoch: [7] [220/289]  eta: 0:00:05  time: 0.0814  loss: 1.8753 (2.2113)  bbox_regression: 0.2527 (0.3725)  classification: 1.6226 (1.8387)\n",
            "Epoch: [7] [230/289]  eta: 0:00:04  time: 0.0816  loss: 1.8869 (2.2376)  bbox_regression: 0.2557 (0.3783)  classification: 1.6312 (1.8593)\n",
            "Epoch: [7] [240/289]  eta: 0:00:03  time: 0.0814  loss: 1.8726 (1.8422)  bbox_regression: 0.2529 (0.2545)  classification: 1.6197 (1.5876)\n",
            "Epoch: [7] [250/289]  eta: 0:00:03  time: 0.0814  loss: 1.8608 (1.5594)  bbox_regression: 0.2501 (0.1852)  classification: 1.6107 (1.3742)\n",
            "Epoch: [7] [260/289]  eta: 0:00:02  time: 0.0814  loss: 1.8512 (1.5940)  bbox_regression: 0.2485 (0.1962)  classification: 1.6027 (1.3978)\n",
            "Epoch: [7] [270/289]  eta: 0:00:01  time: 0.0814  loss: 1.8433 (1.6240)  bbox_regression: 0.2452 (0.1835)  classification: 1.5981 (1.4405)\n",
            "Epoch: [7] [280/289]  eta: 0:00:00  time: 0.0814  loss: 1.8392 (1.6827)  bbox_regression: 0.2423 (0.1606)  classification: 1.5970 (1.5221)\n",
            "Epoch: [7] [288/289]  eta: 0:00:00  time: 0.0812  loss: 1.8372 (1.7000)  bbox_regression: 0.2407 (0.1615)  classification: 1.5965 (1.5385)\n",
            "Epoch: [7] Time: 0:00:23 (0.0813 s / it)\n",
            "Epoch: [8]\n",
            "Epoch: [8] [  0/289]  eta: 0:00:26  time: 0.0900  loss: 1.7417 (1.7417)  bbox_regression: 0.1212 (0.1212)  classification: 1.6204 (1.6204)\n",
            "Epoch: [8] [ 10/289]  eta: 0:00:22  time: 0.0810  loss: 1.9595 (1.9595)  bbox_regression: 0.2788 (0.2788)  classification: 1.6807 (1.6807)\n",
            "Epoch: [8] [ 20/289]  eta: 0:00:21  time: 0.0816  loss: 1.8270 (1.8313)  bbox_regression: 0.2432 (0.2493)  classification: 1.5838 (1.5820)\n",
            "Epoch: [8] [ 30/289]  eta: 0:00:21  time: 0.0811  loss: 1.7508 (1.6360)  bbox_regression: 0.2353 (0.2115)  classification: 1.5155 (1.4246)\n",
            "Epoch: [8] [ 40/289]  eta: 0:00:20  time: 0.0813  loss: 1.7889 (1.7489)  bbox_regression: 0.2517 (0.2605)  classification: 1.5372 (1.4884)\n",
            "Epoch: [8] [ 50/289]  eta: 0:00:19  time: 0.0812  loss: 1.8612 (2.0322)  bbox_regression: 0.2709 (0.3259)  classification: 1.5903 (1.7063)\n",
            "Epoch: [8] [ 60/289]  eta: 0:00:18  time: 0.0810  loss: 1.8833 (2.0769)  bbox_regression: 0.2795 (0.3367)  classification: 1.6038 (1.7402)\n",
            "Epoch: [8] [ 70/289]  eta: 0:00:17  time: 0.0814  loss: 1.8618 (1.8635)  bbox_regression: 0.2646 (0.2488)  classification: 1.5972 (1.6147)\n",
            "Epoch: [8] [ 80/289]  eta: 0:00:17  time: 0.0817  loss: 1.8553 (1.7698)  bbox_regression: 0.2631 (0.2129)  classification: 1.5922 (1.5569)\n",
            "Epoch: [8] [ 90/289]  eta: 0:00:16  time: 0.0821  loss: 1.8359 (1.7437)  bbox_regression: 0.2571 (0.2302)  classification: 1.5788 (1.5135)\n",
            "Epoch: [8] [100/289]  eta: 0:00:15  time: 0.0821  loss: 1.8104 (1.6286)  bbox_regression: 0.2495 (0.1946)  classification: 1.5609 (1.4340)\n",
            "Epoch: [8] [110/289]  eta: 0:00:14  time: 0.0826  loss: 1.8085 (1.6839)  bbox_regression: 0.2452 (0.1913)  classification: 1.5632 (1.4925)\n",
            "Epoch: [8] [120/289]  eta: 0:00:13  time: 0.0824  loss: 1.7852 (1.6582)  bbox_regression: 0.2363 (0.1696)  classification: 1.5489 (1.4886)\n",
            "Epoch: [8] [130/289]  eta: 0:00:13  time: 0.0820  loss: 1.7689 (1.5491)  bbox_regression: 0.2299 (0.1450)  classification: 1.5390 (1.4042)\n",
            "Epoch: [8] [140/289]  eta: 0:00:12  time: 0.0820  loss: 1.7771 (1.7277)  bbox_regression: 0.2268 (0.1694)  classification: 1.5503 (1.5583)\n",
            "Epoch: [8] [150/289]  eta: 0:00:11  time: 0.0820  loss: 1.7877 (1.9109)  bbox_regression: 0.2339 (0.2597)  classification: 1.5538 (1.6512)\n",
            "Epoch: [8] [160/289]  eta: 0:00:10  time: 0.0819  loss: 1.7629 (1.6630)  bbox_regression: 0.2239 (0.2035)  classification: 1.5390 (1.4596)\n",
            "Epoch: [8] [170/289]  eta: 0:00:09  time: 0.0818  loss: 1.7534 (1.4941)  bbox_regression: 0.2207 (0.1214)  classification: 1.5326 (1.3727)\n",
            "Epoch: [8] [180/289]  eta: 0:00:08  time: 0.0818  loss: 1.7502 (1.6475)  bbox_regression: 0.2197 (0.1858)  classification: 1.5305 (1.4616)\n",
            "Epoch: [8] [190/289]  eta: 0:00:08  time: 0.0817  loss: 1.7515 (1.7359)  bbox_regression: 0.2215 (0.2283)  classification: 1.5300 (1.5076)\n",
            "Epoch: [8] [200/289]  eta: 0:00:07  time: 0.0818  loss: 1.7556 (1.8051)  bbox_regression: 0.2234 (0.2566)  classification: 1.5322 (1.5485)\n",
            "Epoch: [8] [210/289]  eta: 0:00:06  time: 0.0818  loss: 1.7642 (1.8848)  bbox_regression: 0.2215 (0.2218)  classification: 1.5426 (1.6630)\n",
            "Epoch: [8] [220/289]  eta: 0:00:05  time: 0.0818  loss: 1.7615 (1.8209)  bbox_regression: 0.2176 (0.1594)  classification: 1.5439 (1.6615)\n",
            "Epoch: [8] [230/289]  eta: 0:00:04  time: 0.0818  loss: 1.7543 (1.6499)  bbox_regression: 0.2153 (0.1491)  classification: 1.5390 (1.5008)\n",
            "Epoch: [8] [240/289]  eta: 0:00:04  time: 0.0819  loss: 1.7473 (1.5900)  bbox_regression: 0.2145 (0.1807)  classification: 1.5328 (1.4092)\n",
            "Epoch: [8] [250/289]  eta: 0:00:03  time: 0.0818  loss: 1.7410 (1.5880)  bbox_regression: 0.2131 (0.1875)  classification: 1.5280 (1.4005)\n",
            "Epoch: [8] [260/289]  eta: 0:00:02  time: 0.0818  loss: 1.7343 (1.5778)  bbox_regression: 0.2126 (0.1899)  classification: 1.5217 (1.3879)\n",
            "Epoch: [8] [270/289]  eta: 0:00:01  time: 0.0818  loss: 1.7278 (1.5623)  bbox_regression: 0.2102 (0.1744)  classification: 1.5176 (1.3879)\n",
            "Epoch: [8] [280/289]  eta: 0:00:00  time: 0.0817  loss: 1.7300 (1.6735)  bbox_regression: 0.2099 (0.1740)  classification: 1.5201 (1.4995)\n",
            "Epoch: [8] [288/289]  eta: 0:00:00  time: 0.0816  loss: 1.7394 (1.8910)  bbox_regression: 0.2139 (0.2505)  classification: 1.5255 (1.6405)\n",
            "Epoch: [8] Time: 0:00:23 (0.0816 s / it)\n",
            "Epoch: [9]\n",
            "Epoch: [9] [  0/289]  eta: 0:00:22  time: 0.0776  loss: 1.6508 (1.6508)  bbox_regression: 0.0708 (0.0708)  classification: 1.5800 (1.5800)\n",
            "Epoch: [9] [ 10/289]  eta: 0:00:23  time: 0.0826  loss: 1.7874 (1.7874)  bbox_regression: 0.2467 (0.2467)  classification: 1.5407 (1.5407)\n",
            "Epoch: [9] [ 20/289]  eta: 0:00:22  time: 0.0824  loss: 1.7122 (1.7153)  bbox_regression: 0.2245 (0.2322)  classification: 1.4877 (1.4831)\n",
            "Epoch: [9] [ 30/289]  eta: 0:00:21  time: 0.0816  loss: 1.7049 (1.6595)  bbox_regression: 0.2107 (0.1909)  classification: 1.4942 (1.4686)\n",
            "Epoch: [9] [ 40/289]  eta: 0:00:20  time: 0.0807  loss: 1.6643 (1.6140)  bbox_regression: 0.2022 (0.1788)  classification: 1.4621 (1.4352)\n",
            "Epoch: [9] [ 50/289]  eta: 0:00:19  time: 0.0810  loss: 1.7080 (1.7128)  bbox_regression: 0.2116 (0.2130)  classification: 1.4964 (1.4997)\n",
            "Epoch: [9] [ 60/289]  eta: 0:00:18  time: 0.0815  loss: 1.6972 (1.7647)  bbox_regression: 0.2159 (0.2440)  classification: 1.4813 (1.5207)\n",
            "Epoch: [9] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 1.7001 (1.6802)  bbox_regression: 0.2098 (0.2053)  classification: 1.4903 (1.4749)\n",
            "Epoch: [9] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 1.7142 (1.7658)  bbox_regression: 0.2104 (0.1936)  classification: 1.5038 (1.5722)\n",
            "Epoch: [9] [ 90/289]  eta: 0:00:16  time: 0.0818  loss: 1.7565 (1.9567)  bbox_regression: 0.2217 (0.2639)  classification: 1.5348 (1.6928)\n",
            "Epoch: [9] [100/289]  eta: 0:00:15  time: 0.0819  loss: 1.7503 (1.8967)  bbox_regression: 0.2159 (0.2381)  classification: 1.5344 (1.6586)\n",
            "Epoch: [9] [110/289]  eta: 0:00:14  time: 0.0818  loss: 1.7656 (1.8071)  bbox_regression: 0.2249 (0.2395)  classification: 1.5407 (1.5677)\n",
            "Epoch: [9] [120/289]  eta: 0:00:13  time: 0.0816  loss: 1.7518 (1.7595)  bbox_regression: 0.2194 (0.2369)  classification: 1.5325 (1.5226)\n",
            "Epoch: [9] [130/289]  eta: 0:00:12  time: 0.0815  loss: 1.7448 (1.6294)  bbox_regression: 0.2172 (0.1746)  classification: 1.5276 (1.4548)\n",
            "Epoch: [9] [140/289]  eta: 0:00:12  time: 0.0813  loss: 1.7809 (1.9564)  bbox_regression: 0.2301 (0.2951)  classification: 1.5507 (1.6612)\n",
            "Epoch: [9] [150/289]  eta: 0:00:11  time: 0.0812  loss: 1.7748 (1.9713)  bbox_regression: 0.2317 (0.3262)  classification: 1.5432 (1.6451)\n",
            "Epoch: [9] [160/289]  eta: 0:00:10  time: 0.0812  loss: 1.7610 (1.6210)  bbox_regression: 0.2272 (0.2065)  classification: 1.5338 (1.4145)\n",
            "Epoch: [9] [170/289]  eta: 0:00:09  time: 0.0812  loss: 1.7644 (1.6859)  bbox_regression: 0.2297 (0.2149)  classification: 1.5347 (1.4710)\n",
            "Epoch: [9] [180/289]  eta: 0:00:08  time: 0.0811  loss: 1.7769 (1.9045)  bbox_regression: 0.2359 (0.3061)  classification: 1.5410 (1.5985)\n",
            "Epoch: [9] [190/289]  eta: 0:00:08  time: 0.0810  loss: 1.7610 (1.7313)  bbox_regression: 0.2305 (0.2378)  classification: 1.5304 (1.4935)\n",
            "Epoch: [9] [200/289]  eta: 0:00:07  time: 0.0811  loss: 1.7490 (1.4966)  bbox_regression: 0.2260 (0.1363)  classification: 1.5230 (1.3603)\n",
            "Epoch: [9] [210/289]  eta: 0:00:06  time: 0.0810  loss: 1.7458 (1.6008)  bbox_regression: 0.2220 (0.1401)  classification: 1.5238 (1.4607)\n",
            "Epoch: [9] [220/289]  eta: 0:00:05  time: 0.0812  loss: 1.7404 (1.6548)  bbox_regression: 0.2177 (0.1347)  classification: 1.5227 (1.5201)\n",
            "Epoch: [9] [230/289]  eta: 0:00:04  time: 0.0815  loss: 1.7300 (1.5630)  bbox_regression: 0.2131 (0.1199)  classification: 1.5168 (1.4431)\n",
            "Epoch: [9] [240/289]  eta: 0:00:03  time: 0.0815  loss: 1.7243 (1.5464)  bbox_regression: 0.2117 (0.1451)  classification: 1.5127 (1.4013)\n",
            "Epoch: [9] [250/289]  eta: 0:00:03  time: 0.0814  loss: 1.7232 (1.6456)  bbox_regression: 0.2111 (0.1879)  classification: 1.5121 (1.4578)\n",
            "Epoch: [9] [260/289]  eta: 0:00:02  time: 0.0815  loss: 1.7161 (1.6172)  bbox_regression: 0.2097 (0.1859)  classification: 1.5064 (1.4313)\n",
            "Epoch: [9] [270/289]  eta: 0:00:01  time: 0.0814  loss: 1.7201 (1.6811)  bbox_regression: 0.2098 (0.1927)  classification: 1.5104 (1.4884)\n",
            "Epoch: [9] [280/289]  eta: 0:00:00  time: 0.0814  loss: 1.7143 (1.6898)  bbox_regression: 0.2085 (0.1923)  classification: 1.5058 (1.4975)\n",
            "Epoch: [9] [288/289]  eta: 0:00:00  time: 0.0813  loss: 1.7062 (1.4696)  bbox_regression: 0.2059 (0.1394)  classification: 1.5003 (1.3303)\n",
            "Epoch: [9] Time: 0:00:23 (0.0813 s / it)\n",
            "Validation: [9]\n",
            "Validation: [9] [ 0/62]  eta: 0:00:04  time: 0.0684  \n",
            "Validation: [9] [10/62]  eta: 0:00:03  time: 0.0688  \n",
            "Validation: [9] [20/62]  eta: 0:00:02  time: 0.0677  \n",
            "Validation: [9] [30/62]  eta: 0:00:02  time: 0.0684  \n",
            "Validation: [9] [40/62]  eta: 0:00:01  time: 0.0688  \n",
            "Validation: [9] [50/62]  eta: 0:00:00  time: 0.0691  \n",
            "Validation: [9] [60/62]  eta: 0:00:00  time: 0.0692  \n",
            "Validation: [9] [61/62]  eta: 0:00:00  time: 0.0687  \n",
            "Validation: [9] Time: 0:00:04 (0.0688 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_10/mAP_vs_threshold_epoch_9.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_10/pr_curves_epoch_9.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_10/per_class_ap_epoch_9.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_10/confusion_matrix_epoch_9.png\n",
            "Epoch 9: mAP@0.5 = 0.2223\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.0125\n",
            "  Bacterial-Black-spot: 0.1493\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.0945\n",
            "  Mechanical-damage: 0.4429\n",
            "  Others: 0.6349\n",
            "Saved best model with mAP: 0.2223\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied confusion_matrix_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/confusion_matrix_epoch_9.png\n",
            "Copied mAP_vs_threshold_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/mAP_vs_threshold_epoch_9.png\n",
            "Copied pr_curves_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/pr_curves_epoch_9.png\n",
            "Copied per_class_ap_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/per_class_ap_epoch_9.png\n",
            "Copied per_class_mAP_epoch_9.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/per_class_mAP_epoch_9.csv\n",
            "Copied mAP_vs_threshold_epoch_9.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/mAP_vs_threshold_epoch_9.csv\n",
            "Saved checkpoint at epoch 10\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [10]\n",
            "Epoch: [10] [  0/289]  eta: 0:00:26  time: 0.0902  loss: 1.7210 (1.7210)  bbox_regression: 0.2902 (0.2902)  classification: 1.4307 (1.4307)\n",
            "Epoch: [10] [ 10/289]  eta: 0:00:24  time: 0.0868  loss: 1.4891 (1.4891)  bbox_regression: 0.1968 (0.1968)  classification: 1.2923 (1.2923)\n",
            "Epoch: [10] [ 20/289]  eta: 0:00:22  time: 0.0852  loss: 1.5792 (1.5721)  bbox_regression: 0.1770 (0.1713)  classification: 1.4022 (1.4008)\n",
            "Epoch: [10] [ 30/289]  eta: 0:00:21  time: 0.0834  loss: 1.4722 (1.4628)  bbox_regression: 0.1505 (0.1251)  classification: 1.3216 (1.3377)\n",
            "Epoch: [10] [ 40/289]  eta: 0:00:20  time: 0.0825  loss: 1.5056 (1.4283)  bbox_regression: 0.1578 (0.1376)  classification: 1.3478 (1.2907)\n",
            "Epoch: [10] [ 50/289]  eta: 0:00:19  time: 0.0827  loss: 1.5921 (1.7779)  bbox_regression: 0.1880 (0.2461)  classification: 1.4041 (1.5319)\n",
            "Epoch: [10] [ 60/289]  eta: 0:00:18  time: 0.0825  loss: 1.5872 (1.7545)  bbox_regression: 0.1868 (0.2464)  classification: 1.4004 (1.5080)\n",
            "Epoch: [10] [ 70/289]  eta: 0:00:18  time: 0.0823  loss: 1.5795 (1.5474)  bbox_regression: 0.1804 (0.1611)  classification: 1.3991 (1.3863)\n",
            "Epoch: [10] [ 80/289]  eta: 0:00:17  time: 0.0821  loss: 1.6003 (1.6403)  bbox_regression: 0.1863 (0.1848)  classification: 1.4140 (1.4555)\n",
            "Epoch: [10] [ 90/289]  eta: 0:00:16  time: 0.0823  loss: 1.6020 (1.6818)  bbox_regression: 0.1864 (0.2076)  classification: 1.4156 (1.4742)\n",
            "Epoch: [10] [100/289]  eta: 0:00:15  time: 0.0820  loss: 1.6004 (1.6008)  bbox_regression: 0.1825 (0.1671)  classification: 1.4179 (1.4336)\n",
            "Epoch: [10] [110/289]  eta: 0:00:14  time: 0.0818  loss: 1.6252 (1.7309)  bbox_regression: 0.1846 (0.1764)  classification: 1.4406 (1.5544)\n",
            "Epoch: [10] [120/289]  eta: 0:00:13  time: 0.0823  loss: 1.6420 (1.8519)  bbox_regression: 0.1939 (0.2515)  classification: 1.4480 (1.6003)\n",
            "Epoch: [10] [130/289]  eta: 0:00:13  time: 0.0826  loss: 1.6302 (1.6580)  bbox_regression: 0.1890 (0.2134)  classification: 1.4412 (1.4446)\n",
            "Epoch: [10] [140/289]  eta: 0:00:12  time: 0.0829  loss: 1.6570 (1.7480)  bbox_regression: 0.2032 (0.2591)  classification: 1.4538 (1.4888)\n",
            "Epoch: [10] [150/289]  eta: 0:00:11  time: 0.0830  loss: 1.6337 (1.6567)  bbox_regression: 0.1950 (0.2339)  classification: 1.4388 (1.4228)\n",
            "Epoch: [10] [160/289]  eta: 0:00:10  time: 0.0830  loss: 1.6358 (1.4861)  bbox_regression: 0.1959 (0.1448)  classification: 1.4398 (1.3413)\n",
            "Epoch: [10] [170/289]  eta: 0:00:09  time: 0.0828  loss: 1.6191 (1.5086)  bbox_regression: 0.1924 (0.1728)  classification: 1.4267 (1.3358)\n",
            "Epoch: [10] [180/289]  eta: 0:00:09  time: 0.0827  loss: 1.6103 (1.4049)  bbox_regression: 0.1893 (0.1361)  classification: 1.4210 (1.2689)\n",
            "Epoch: [10] [190/289]  eta: 0:00:08  time: 0.0826  loss: 1.6040 (1.4751)  bbox_regression: 0.1879 (0.1494)  classification: 1.4162 (1.3257)\n",
            "Epoch: [10] [200/289]  eta: 0:00:07  time: 0.0825  loss: 1.6024 (1.5311)  bbox_regression: 0.1877 (0.1731)  classification: 1.4147 (1.3580)\n",
            "Epoch: [10] [210/289]  eta: 0:00:06  time: 0.0826  loss: 1.6000 (1.5613)  bbox_regression: 0.1874 (0.1829)  classification: 1.4126 (1.3783)\n",
            "Epoch: [10] [220/289]  eta: 0:00:05  time: 0.0826  loss: 1.6112 (1.6996)  bbox_regression: 0.1908 (0.2222)  classification: 1.4204 (1.4774)\n",
            "Epoch: [10] [230/289]  eta: 0:00:04  time: 0.0825  loss: 1.6060 (1.6693)  bbox_regression: 0.1894 (0.2108)  classification: 1.4166 (1.4586)\n",
            "Epoch: [10] [240/289]  eta: 0:00:04  time: 0.0824  loss: 1.6119 (1.6199)  bbox_regression: 0.1922 (0.2079)  classification: 1.4197 (1.4121)\n",
            "Epoch: [10] [250/289]  eta: 0:00:03  time: 0.0822  loss: 1.6250 (1.8448)  bbox_regression: 0.1970 (0.2846)  classification: 1.4280 (1.5602)\n",
            "Epoch: [10] [260/289]  eta: 0:00:02  time: 0.0822  loss: 1.6325 (1.8800)  bbox_regression: 0.1984 (0.2725)  classification: 1.4341 (1.6075)\n",
            "Epoch: [10] [270/289]  eta: 0:00:01  time: 0.0821  loss: 1.6320 (1.7200)  bbox_regression: 0.1971 (0.1986)  classification: 1.4349 (1.5214)\n",
            "Epoch: [10] [280/289]  eta: 0:00:00  time: 0.0822  loss: 1.6453 (1.8129)  bbox_regression: 0.2004 (0.2259)  classification: 1.4449 (1.5870)\n",
            "Epoch: [10] [288/289]  eta: 0:00:00  time: 0.0820  loss: 1.6546 (1.9801)  bbox_regression: 0.2004 (0.2473)  classification: 1.4542 (1.7328)\n",
            "Epoch: [10] Time: 0:00:23 (0.0821 s / it)\n",
            "Epoch: [11]\n",
            "Epoch: [11] [  0/289]  eta: 0:00:25  time: 0.0895  loss: 1.3467 (1.3467)  bbox_regression: 0.2346 (0.2346)  classification: 1.1121 (1.1121)\n",
            "Epoch: [11] [ 10/289]  eta: 0:00:22  time: 0.0818  loss: 2.3650 (2.3650)  bbox_regression: 0.3860 (0.3860)  classification: 1.9790 (1.9790)\n",
            "Epoch: [11] [ 20/289]  eta: 0:00:22  time: 0.0852  loss: 2.2787 (2.3254)  bbox_regression: 0.3858 (0.3934)  classification: 1.8929 (1.9319)\n",
            "Epoch: [11] [ 30/289]  eta: 0:00:21  time: 0.0831  loss: 2.3026 (2.2683)  bbox_regression: 0.4097 (0.4227)  classification: 1.8929 (1.8456)\n",
            "Epoch: [11] [ 40/289]  eta: 0:00:20  time: 0.0824  loss: 2.2113 (2.1406)  bbox_regression: 0.3701 (0.3535)  classification: 1.8413 (1.7870)\n",
            "Epoch: [11] [ 50/289]  eta: 0:00:19  time: 0.0825  loss: 2.1537 (1.9228)  bbox_regression: 0.3555 (0.2716)  classification: 1.7981 (1.6511)\n",
            "Epoch: [11] [ 60/289]  eta: 0:00:18  time: 0.0822  loss: 2.0856 (1.8279)  bbox_regression: 0.3234 (0.2276)  classification: 1.7622 (1.6003)\n",
            "Epoch: [11] [ 70/289]  eta: 0:00:18  time: 0.0823  loss: 2.0352 (1.7330)  bbox_regression: 0.3064 (0.1811)  classification: 1.7288 (1.5519)\n",
            "Epoch: [11] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 2.1419 (2.3137)  bbox_regression: 0.3304 (0.3516)  classification: 1.8116 (1.9621)\n",
            "Epoch: [11] [ 90/289]  eta: 0:00:16  time: 0.0822  loss: 2.2276 (2.9108)  bbox_regression: 0.3754 (0.6204)  classification: 1.8522 (2.2904)\n",
            "Epoch: [11] [100/289]  eta: 0:00:15  time: 0.0821  loss: 2.2661 (2.7689)  bbox_regression: 0.3867 (0.6149)  classification: 1.8794 (2.1540)\n",
            "Epoch: [11] [110/289]  eta: 0:00:14  time: 0.0819  loss: 2.2774 (2.5038)  bbox_regression: 0.3855 (0.4313)  classification: 1.8919 (2.0725)\n",
            "Epoch: [11] [120/289]  eta: 0:00:13  time: 0.0818  loss: 2.3371 (2.6954)  bbox_regression: 0.4137 (0.5502)  classification: 1.9233 (2.1453)\n",
            "Epoch: [11] [130/289]  eta: 0:00:12  time: 0.0817  loss: 2.2981 (2.4132)  bbox_regression: 0.3973 (0.4631)  classification: 1.9008 (1.9501)\n",
            "Epoch: [11] [140/289]  eta: 0:00:12  time: 0.0816  loss: 2.3254 (2.2547)  bbox_regression: 0.4074 (0.3693)  classification: 1.9180 (1.8854)\n",
            "Epoch: [11] [150/289]  eta: 0:00:11  time: 0.0815  loss: 2.3048 (2.3489)  bbox_regression: 0.4010 (0.4253)  classification: 1.9038 (1.9237)\n",
            "Epoch: [11] [160/289]  eta: 0:00:10  time: 0.0816  loss: 2.2808 (1.9667)  bbox_regression: 0.3899 (0.2663)  classification: 1.8909 (1.7004)\n",
            "Epoch: [11] [170/289]  eta: 0:00:09  time: 0.0818  loss: 2.2794 (2.0869)  bbox_regression: 0.3916 (0.3207)  classification: 1.8877 (1.7662)\n",
            "Epoch: [11] [180/289]  eta: 0:00:08  time: 0.0818  loss: 2.2636 (2.1253)  bbox_regression: 0.3857 (0.3520)  classification: 1.8779 (1.7734)\n",
            "Epoch: [11] [190/289]  eta: 0:00:08  time: 0.0817  loss: 2.2613 (2.1070)  bbox_regression: 0.3828 (0.3076)  classification: 1.8785 (1.7994)\n",
            "Epoch: [11] [200/289]  eta: 0:00:07  time: 0.0817  loss: 2.2551 (2.1778)  bbox_regression: 0.3799 (0.3279)  classification: 1.8752 (1.8499)\n",
            "Epoch: [11] [210/289]  eta: 0:00:06  time: 0.0815  loss: 2.2462 (2.1015)  bbox_regression: 0.3776 (0.3278)  classification: 1.8685 (1.7737)\n",
            "Epoch: [11] [220/289]  eta: 0:00:05  time: 0.0814  loss: 2.2381 (2.0673)  bbox_regression: 0.3757 (0.3331)  classification: 1.8624 (1.7342)\n",
            "Epoch: [11] [230/289]  eta: 0:00:04  time: 0.0814  loss: 2.2130 (1.8632)  bbox_regression: 0.3690 (0.2785)  classification: 1.8440 (1.5848)\n",
            "Epoch: [11] [240/289]  eta: 0:00:03  time: 0.0814  loss: 2.2047 (1.8353)  bbox_regression: 0.3672 (0.2726)  classification: 1.8375 (1.5626)\n",
            "Epoch: [11] [250/289]  eta: 0:00:03  time: 0.0814  loss: 2.2008 (2.0603)  bbox_regression: 0.3643 (0.3090)  classification: 1.8366 (1.7513)\n",
            "Epoch: [11] [260/289]  eta: 0:00:02  time: 0.0813  loss: 2.1878 (1.9851)  bbox_regression: 0.3592 (0.2640)  classification: 1.8286 (1.7211)\n",
            "Epoch: [11] [270/289]  eta: 0:00:01  time: 0.0814  loss: 2.1826 (1.9538)  bbox_regression: 0.3641 (0.3623)  classification: 1.8185 (1.5915)\n",
            "Epoch: [11] [280/289]  eta: 0:00:00  time: 0.0813  loss: 2.1685 (1.9164)  bbox_regression: 0.3580 (0.3423)  classification: 1.8105 (1.5740)\n",
            "Epoch: [11] [288/289]  eta: 0:00:00  time: 0.0812  loss: 2.1464 (1.6519)  bbox_regression: 0.3516 (0.2102)  classification: 1.7948 (1.4417)\n",
            "Epoch: [11] Time: 0:00:23 (0.0812 s / it)\n",
            "Epoch: [12]\n",
            "Epoch: [12] [  0/289]  eta: 0:00:23  time: 0.0823  loss: 1.3856 (1.3856)  bbox_regression: 0.0284 (0.0284)  classification: 1.3572 (1.3572)\n",
            "Epoch: [12] [ 10/289]  eta: 0:00:23  time: 0.0846  loss: 1.8949 (1.8949)  bbox_regression: 0.2165 (0.2165)  classification: 1.6785 (1.6785)\n",
            "Epoch: [12] [ 20/289]  eta: 0:00:22  time: 0.0846  loss: 1.7326 (1.7500)  bbox_regression: 0.2028 (0.2115)  classification: 1.5299 (1.5385)\n",
            "Epoch: [12] [ 30/289]  eta: 0:00:21  time: 0.0842  loss: 1.7737 (1.7070)  bbox_regression: 0.2228 (0.2263)  classification: 1.5509 (1.4807)\n",
            "Epoch: [12] [ 40/289]  eta: 0:00:20  time: 0.0835  loss: 1.8458 (1.9647)  bbox_regression: 0.2730 (0.3466)  classification: 1.5729 (1.6180)\n",
            "Epoch: [12] [ 50/289]  eta: 0:00:19  time: 0.0833  loss: 1.8181 (1.8868)  bbox_regression: 0.2554 (0.3059)  classification: 1.5627 (1.5809)\n",
            "Epoch: [12] [ 60/289]  eta: 0:00:19  time: 0.0830  loss: 1.7655 (1.6008)  bbox_regression: 0.2419 (0.1783)  classification: 1.5235 (1.4224)\n",
            "Epoch: [12] [ 70/289]  eta: 0:00:18  time: 0.0827  loss: 1.7296 (1.5039)  bbox_regression: 0.2275 (0.1565)  classification: 1.5020 (1.3474)\n",
            "Epoch: [12] [ 80/289]  eta: 0:00:17  time: 0.0828  loss: 1.7439 (1.6779)  bbox_regression: 0.2302 (0.1944)  classification: 1.5137 (1.4835)\n",
            "Epoch: [12] [ 90/289]  eta: 0:00:16  time: 0.0823  loss: 1.7375 (1.7657)  bbox_regression: 0.2291 (0.2347)  classification: 1.5084 (1.5310)\n",
            "Epoch: [12] [100/289]  eta: 0:00:15  time: 0.0824  loss: 1.7376 (1.7125)  bbox_regression: 0.2325 (0.2420)  classification: 1.5051 (1.4705)\n",
            "Epoch: [12] [110/289]  eta: 0:00:14  time: 0.0821  loss: 1.7510 (1.8122)  bbox_regression: 0.2408 (0.2939)  classification: 1.5102 (1.5183)\n",
            "Epoch: [12] [120/289]  eta: 0:00:13  time: 0.0820  loss: 1.7470 (1.7942)  bbox_regression: 0.2425 (0.2927)  classification: 1.5045 (1.5016)\n",
            "Epoch: [12] [130/289]  eta: 0:00:13  time: 0.0820  loss: 1.7626 (1.8269)  bbox_regression: 0.2471 (0.2823)  classification: 1.5154 (1.5446)\n",
            "Epoch: [12] [140/289]  eta: 0:00:12  time: 0.0819  loss: 1.7483 (1.7563)  bbox_regression: 0.2415 (0.2353)  classification: 1.5069 (1.5210)\n",
            "Epoch: [12] [150/289]  eta: 0:00:11  time: 0.0822  loss: 1.7517 (1.6807)  bbox_regression: 0.2432 (0.2173)  classification: 1.5085 (1.4634)\n",
            "Epoch: [12] [160/289]  eta: 0:00:10  time: 0.0824  loss: 1.7394 (1.6769)  bbox_regression: 0.2365 (0.2013)  classification: 1.5030 (1.4756)\n",
            "Epoch: [12] [170/289]  eta: 0:00:09  time: 0.0824  loss: 1.7280 (1.5488)  bbox_regression: 0.2328 (0.1542)  classification: 1.4952 (1.3945)\n",
            "Epoch: [12] [180/289]  eta: 0:00:08  time: 0.0823  loss: 1.7262 (1.6195)  bbox_regression: 0.2319 (0.1954)  classification: 1.4943 (1.4241)\n",
            "Epoch: [12] [190/289]  eta: 0:00:08  time: 0.0821  loss: 1.7183 (1.6359)  bbox_regression: 0.2278 (0.1858)  classification: 1.4905 (1.4500)\n",
            "Epoch: [12] [200/289]  eta: 0:00:07  time: 0.0818  loss: 1.7177 (1.6410)  bbox_regression: 0.2252 (0.1647)  classification: 1.4925 (1.4763)\n",
            "Epoch: [12] [210/289]  eta: 0:00:06  time: 0.0818  loss: 1.7153 (1.6864)  bbox_regression: 0.2241 (0.1882)  classification: 1.4912 (1.4983)\n",
            "Epoch: [12] [220/289]  eta: 0:00:05  time: 0.0817  loss: 1.7372 (1.9328)  bbox_regression: 0.2282 (0.2585)  classification: 1.5089 (1.6743)\n",
            "Epoch: [12] [230/289]  eta: 0:00:04  time: 0.0817  loss: 1.7261 (1.8405)  bbox_regression: 0.2242 (0.2248)  classification: 1.5020 (1.6156)\n",
            "Epoch: [12] [240/289]  eta: 0:00:03  time: 0.0816  loss: 1.7346 (1.7055)  bbox_regression: 0.2276 (0.2199)  classification: 1.5070 (1.4856)\n",
            "Epoch: [12] [250/289]  eta: 0:00:03  time: 0.0815  loss: 1.7421 (1.9269)  bbox_regression: 0.2284 (0.2773)  classification: 1.5138 (1.6496)\n",
            "Epoch: [12] [260/289]  eta: 0:00:02  time: 0.0814  loss: 1.7514 (1.9540)  bbox_regression: 0.2341 (0.3135)  classification: 1.5172 (1.6404)\n",
            "Epoch: [12] [270/289]  eta: 0:00:01  time: 0.0815  loss: 1.7532 (1.8913)  bbox_regression: 0.2352 (0.3201)  classification: 1.5180 (1.5712)\n",
            "Epoch: [12] [280/289]  eta: 0:00:00  time: 0.0815  loss: 1.7493 (1.7220)  bbox_regression: 0.2332 (0.2215)  classification: 1.5160 (1.5005)\n",
            "Epoch: [12] [288/289]  eta: 0:00:00  time: 0.0813  loss: 1.7422 (1.6815)  bbox_regression: 0.2298 (0.1941)  classification: 1.5124 (1.4874)\n",
            "Epoch: [12] Time: 0:00:23 (0.0813 s / it)\n",
            "Epoch: [13]\n",
            "Epoch: [13] [  0/289]  eta: 0:00:23  time: 0.0824  loss: 1.8144 (1.8144)  bbox_regression: 0.2188 (0.2188)  classification: 1.5955 (1.5955)\n",
            "Epoch: [13] [ 10/289]  eta: 0:00:22  time: 0.0798  loss: 1.7114 (1.7114)  bbox_regression: 0.2083 (0.2083)  classification: 1.5031 (1.5031)\n",
            "Epoch: [13] [ 20/289]  eta: 0:00:22  time: 0.0822  loss: 1.6814 (1.6747)  bbox_regression: 0.1644 (0.1617)  classification: 1.5169 (1.5130)\n",
            "Epoch: [13] [ 30/289]  eta: 0:00:21  time: 0.0835  loss: 1.6014 (1.5408)  bbox_regression: 0.1440 (0.1086)  classification: 1.4574 (1.4323)\n",
            "Epoch: [13] [ 40/289]  eta: 0:00:20  time: 0.0830  loss: 1.5593 (1.4312)  bbox_regression: 0.1323 (0.0985)  classification: 1.4270 (1.3326)\n",
            "Epoch: [13] [ 50/289]  eta: 0:00:19  time: 0.0825  loss: 1.5660 (1.5111)  bbox_regression: 0.1424 (0.1401)  classification: 1.4235 (1.3710)\n",
            "Epoch: [13] [ 60/289]  eta: 0:00:18  time: 0.0820  loss: 1.5780 (1.6162)  bbox_regression: 0.1542 (0.1992)  classification: 1.4237 (1.4170)\n",
            "Epoch: [13] [ 70/289]  eta: 0:00:17  time: 0.0817  loss: 1.5667 (1.5686)  bbox_regression: 0.1543 (0.1847)  classification: 1.4124 (1.3839)\n",
            "Epoch: [13] [ 80/289]  eta: 0:00:17  time: 0.0816  loss: 1.5529 (1.4765)  bbox_regression: 0.1465 (0.1228)  classification: 1.4064 (1.3537)\n",
            "Epoch: [13] [ 90/289]  eta: 0:00:16  time: 0.0814  loss: 1.5367 (1.4301)  bbox_regression: 0.1470 (0.1210)  classification: 1.3897 (1.3091)\n",
            "Epoch: [13] [100/289]  eta: 0:00:15  time: 0.0811  loss: 1.5316 (1.4451)  bbox_regression: 0.1457 (0.1426)  classification: 1.3858 (1.3024)\n",
            "Epoch: [13] [110/289]  eta: 0:00:14  time: 0.0809  loss: 1.5528 (1.6261)  bbox_regression: 0.1566 (0.2001)  classification: 1.3962 (1.4259)\n",
            "Epoch: [13] [120/289]  eta: 0:00:13  time: 0.0807  loss: 1.5616 (1.7131)  bbox_regression: 0.1633 (0.2522)  classification: 1.3982 (1.4609)\n",
            "Epoch: [13] [130/289]  eta: 0:00:12  time: 0.0807  loss: 1.5654 (1.6355)  bbox_regression: 0.1683 (0.2331)  classification: 1.3971 (1.4024)\n",
            "Epoch: [13] [140/289]  eta: 0:00:12  time: 0.0806  loss: 1.5791 (1.6850)  bbox_regression: 0.1753 (0.2477)  classification: 1.4038 (1.4374)\n",
            "Epoch: [13] [150/289]  eta: 0:00:11  time: 0.0806  loss: 1.5788 (1.6669)  bbox_regression: 0.1786 (0.2463)  classification: 1.4002 (1.4205)\n",
            "Epoch: [13] [160/289]  eta: 0:00:10  time: 0.0808  loss: 1.5732 (1.5314)  bbox_regression: 0.1755 (0.1768)  classification: 1.3977 (1.3546)\n",
            "Epoch: [13] [170/289]  eta: 0:00:09  time: 0.0809  loss: 1.5803 (1.5914)  bbox_regression: 0.1807 (0.1966)  classification: 1.3996 (1.3948)\n",
            "Epoch: [13] [180/289]  eta: 0:00:08  time: 0.0810  loss: 1.5819 (1.6520)  bbox_regression: 0.1824 (0.2385)  classification: 1.3994 (1.4136)\n",
            "Epoch: [13] [190/289]  eta: 0:00:08  time: 0.0811  loss: 1.5891 (1.6638)  bbox_regression: 0.1845 (0.2165)  classification: 1.4046 (1.4473)\n",
            "Epoch: [13] [200/289]  eta: 0:00:07  time: 0.0811  loss: 1.6153 (1.9174)  bbox_regression: 0.1943 (0.3021)  classification: 1.4209 (1.6154)\n",
            "Epoch: [13] [210/289]  eta: 0:00:06  time: 0.0811  loss: 1.6178 (1.8921)  bbox_regression: 0.1980 (0.3276)  classification: 1.4198 (1.5646)\n",
            "Epoch: [13] [220/289]  eta: 0:00:05  time: 0.0810  loss: 1.6199 (1.6664)  bbox_regression: 0.1987 (0.2431)  classification: 1.4211 (1.4233)\n",
            "Epoch: [13] [230/289]  eta: 0:00:04  time: 0.0808  loss: 1.6164 (1.6022)  bbox_regression: 0.1963 (0.1776)  classification: 1.4202 (1.4246)\n",
            "Epoch: [13] [240/289]  eta: 0:00:03  time: 0.0810  loss: 1.6298 (1.7397)  bbox_regression: 0.2017 (0.2345)  classification: 1.4281 (1.5052)\n",
            "Epoch: [13] [250/289]  eta: 0:00:03  time: 0.0811  loss: 1.6213 (1.6776)  bbox_regression: 0.1978 (0.2161)  classification: 1.4235 (1.4615)\n",
            "Epoch: [13] [260/289]  eta: 0:00:02  time: 0.0810  loss: 1.6189 (1.4876)  bbox_regression: 0.1957 (0.1226)  classification: 1.4233 (1.3650)\n",
            "Epoch: [13] [270/289]  eta: 0:00:01  time: 0.0810  loss: 1.6038 (1.3845)  bbox_regression: 0.1924 (0.1244)  classification: 1.4114 (1.2601)\n",
            "Epoch: [13] [280/289]  eta: 0:00:00  time: 0.0810  loss: 1.6047 (1.4194)  bbox_regression: 0.1934 (0.1646)  classification: 1.4113 (1.2548)\n",
            "Epoch: [13] [288/289]  eta: 0:00:00  time: 0.0809  loss: 1.6021 (1.5281)  bbox_regression: 0.1921 (0.1746)  classification: 1.4101 (1.3536)\n",
            "Epoch: [13] Time: 0:00:23 (0.0810 s / it)\n",
            "Epoch: [14]\n",
            "Epoch: [14] [  0/289]  eta: 0:00:25  time: 0.0878  loss: 2.0205 (2.0205)  bbox_regression: 0.3711 (0.3711)  classification: 1.6494 (1.6494)\n",
            "Epoch: [14] [ 10/289]  eta: 0:00:23  time: 0.0825  loss: 1.7832 (1.7832)  bbox_regression: 0.2715 (0.2715)  classification: 1.5117 (1.5117)\n",
            "Epoch: [14] [ 20/289]  eta: 0:00:22  time: 0.0835  loss: 1.5877 (1.5661)  bbox_regression: 0.2138 (0.2059)  classification: 1.3739 (1.3602)\n",
            "Epoch: [14] [ 30/289]  eta: 0:00:21  time: 0.0831  loss: 1.5005 (1.3451)  bbox_regression: 0.1848 (0.1370)  classification: 1.3158 (1.2081)\n",
            "Epoch: [14] [ 40/289]  eta: 0:00:20  time: 0.0832  loss: 1.4973 (1.4023)  bbox_regression: 0.1921 (0.1693)  classification: 1.3052 (1.2330)\n",
            "Epoch: [14] [ 50/289]  eta: 0:00:19  time: 0.0823  loss: 1.5199 (1.5498)  bbox_regression: 0.1845 (0.1842)  classification: 1.3353 (1.3657)\n",
            "Epoch: [14] [ 60/289]  eta: 0:00:18  time: 0.0814  loss: 1.5602 (1.6891)  bbox_regression: 0.1988 (0.2125)  classification: 1.3614 (1.4766)\n",
            "Epoch: [14] [ 70/289]  eta: 0:00:17  time: 0.0814  loss: 1.5351 (1.5740)  bbox_regression: 0.1844 (0.1841)  classification: 1.3507 (1.3898)\n",
            "Epoch: [14] [ 80/289]  eta: 0:00:17  time: 0.0814  loss: 1.5356 (1.4607)  bbox_regression: 0.1798 (0.1217)  classification: 1.3559 (1.3390)\n",
            "Epoch: [14] [ 90/289]  eta: 0:00:16  time: 0.0814  loss: 1.5445 (1.5781)  bbox_regression: 0.1813 (0.1703)  classification: 1.3632 (1.4077)\n",
            "Epoch: [14] [100/289]  eta: 0:00:15  time: 0.0810  loss: 1.5232 (1.4731)  bbox_regression: 0.1745 (0.1531)  classification: 1.3488 (1.3200)\n",
            "Epoch: [14] [110/289]  eta: 0:00:14  time: 0.0810  loss: 1.5106 (1.3560)  bbox_regression: 0.1661 (0.0967)  classification: 1.3445 (1.2593)\n",
            "Epoch: [14] [120/289]  eta: 0:00:13  time: 0.0810  loss: 1.4865 (1.3007)  bbox_regression: 0.1581 (0.0754)  classification: 1.3284 (1.2253)\n",
            "Epoch: [14] [130/289]  eta: 0:00:12  time: 0.0808  loss: 1.4749 (1.2767)  bbox_regression: 0.1545 (0.0900)  classification: 1.3204 (1.1868)\n",
            "Epoch: [14] [140/289]  eta: 0:00:12  time: 0.0808  loss: 1.4798 (1.4397)  bbox_regression: 0.1568 (0.1488)  classification: 1.3230 (1.2909)\n",
            "Epoch: [14] [150/289]  eta: 0:00:11  time: 0.0808  loss: 1.4682 (1.4242)  bbox_regression: 0.1537 (0.1489)  classification: 1.3144 (1.2753)\n",
            "Epoch: [14] [160/289]  eta: 0:00:10  time: 0.0810  loss: 1.4791 (1.4736)  bbox_regression: 0.1606 (0.1873)  classification: 1.3185 (1.2863)\n",
            "Epoch: [14] [170/289]  eta: 0:00:09  time: 0.0811  loss: 1.4734 (1.5132)  bbox_regression: 0.1588 (0.1967)  classification: 1.3147 (1.3165)\n",
            "Epoch: [14] [180/289]  eta: 0:00:08  time: 0.0811  loss: 1.4834 (1.5180)  bbox_regression: 0.1590 (0.1465)  classification: 1.3243 (1.3716)\n",
            "Epoch: [14] [190/289]  eta: 0:00:08  time: 0.0811  loss: 1.4841 (1.5756)  bbox_regression: 0.1571 (0.1430)  classification: 1.3270 (1.4326)\n",
            "Epoch: [14] [200/289]  eta: 0:00:07  time: 0.0811  loss: 1.4848 (1.4980)  bbox_regression: 0.1578 (0.1468)  classification: 1.3270 (1.3512)\n",
            "Epoch: [14] [210/289]  eta: 0:00:06  time: 0.0811  loss: 1.4886 (1.5315)  bbox_regression: 0.1604 (0.1924)  classification: 1.3282 (1.3392)\n",
            "Epoch: [14] [220/289]  eta: 0:00:05  time: 0.0811  loss: 1.4918 (1.5615)  bbox_regression: 0.1592 (0.1731)  classification: 1.3326 (1.3884)\n",
            "Epoch: [14] [230/289]  eta: 0:00:04  time: 0.0811  loss: 1.5000 (1.6194)  bbox_regression: 0.1614 (0.1717)  classification: 1.3385 (1.4477)\n",
            "Epoch: [14] [240/289]  eta: 0:00:03  time: 0.0811  loss: 1.4968 (1.5522)  bbox_regression: 0.1612 (0.1835)  classification: 1.3356 (1.3687)\n",
            "Epoch: [14] [250/289]  eta: 0:00:03  time: 0.0810  loss: 1.5032 (1.5402)  bbox_regression: 0.1627 (0.1778)  classification: 1.3404 (1.3624)\n",
            "Epoch: [14] [260/289]  eta: 0:00:02  time: 0.0810  loss: 1.5001 (1.5400)  bbox_regression: 0.1608 (0.1565)  classification: 1.3393 (1.3836)\n",
            "Epoch: [14] [270/289]  eta: 0:00:01  time: 0.0810  loss: 1.5017 (1.4833)  bbox_regression: 0.1600 (0.1264)  classification: 1.3417 (1.3569)\n",
            "Epoch: [14] [280/289]  eta: 0:00:00  time: 0.0811  loss: 1.4977 (1.4671)  bbox_regression: 0.1597 (0.1454)  classification: 1.3380 (1.3217)\n",
            "Epoch: [14] [288/289]  eta: 0:00:00  time: 0.0808  loss: 1.4948 (1.3747)  bbox_regression: 0.1590 (0.1378)  classification: 1.3359 (1.2369)\n",
            "Epoch: [14] Time: 0:00:23 (0.0808 s / it)\n",
            "Validation: [14]\n",
            "Validation: [14] [ 0/62]  eta: 0:00:04  time: 0.0697  \n",
            "Validation: [14] [10/62]  eta: 0:00:03  time: 0.0687  \n",
            "Validation: [14] [20/62]  eta: 0:00:02  time: 0.0698  \n",
            "Validation: [14] [30/62]  eta: 0:00:02  time: 0.0707  \n",
            "Validation: [14] [40/62]  eta: 0:00:01  time: 0.0711  \n",
            "Validation: [14] [50/62]  eta: 0:00:00  time: 0.0715  \n",
            "Validation: [14] [60/62]  eta: 0:00:00  time: 0.0715  \n",
            "Validation: [14] [61/62]  eta: 0:00:00  time: 0.0710  \n",
            "Validation: [14] Time: 0:00:04 (0.0710 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_15/mAP_vs_threshold_epoch_14.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_15/pr_curves_epoch_14.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_15/per_class_ap_epoch_14.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_15/confusion_matrix_epoch_14.png\n",
            "Epoch 14: mAP@0.5 = 0.2134\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.0687\n",
            "  Bacterial-Black-spot: 0.1269\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.1538\n",
            "  Mechanical-damage: 0.4571\n",
            "  Others: 0.4737\n",
            "Copied confusion_matrix_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/confusion_matrix_epoch_14.png\n",
            "Copied per_class_mAP_epoch_14.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/per_class_mAP_epoch_14.csv\n",
            "Copied per_class_ap_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/per_class_ap_epoch_14.png\n",
            "Copied mAP_vs_threshold_epoch_14.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/mAP_vs_threshold_epoch_14.csv\n",
            "Copied mAP_vs_threshold_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/mAP_vs_threshold_epoch_14.png\n",
            "Copied pr_curves_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/pr_curves_epoch_14.png\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [15]\n",
            "Epoch: [15] [  0/289]  eta: 0:00:25  time: 0.0871  loss: 1.2535 (1.2535)  bbox_regression: 0.1777 (0.1777)  classification: 1.0758 (1.0758)\n",
            "Epoch: [15] [ 10/289]  eta: 0:00:23  time: 0.0843  loss: 1.4717 (1.4717)  bbox_regression: 0.1198 (0.1198)  classification: 1.3518 (1.3518)\n",
            "Epoch: [15] [ 20/289]  eta: 0:00:22  time: 0.0830  loss: 1.3650 (1.3706)  bbox_regression: 0.1087 (0.1053)  classification: 1.2563 (1.2653)\n",
            "Epoch: [15] [ 30/289]  eta: 0:00:21  time: 0.0825  loss: 1.3411 (1.2694)  bbox_regression: 0.1189 (0.1184)  classification: 1.2222 (1.1510)\n",
            "Epoch: [15] [ 40/289]  eta: 0:00:20  time: 0.0820  loss: 1.3338 (1.3010)  bbox_regression: 0.1196 (0.1311)  classification: 1.2142 (1.1699)\n",
            "Epoch: [15] [ 50/289]  eta: 0:00:19  time: 0.0822  loss: 1.3939 (1.4756)  bbox_regression: 0.1439 (0.1826)  classification: 1.2500 (1.2930)\n",
            "Epoch: [15] [ 60/289]  eta: 0:00:19  time: 0.0832  loss: 1.3776 (1.4674)  bbox_regression: 0.1432 (0.1914)  classification: 1.2345 (1.2760)\n",
            "Epoch: [15] [ 70/289]  eta: 0:00:18  time: 0.0828  loss: 1.3670 (1.2984)  bbox_regression: 0.1399 (0.1297)  classification: 1.2271 (1.1687)\n",
            "Epoch: [15] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 1.3482 (1.2583)  bbox_regression: 0.1360 (0.1142)  classification: 1.2121 (1.1441)\n",
            "Epoch: [15] [ 90/289]  eta: 0:00:16  time: 0.0819  loss: 1.3505 (1.2922)  bbox_regression: 0.1326 (0.1067)  classification: 1.2180 (1.1855)\n",
            "Epoch: [15] [100/289]  eta: 0:00:15  time: 0.0819  loss: 1.3269 (1.2407)  bbox_regression: 0.1268 (0.0897)  classification: 1.2000 (1.1510)\n",
            "Epoch: [15] [110/289]  eta: 0:00:14  time: 0.0818  loss: 1.3219 (1.1914)  bbox_regression: 0.1259 (0.0956)  classification: 1.1959 (1.0958)\n",
            "Epoch: [15] [120/289]  eta: 0:00:13  time: 0.0816  loss: 1.3193 (1.2812)  bbox_regression: 0.1220 (0.0973)  classification: 1.1974 (1.1840)\n",
            "Epoch: [15] [130/289]  eta: 0:00:12  time: 0.0815  loss: 1.3088 (1.2361)  bbox_regression: 0.1201 (0.0880)  classification: 1.1887 (1.1482)\n",
            "Epoch: [15] [140/289]  eta: 0:00:12  time: 0.0813  loss: 1.3064 (1.2278)  bbox_regression: 0.1177 (0.0921)  classification: 1.1886 (1.1358)\n",
            "Epoch: [15] [150/289]  eta: 0:00:11  time: 0.0812  loss: 1.3125 (1.3372)  bbox_regression: 0.1210 (0.1268)  classification: 1.1915 (1.2104)\n",
            "Epoch: [15] [160/289]  eta: 0:00:10  time: 0.0814  loss: 1.3036 (1.2844)  bbox_regression: 0.1169 (0.1113)  classification: 1.1867 (1.1731)\n",
            "Epoch: [15] [170/289]  eta: 0:00:09  time: 0.0814  loss: 1.3054 (1.2518)  bbox_regression: 0.1151 (0.0709)  classification: 1.1903 (1.1809)\n",
            "Epoch: [15] [180/289]  eta: 0:00:08  time: 0.0814  loss: 1.2947 (1.2233)  bbox_regression: 0.1112 (0.0651)  classification: 1.1836 (1.1582)\n",
            "Epoch: [15] [190/289]  eta: 0:00:08  time: 0.0815  loss: 1.2812 (1.0739)  bbox_regression: 0.1087 (0.0539)  classification: 1.1725 (1.0200)\n",
            "Epoch: [15] [200/289]  eta: 0:00:07  time: 0.0815  loss: 1.2874 (1.2209)  bbox_regression: 0.1147 (0.1470)  classification: 1.1726 (1.0739)\n",
            "Epoch: [15] [210/289]  eta: 0:00:06  time: 0.0815  loss: 1.2868 (1.3404)  bbox_regression: 0.1146 (0.1709)  classification: 1.1722 (1.1695)\n",
            "Epoch: [15] [220/289]  eta: 0:00:05  time: 0.0816  loss: 1.2834 (1.2432)  bbox_regression: 0.1129 (0.0946)  classification: 1.1705 (1.1486)\n",
            "Epoch: [15] [230/289]  eta: 0:00:04  time: 0.0816  loss: 1.2821 (1.2323)  bbox_regression: 0.1133 (0.0991)  classification: 1.1688 (1.1332)\n",
            "Epoch: [15] [240/289]  eta: 0:00:04  time: 0.0817  loss: 1.2816 (1.2615)  bbox_regression: 0.1137 (0.1225)  classification: 1.1679 (1.1390)\n",
            "Epoch: [15] [250/289]  eta: 0:00:03  time: 0.0817  loss: 1.2776 (1.2264)  bbox_regression: 0.1115 (0.0905)  classification: 1.1662 (1.1360)\n",
            "Epoch: [15] [260/289]  eta: 0:00:02  time: 0.0818  loss: 1.2834 (1.3054)  bbox_regression: 0.1126 (0.0989)  classification: 1.1708 (1.2065)\n",
            "Epoch: [15] [270/289]  eta: 0:00:01  time: 0.0817  loss: 1.2864 (1.3958)  bbox_regression: 0.1105 (0.0988)  classification: 1.1758 (1.2970)\n",
            "Epoch: [15] [280/289]  eta: 0:00:00  time: 0.0816  loss: 1.2823 (1.2675)  bbox_regression: 0.1089 (0.0605)  classification: 1.1734 (1.2070)\n",
            "Epoch: [15] [288/289]  eta: 0:00:00  time: 0.0814  loss: 1.2832 (1.2183)  bbox_regression: 0.1100 (0.1018)  classification: 1.1733 (1.1165)\n",
            "Epoch: [15] Time: 0:00:23 (0.0814 s / it)\n",
            "Epoch: [16]\n",
            "Epoch: [16] [  0/289]  eta: 0:00:23  time: 0.0822  loss: 1.2748 (1.2748)  bbox_regression: 0.0263 (0.0263)  classification: 1.2485 (1.2485)\n",
            "Epoch: [16] [ 10/289]  eta: 0:00:22  time: 0.0804  loss: 1.1295 (1.1295)  bbox_regression: 0.0456 (0.0456)  classification: 1.0839 (1.0839)\n",
            "Epoch: [16] [ 20/289]  eta: 0:00:21  time: 0.0807  loss: 1.1454 (1.1389)  bbox_regression: 0.0552 (0.0567)  classification: 1.0901 (1.0822)\n",
            "Epoch: [16] [ 30/289]  eta: 0:00:21  time: 0.0826  loss: 1.1483 (1.1586)  bbox_regression: 0.0475 (0.0485)  classification: 1.1008 (1.1101)\n",
            "Epoch: [16] [ 40/289]  eta: 0:00:20  time: 0.0830  loss: 1.1956 (1.2483)  bbox_regression: 0.0668 (0.0789)  classification: 1.1288 (1.1694)\n",
            "Epoch: [16] [ 50/289]  eta: 0:00:19  time: 0.0826  loss: 1.1913 (1.2580)  bbox_regression: 0.0678 (0.0993)  classification: 1.1235 (1.1587)\n",
            "Epoch: [16] [ 60/289]  eta: 0:00:19  time: 0.0832  loss: 1.1864 (1.1676)  bbox_regression: 0.0727 (0.0847)  classification: 1.1137 (1.0828)\n",
            "Epoch: [16] [ 70/289]  eta: 0:00:18  time: 0.0827  loss: 1.2051 (1.2402)  bbox_regression: 0.0811 (0.1150)  classification: 1.1240 (1.1252)\n",
            "Epoch: [16] [ 80/289]  eta: 0:00:17  time: 0.0826  loss: 1.2143 (1.2995)  bbox_regression: 0.0794 (0.1000)  classification: 1.1349 (1.1995)\n",
            "Epoch: [16] [ 90/289]  eta: 0:00:16  time: 0.0825  loss: 1.2042 (1.2010)  bbox_regression: 0.0786 (0.0695)  classification: 1.1256 (1.1315)\n",
            "Epoch: [16] [100/289]  eta: 0:00:15  time: 0.0821  loss: 1.2044 (1.1640)  bbox_regression: 0.0775 (0.0696)  classification: 1.1269 (1.0944)\n",
            "Epoch: [16] [110/289]  eta: 0:00:14  time: 0.0822  loss: 1.1981 (1.1704)  bbox_regression: 0.0783 (0.0771)  classification: 1.1198 (1.0933)\n",
            "Epoch: [16] [120/289]  eta: 0:00:13  time: 0.0822  loss: 1.2058 (1.2133)  bbox_regression: 0.0798 (0.0917)  classification: 1.1260 (1.1216)\n",
            "Epoch: [16] [130/289]  eta: 0:00:13  time: 0.0822  loss: 1.1988 (1.2025)  bbox_regression: 0.0759 (0.0626)  classification: 1.1229 (1.1399)\n",
            "Epoch: [16] [140/289]  eta: 0:00:12  time: 0.0821  loss: 1.1876 (1.0776)  bbox_regression: 0.0753 (0.0478)  classification: 1.1124 (1.0298)\n",
            "Epoch: [16] [150/289]  eta: 0:00:11  time: 0.0820  loss: 1.1873 (1.1124)  bbox_regression: 0.0788 (0.0978)  classification: 1.1085 (1.0147)\n",
            "Epoch: [16] [160/289]  eta: 0:00:10  time: 0.0819  loss: 1.1911 (1.2153)  bbox_regression: 0.0803 (0.1156)  classification: 1.1108 (1.0997)\n",
            "Epoch: [16] [170/289]  eta: 0:00:09  time: 0.0818  loss: 1.1955 (1.2576)  bbox_regression: 0.0807 (0.0949)  classification: 1.1149 (1.1627)\n",
            "Epoch: [16] [180/289]  eta: 0:00:08  time: 0.0819  loss: 1.1953 (1.2297)  bbox_regression: 0.0817 (0.0933)  classification: 1.1136 (1.1364)\n",
            "Epoch: [16] [190/289]  eta: 0:00:08  time: 0.0819  loss: 1.1977 (1.2158)  bbox_regression: 0.0818 (0.0917)  classification: 1.1158 (1.1241)\n",
            "Epoch: [16] [200/289]  eta: 0:00:07  time: 0.0818  loss: 1.1884 (1.1258)  bbox_regression: 0.0820 (0.0847)  classification: 1.1064 (1.0411)\n",
            "Epoch: [16] [210/289]  eta: 0:00:06  time: 0.0818  loss: 1.1862 (1.0771)  bbox_regression: 0.0822 (0.0854)  classification: 1.1041 (0.9916)\n",
            "Epoch: [16] [220/289]  eta: 0:00:05  time: 0.0817  loss: 1.1899 (1.2043)  bbox_regression: 0.0825 (0.0875)  classification: 1.1073 (1.1168)\n",
            "Epoch: [16] [230/289]  eta: 0:00:04  time: 0.0817  loss: 1.1901 (1.2313)  bbox_regression: 0.0851 (0.1162)  classification: 1.1050 (1.1150)\n",
            "Epoch: [16] [240/289]  eta: 0:00:04  time: 0.0817  loss: 1.1885 (1.1732)  bbox_regression: 0.0850 (0.1128)  classification: 1.1034 (1.0604)\n",
            "Epoch: [16] [250/289]  eta: 0:00:03  time: 0.0816  loss: 1.1870 (1.1513)  bbox_regression: 0.0846 (0.0784)  classification: 1.1025 (1.0729)\n",
            "Epoch: [16] [260/289]  eta: 0:00:02  time: 0.0815  loss: 1.1970 (1.2996)  bbox_regression: 0.0897 (0.1457)  classification: 1.1073 (1.1539)\n",
            "Epoch: [16] [270/289]  eta: 0:00:01  time: 0.0814  loss: 1.1953 (1.2992)  bbox_regression: 0.0885 (0.1370)  classification: 1.1069 (1.1622)\n",
            "Epoch: [16] [280/289]  eta: 0:00:00  time: 0.0814  loss: 1.1960 (1.1825)  bbox_regression: 0.0897 (0.0894)  classification: 1.1063 (1.0931)\n",
            "Epoch: [16] [288/289]  eta: 0:00:00  time: 0.0812  loss: 1.1962 (1.2061)  bbox_regression: 0.0917 (0.1292)  classification: 1.1045 (1.0769)\n",
            "Epoch: [16] Time: 0:00:23 (0.0813 s / it)\n",
            "Epoch: [17]\n",
            "Epoch: [17] [  0/289]  eta: 0:00:22  time: 0.0780  loss: 0.8294 (0.8294)  bbox_regression: 0.0829 (0.0829)  classification: 0.7466 (0.7466)\n",
            "Epoch: [17] [ 10/289]  eta: 0:00:22  time: 0.0796  loss: 1.1654 (1.1654)  bbox_regression: 0.0873 (0.0873)  classification: 1.0781 (1.0781)\n",
            "Epoch: [17] [ 20/289]  eta: 0:00:21  time: 0.0799  loss: 1.1737 (1.1909)  bbox_regression: 0.0691 (0.0684)  classification: 1.1046 (1.1225)\n",
            "Epoch: [17] [ 30/289]  eta: 0:00:20  time: 0.0807  loss: 1.1766 (1.1827)  bbox_regression: 0.0691 (0.0590)  classification: 1.1075 (1.1237)\n",
            "Epoch: [17] [ 40/289]  eta: 0:00:20  time: 0.0812  loss: 1.1334 (1.0911)  bbox_regression: 0.0650 (0.0607)  classification: 1.0684 (1.0303)\n",
            "Epoch: [17] [ 50/289]  eta: 0:00:19  time: 0.0814  loss: 1.1653 (1.1478)  bbox_regression: 0.0643 (0.0569)  classification: 1.1010 (1.0909)\n",
            "Epoch: [17] [ 60/289]  eta: 0:00:18  time: 0.0814  loss: 1.2170 (1.3886)  bbox_regression: 0.0875 (0.1336)  classification: 1.1295 (1.2549)\n",
            "Epoch: [17] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 1.1966 (1.2765)  bbox_regression: 0.0805 (0.1219)  classification: 1.1161 (1.1546)\n",
            "Epoch: [17] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 1.1825 (1.0771)  bbox_regression: 0.0819 (0.0649)  classification: 1.1006 (1.0122)\n",
            "Epoch: [17] [ 90/289]  eta: 0:00:16  time: 0.0814  loss: 1.1707 (1.0787)  bbox_regression: 0.0803 (0.0793)  classification: 1.0905 (0.9994)\n",
            "Epoch: [17] [100/289]  eta: 0:00:15  time: 0.0812  loss: 1.1651 (1.0949)  bbox_regression: 0.0810 (0.0773)  classification: 1.0841 (1.0176)\n",
            "Epoch: [17] [110/289]  eta: 0:00:14  time: 0.0812  loss: 1.1568 (1.0936)  bbox_regression: 0.0810 (0.0842)  classification: 1.0759 (1.0094)\n",
            "Epoch: [17] [120/289]  eta: 0:00:13  time: 0.0812  loss: 1.1713 (1.2022)  bbox_regression: 0.0823 (0.0888)  classification: 1.0890 (1.1134)\n",
            "Epoch: [17] [130/289]  eta: 0:00:12  time: 0.0812  loss: 1.1590 (1.1708)  bbox_regression: 0.0809 (0.0809)  classification: 1.0780 (1.0899)\n",
            "Epoch: [17] [140/289]  eta: 0:00:12  time: 0.0810  loss: 1.1521 (1.0364)  bbox_regression: 0.0801 (0.0671)  classification: 1.0720 (0.9693)\n",
            "Epoch: [17] [150/289]  eta: 0:00:11  time: 0.0811  loss: 1.1467 (1.0660)  bbox_regression: 0.0798 (0.0720)  classification: 1.0669 (0.9940)\n",
            "Epoch: [17] [160/289]  eta: 0:00:10  time: 0.0810  loss: 1.1448 (1.0934)  bbox_regression: 0.0799 (0.0787)  classification: 1.0649 (1.0147)\n",
            "Epoch: [17] [170/289]  eta: 0:00:09  time: 0.0809  loss: 1.1417 (1.1044)  bbox_regression: 0.0777 (0.0618)  classification: 1.0640 (1.0426)\n",
            "Epoch: [17] [180/289]  eta: 0:00:08  time: 0.0809  loss: 1.1433 (1.1308)  bbox_regression: 0.0795 (0.0759)  classification: 1.0638 (1.0549)\n",
            "Epoch: [17] [190/289]  eta: 0:00:08  time: 0.0812  loss: 1.1402 (1.1270)  bbox_regression: 0.0786 (0.0868)  classification: 1.0615 (1.0401)\n",
            "Epoch: [17] [200/289]  eta: 0:00:07  time: 0.0813  loss: 1.1381 (1.0908)  bbox_regression: 0.0799 (0.0833)  classification: 1.0582 (1.0075)\n",
            "Epoch: [17] [210/289]  eta: 0:00:06  time: 0.0812  loss: 1.1384 (1.1220)  bbox_regression: 0.0841 (0.1360)  classification: 1.0544 (0.9861)\n",
            "Epoch: [17] [220/289]  eta: 0:00:05  time: 0.0812  loss: 1.1417 (1.1786)  bbox_regression: 0.0832 (0.1163)  classification: 1.0586 (1.0623)\n",
            "Epoch: [17] [230/289]  eta: 0:00:04  time: 0.0811  loss: 1.1402 (1.1582)  bbox_regression: 0.0844 (0.0875)  classification: 1.0558 (1.0706)\n",
            "Epoch: [17] [240/289]  eta: 0:00:03  time: 0.0813  loss: 1.1423 (1.1484)  bbox_regression: 0.0842 (0.0957)  classification: 1.0581 (1.0527)\n",
            "Epoch: [17] [250/289]  eta: 0:00:03  time: 0.0813  loss: 1.1392 (1.1284)  bbox_regression: 0.0830 (0.0670)  classification: 1.0562 (1.0614)\n",
            "Epoch: [17] [260/289]  eta: 0:00:02  time: 0.0812  loss: 1.1429 (1.1503)  bbox_regression: 0.0848 (0.0919)  classification: 1.0581 (1.0584)\n",
            "Epoch: [17] [270/289]  eta: 0:00:01  time: 0.0812  loss: 1.1459 (1.2299)  bbox_regression: 0.0843 (0.1002)  classification: 1.0617 (1.1297)\n",
            "Epoch: [17] [280/289]  eta: 0:00:00  time: 0.0813  loss: 1.1435 (1.1518)  bbox_regression: 0.0851 (0.0886)  classification: 1.0585 (1.0632)\n",
            "Epoch: [17] [288/289]  eta: 0:00:00  time: 0.0811  loss: 1.1455 (1.1688)  bbox_regression: 0.0853 (0.1107)  classification: 1.0601 (1.0581)\n",
            "Epoch: [17] Time: 0:00:23 (0.0812 s / it)\n",
            "Epoch: [18]\n",
            "Epoch: [18] [  0/289]  eta: 0:00:22  time: 0.0764  loss: 0.9953 (0.9953)  bbox_regression: 0.0371 (0.0371)  classification: 0.9581 (0.9581)\n",
            "Epoch: [18] [ 10/289]  eta: 0:00:21  time: 0.0788  loss: 1.0417 (1.0417)  bbox_regression: 0.0662 (0.0662)  classification: 0.9755 (0.9755)\n",
            "Epoch: [18] [ 20/289]  eta: 0:00:20  time: 0.0781  loss: 1.0808 (1.0850)  bbox_regression: 0.0602 (0.0613)  classification: 1.0206 (1.0237)\n",
            "Epoch: [18] [ 30/289]  eta: 0:00:20  time: 0.0795  loss: 1.0797 (1.1006)  bbox_regression: 0.0845 (0.0946)  classification: 0.9952 (1.0060)\n",
            "Epoch: [18] [ 40/289]  eta: 0:00:19  time: 0.0801  loss: 1.1373 (1.1967)  bbox_regression: 0.0934 (0.1283)  classification: 1.0439 (1.0684)\n",
            "Epoch: [18] [ 50/289]  eta: 0:00:19  time: 0.0808  loss: 1.1255 (1.1964)  bbox_regression: 0.0882 (0.0940)  classification: 1.0372 (1.1024)\n",
            "Epoch: [18] [ 60/289]  eta: 0:00:18  time: 0.0811  loss: 1.1143 (1.0671)  bbox_regression: 0.0872 (0.0744)  classification: 1.0271 (0.9927)\n",
            "Epoch: [18] [ 70/289]  eta: 0:00:17  time: 0.0814  loss: 1.1197 (1.1048)  bbox_regression: 0.0882 (0.0879)  classification: 1.0315 (1.0168)\n",
            "Epoch: [18] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 1.1342 (1.1949)  bbox_regression: 0.0895 (0.0966)  classification: 1.0447 (1.0983)\n",
            "Epoch: [18] [ 90/289]  eta: 0:00:16  time: 0.0818  loss: 1.1226 (1.1330)  bbox_regression: 0.0921 (0.1063)  classification: 1.0304 (1.0267)\n",
            "Epoch: [18] [100/289]  eta: 0:00:15  time: 0.0820  loss: 1.1082 (1.0029)  bbox_regression: 0.0871 (0.0774)  classification: 1.0211 (0.9255)\n",
            "Epoch: [18] [110/289]  eta: 0:00:14  time: 0.0819  loss: 1.1175 (1.0943)  bbox_regression: 0.0859 (0.0577)  classification: 1.0316 (1.0366)\n",
            "Epoch: [18] [120/289]  eta: 0:00:13  time: 0.0819  loss: 1.1188 (1.1720)  bbox_regression: 0.0876 (0.0898)  classification: 1.0312 (1.0822)\n",
            "Epoch: [18] [130/289]  eta: 0:00:13  time: 0.0819  loss: 1.1078 (1.0543)  bbox_regression: 0.0829 (0.0658)  classification: 1.0250 (0.9885)\n",
            "Epoch: [18] [140/289]  eta: 0:00:12  time: 0.0817  loss: 1.1006 (0.9909)  bbox_regression: 0.0800 (0.0344)  classification: 1.0206 (0.9564)\n",
            "Epoch: [18] [150/289]  eta: 0:00:11  time: 0.0816  loss: 1.0986 (1.0382)  bbox_regression: 0.0814 (0.0719)  classification: 1.0172 (0.9662)\n",
            "Epoch: [18] [160/289]  eta: 0:00:10  time: 0.0815  loss: 1.0991 (1.0881)  bbox_regression: 0.0817 (0.0931)  classification: 1.0174 (0.9950)\n",
            "Epoch: [18] [170/289]  eta: 0:00:09  time: 0.0816  loss: 1.0928 (1.0493)  bbox_regression: 0.0805 (0.0737)  classification: 1.0123 (0.9756)\n",
            "Epoch: [18] [180/289]  eta: 0:00:08  time: 0.0816  loss: 1.0992 (1.1000)  bbox_regression: 0.0810 (0.0757)  classification: 1.0182 (1.0243)\n",
            "Epoch: [18] [190/289]  eta: 0:00:08  time: 0.0818  loss: 1.0973 (1.1357)  bbox_regression: 0.0789 (0.0646)  classification: 1.0185 (1.0711)\n",
            "Epoch: [18] [200/289]  eta: 0:00:07  time: 0.0821  loss: 1.0905 (1.0122)  bbox_regression: 0.0764 (0.0349)  classification: 1.0141 (0.9773)\n",
            "Epoch: [18] [210/289]  eta: 0:00:06  time: 0.0823  loss: 1.0994 (1.1190)  bbox_regression: 0.0798 (0.0884)  classification: 1.0196 (1.0307)\n",
            "Epoch: [18] [220/289]  eta: 0:00:05  time: 0.0822  loss: 1.1008 (1.2044)  bbox_regression: 0.0781 (0.0949)  classification: 1.0227 (1.1096)\n",
            "Epoch: [18] [230/289]  eta: 0:00:04  time: 0.0820  loss: 1.1032 (1.1436)  bbox_regression: 0.0769 (0.0464)  classification: 1.0263 (1.0972)\n",
            "Epoch: [18] [240/289]  eta: 0:00:04  time: 0.0820  loss: 1.1065 (1.1699)  bbox_regression: 0.0812 (0.1151)  classification: 1.0254 (1.0548)\n",
            "Epoch: [18] [250/289]  eta: 0:00:03  time: 0.0820  loss: 1.1049 (1.1244)  bbox_regression: 0.0817 (0.1378)  classification: 1.0232 (0.9866)\n",
            "Epoch: [18] [260/289]  eta: 0:00:02  time: 0.0819  loss: 1.0983 (0.9987)  bbox_regression: 0.0801 (0.0679)  classification: 1.0181 (0.9308)\n",
            "Epoch: [18] [270/289]  eta: 0:00:01  time: 0.0818  loss: 1.0919 (0.9281)  bbox_regression: 0.0788 (0.0420)  classification: 1.0131 (0.8861)\n",
            "Epoch: [18] [280/289]  eta: 0:00:00  time: 0.0819  loss: 1.0933 (1.0280)  bbox_regression: 0.0802 (0.0810)  classification: 1.0131 (0.9471)\n",
            "Epoch: [18] [288/289]  eta: 0:00:00  time: 0.0817  loss: 1.0939 (1.1082)  bbox_regression: 0.0807 (0.1043)  classification: 1.0132 (1.0039)\n",
            "Epoch: [18] Time: 0:00:23 (0.0817 s / it)\n",
            "Epoch: [19]\n",
            "Epoch: [19] [  0/289]  eta: 0:00:22  time: 0.0786  loss: 0.7523 (0.7523)  bbox_regression: 0.0160 (0.0160)  classification: 0.7362 (0.7362)\n",
            "Epoch: [19] [ 10/289]  eta: 0:00:22  time: 0.0802  loss: 1.0533 (1.0533)  bbox_regression: 0.1067 (0.1067)  classification: 0.9466 (0.9466)\n",
            "Epoch: [19] [ 20/289]  eta: 0:00:22  time: 0.0819  loss: 1.0587 (1.0740)  bbox_regression: 0.0894 (0.0930)  classification: 0.9693 (0.9810)\n",
            "Epoch: [19] [ 30/289]  eta: 0:00:21  time: 0.0819  loss: 1.0468 (1.0432)  bbox_regression: 0.0786 (0.0632)  classification: 0.9682 (0.9800)\n",
            "Epoch: [19] [ 40/289]  eta: 0:00:20  time: 0.0824  loss: 1.0150 (0.9691)  bbox_regression: 0.0692 (0.0481)  classification: 0.9458 (0.9210)\n",
            "Epoch: [19] [ 50/289]  eta: 0:00:19  time: 0.0827  loss: 1.0422 (1.0351)  bbox_regression: 0.0698 (0.0562)  classification: 0.9724 (0.9789)\n",
            "Epoch: [19] [ 60/289]  eta: 0:00:19  time: 0.0830  loss: 1.0475 (1.1141)  bbox_regression: 0.0684 (0.0667)  classification: 0.9791 (1.0474)\n",
            "Epoch: [19] [ 70/289]  eta: 0:00:18  time: 0.0832  loss: 1.0668 (1.1296)  bbox_regression: 0.0792 (0.1031)  classification: 0.9876 (1.0265)\n",
            "Epoch: [19] [ 80/289]  eta: 0:00:17  time: 0.0829  loss: 1.0544 (1.0755)  bbox_regression: 0.0760 (0.0992)  classification: 0.9784 (0.9763)\n",
            "Epoch: [19] [ 90/289]  eta: 0:00:16  time: 0.0828  loss: 1.0257 (0.8799)  bbox_regression: 0.0740 (0.0556)  classification: 0.9517 (0.8244)\n",
            "Epoch: [19] [100/289]  eta: 0:00:15  time: 0.0825  loss: 1.0172 (0.8665)  bbox_regression: 0.0733 (0.0621)  classification: 0.9439 (0.8044)\n",
            "Epoch: [19] [110/289]  eta: 0:00:14  time: 0.0823  loss: 1.0432 (1.1225)  bbox_regression: 0.0759 (0.0843)  classification: 0.9673 (1.0382)\n",
            "Epoch: [19] [120/289]  eta: 0:00:13  time: 0.0821  loss: 1.0437 (1.1777)  bbox_regression: 0.0745 (0.0808)  classification: 0.9692 (1.0969)\n",
            "Epoch: [19] [130/289]  eta: 0:00:13  time: 0.0820  loss: 1.0543 (1.1158)  bbox_regression: 0.0805 (0.1060)  classification: 0.9738 (1.0098)\n",
            "Epoch: [19] [140/289]  eta: 0:00:12  time: 0.0819  loss: 1.0483 (1.0759)  bbox_regression: 0.0792 (0.1076)  classification: 0.9691 (0.9683)\n",
            "Epoch: [19] [150/289]  eta: 0:00:11  time: 0.0818  loss: 1.0415 (0.9580)  bbox_regression: 0.0784 (0.0651)  classification: 0.9631 (0.8929)\n",
            "Epoch: [19] [160/289]  eta: 0:00:10  time: 0.0817  loss: 1.0407 (0.9873)  bbox_regression: 0.0767 (0.0587)  classification: 0.9641 (0.9286)\n",
            "Epoch: [19] [170/289]  eta: 0:00:09  time: 0.0818  loss: 1.0499 (1.1136)  bbox_regression: 0.0772 (0.0679)  classification: 0.9727 (1.0457)\n",
            "Epoch: [19] [180/289]  eta: 0:00:08  time: 0.0818  loss: 1.0522 (1.1442)  bbox_regression: 0.0773 (0.0824)  classification: 0.9749 (1.0618)\n",
            "Epoch: [19] [190/289]  eta: 0:00:08  time: 0.0817  loss: 1.0549 (1.0975)  bbox_regression: 0.0772 (0.0771)  classification: 0.9777 (1.0205)\n",
            "Epoch: [19] [200/289]  eta: 0:00:07  time: 0.0820  loss: 1.0562 (1.0929)  bbox_regression: 0.0785 (0.0897)  classification: 0.9777 (1.0032)\n",
            "Epoch: [19] [210/289]  eta: 0:00:06  time: 0.0822  loss: 1.0512 (1.0154)  bbox_regression: 0.0779 (0.0845)  classification: 0.9733 (0.9309)\n",
            "Epoch: [19] [220/289]  eta: 0:00:05  time: 0.0822  loss: 1.0438 (0.9187)  bbox_regression: 0.0767 (0.0580)  classification: 0.9671 (0.8608)\n",
            "Epoch: [19] [230/289]  eta: 0:00:04  time: 0.0821  loss: 1.0423 (0.9484)  bbox_regression: 0.0746 (0.0404)  classification: 0.9676 (0.9080)\n",
            "Epoch: [19] [240/289]  eta: 0:00:04  time: 0.0821  loss: 1.0362 (0.9526)  bbox_regression: 0.0744 (0.0488)  classification: 0.9618 (0.9038)\n",
            "Epoch: [19] [250/289]  eta: 0:00:03  time: 0.0820  loss: 1.0448 (1.0742)  bbox_regression: 0.0756 (0.0864)  classification: 0.9693 (0.9878)\n",
            "Epoch: [19] [260/289]  eta: 0:00:02  time: 0.0819  loss: 1.0481 (1.1912)  bbox_regression: 0.0775 (0.1157)  classification: 0.9706 (1.0755)\n",
            "Epoch: [19] [270/289]  eta: 0:00:01  time: 0.0818  loss: 1.0551 (1.1844)  bbox_regression: 0.0782 (0.1110)  classification: 0.9769 (1.0734)\n",
            "Epoch: [19] [280/289]  eta: 0:00:00  time: 0.0818  loss: 1.0545 (1.1388)  bbox_regression: 0.0781 (0.0852)  classification: 0.9765 (1.0536)\n",
            "Epoch: [19] [288/289]  eta: 0:00:00  time: 0.0815  loss: 1.0534 (1.0563)  bbox_regression: 0.0771 (0.0760)  classification: 0.9763 (0.9802)\n",
            "Epoch: [19] Time: 0:00:23 (0.0816 s / it)\n",
            "Validation: [19]\n",
            "Validation: [19] [ 0/62]  eta: 0:00:04  time: 0.0693  \n",
            "Validation: [19] [10/62]  eta: 0:00:03  time: 0.0690  \n",
            "Validation: [19] [20/62]  eta: 0:00:02  time: 0.0678  \n",
            "Validation: [19] [30/62]  eta: 0:00:02  time: 0.0685  \n",
            "Validation: [19] [40/62]  eta: 0:00:01  time: 0.0688  \n",
            "Validation: [19] [50/62]  eta: 0:00:00  time: 0.0693  \n",
            "Validation: [19] [60/62]  eta: 0:00:00  time: 0.0697  \n",
            "Validation: [19] [61/62]  eta: 0:00:00  time: 0.0693  \n",
            "Validation: [19] Time: 0:00:04 (0.0694 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_20/mAP_vs_threshold_epoch_19.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_20/pr_curves_epoch_19.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_20/per_class_ap_epoch_19.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_20/confusion_matrix_epoch_19.png\n",
            "Epoch 19: mAP@0.5 = 0.3493\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6766\n",
            "  Bacterial-Black-spot: 0.1828\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.2299\n",
            "  Mechanical-damage: 0.5000\n",
            "  Others: 0.5066\n",
            "Saved best model with mAP: 0.3493\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied per_class_mAP_epoch_19.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/per_class_mAP_epoch_19.csv\n",
            "Copied per_class_ap_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/per_class_ap_epoch_19.png\n",
            "Copied mAP_vs_threshold_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/mAP_vs_threshold_epoch_19.png\n",
            "Copied mAP_vs_threshold_epoch_19.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/mAP_vs_threshold_epoch_19.csv\n",
            "Copied confusion_matrix_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/confusion_matrix_epoch_19.png\n",
            "Copied pr_curves_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/pr_curves_epoch_19.png\n",
            "Saved checkpoint at epoch 20\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [20]\n",
            "Epoch: [20] [  0/289]  eta: 0:00:24  time: 0.0837  loss: 0.8331 (0.8331)  bbox_regression: 0.0210 (0.0210)  classification: 0.8121 (0.8121)\n",
            "Epoch: [20] [ 10/289]  eta: 0:00:23  time: 0.0849  loss: 0.8611 (0.8611)  bbox_regression: 0.0421 (0.0421)  classification: 0.8190 (0.8190)\n",
            "Epoch: [20] [ 20/289]  eta: 0:00:22  time: 0.0826  loss: 0.9246 (0.9291)  bbox_regression: 0.0593 (0.0612)  classification: 0.8652 (0.8679)\n",
            "Epoch: [20] [ 30/289]  eta: 0:00:21  time: 0.0833  loss: 0.9871 (1.0564)  bbox_regression: 0.0714 (0.0875)  classification: 0.9157 (0.9689)\n",
            "Epoch: [20] [ 40/289]  eta: 0:00:20  time: 0.0827  loss: 0.9652 (1.0078)  bbox_regression: 0.0713 (0.0838)  classification: 0.8939 (0.9240)\n",
            "Epoch: [20] [ 50/289]  eta: 0:00:19  time: 0.0825  loss: 0.9783 (0.9647)  bbox_regression: 0.0706 (0.0693)  classification: 0.9078 (0.8954)\n",
            "Epoch: [20] [ 60/289]  eta: 0:00:18  time: 0.0820  loss: 1.0156 (1.1189)  bbox_regression: 0.0808 (0.1005)  classification: 0.9347 (1.0184)\n",
            "Epoch: [20] [ 70/289]  eta: 0:00:18  time: 0.0823  loss: 1.0039 (1.0693)  bbox_regression: 0.0773 (0.0945)  classification: 0.9266 (0.9747)\n",
            "Epoch: [20] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 1.0228 (1.0449)  bbox_regression: 0.0791 (0.0739)  classification: 0.9437 (0.9710)\n",
            "Epoch: [20] [ 90/289]  eta: 0:00:16  time: 0.0822  loss: 1.0262 (1.1053)  bbox_regression: 0.0777 (0.0789)  classification: 0.9486 (1.0264)\n",
            "Epoch: [20] [100/289]  eta: 0:00:15  time: 0.0818  loss: 1.0133 (0.9747)  bbox_regression: 0.0753 (0.0600)  classification: 0.9379 (0.9147)\n",
            "Epoch: [20] [110/289]  eta: 0:00:14  time: 0.0828  loss: 1.0104 (0.9383)  bbox_regression: 0.0731 (0.0524)  classification: 0.9373 (0.8858)\n",
            "Epoch: [20] [120/289]  eta: 0:00:14  time: 0.0835  loss: 1.0101 (0.9943)  bbox_regression: 0.0756 (0.0771)  classification: 0.9345 (0.9172)\n",
            "Epoch: [20] [130/289]  eta: 0:00:13  time: 0.0834  loss: 1.0076 (0.9921)  bbox_regression: 0.0742 (0.0803)  classification: 0.9334 (0.9118)\n",
            "Epoch: [20] [140/289]  eta: 0:00:12  time: 0.0834  loss: 1.0089 (1.0014)  bbox_regression: 0.0768 (0.0839)  classification: 0.9321 (0.9175)\n",
            "Epoch: [20] [150/289]  eta: 0:00:11  time: 0.0831  loss: 1.0043 (0.9825)  bbox_regression: 0.0749 (0.0794)  classification: 0.9294 (0.9031)\n",
            "Epoch: [20] [160/289]  eta: 0:00:10  time: 0.0832  loss: 1.0061 (0.9864)  bbox_regression: 0.0747 (0.0598)  classification: 0.9314 (0.9267)\n",
            "Epoch: [20] [170/289]  eta: 0:00:09  time: 0.0830  loss: 1.0014 (0.9799)  bbox_regression: 0.0730 (0.0584)  classification: 0.9284 (0.9215)\n",
            "Epoch: [20] [180/289]  eta: 0:00:09  time: 0.0830  loss: 0.9929 (0.8862)  bbox_regression: 0.0704 (0.0355)  classification: 0.9225 (0.8508)\n",
            "Epoch: [20] [190/289]  eta: 0:00:08  time: 0.0830  loss: 0.9887 (0.8803)  bbox_regression: 0.0699 (0.0436)  classification: 0.9188 (0.8367)\n",
            "Epoch: [20] [200/289]  eta: 0:00:07  time: 0.0830  loss: 0.9941 (1.0054)  bbox_regression: 0.0704 (0.0712)  classification: 0.9237 (0.9342)\n",
            "Epoch: [20] [210/289]  eta: 0:00:06  time: 0.0827  loss: 0.9911 (1.0142)  bbox_regression: 0.0704 (0.0751)  classification: 0.9208 (0.9391)\n",
            "Epoch: [20] [220/289]  eta: 0:00:05  time: 0.0826  loss: 1.0000 (1.0593)  bbox_regression: 0.0709 (0.0755)  classification: 0.9291 (0.9838)\n",
            "Epoch: [20] [230/289]  eta: 0:00:04  time: 0.0826  loss: 0.9965 (1.0532)  bbox_regression: 0.0703 (0.0690)  classification: 0.9262 (0.9841)\n",
            "Epoch: [20] [240/289]  eta: 0:00:04  time: 0.0826  loss: 1.0014 (1.0169)  bbox_regression: 0.0747 (0.1169)  classification: 0.9267 (0.9000)\n",
            "Epoch: [20] [250/289]  eta: 0:00:03  time: 0.0826  loss: 1.0036 (1.0849)  bbox_regression: 0.0732 (0.1071)  classification: 0.9304 (0.9778)\n",
            "Epoch: [20] [260/289]  eta: 0:00:02  time: 0.0825  loss: 1.0039 (1.0334)  bbox_regression: 0.0725 (0.0463)  classification: 0.9313 (0.9871)\n",
            "Epoch: [20] [270/289]  eta: 0:00:01  time: 0.0824  loss: 1.0120 (1.1184)  bbox_regression: 0.0739 (0.0828)  classification: 0.9381 (1.0356)\n",
            "Epoch: [20] [280/289]  eta: 0:00:00  time: 0.0823  loss: 1.0106 (1.0979)  bbox_regression: 0.0738 (0.0899)  classification: 0.9368 (1.0080)\n",
            "Epoch: [20] [288/289]  eta: 0:00:00  time: 0.0820  loss: 1.0094 (0.9545)  bbox_regression: 0.0740 (0.0704)  classification: 0.9355 (0.8840)\n",
            "Epoch: [20] Time: 0:00:23 (0.0820 s / it)\n",
            "Epoch: [21]\n",
            "Epoch: [21] [  0/289]  eta: 0:00:24  time: 0.0850  loss: 1.0522 (1.0522)  bbox_regression: 0.0905 (0.0905)  classification: 0.9617 (0.9617)\n",
            "Epoch: [21] [ 10/289]  eta: 0:00:23  time: 0.0833  loss: 1.0964 (1.0964)  bbox_regression: 0.0911 (0.0911)  classification: 1.0053 (1.0053)\n",
            "Epoch: [21] [ 20/289]  eta: 0:00:21  time: 0.0808  loss: 0.9221 (0.9156)  bbox_regression: 0.0644 (0.0631)  classification: 0.8577 (0.8525)\n",
            "Epoch: [21] [ 30/289]  eta: 0:00:20  time: 0.0802  loss: 0.9512 (0.8713)  bbox_regression: 0.0622 (0.0462)  classification: 0.8890 (0.8250)\n",
            "Epoch: [21] [ 40/289]  eta: 0:00:20  time: 0.0807  loss: 0.9838 (1.0485)  bbox_regression: 0.0772 (0.0906)  classification: 0.9066 (0.9579)\n",
            "Epoch: [21] [ 50/289]  eta: 0:00:19  time: 0.0813  loss: 0.9795 (1.0235)  bbox_regression: 0.0729 (0.0894)  classification: 0.9066 (0.9340)\n",
            "Epoch: [21] [ 60/289]  eta: 0:00:18  time: 0.0813  loss: 0.9641 (0.9237)  bbox_regression: 0.0675 (0.0477)  classification: 0.8965 (0.8760)\n",
            "Epoch: [21] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 0.9682 (0.9394)  bbox_regression: 0.0655 (0.0468)  classification: 0.9027 (0.8926)\n",
            "Epoch: [21] [ 80/289]  eta: 0:00:17  time: 0.0821  loss: 0.9638 (0.9628)  bbox_regression: 0.0623 (0.0464)  classification: 0.9014 (0.9163)\n",
            "Epoch: [21] [ 90/289]  eta: 0:00:16  time: 0.0822  loss: 0.9560 (0.9124)  bbox_regression: 0.0621 (0.0501)  classification: 0.8938 (0.8623)\n",
            "Epoch: [21] [100/289]  eta: 0:00:15  time: 0.0829  loss: 0.9558 (0.9234)  bbox_regression: 0.0652 (0.0769)  classification: 0.8906 (0.8465)\n",
            "Epoch: [21] [110/289]  eta: 0:00:14  time: 0.0827  loss: 0.9780 (1.0782)  bbox_regression: 0.0736 (0.1259)  classification: 0.9043 (0.9523)\n",
            "Epoch: [21] [120/289]  eta: 0:00:13  time: 0.0826  loss: 0.9657 (1.0161)  bbox_regression: 0.0712 (0.1015)  classification: 0.8945 (0.9146)\n",
            "Epoch: [21] [130/289]  eta: 0:00:13  time: 0.0822  loss: 0.9553 (0.8294)  bbox_regression: 0.0695 (0.0464)  classification: 0.8858 (0.7830)\n",
            "Epoch: [21] [140/289]  eta: 0:00:12  time: 0.0820  loss: 0.9489 (0.8473)  bbox_regression: 0.0684 (0.0517)  classification: 0.8805 (0.7956)\n",
            "Epoch: [21] [150/289]  eta: 0:00:11  time: 0.0819  loss: 0.9470 (0.8929)  bbox_regression: 0.0670 (0.0505)  classification: 0.8801 (0.8423)\n",
            "Epoch: [21] [160/289]  eta: 0:00:10  time: 0.0819  loss: 0.9606 (1.0427)  bbox_regression: 0.0700 (0.0814)  classification: 0.8905 (0.9614)\n",
            "Epoch: [21] [170/289]  eta: 0:00:09  time: 0.0818  loss: 0.9641 (1.0931)  bbox_regression: 0.0696 (0.0897)  classification: 0.8945 (1.0034)\n",
            "Epoch: [21] [180/289]  eta: 0:00:08  time: 0.0819  loss: 0.9717 (1.0615)  bbox_regression: 0.0686 (0.0565)  classification: 0.9032 (1.0050)\n",
            "Epoch: [21] [190/289]  eta: 0:00:08  time: 0.0819  loss: 0.9739 (1.0576)  bbox_regression: 0.0683 (0.0565)  classification: 0.9056 (1.0011)\n",
            "Epoch: [21] [200/289]  eta: 0:00:07  time: 0.0819  loss: 0.9830 (1.0847)  bbox_regression: 0.0718 (0.1007)  classification: 0.9112 (0.9840)\n",
            "Epoch: [21] [210/289]  eta: 0:00:06  time: 0.0819  loss: 0.9763 (0.9993)  bbox_regression: 0.0711 (0.0986)  classification: 0.9052 (0.9008)\n",
            "Epoch: [21] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.9767 (0.9133)  bbox_regression: 0.0720 (0.0743)  classification: 0.9047 (0.8390)\n",
            "Epoch: [21] [230/289]  eta: 0:00:04  time: 0.0819  loss: 0.9874 (1.1038)  bbox_regression: 0.0716 (0.0766)  classification: 0.9157 (1.0272)\n",
            "Epoch: [21] [240/289]  eta: 0:00:04  time: 0.0818  loss: 0.9878 (1.1108)  bbox_regression: 0.0712 (0.0626)  classification: 0.9166 (1.0482)\n",
            "Epoch: [21] [250/289]  eta: 0:00:03  time: 0.0818  loss: 0.9839 (0.9435)  bbox_regression: 0.0710 (0.0644)  classification: 0.9128 (0.8792)\n",
            "Epoch: [21] [260/289]  eta: 0:00:02  time: 0.0818  loss: 0.9786 (0.8680)  bbox_regression: 0.0706 (0.0629)  classification: 0.9081 (0.8052)\n",
            "Epoch: [21] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.9760 (0.8767)  bbox_regression: 0.0703 (0.0616)  classification: 0.9056 (0.8151)\n",
            "Epoch: [21] [280/289]  eta: 0:00:00  time: 0.0818  loss: 0.9716 (0.8802)  bbox_regression: 0.0707 (0.0728)  classification: 0.9009 (0.8074)\n",
            "Epoch: [21] [288/289]  eta: 0:00:00  time: 0.0816  loss: 0.9731 (0.9409)  bbox_regression: 0.0700 (0.0658)  classification: 0.9031 (0.8751)\n",
            "Epoch: [21] Time: 0:00:23 (0.0817 s / it)\n",
            "Epoch: [22]\n",
            "Epoch: [22] [  0/289]  eta: 0:00:22  time: 0.0794  loss: 0.7581 (0.7581)  bbox_regression: 0.0149 (0.0149)  classification: 0.7432 (0.7432)\n",
            "Epoch: [22] [ 10/289]  eta: 0:00:21  time: 0.0775  loss: 0.9324 (0.9324)  bbox_regression: 0.0472 (0.0472)  classification: 0.8853 (0.8853)\n",
            "Epoch: [22] [ 20/289]  eta: 0:00:21  time: 0.0787  loss: 0.9071 (0.9145)  bbox_regression: 0.0418 (0.0431)  classification: 0.8653 (0.8714)\n",
            "Epoch: [22] [ 30/289]  eta: 0:00:20  time: 0.0790  loss: 0.9257 (0.9220)  bbox_regression: 0.0530 (0.0562)  classification: 0.8727 (0.8658)\n",
            "Epoch: [22] [ 40/289]  eta: 0:00:20  time: 0.0805  loss: 0.9299 (0.9538)  bbox_regression: 0.0594 (0.0779)  classification: 0.8705 (0.8760)\n",
            "Epoch: [22] [ 50/289]  eta: 0:00:19  time: 0.0804  loss: 0.9133 (0.8942)  bbox_regression: 0.0603 (0.0716)  classification: 0.8530 (0.8226)\n",
            "Epoch: [22] [ 60/289]  eta: 0:00:18  time: 0.0807  loss: 0.8995 (0.8372)  bbox_regression: 0.0578 (0.0544)  classification: 0.8418 (0.7828)\n",
            "Epoch: [22] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 0.8887 (0.8260)  bbox_regression: 0.0604 (0.0605)  classification: 0.8284 (0.7655)\n",
            "Epoch: [22] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 0.9058 (0.9248)  bbox_regression: 0.0679 (0.0989)  classification: 0.8378 (0.8259)\n",
            "Epoch: [22] [ 90/289]  eta: 0:00:16  time: 0.0812  loss: 0.8945 (0.9148)  bbox_regression: 0.0653 (0.0829)  classification: 0.8292 (0.8319)\n",
            "Epoch: [22] [100/289]  eta: 0:00:15  time: 0.0812  loss: 0.8871 (0.8114)  bbox_regression: 0.0643 (0.0499)  classification: 0.8227 (0.7615)\n",
            "Epoch: [22] [110/289]  eta: 0:00:14  time: 0.0812  loss: 0.8856 (0.8452)  bbox_regression: 0.0661 (0.0696)  classification: 0.8195 (0.7756)\n",
            "Epoch: [22] [120/289]  eta: 0:00:13  time: 0.0811  loss: 0.8834 (0.8649)  bbox_regression: 0.0650 (0.0683)  classification: 0.8184 (0.7966)\n",
            "Epoch: [22] [130/289]  eta: 0:00:12  time: 0.0814  loss: 0.8850 (0.8819)  bbox_regression: 0.0715 (0.1014)  classification: 0.8135 (0.7805)\n",
            "Epoch: [22] [140/289]  eta: 0:00:12  time: 0.0812  loss: 0.8825 (0.8770)  bbox_regression: 0.0702 (0.1019)  classification: 0.8123 (0.7751)\n",
            "Epoch: [22] [150/289]  eta: 0:00:11  time: 0.0811  loss: 0.8833 (0.8717)  bbox_regression: 0.0695 (0.0562)  classification: 0.8138 (0.8155)\n",
            "Epoch: [22] [160/289]  eta: 0:00:10  time: 0.0811  loss: 0.8837 (0.8925)  bbox_regression: 0.0677 (0.0497)  classification: 0.8161 (0.8428)\n",
            "Epoch: [22] [170/289]  eta: 0:00:09  time: 0.0810  loss: 0.8811 (0.8647)  bbox_regression: 0.0678 (0.0549)  classification: 0.8133 (0.8098)\n",
            "Epoch: [22] [180/289]  eta: 0:00:08  time: 0.0812  loss: 0.8929 (0.9664)  bbox_regression: 0.0686 (0.0762)  classification: 0.8243 (0.8902)\n",
            "Epoch: [22] [190/289]  eta: 0:00:08  time: 0.0812  loss: 0.8956 (1.0193)  bbox_regression: 0.0697 (0.0862)  classification: 0.8259 (0.9332)\n",
            "Epoch: [22] [200/289]  eta: 0:00:07  time: 0.0812  loss: 0.8962 (0.9261)  bbox_regression: 0.0691 (0.0734)  classification: 0.8271 (0.8527)\n",
            "Epoch: [22] [210/289]  eta: 0:00:06  time: 0.0813  loss: 0.8956 (0.8957)  bbox_regression: 0.0680 (0.0515)  classification: 0.8276 (0.8442)\n",
            "Epoch: [22] [220/289]  eta: 0:00:05  time: 0.0814  loss: 0.8982 (0.9184)  bbox_regression: 0.0684 (0.0619)  classification: 0.8298 (0.8565)\n",
            "Epoch: [22] [230/289]  eta: 0:00:04  time: 0.0813  loss: 0.8992 (0.9371)  bbox_regression: 0.0674 (0.0618)  classification: 0.8317 (0.8753)\n",
            "Epoch: [22] [240/289]  eta: 0:00:03  time: 0.0814  loss: 0.9073 (1.0083)  bbox_regression: 0.0709 (0.0986)  classification: 0.8364 (0.9097)\n",
            "Epoch: [22] [250/289]  eta: 0:00:03  time: 0.0813  loss: 0.9090 (1.0226)  bbox_regression: 0.0694 (0.0919)  classification: 0.8396 (0.9307)\n",
            "Epoch: [22] [260/289]  eta: 0:00:02  time: 0.0811  loss: 0.9126 (0.9765)  bbox_regression: 0.0691 (0.0466)  classification: 0.8436 (0.9299)\n",
            "Epoch: [22] [270/289]  eta: 0:00:01  time: 0.0811  loss: 0.9178 (1.0277)  bbox_regression: 0.0690 (0.0643)  classification: 0.8488 (0.9634)\n",
            "Epoch: [22] [280/289]  eta: 0:00:00  time: 0.0810  loss: 0.9220 (1.0450)  bbox_regression: 0.0689 (0.0674)  classification: 0.8531 (0.9776)\n",
            "Epoch: [22] [288/289]  eta: 0:00:00  time: 0.0809  loss: 0.9253 (1.0540)  bbox_regression: 0.0689 (0.0630)  classification: 0.8564 (0.9910)\n",
            "Epoch: [22] Time: 0:00:23 (0.0809 s / it)\n",
            "Epoch: [23]\n",
            "Epoch: [23] [  0/289]  eta: 0:00:27  time: 0.0946  loss: 1.4148 (1.4148)  bbox_regression: 0.0704 (0.0704)  classification: 1.3444 (1.3444)\n",
            "Epoch: [23] [ 10/289]  eta: 0:00:23  time: 0.0835  loss: 1.0432 (1.0432)  bbox_regression: 0.1353 (0.1353)  classification: 0.9079 (0.9079)\n",
            "Epoch: [23] [ 20/289]  eta: 0:00:22  time: 0.0828  loss: 0.9343 (0.9103)  bbox_regression: 0.0933 (0.0945)  classification: 0.8410 (0.8158)\n",
            "Epoch: [23] [ 30/289]  eta: 0:00:21  time: 0.0818  loss: 0.9254 (0.8606)  bbox_regression: 0.0884 (0.0626)  classification: 0.8370 (0.7980)\n",
            "Epoch: [23] [ 40/289]  eta: 0:00:20  time: 0.0833  loss: 0.9020 (0.8681)  bbox_regression: 0.0785 (0.0630)  classification: 0.8235 (0.8051)\n",
            "Epoch: [23] [ 50/289]  eta: 0:00:20  time: 0.0842  loss: 0.8844 (0.8207)  bbox_regression: 0.0714 (0.0452)  classification: 0.8129 (0.7756)\n",
            "Epoch: [23] [ 60/289]  eta: 0:00:19  time: 0.0844  loss: 0.8729 (0.8131)  bbox_regression: 0.0694 (0.0508)  classification: 0.8034 (0.7623)\n",
            "Epoch: [23] [ 70/289]  eta: 0:00:18  time: 0.0849  loss: 0.8787 (0.8644)  bbox_regression: 0.0683 (0.0603)  classification: 0.8104 (0.8041)\n",
            "Epoch: [23] [ 80/289]  eta: 0:00:17  time: 0.0842  loss: 0.8666 (0.8474)  bbox_regression: 0.0638 (0.0467)  classification: 0.8027 (0.8007)\n",
            "Epoch: [23] [ 90/289]  eta: 0:00:16  time: 0.0837  loss: 0.8554 (0.7726)  bbox_regression: 0.0640 (0.0485)  classification: 0.7915 (0.7241)\n",
            "Epoch: [23] [100/289]  eta: 0:00:15  time: 0.0834  loss: 0.8840 (0.9544)  bbox_regression: 0.0663 (0.0764)  classification: 0.8177 (0.8781)\n",
            "Epoch: [23] [110/289]  eta: 0:00:14  time: 0.0831  loss: 0.8791 (0.9871)  bbox_regression: 0.0641 (0.0647)  classification: 0.8150 (0.9224)\n",
            "Epoch: [23] [120/289]  eta: 0:00:13  time: 0.0827  loss: 0.8778 (0.8469)  bbox_regression: 0.0637 (0.0503)  classification: 0.8142 (0.7966)\n",
            "Epoch: [23] [130/289]  eta: 0:00:13  time: 0.0826  loss: 0.8762 (0.8598)  bbox_regression: 0.0646 (0.0674)  classification: 0.8116 (0.7925)\n",
            "Epoch: [23] [140/289]  eta: 0:00:12  time: 0.0826  loss: 0.8765 (0.8686)  bbox_regression: 0.0657 (0.0779)  classification: 0.8108 (0.7907)\n",
            "Epoch: [23] [150/289]  eta: 0:00:11  time: 0.0824  loss: 0.8803 (0.9070)  bbox_regression: 0.0660 (0.0755)  classification: 0.8142 (0.8315)\n",
            "Epoch: [23] [160/289]  eta: 0:00:10  time: 0.0823  loss: 0.8844 (0.9397)  bbox_regression: 0.0659 (0.0677)  classification: 0.8184 (0.8720)\n",
            "Epoch: [23] [170/289]  eta: 0:00:09  time: 0.0822  loss: 0.8887 (0.9521)  bbox_regression: 0.0665 (0.0704)  classification: 0.8221 (0.8817)\n",
            "Epoch: [23] [180/289]  eta: 0:00:08  time: 0.0823  loss: 0.8974 (1.0022)  bbox_regression: 0.0657 (0.0637)  classification: 0.8317 (0.9386)\n",
            "Epoch: [23] [190/289]  eta: 0:00:08  time: 0.0822  loss: 0.8885 (0.8867)  bbox_regression: 0.0649 (0.0506)  classification: 0.8236 (0.8361)\n",
            "Epoch: [23] [200/289]  eta: 0:00:07  time: 0.0822  loss: 0.8769 (0.6917)  bbox_regression: 0.0635 (0.0434)  classification: 0.8135 (0.6483)\n",
            "Epoch: [23] [210/289]  eta: 0:00:06  time: 0.0822  loss: 0.8756 (0.7526)  bbox_regression: 0.0628 (0.0429)  classification: 0.8128 (0.7097)\n",
            "Epoch: [23] [220/289]  eta: 0:00:05  time: 0.0821  loss: 0.8773 (0.8810)  bbox_regression: 0.0621 (0.0483)  classification: 0.8152 (0.8327)\n",
            "Epoch: [23] [230/289]  eta: 0:00:04  time: 0.0820  loss: 0.8775 (0.8971)  bbox_regression: 0.0621 (0.0554)  classification: 0.8153 (0.8417)\n",
            "Epoch: [23] [240/289]  eta: 0:00:04  time: 0.0819  loss: 0.8750 (0.8500)  bbox_regression: 0.0622 (0.0639)  classification: 0.8128 (0.7860)\n",
            "Epoch: [23] [250/289]  eta: 0:00:03  time: 0.0818  loss: 0.8790 (0.8973)  bbox_regression: 0.0610 (0.0483)  classification: 0.8180 (0.8490)\n",
            "Epoch: [23] [260/289]  eta: 0:00:02  time: 0.0817  loss: 0.8769 (0.8998)  bbox_regression: 0.0608 (0.0440)  classification: 0.8161 (0.8558)\n",
            "Epoch: [23] [270/289]  eta: 0:00:01  time: 0.0817  loss: 0.8798 (0.8897)  bbox_regression: 0.0613 (0.0650)  classification: 0.8185 (0.8247)\n",
            "Epoch: [23] [280/289]  eta: 0:00:00  time: 0.0817  loss: 0.8812 (0.9373)  bbox_regression: 0.0645 (0.1119)  classification: 0.8167 (0.8254)\n",
            "Epoch: [23] [288/289]  eta: 0:00:00  time: 0.0816  loss: 0.8777 (0.8507)  bbox_regression: 0.0663 (0.1330)  classification: 0.8114 (0.7177)\n",
            "Epoch: [23] Time: 0:00:23 (0.0816 s / it)\n",
            "Epoch: [24]\n",
            "Epoch: [24] [  0/289]  eta: 0:00:21  time: 0.0757  loss: 1.1441 (1.1441)  bbox_regression: 0.0301 (0.0301)  classification: 1.1140 (1.1140)\n",
            "Epoch: [24] [ 10/289]  eta: 0:00:22  time: 0.0817  loss: 0.7639 (0.7639)  bbox_regression: 0.0431 (0.0431)  classification: 0.7208 (0.7208)\n",
            "Epoch: [24] [ 20/289]  eta: 0:00:21  time: 0.0815  loss: 0.6953 (0.6728)  bbox_regression: 0.0432 (0.0439)  classification: 0.6521 (0.6290)\n",
            "Epoch: [24] [ 30/289]  eta: 0:00:21  time: 0.0812  loss: 0.7043 (0.6715)  bbox_regression: 0.0410 (0.0398)  classification: 0.6634 (0.6318)\n",
            "Epoch: [24] [ 40/289]  eta: 0:00:20  time: 0.0810  loss: 0.7189 (0.7437)  bbox_regression: 0.0446 (0.0460)  classification: 0.6743 (0.6977)\n",
            "Epoch: [24] [ 50/289]  eta: 0:00:19  time: 0.0806  loss: 0.7321 (0.7752)  bbox_regression: 0.0433 (0.0471)  classification: 0.6888 (0.7282)\n",
            "Epoch: [24] [ 60/289]  eta: 0:00:18  time: 0.0814  loss: 0.7559 (0.8317)  bbox_regression: 0.0414 (0.0349)  classification: 0.7145 (0.7968)\n",
            "Epoch: [24] [ 70/289]  eta: 0:00:17  time: 0.0816  loss: 0.7716 (0.8721)  bbox_regression: 0.0450 (0.0491)  classification: 0.7266 (0.8230)\n",
            "Epoch: [24] [ 80/289]  eta: 0:00:17  time: 0.0824  loss: 0.7698 (0.8124)  bbox_regression: 0.0447 (0.0549)  classification: 0.7251 (0.7574)\n",
            "Epoch: [24] [ 90/289]  eta: 0:00:16  time: 0.0825  loss: 0.7695 (0.7623)  bbox_regression: 0.0470 (0.0541)  classification: 0.7225 (0.7082)\n",
            "Epoch: [24] [100/289]  eta: 0:00:15  time: 0.0822  loss: 0.7647 (0.7438)  bbox_regression: 0.0470 (0.0562)  classification: 0.7177 (0.6876)\n",
            "Epoch: [24] [110/289]  eta: 0:00:14  time: 0.0821  loss: 0.7650 (0.7445)  bbox_regression: 0.0504 (0.0661)  classification: 0.7146 (0.6784)\n",
            "Epoch: [24] [120/289]  eta: 0:00:13  time: 0.0821  loss: 0.7695 (0.7939)  bbox_regression: 0.0541 (0.0897)  classification: 0.7154 (0.7042)\n",
            "Epoch: [24] [130/289]  eta: 0:00:13  time: 0.0818  loss: 0.7813 (0.8718)  bbox_regression: 0.0567 (0.0916)  classification: 0.7246 (0.7803)\n",
            "Epoch: [24] [140/289]  eta: 0:00:12  time: 0.0816  loss: 0.7809 (0.8500)  bbox_regression: 0.0585 (0.0854)  classification: 0.7224 (0.7646)\n",
            "Epoch: [24] [150/289]  eta: 0:00:11  time: 0.0816  loss: 0.7787 (0.7616)  bbox_regression: 0.0571 (0.0599)  classification: 0.7216 (0.7017)\n",
            "Epoch: [24] [160/289]  eta: 0:00:10  time: 0.0819  loss: 0.7785 (0.7611)  bbox_regression: 0.0562 (0.0399)  classification: 0.7223 (0.7212)\n",
            "Epoch: [24] [170/289]  eta: 0:00:09  time: 0.0818  loss: 0.7879 (0.8575)  bbox_regression: 0.0596 (0.0778)  classification: 0.7284 (0.7796)\n",
            "Epoch: [24] [180/289]  eta: 0:00:08  time: 0.0816  loss: 0.7987 (0.9615)  bbox_regression: 0.0649 (0.1350)  classification: 0.7338 (0.8265)\n",
            "Epoch: [24] [190/289]  eta: 0:00:08  time: 0.0817  loss: 0.8008 (0.9109)  bbox_regression: 0.0652 (0.1137)  classification: 0.7356 (0.7972)\n",
            "Epoch: [24] [200/289]  eta: 0:00:07  time: 0.0817  loss: 0.8028 (0.8397)  bbox_regression: 0.0647 (0.0632)  classification: 0.7380 (0.7764)\n",
            "Epoch: [24] [210/289]  eta: 0:00:06  time: 0.0819  loss: 0.8079 (0.8761)  bbox_regression: 0.0655 (0.0680)  classification: 0.7425 (0.8081)\n",
            "Epoch: [24] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.8103 (0.8860)  bbox_regression: 0.0667 (0.0868)  classification: 0.7436 (0.7992)\n",
            "Epoch: [24] [230/289]  eta: 0:00:04  time: 0.0819  loss: 0.8090 (0.8199)  bbox_regression: 0.0673 (0.0866)  classification: 0.7417 (0.7333)\n",
            "Epoch: [24] [240/289]  eta: 0:00:04  time: 0.0818  loss: 0.8125 (0.8365)  bbox_regression: 0.0684 (0.0865)  classification: 0.7441 (0.7500)\n",
            "Epoch: [24] [250/289]  eta: 0:00:03  time: 0.0819  loss: 0.8122 (0.8491)  bbox_regression: 0.0678 (0.0728)  classification: 0.7444 (0.7764)\n",
            "Epoch: [24] [260/289]  eta: 0:00:02  time: 0.0819  loss: 0.8152 (0.8484)  bbox_regression: 0.0671 (0.0519)  classification: 0.7481 (0.7965)\n",
            "Epoch: [24] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.8165 (0.8711)  bbox_regression: 0.0672 (0.0600)  classification: 0.7493 (0.8111)\n",
            "Epoch: [24] [280/289]  eta: 0:00:00  time: 0.0818  loss: 0.8205 (0.8895)  bbox_regression: 0.0668 (0.0632)  classification: 0.7537 (0.8263)\n",
            "Epoch: [24] [288/289]  eta: 0:00:00  time: 0.0817  loss: 0.8150 (0.7788)  bbox_regression: 0.0659 (0.0489)  classification: 0.7491 (0.7299)\n",
            "Epoch: [24] Time: 0:00:23 (0.0817 s / it)\n",
            "Validation: [24]\n",
            "Validation: [24] [ 0/62]  eta: 0:00:04  time: 0.0681  \n",
            "Validation: [24] [10/62]  eta: 0:00:03  time: 0.0683  \n",
            "Validation: [24] [20/62]  eta: 0:00:02  time: 0.0680  \n",
            "Validation: [24] [30/62]  eta: 0:00:02  time: 0.0685  \n",
            "Validation: [24] [40/62]  eta: 0:00:01  time: 0.0693  \n",
            "Validation: [24] [50/62]  eta: 0:00:00  time: 0.0695  \n",
            "Validation: [24] [60/62]  eta: 0:00:00  time: 0.0696  \n",
            "Validation: [24] [61/62]  eta: 0:00:00  time: 0.0691  \n",
            "Validation: [24] Time: 0:00:04 (0.0692 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_25/mAP_vs_threshold_epoch_24.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_25/pr_curves_epoch_24.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_25/per_class_ap_epoch_24.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_25/confusion_matrix_epoch_24.png\n",
            "Epoch 24: mAP@0.5 = 0.4310\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.5328\n",
            "  Bacterial-Black-spot: 0.5112\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.2543\n",
            "  Mechanical-damage: 0.6429\n",
            "  Others: 0.6447\n",
            "Saved best model with mAP: 0.4310\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied per_class_ap_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/per_class_ap_epoch_24.png\n",
            "Copied mAP_vs_threshold_epoch_24.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/mAP_vs_threshold_epoch_24.csv\n",
            "Copied pr_curves_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/pr_curves_epoch_24.png\n",
            "Copied mAP_vs_threshold_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/mAP_vs_threshold_epoch_24.png\n",
            "Copied per_class_mAP_epoch_24.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/per_class_mAP_epoch_24.csv\n",
            "Copied confusion_matrix_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/confusion_matrix_epoch_24.png\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [25]\n",
            "Epoch: [25] [  0/289]  eta: 0:00:25  time: 0.0878  loss: 0.6726 (0.6726)  bbox_regression: 0.0072 (0.0072)  classification: 0.6655 (0.6655)\n",
            "Epoch: [25] [ 10/289]  eta: 0:00:23  time: 0.0837  loss: 0.7856 (0.7856)  bbox_regression: 0.0525 (0.0525)  classification: 0.7330 (0.7330)\n",
            "Epoch: [25] [ 20/289]  eta: 0:00:22  time: 0.0831  loss: 0.7302 (0.7330)  bbox_regression: 0.0559 (0.0583)  classification: 0.6743 (0.6747)\n",
            "Epoch: [25] [ 30/289]  eta: 0:00:21  time: 0.0831  loss: 0.7424 (0.7187)  bbox_regression: 0.0626 (0.0682)  classification: 0.6798 (0.6505)\n",
            "Epoch: [25] [ 40/289]  eta: 0:00:20  time: 0.0826  loss: 0.7911 (0.8551)  bbox_regression: 0.0825 (0.1104)  classification: 0.7086 (0.7447)\n",
            "Epoch: [25] [ 50/289]  eta: 0:00:20  time: 0.0837  loss: 0.7738 (0.8224)  bbox_regression: 0.0776 (0.1007)  classification: 0.6962 (0.7217)\n",
            "Epoch: [25] [ 60/289]  eta: 0:00:19  time: 0.0835  loss: 0.7960 (0.8060)  bbox_regression: 0.0821 (0.0813)  classification: 0.7139 (0.7247)\n",
            "Epoch: [25] [ 70/289]  eta: 0:00:18  time: 0.0833  loss: 0.7793 (0.7933)  bbox_regression: 0.0752 (0.0692)  classification: 0.7041 (0.7241)\n",
            "Epoch: [25] [ 80/289]  eta: 0:00:17  time: 0.0838  loss: 0.7655 (0.6726)  bbox_regression: 0.0717 (0.0399)  classification: 0.6938 (0.6327)\n",
            "Epoch: [25] [ 90/289]  eta: 0:00:16  time: 0.0844  loss: 0.7619 (0.7003)  bbox_regression: 0.0710 (0.0562)  classification: 0.6909 (0.6441)\n",
            "Epoch: [25] [100/289]  eta: 0:00:15  time: 0.0844  loss: 0.7724 (0.8002)  bbox_regression: 0.0689 (0.0578)  classification: 0.7035 (0.7424)\n",
            "Epoch: [25] [110/289]  eta: 0:00:15  time: 0.0845  loss: 0.7633 (0.7698)  bbox_regression: 0.0666 (0.0465)  classification: 0.6967 (0.7232)\n",
            "Epoch: [25] [120/289]  eta: 0:00:14  time: 0.0844  loss: 0.7746 (0.7858)  bbox_regression: 0.0664 (0.0538)  classification: 0.7082 (0.7320)\n",
            "Epoch: [25] [130/289]  eta: 0:00:13  time: 0.0844  loss: 0.7772 (0.8545)  bbox_regression: 0.0684 (0.0785)  classification: 0.7088 (0.7760)\n",
            "Epoch: [25] [140/289]  eta: 0:00:12  time: 0.0842  loss: 0.7765 (0.7879)  bbox_regression: 0.0673 (0.0729)  classification: 0.7092 (0.7150)\n",
            "Epoch: [25] [150/289]  eta: 0:00:11  time: 0.0840  loss: 0.7841 (0.8291)  bbox_regression: 0.0666 (0.0544)  classification: 0.7175 (0.7746)\n",
            "Epoch: [25] [160/289]  eta: 0:00:10  time: 0.0839  loss: 0.7840 (0.8365)  bbox_regression: 0.0669 (0.0638)  classification: 0.7171 (0.7727)\n",
            "Epoch: [25] [170/289]  eta: 0:00:09  time: 0.0838  loss: 0.7801 (0.7498)  bbox_regression: 0.0658 (0.0602)  classification: 0.7143 (0.6896)\n",
            "Epoch: [25] [180/289]  eta: 0:00:09  time: 0.0838  loss: 0.7876 (0.8168)  bbox_regression: 0.0678 (0.0752)  classification: 0.7198 (0.7416)\n",
            "Epoch: [25] [190/289]  eta: 0:00:08  time: 0.0836  loss: 0.7937 (0.9095)  bbox_regression: 0.0687 (0.0934)  classification: 0.7249 (0.8161)\n",
            "Epoch: [25] [200/289]  eta: 0:00:07  time: 0.0833  loss: 0.7896 (0.8076)  bbox_regression: 0.0683 (0.0731)  classification: 0.7212 (0.7345)\n",
            "Epoch: [25] [210/289]  eta: 0:00:06  time: 0.0832  loss: 0.7860 (0.7128)  bbox_regression: 0.0667 (0.0478)  classification: 0.7193 (0.6650)\n",
            "Epoch: [25] [220/289]  eta: 0:00:05  time: 0.0832  loss: 0.7918 (0.8144)  bbox_regression: 0.0673 (0.0573)  classification: 0.7245 (0.7571)\n",
            "Epoch: [25] [230/289]  eta: 0:00:04  time: 0.0832  loss: 0.7931 (0.8679)  bbox_regression: 0.0670 (0.0701)  classification: 0.7261 (0.7979)\n",
            "Epoch: [25] [240/289]  eta: 0:00:04  time: 0.0831  loss: 0.7976 (0.8615)  bbox_regression: 0.0680 (0.0756)  classification: 0.7296 (0.7859)\n",
            "Epoch: [25] [250/289]  eta: 0:00:03  time: 0.0832  loss: 0.7946 (0.8122)  bbox_regression: 0.0683 (0.0826)  classification: 0.7263 (0.7296)\n",
            "Epoch: [25] [260/289]  eta: 0:00:02  time: 0.0831  loss: 0.7920 (0.7246)  bbox_regression: 0.0671 (0.0559)  classification: 0.7249 (0.6687)\n",
            "Epoch: [25] [270/289]  eta: 0:00:01  time: 0.0830  loss: 0.7876 (0.6996)  bbox_regression: 0.0661 (0.0391)  classification: 0.7215 (0.6605)\n",
            "Epoch: [25] [280/289]  eta: 0:00:00  time: 0.0829  loss: 0.7873 (0.7254)  bbox_regression: 0.0661 (0.0526)  classification: 0.7212 (0.6728)\n",
            "Epoch: [25] [288/289]  eta: 0:00:00  time: 0.0826  loss: 0.7887 (0.7916)  bbox_regression: 0.0657 (0.0599)  classification: 0.7230 (0.7316)\n",
            "Epoch: [25] Time: 0:00:23 (0.0827 s / it)\n",
            "Epoch: [26]\n",
            "Epoch: [26] [  0/289]  eta: 0:00:24  time: 0.0835  loss: 0.2369 (0.2369)  bbox_regression: 0.0277 (0.0277)  classification: 0.2092 (0.2092)\n",
            "Epoch: [26] [ 10/289]  eta: 0:00:23  time: 0.0832  loss: 0.4957 (0.4957)  bbox_regression: 0.0419 (0.0419)  classification: 0.4538 (0.4538)\n",
            "Epoch: [26] [ 20/289]  eta: 0:00:22  time: 0.0821  loss: 0.6760 (0.6980)  bbox_regression: 0.0743 (0.0767)  classification: 0.6017 (0.6213)\n",
            "Epoch: [26] [ 30/289]  eta: 0:00:21  time: 0.0817  loss: 0.6360 (0.7133)  bbox_regression: 0.0664 (0.0798)  classification: 0.5697 (0.6334)\n",
            "Epoch: [26] [ 40/289]  eta: 0:00:20  time: 0.0811  loss: 0.6691 (0.6619)  bbox_regression: 0.0614 (0.0479)  classification: 0.6077 (0.6140)\n",
            "Epoch: [26] [ 50/289]  eta: 0:00:19  time: 0.0832  loss: 0.6438 (0.6557)  bbox_regression: 0.0620 (0.0552)  classification: 0.5818 (0.6005)\n",
            "Epoch: [26] [ 60/289]  eta: 0:00:19  time: 0.0832  loss: 0.6269 (0.5403)  bbox_regression: 0.0593 (0.0550)  classification: 0.5676 (0.4853)\n",
            "Epoch: [26] [ 70/289]  eta: 0:00:18  time: 0.0827  loss: 0.6689 (0.7329)  bbox_regression: 0.0740 (0.1046)  classification: 0.5949 (0.6283)\n",
            "Epoch: [26] [ 80/289]  eta: 0:00:17  time: 0.0824  loss: 0.6672 (0.7901)  bbox_regression: 0.0697 (0.1014)  classification: 0.5975 (0.6887)\n",
            "Epoch: [26] [ 90/289]  eta: 0:00:16  time: 0.0825  loss: 0.6742 (0.6930)  bbox_regression: 0.0682 (0.0476)  classification: 0.6060 (0.6454)\n",
            "Epoch: [26] [100/289]  eta: 0:00:15  time: 0.0826  loss: 0.6726 (0.6943)  bbox_regression: 0.0660 (0.0510)  classification: 0.6065 (0.6433)\n",
            "Epoch: [26] [110/289]  eta: 0:00:14  time: 0.0831  loss: 0.6721 (0.6627)  bbox_regression: 0.0638 (0.0441)  classification: 0.6083 (0.6186)\n",
            "Epoch: [26] [120/289]  eta: 0:00:14  time: 0.0829  loss: 0.6834 (0.7384)  bbox_regression: 0.0682 (0.0794)  classification: 0.6152 (0.6590)\n",
            "Epoch: [26] [130/289]  eta: 0:00:13  time: 0.0829  loss: 0.6857 (0.7609)  bbox_regression: 0.0665 (0.0809)  classification: 0.6192 (0.6799)\n",
            "Epoch: [26] [140/289]  eta: 0:00:12  time: 0.0827  loss: 0.6871 (0.7096)  bbox_regression: 0.0666 (0.0569)  classification: 0.6205 (0.6526)\n",
            "Epoch: [26] [150/289]  eta: 0:00:11  time: 0.0824  loss: 0.6875 (0.6994)  bbox_regression: 0.0657 (0.0609)  classification: 0.6217 (0.6385)\n",
            "Epoch: [26] [160/289]  eta: 0:00:10  time: 0.0826  loss: 0.6872 (0.6875)  bbox_regression: 0.0660 (0.0616)  classification: 0.6212 (0.6259)\n",
            "Epoch: [26] [170/289]  eta: 0:00:09  time: 0.0824  loss: 0.6950 (0.7522)  bbox_regression: 0.0647 (0.0571)  classification: 0.6303 (0.6950)\n",
            "Epoch: [26] [180/289]  eta: 0:00:08  time: 0.0823  loss: 0.7035 (0.8351)  bbox_regression: 0.0635 (0.0433)  classification: 0.6400 (0.7918)\n",
            "Epoch: [26] [190/289]  eta: 0:00:08  time: 0.0823  loss: 0.7085 (0.8239)  bbox_regression: 0.0630 (0.0482)  classification: 0.6455 (0.7757)\n",
            "Epoch: [26] [200/289]  eta: 0:00:07  time: 0.0822  loss: 0.7166 (0.8349)  bbox_regression: 0.0620 (0.0481)  classification: 0.6546 (0.7869)\n",
            "Epoch: [26] [210/289]  eta: 0:00:06  time: 0.0821  loss: 0.7139 (0.7654)  bbox_regression: 0.0613 (0.0450)  classification: 0.6526 (0.7205)\n",
            "Epoch: [26] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.7177 (0.7286)  bbox_regression: 0.0612 (0.0531)  classification: 0.6565 (0.6755)\n",
            "Epoch: [26] [230/289]  eta: 0:00:04  time: 0.0821  loss: 0.7163 (0.7418)  bbox_regression: 0.0612 (0.0606)  classification: 0.6551 (0.6812)\n",
            "Epoch: [26] [240/289]  eta: 0:00:04  time: 0.0823  loss: 0.7270 (0.8293)  bbox_regression: 0.0613 (0.0629)  classification: 0.6657 (0.7664)\n",
            "Epoch: [26] [250/289]  eta: 0:00:03  time: 0.0822  loss: 0.7243 (0.8166)  bbox_regression: 0.0613 (0.0627)  classification: 0.6630 (0.7539)\n",
            "Epoch: [26] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.7275 (0.7347)  bbox_regression: 0.0636 (0.0907)  classification: 0.6640 (0.6440)\n",
            "Epoch: [26] [270/289]  eta: 0:00:01  time: 0.0821  loss: 0.7219 (0.6911)  bbox_regression: 0.0628 (0.0809)  classification: 0.6591 (0.6103)\n",
            "Epoch: [26] [280/289]  eta: 0:00:00  time: 0.0820  loss: 0.7170 (0.5795)  bbox_regression: 0.0618 (0.0384)  classification: 0.6552 (0.5411)\n",
            "Epoch: [26] [288/289]  eta: 0:00:00  time: 0.0818  loss: 0.7218 (0.7020)  bbox_regression: 0.0614 (0.0405)  classification: 0.6604 (0.6615)\n",
            "Epoch: [26] Time: 0:00:23 (0.0819 s / it)\n",
            "Epoch: [27]\n",
            "Epoch: [27] [  0/289]  eta: 0:00:23  time: 0.0811  loss: 0.6896 (0.6896)  bbox_regression: 0.0936 (0.0936)  classification: 0.5960 (0.5960)\n",
            "Epoch: [27] [ 10/289]  eta: 0:00:22  time: 0.0815  loss: 0.7074 (0.7074)  bbox_regression: 0.0377 (0.0377)  classification: 0.6696 (0.6696)\n",
            "Epoch: [27] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.7396 (0.7421)  bbox_regression: 0.0487 (0.0464)  classification: 0.6909 (0.6957)\n",
            "Epoch: [27] [ 30/289]  eta: 0:00:21  time: 0.0811  loss: 0.7781 (0.8169)  bbox_regression: 0.0572 (0.0679)  classification: 0.7208 (0.7490)\n",
            "Epoch: [27] [ 40/289]  eta: 0:00:20  time: 0.0815  loss: 0.7493 (0.7595)  bbox_regression: 0.0657 (0.0836)  classification: 0.6836 (0.6759)\n",
            "Epoch: [27] [ 50/289]  eta: 0:00:19  time: 0.0814  loss: 0.7454 (0.6948)  bbox_regression: 0.0674 (0.0833)  classification: 0.6780 (0.6115)\n",
            "Epoch: [27] [ 60/289]  eta: 0:00:18  time: 0.0819  loss: 0.7386 (0.7167)  bbox_regression: 0.0650 (0.0636)  classification: 0.6736 (0.6531)\n",
            "Epoch: [27] [ 70/289]  eta: 0:00:18  time: 0.0826  loss: 0.7158 (0.6405)  bbox_regression: 0.0627 (0.0507)  classification: 0.6531 (0.5898)\n",
            "Epoch: [27] [ 80/289]  eta: 0:00:17  time: 0.0832  loss: 0.7301 (0.7042)  bbox_regression: 0.0610 (0.0486)  classification: 0.6692 (0.6556)\n",
            "Epoch: [27] [ 90/289]  eta: 0:00:16  time: 0.0835  loss: 0.7148 (0.7111)  bbox_regression: 0.0612 (0.0559)  classification: 0.6536 (0.6552)\n",
            "Epoch: [27] [100/289]  eta: 0:00:15  time: 0.0836  loss: 0.7028 (0.5920)  bbox_regression: 0.0624 (0.0682)  classification: 0.6404 (0.5238)\n",
            "Epoch: [27] [110/289]  eta: 0:00:14  time: 0.0836  loss: 0.6964 (0.6129)  bbox_regression: 0.0624 (0.0676)  classification: 0.6341 (0.5453)\n",
            "Epoch: [27] [120/289]  eta: 0:00:14  time: 0.0836  loss: 0.6931 (0.6442)  bbox_regression: 0.0623 (0.0618)  classification: 0.6308 (0.5824)\n",
            "Epoch: [27] [130/289]  eta: 0:00:13  time: 0.0834  loss: 0.6959 (0.6929)  bbox_regression: 0.0593 (0.0422)  classification: 0.6366 (0.6507)\n",
            "Epoch: [27] [140/289]  eta: 0:00:12  time: 0.0833  loss: 0.6846 (0.6329)  bbox_regression: 0.0576 (0.0294)  classification: 0.6269 (0.6035)\n",
            "Epoch: [27] [150/289]  eta: 0:00:11  time: 0.0831  loss: 0.6903 (0.6535)  bbox_regression: 0.0583 (0.0519)  classification: 0.6320 (0.6016)\n",
            "Epoch: [27] [160/289]  eta: 0:00:10  time: 0.0830  loss: 0.6863 (0.6989)  bbox_regression: 0.0638 (0.1072)  classification: 0.6226 (0.5917)\n",
            "Epoch: [27] [170/289]  eta: 0:00:09  time: 0.0829  loss: 0.6898 (0.6864)  bbox_regression: 0.0647 (0.1130)  classification: 0.6251 (0.5734)\n",
            "Epoch: [27] [180/289]  eta: 0:00:09  time: 0.0828  loss: 0.6847 (0.6711)  bbox_regression: 0.0635 (0.0614)  classification: 0.6211 (0.6097)\n",
            "Epoch: [27] [190/289]  eta: 0:00:08  time: 0.0827  loss: 0.6840 (0.6339)  bbox_regression: 0.0627 (0.0453)  classification: 0.6213 (0.5885)\n",
            "Epoch: [27] [200/289]  eta: 0:00:07  time: 0.0826  loss: 0.6788 (0.6260)  bbox_regression: 0.0623 (0.0510)  classification: 0.6165 (0.5750)\n",
            "Epoch: [27] [210/289]  eta: 0:00:06  time: 0.0825  loss: 0.6797 (0.6387)  bbox_regression: 0.0619 (0.0549)  classification: 0.6177 (0.5839)\n",
            "Epoch: [27] [220/289]  eta: 0:00:05  time: 0.0824  loss: 0.6835 (0.7303)  bbox_regression: 0.0608 (0.0457)  classification: 0.6227 (0.6846)\n",
            "Epoch: [27] [230/289]  eta: 0:00:04  time: 0.0825  loss: 0.6805 (0.6894)  bbox_regression: 0.0609 (0.0502)  classification: 0.6196 (0.6392)\n",
            "Epoch: [27] [240/289]  eta: 0:00:04  time: 0.0825  loss: 0.6769 (0.6045)  bbox_regression: 0.0607 (0.0599)  classification: 0.6162 (0.5446)\n",
            "Epoch: [27] [250/289]  eta: 0:00:03  time: 0.0826  loss: 0.6800 (0.6743)  bbox_regression: 0.0609 (0.0607)  classification: 0.6191 (0.6136)\n",
            "Epoch: [27] [260/289]  eta: 0:00:02  time: 0.0828  loss: 0.6764 (0.6695)  bbox_regression: 0.0597 (0.0483)  classification: 0.6166 (0.6212)\n",
            "Epoch: [27] [270/289]  eta: 0:00:01  time: 0.0827  loss: 0.6753 (0.6160)  bbox_regression: 0.0593 (0.0386)  classification: 0.6160 (0.5774)\n",
            "Epoch: [27] [280/289]  eta: 0:00:00  time: 0.0827  loss: 0.6712 (0.6035)  bbox_regression: 0.0597 (0.0597)  classification: 0.6114 (0.5438)\n",
            "Epoch: [27] [288/289]  eta: 0:00:00  time: 0.0825  loss: 0.6786 (0.7257)  bbox_regression: 0.0605 (0.0734)  classification: 0.6181 (0.6523)\n",
            "Epoch: [27] Time: 0:00:23 (0.0825 s / it)\n",
            "Epoch: [28]\n",
            "Epoch: [28] [  0/289]  eta: 0:00:22  time: 0.0764  loss: 0.3413 (0.3413)  bbox_regression: 0.0515 (0.0515)  classification: 0.2898 (0.2898)\n",
            "Epoch: [28] [ 10/289]  eta: 0:00:22  time: 0.0819  loss: 0.5209 (0.5209)  bbox_regression: 0.0608 (0.0608)  classification: 0.4600 (0.4600)\n",
            "Epoch: [28] [ 20/289]  eta: 0:00:21  time: 0.0817  loss: 0.5547 (0.5653)  bbox_regression: 0.0642 (0.0648)  classification: 0.4905 (0.5005)\n",
            "Epoch: [28] [ 30/289]  eta: 0:00:21  time: 0.0821  loss: 0.5483 (0.5633)  bbox_regression: 0.0553 (0.0523)  classification: 0.4929 (0.5110)\n",
            "Epoch: [28] [ 40/289]  eta: 0:00:20  time: 0.0825  loss: 0.5401 (0.5248)  bbox_regression: 0.0534 (0.0421)  classification: 0.4867 (0.4827)\n",
            "Epoch: [28] [ 50/289]  eta: 0:00:19  time: 0.0822  loss: 0.5531 (0.5607)  bbox_regression: 0.0592 (0.0652)  classification: 0.4939 (0.4955)\n",
            "Epoch: [28] [ 60/289]  eta: 0:00:18  time: 0.0822  loss: 0.5542 (0.5831)  bbox_regression: 0.0551 (0.0587)  classification: 0.4990 (0.5243)\n",
            "Epoch: [28] [ 70/289]  eta: 0:00:18  time: 0.0824  loss: 0.5653 (0.5962)  bbox_regression: 0.0539 (0.0402)  classification: 0.5114 (0.5560)\n",
            "Epoch: [28] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 0.5590 (0.5738)  bbox_regression: 0.0521 (0.0430)  classification: 0.5069 (0.5308)\n",
            "Epoch: [28] [ 90/289]  eta: 0:00:16  time: 0.0824  loss: 0.5606 (0.5441)  bbox_regression: 0.0513 (0.0421)  classification: 0.5093 (0.5019)\n",
            "Epoch: [28] [100/289]  eta: 0:00:15  time: 0.0828  loss: 0.5571 (0.5494)  bbox_regression: 0.0524 (0.0534)  classification: 0.5047 (0.4960)\n",
            "Epoch: [28] [110/289]  eta: 0:00:14  time: 0.0827  loss: 0.5583 (0.5477)  bbox_regression: 0.0526 (0.0585)  classification: 0.5057 (0.4893)\n",
            "Epoch: [28] [120/289]  eta: 0:00:13  time: 0.0826  loss: 0.5588 (0.5670)  bbox_regression: 0.0531 (0.0567)  classification: 0.5057 (0.5103)\n",
            "Epoch: [28] [130/289]  eta: 0:00:13  time: 0.0826  loss: 0.5630 (0.5890)  bbox_regression: 0.0523 (0.0505)  classification: 0.5107 (0.5385)\n",
            "Epoch: [28] [140/289]  eta: 0:00:12  time: 0.0824  loss: 0.5631 (0.5891)  bbox_regression: 0.0519 (0.0445)  classification: 0.5112 (0.5447)\n",
            "Epoch: [28] [150/289]  eta: 0:00:11  time: 0.0823  loss: 0.5694 (0.6116)  bbox_regression: 0.0531 (0.0584)  classification: 0.5164 (0.5532)\n",
            "Epoch: [28] [160/289]  eta: 0:00:10  time: 0.0820  loss: 0.5707 (0.6247)  bbox_regression: 0.0528 (0.0591)  classification: 0.5180 (0.5656)\n",
            "Epoch: [28] [170/289]  eta: 0:00:09  time: 0.0820  loss: 0.5788 (0.6497)  bbox_regression: 0.0538 (0.0594)  classification: 0.5250 (0.5903)\n",
            "Epoch: [28] [180/289]  eta: 0:00:08  time: 0.0819  loss: 0.5869 (0.7173)  bbox_regression: 0.0529 (0.0543)  classification: 0.5340 (0.6630)\n",
            "Epoch: [28] [190/289]  eta: 0:00:08  time: 0.0821  loss: 0.5868 (0.6547)  bbox_regression: 0.0540 (0.0555)  classification: 0.5328 (0.5992)\n",
            "Epoch: [28] [200/289]  eta: 0:00:07  time: 0.0821  loss: 0.5818 (0.5360)  bbox_regression: 0.0542 (0.0654)  classification: 0.5277 (0.4706)\n",
            "Epoch: [28] [210/289]  eta: 0:00:06  time: 0.0821  loss: 0.5834 (0.5515)  bbox_regression: 0.0535 (0.0492)  classification: 0.5299 (0.5023)\n",
            "Epoch: [28] [220/289]  eta: 0:00:05  time: 0.0822  loss: 0.5962 (0.7402)  bbox_regression: 0.0575 (0.0913)  classification: 0.5386 (0.6489)\n",
            "Epoch: [28] [230/289]  eta: 0:00:04  time: 0.0821  loss: 0.5987 (0.7604)  bbox_regression: 0.0571 (0.0947)  classification: 0.5416 (0.6657)\n",
            "Epoch: [28] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.5992 (0.6330)  bbox_regression: 0.0570 (0.0516)  classification: 0.5422 (0.5814)\n",
            "Epoch: [28] [250/289]  eta: 0:00:03  time: 0.0821  loss: 0.6047 (0.6730)  bbox_regression: 0.0599 (0.0922)  classification: 0.5448 (0.5808)\n",
            "Epoch: [28] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.6061 (0.6889)  bbox_regression: 0.0600 (0.0956)  classification: 0.5461 (0.5934)\n",
            "Epoch: [28] [270/289]  eta: 0:00:01  time: 0.0822  loss: 0.6063 (0.6273)  bbox_regression: 0.0605 (0.0685)  classification: 0.5458 (0.5589)\n",
            "Epoch: [28] [280/289]  eta: 0:00:00  time: 0.0822  loss: 0.6100 (0.6602)  bbox_regression: 0.0597 (0.0565)  classification: 0.5502 (0.6037)\n",
            "Epoch: [28] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.6061 (0.5865)  bbox_regression: 0.0591 (0.0376)  classification: 0.5470 (0.5489)\n",
            "Epoch: [28] Time: 0:00:23 (0.0821 s / it)\n",
            "Epoch: [29]\n",
            "Epoch: [29] [  0/289]  eta: 0:00:22  time: 0.0764  loss: 0.7922 (0.7922)  bbox_regression: 0.0594 (0.0594)  classification: 0.7328 (0.7328)\n",
            "Epoch: [29] [ 10/289]  eta: 0:00:22  time: 0.0812  loss: 0.4200 (0.4200)  bbox_regression: 0.0387 (0.0387)  classification: 0.3813 (0.3813)\n",
            "Epoch: [29] [ 20/289]  eta: 0:00:22  time: 0.0822  loss: 0.4658 (0.4495)  bbox_regression: 0.0419 (0.0410)  classification: 0.4239 (0.4084)\n",
            "Epoch: [29] [ 30/289]  eta: 0:00:21  time: 0.0836  loss: 0.5192 (0.5738)  bbox_regression: 0.0470 (0.0516)  classification: 0.4722 (0.5222)\n",
            "Epoch: [29] [ 40/289]  eta: 0:00:20  time: 0.0831  loss: 0.5112 (0.5588)  bbox_regression: 0.0424 (0.0429)  classification: 0.4688 (0.5159)\n",
            "Epoch: [29] [ 50/289]  eta: 0:00:19  time: 0.0828  loss: 0.5199 (0.5209)  bbox_regression: 0.0463 (0.0451)  classification: 0.4737 (0.4759)\n",
            "Epoch: [29] [ 60/289]  eta: 0:00:18  time: 0.0826  loss: 0.5117 (0.5128)  bbox_regression: 0.0467 (0.0556)  classification: 0.4650 (0.4572)\n",
            "Epoch: [29] [ 70/289]  eta: 0:00:18  time: 0.0824  loss: 0.5261 (0.5419)  bbox_regression: 0.0480 (0.0524)  classification: 0.4781 (0.4895)\n",
            "Epoch: [29] [ 80/289]  eta: 0:00:17  time: 0.0824  loss: 0.5315 (0.5920)  bbox_regression: 0.0489 (0.0556)  classification: 0.4826 (0.5364)\n",
            "Epoch: [29] [ 90/289]  eta: 0:00:16  time: 0.0820  loss: 0.5399 (0.5890)  bbox_regression: 0.0474 (0.0454)  classification: 0.4925 (0.5436)\n",
            "Epoch: [29] [100/289]  eta: 0:00:15  time: 0.0818  loss: 0.5320 (0.5342)  bbox_regression: 0.0468 (0.0381)  classification: 0.4853 (0.4961)\n",
            "Epoch: [29] [110/289]  eta: 0:00:14  time: 0.0817  loss: 0.5220 (0.4402)  bbox_regression: 0.0466 (0.0429)  classification: 0.4754 (0.3973)\n",
            "Epoch: [29] [120/289]  eta: 0:00:13  time: 0.0816  loss: 0.5272 (0.5029)  bbox_regression: 0.0462 (0.0431)  classification: 0.4811 (0.4598)\n",
            "Epoch: [29] [130/289]  eta: 0:00:12  time: 0.0817  loss: 0.5256 (0.5458)  bbox_regression: 0.0456 (0.0402)  classification: 0.4800 (0.5057)\n",
            "Epoch: [29] [140/289]  eta: 0:00:12  time: 0.0816  loss: 0.5246 (0.5085)  bbox_regression: 0.0448 (0.0362)  classification: 0.4798 (0.4723)\n",
            "Epoch: [29] [150/289]  eta: 0:00:11  time: 0.0816  loss: 0.5335 (0.5851)  bbox_regression: 0.0453 (0.0435)  classification: 0.4882 (0.5416)\n",
            "Epoch: [29] [160/289]  eta: 0:00:10  time: 0.0818  loss: 0.5299 (0.5678)  bbox_regression: 0.0478 (0.0695)  classification: 0.4821 (0.4983)\n",
            "Epoch: [29] [170/289]  eta: 0:00:09  time: 0.0821  loss: 0.5401 (0.5901)  bbox_regression: 0.0509 (0.0932)  classification: 0.4892 (0.4969)\n",
            "Epoch: [29] [180/289]  eta: 0:00:08  time: 0.0821  loss: 0.5407 (0.6272)  bbox_regression: 0.0511 (0.0776)  classification: 0.4896 (0.5496)\n",
            "Epoch: [29] [190/289]  eta: 0:00:08  time: 0.0820  loss: 0.5444 (0.5811)  bbox_regression: 0.0513 (0.0543)  classification: 0.4931 (0.5268)\n",
            "Epoch: [29] [200/289]  eta: 0:00:07  time: 0.0820  loss: 0.5503 (0.6369)  bbox_regression: 0.0527 (0.0666)  classification: 0.4976 (0.5703)\n",
            "Epoch: [29] [210/289]  eta: 0:00:06  time: 0.0820  loss: 0.5546 (0.6525)  bbox_regression: 0.0528 (0.0669)  classification: 0.5019 (0.5856)\n",
            "Epoch: [29] [220/289]  eta: 0:00:05  time: 0.0819  loss: 0.5636 (0.6980)  bbox_regression: 0.0583 (0.1152)  classification: 0.5053 (0.5828)\n",
            "Epoch: [29] [230/289]  eta: 0:00:04  time: 0.0819  loss: 0.5616 (0.6345)  bbox_regression: 0.0593 (0.1282)  classification: 0.5023 (0.5063)\n",
            "Epoch: [29] [240/289]  eta: 0:00:04  time: 0.0818  loss: 0.5608 (0.5301)  bbox_regression: 0.0582 (0.0566)  classification: 0.5027 (0.4735)\n",
            "Epoch: [29] [250/289]  eta: 0:00:03  time: 0.0818  loss: 0.5607 (0.5502)  bbox_regression: 0.0587 (0.0522)  classification: 0.5019 (0.4980)\n",
            "Epoch: [29] [260/289]  eta: 0:00:02  time: 0.0819  loss: 0.5566 (0.5059)  bbox_regression: 0.0581 (0.0573)  classification: 0.4985 (0.4487)\n",
            "Epoch: [29] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.5590 (0.5386)  bbox_regression: 0.0581 (0.0503)  classification: 0.5009 (0.4882)\n",
            "Epoch: [29] [280/289]  eta: 0:00:00  time: 0.0819  loss: 0.5625 (0.6392)  bbox_regression: 0.0577 (0.0521)  classification: 0.5048 (0.5871)\n",
            "Epoch: [29] [288/289]  eta: 0:00:00  time: 0.0817  loss: 0.5616 (0.5747)  bbox_regression: 0.0582 (0.0561)  classification: 0.5033 (0.5186)\n",
            "Epoch: [29] Time: 0:00:23 (0.0817 s / it)\n",
            "Validation: [29]\n",
            "Validation: [29] [ 0/62]  eta: 0:00:04  time: 0.0690  \n",
            "Validation: [29] [10/62]  eta: 0:00:03  time: 0.0684  \n",
            "Validation: [29] [20/62]  eta: 0:00:02  time: 0.0676  \n",
            "Validation: [29] [30/62]  eta: 0:00:02  time: 0.0678  \n",
            "Validation: [29] [40/62]  eta: 0:00:01  time: 0.0681  \n",
            "Validation: [29] [50/62]  eta: 0:00:00  time: 0.0685  \n",
            "Validation: [29] [60/62]  eta: 0:00:00  time: 0.0688  \n",
            "Validation: [29] [61/62]  eta: 0:00:00  time: 0.0684  \n",
            "Validation: [29] Time: 0:00:04 (0.0684 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_30/mAP_vs_threshold_epoch_29.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_30/pr_curves_epoch_29.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_30/per_class_ap_epoch_29.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_30/confusion_matrix_epoch_29.png\n",
            "Epoch 29: mAP@0.5 = 0.5019\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6953\n",
            "  Bacterial-Black-spot: 0.5970\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.2897\n",
            "  Mechanical-damage: 0.7286\n",
            "  Others: 0.7007\n",
            "Saved best model with mAP: 0.5019\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied pr_curves_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/pr_curves_epoch_29.png\n",
            "Copied mAP_vs_threshold_epoch_29.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/mAP_vs_threshold_epoch_29.csv\n",
            "Copied per_class_mAP_epoch_29.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/per_class_mAP_epoch_29.csv\n",
            "Copied mAP_vs_threshold_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/mAP_vs_threshold_epoch_29.png\n",
            "Copied confusion_matrix_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/confusion_matrix_epoch_29.png\n",
            "Copied per_class_ap_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/per_class_ap_epoch_29.png\n",
            "Saved checkpoint at epoch 30\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [30]\n",
            "Epoch: [30] [  0/289]  eta: 0:00:25  time: 0.0886  loss: 0.8141 (0.8141)  bbox_regression: 0.0201 (0.0201)  classification: 0.7939 (0.7939)\n",
            "Epoch: [30] [ 10/289]  eta: 0:00:23  time: 0.0827  loss: 0.6091 (0.6091)  bbox_regression: 0.0426 (0.0426)  classification: 0.5665 (0.5665)\n",
            "Epoch: [30] [ 20/289]  eta: 0:00:22  time: 0.0822  loss: 0.5210 (0.5064)  bbox_regression: 0.0430 (0.0441)  classification: 0.4780 (0.4622)\n",
            "Epoch: [30] [ 30/289]  eta: 0:00:21  time: 0.0815  loss: 0.4703 (0.3940)  bbox_regression: 0.0447 (0.0458)  classification: 0.4257 (0.3482)\n",
            "Epoch: [30] [ 40/289]  eta: 0:00:20  time: 0.0814  loss: 0.4681 (0.4125)  bbox_regression: 0.0444 (0.0459)  classification: 0.4236 (0.3665)\n",
            "Epoch: [30] [ 50/289]  eta: 0:00:19  time: 0.0817  loss: 0.4856 (0.5092)  bbox_regression: 0.0476 (0.0521)  classification: 0.4380 (0.4571)\n",
            "Epoch: [30] [ 60/289]  eta: 0:00:18  time: 0.0813  loss: 0.5010 (0.5687)  bbox_regression: 0.0503 (0.0625)  classification: 0.4507 (0.5062)\n",
            "Epoch: [30] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 0.4875 (0.4925)  bbox_regression: 0.0492 (0.0532)  classification: 0.4384 (0.4393)\n",
            "Epoch: [30] [ 80/289]  eta: 0:00:17  time: 0.0816  loss: 0.4804 (0.4174)  bbox_regression: 0.0502 (0.0497)  classification: 0.4302 (0.3677)\n",
            "Epoch: [30] [ 90/289]  eta: 0:00:16  time: 0.0816  loss: 0.4731 (0.4219)  bbox_regression: 0.0481 (0.0442)  classification: 0.4250 (0.3777)\n",
            "Epoch: [30] [100/289]  eta: 0:00:15  time: 0.0817  loss: 0.4664 (0.4095)  bbox_regression: 0.0470 (0.0339)  classification: 0.4194 (0.3756)\n",
            "Epoch: [30] [110/289]  eta: 0:00:14  time: 0.0822  loss: 0.4670 (0.4392)  bbox_regression: 0.0462 (0.0377)  classification: 0.4208 (0.4014)\n",
            "Epoch: [30] [120/289]  eta: 0:00:14  time: 0.0830  loss: 0.4655 (0.4611)  bbox_regression: 0.0445 (0.0322)  classification: 0.4210 (0.4289)\n",
            "Epoch: [30] [130/289]  eta: 0:00:13  time: 0.0827  loss: 0.4626 (0.4383)  bbox_regression: 0.0444 (0.0346)  classification: 0.4182 (0.4038)\n",
            "Epoch: [30] [140/289]  eta: 0:00:12  time: 0.0828  loss: 0.4609 (0.4330)  bbox_regression: 0.0451 (0.0487)  classification: 0.4158 (0.3843)\n",
            "Epoch: [30] [150/289]  eta: 0:00:11  time: 0.0827  loss: 0.4644 (0.4762)  bbox_regression: 0.0480 (0.0717)  classification: 0.4164 (0.4045)\n",
            "Epoch: [30] [160/289]  eta: 0:00:10  time: 0.0827  loss: 0.4597 (0.4512)  bbox_regression: 0.0483 (0.0709)  classification: 0.4114 (0.3803)\n",
            "Epoch: [30] [170/289]  eta: 0:00:09  time: 0.0826  loss: 0.4586 (0.4146)  bbox_regression: 0.0476 (0.0444)  classification: 0.4110 (0.3702)\n",
            "Epoch: [30] [180/289]  eta: 0:00:09  time: 0.0826  loss: 0.4532 (0.4013)  bbox_regression: 0.0470 (0.0367)  classification: 0.4062 (0.3646)\n",
            "Epoch: [30] [190/289]  eta: 0:00:08  time: 0.0827  loss: 0.4510 (0.3863)  bbox_regression: 0.0463 (0.0355)  classification: 0.4047 (0.3509)\n",
            "Epoch: [30] [200/289]  eta: 0:00:07  time: 0.0827  loss: 0.4506 (0.4274)  bbox_regression: 0.0462 (0.0388)  classification: 0.4044 (0.3886)\n",
            "Epoch: [30] [210/289]  eta: 0:00:06  time: 0.0826  loss: 0.4496 (0.4356)  bbox_regression: 0.0460 (0.0424)  classification: 0.4036 (0.3932)\n",
            "Epoch: [30] [220/289]  eta: 0:00:05  time: 0.0824  loss: 0.4478 (0.4192)  bbox_regression: 0.0461 (0.0448)  classification: 0.4017 (0.3744)\n",
            "Epoch: [30] [230/289]  eta: 0:00:04  time: 0.0824  loss: 0.4506 (0.4614)  bbox_regression: 0.0467 (0.0547)  classification: 0.4039 (0.4067)\n",
            "Epoch: [30] [240/289]  eta: 0:00:04  time: 0.0822  loss: 0.4487 (0.4586)  bbox_regression: 0.0467 (0.0539)  classification: 0.4020 (0.4047)\n",
            "Epoch: [30] [250/289]  eta: 0:00:03  time: 0.0822  loss: 0.4475 (0.4117)  bbox_regression: 0.0461 (0.0387)  classification: 0.4014 (0.3730)\n",
            "Epoch: [30] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.4476 (0.4348)  bbox_regression: 0.0485 (0.0701)  classification: 0.3991 (0.3647)\n",
            "Epoch: [30] [270/289]  eta: 0:00:01  time: 0.0823  loss: 0.4488 (0.4658)  bbox_regression: 0.0512 (0.1154)  classification: 0.3976 (0.3504)\n",
            "Epoch: [30] [280/289]  eta: 0:00:00  time: 0.0824  loss: 0.4471 (0.4403)  bbox_regression: 0.0510 (0.0841)  classification: 0.3961 (0.3563)\n",
            "Epoch: [30] [288/289]  eta: 0:00:00  time: 0.0822  loss: 0.4415 (0.3336)  bbox_regression: 0.0506 (0.0406)  classification: 0.3909 (0.2931)\n",
            "Epoch: [30] Time: 0:00:23 (0.0823 s / it)\n",
            "Epoch: [31]\n",
            "Epoch: [31] [  0/289]  eta: 0:00:25  time: 0.0874  loss: 0.4967 (0.4967)  bbox_regression: 0.0217 (0.0217)  classification: 0.4750 (0.4750)\n",
            "Epoch: [31] [ 10/289]  eta: 0:00:22  time: 0.0815  loss: 0.3884 (0.3884)  bbox_regression: 0.0361 (0.0361)  classification: 0.3523 (0.3523)\n",
            "Epoch: [31] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.3976 (0.3926)  bbox_regression: 0.0376 (0.0384)  classification: 0.3599 (0.3542)\n",
            "Epoch: [31] [ 30/289]  eta: 0:00:21  time: 0.0823  loss: 0.4141 (0.4282)  bbox_regression: 0.0463 (0.0519)  classification: 0.3678 (0.3763)\n",
            "Epoch: [31] [ 40/289]  eta: 0:00:20  time: 0.0822  loss: 0.4394 (0.4834)  bbox_regression: 0.0707 (0.1054)  classification: 0.3687 (0.3780)\n",
            "Epoch: [31] [ 50/289]  eta: 0:00:19  time: 0.0828  loss: 0.4308 (0.4567)  bbox_regression: 0.0704 (0.1076)  classification: 0.3604 (0.3491)\n",
            "Epoch: [31] [ 60/289]  eta: 0:00:18  time: 0.0829  loss: 0.4238 (0.3917)  bbox_regression: 0.0670 (0.0596)  classification: 0.3567 (0.3321)\n",
            "Epoch: [31] [ 70/289]  eta: 0:00:18  time: 0.0824  loss: 0.4195 (0.3906)  bbox_regression: 0.0629 (0.0439)  classification: 0.3566 (0.3468)\n",
            "Epoch: [31] [ 80/289]  eta: 0:00:17  time: 0.0820  loss: 0.4205 (0.4104)  bbox_regression: 0.0598 (0.0375)  classification: 0.3607 (0.3729)\n",
            "Epoch: [31] [ 90/289]  eta: 0:00:16  time: 0.0820  loss: 0.4226 (0.4335)  bbox_regression: 0.0602 (0.0506)  classification: 0.3624 (0.3829)\n",
            "Epoch: [31] [100/289]  eta: 0:00:15  time: 0.0819  loss: 0.4178 (0.4070)  bbox_regression: 0.0577 (0.0494)  classification: 0.3601 (0.3577)\n",
            "Epoch: [31] [110/289]  eta: 0:00:14  time: 0.0818  loss: 0.4144 (0.3772)  bbox_regression: 0.0559 (0.0365)  classification: 0.3585 (0.3406)\n",
            "Epoch: [31] [120/289]  eta: 0:00:13  time: 0.0817  loss: 0.4202 (0.4320)  bbox_regression: 0.0559 (0.0466)  classification: 0.3643 (0.3854)\n",
            "Epoch: [31] [130/289]  eta: 0:00:12  time: 0.0817  loss: 0.4221 (0.4651)  bbox_regression: 0.0556 (0.0535)  classification: 0.3666 (0.4116)\n",
            "Epoch: [31] [140/289]  eta: 0:00:12  time: 0.0817  loss: 0.4119 (0.3619)  bbox_regression: 0.0550 (0.0497)  classification: 0.3569 (0.3122)\n",
            "Epoch: [31] [150/289]  eta: 0:00:11  time: 0.0821  loss: 0.4142 (0.3622)  bbox_regression: 0.0538 (0.0427)  classification: 0.3603 (0.3195)\n",
            "Epoch: [31] [160/289]  eta: 0:00:10  time: 0.0821  loss: 0.4185 (0.4651)  bbox_regression: 0.0550 (0.0553)  classification: 0.3635 (0.4098)\n",
            "Epoch: [31] [170/289]  eta: 0:00:09  time: 0.0822  loss: 0.4158 (0.4281)  bbox_regression: 0.0543 (0.0573)  classification: 0.3616 (0.3708)\n",
            "Epoch: [31] [180/289]  eta: 0:00:08  time: 0.0821  loss: 0.4139 (0.3772)  bbox_regression: 0.0542 (0.0477)  classification: 0.3597 (0.3296)\n",
            "Epoch: [31] [190/289]  eta: 0:00:08  time: 0.0821  loss: 0.4148 (0.4058)  bbox_regression: 0.0553 (0.0640)  classification: 0.3595 (0.3418)\n",
            "Epoch: [31] [200/289]  eta: 0:00:07  time: 0.0820  loss: 0.4145 (0.4192)  bbox_regression: 0.0538 (0.0498)  classification: 0.3607 (0.3694)\n",
            "Epoch: [31] [210/289]  eta: 0:00:06  time: 0.0820  loss: 0.4111 (0.3765)  bbox_regression: 0.0526 (0.0271)  classification: 0.3585 (0.3493)\n",
            "Epoch: [31] [220/289]  eta: 0:00:05  time: 0.0819  loss: 0.4138 (0.4074)  bbox_regression: 0.0515 (0.0290)  classification: 0.3623 (0.3784)\n",
            "Epoch: [31] [230/289]  eta: 0:00:04  time: 0.0819  loss: 0.4165 (0.4732)  bbox_regression: 0.0512 (0.0366)  classification: 0.3653 (0.4366)\n",
            "Epoch: [31] [240/289]  eta: 0:00:04  time: 0.0819  loss: 0.4158 (0.4377)  bbox_regression: 0.0508 (0.0422)  classification: 0.3650 (0.3954)\n",
            "Epoch: [31] [250/289]  eta: 0:00:03  time: 0.0819  loss: 0.4106 (0.3422)  bbox_regression: 0.0501 (0.0371)  classification: 0.3605 (0.3050)\n",
            "Epoch: [31] [260/289]  eta: 0:00:02  time: 0.0818  loss: 0.4101 (0.3415)  bbox_regression: 0.0500 (0.0403)  classification: 0.3602 (0.3012)\n",
            "Epoch: [31] [270/289]  eta: 0:00:01  time: 0.0817  loss: 0.4141 (0.4577)  bbox_regression: 0.0502 (0.0514)  classification: 0.3639 (0.4064)\n",
            "Epoch: [31] [280/289]  eta: 0:00:00  time: 0.0817  loss: 0.4095 (0.4021)  bbox_regression: 0.0496 (0.0456)  classification: 0.3599 (0.3565)\n",
            "Epoch: [31] [288/289]  eta: 0:00:00  time: 0.0815  loss: 0.4087 (0.3499)  bbox_regression: 0.0498 (0.0446)  classification: 0.3589 (0.3053)\n",
            "Epoch: [31] Time: 0:00:23 (0.0815 s / it)\n",
            "Epoch: [32]\n",
            "Epoch: [32] [  0/289]  eta: 0:00:24  time: 0.0834  loss: 0.2963 (0.2963)  bbox_regression: 0.0269 (0.0269)  classification: 0.2694 (0.2694)\n",
            "Epoch: [32] [ 10/289]  eta: 0:00:23  time: 0.0848  loss: 0.4709 (0.4709)  bbox_regression: 0.0536 (0.0536)  classification: 0.4173 (0.4173)\n",
            "Epoch: [32] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.3746 (0.3785)  bbox_regression: 0.0487 (0.0498)  classification: 0.3259 (0.3287)\n",
            "Epoch: [32] [ 30/289]  eta: 0:00:20  time: 0.0811  loss: 0.3417 (0.2706)  bbox_regression: 0.0468 (0.0431)  classification: 0.2948 (0.2275)\n",
            "Epoch: [32] [ 40/289]  eta: 0:00:20  time: 0.0813  loss: 0.3455 (0.3149)  bbox_regression: 0.0494 (0.0501)  classification: 0.2961 (0.2648)\n",
            "Epoch: [32] [ 50/289]  eta: 0:00:19  time: 0.0809  loss: 0.3583 (0.3840)  bbox_regression: 0.0497 (0.0541)  classification: 0.3086 (0.3299)\n",
            "Epoch: [32] [ 60/289]  eta: 0:00:18  time: 0.0811  loss: 0.3687 (0.4164)  bbox_regression: 0.0526 (0.0592)  classification: 0.3161 (0.3572)\n",
            "Epoch: [32] [ 70/289]  eta: 0:00:17  time: 0.0813  loss: 0.3649 (0.3817)  bbox_regression: 0.0514 (0.0557)  classification: 0.3135 (0.3261)\n",
            "Epoch: [32] [ 80/289]  eta: 0:00:16  time: 0.0810  loss: 0.3688 (0.3688)  bbox_regression: 0.0495 (0.0400)  classification: 0.3193 (0.3288)\n",
            "Epoch: [32] [ 90/289]  eta: 0:00:16  time: 0.0811  loss: 0.3668 (0.3735)  bbox_regression: 0.0480 (0.0362)  classification: 0.3187 (0.3372)\n",
            "Epoch: [32] [100/289]  eta: 0:00:15  time: 0.0814  loss: 0.3649 (0.3495)  bbox_regression: 0.0477 (0.0405)  classification: 0.3172 (0.3089)\n",
            "Epoch: [32] [110/289]  eta: 0:00:14  time: 0.0816  loss: 0.3766 (0.4215)  bbox_regression: 0.0520 (0.0699)  classification: 0.3246 (0.3515)\n",
            "Epoch: [32] [120/289]  eta: 0:00:13  time: 0.0816  loss: 0.3869 (0.4977)  bbox_regression: 0.0526 (0.0773)  classification: 0.3343 (0.4205)\n",
            "Epoch: [32] [130/289]  eta: 0:00:13  time: 0.0818  loss: 0.3870 (0.4443)  bbox_regression: 0.0514 (0.0482)  classification: 0.3355 (0.3960)\n",
            "Epoch: [32] [140/289]  eta: 0:00:12  time: 0.0820  loss: 0.3894 (0.4045)  bbox_regression: 0.0515 (0.0446)  classification: 0.3379 (0.3600)\n",
            "Epoch: [32] [150/289]  eta: 0:00:11  time: 0.0822  loss: 0.3933 (0.4352)  bbox_regression: 0.0511 (0.0494)  classification: 0.3422 (0.3859)\n",
            "Epoch: [32] [160/289]  eta: 0:00:10  time: 0.0824  loss: 0.3938 (0.4247)  bbox_regression: 0.0503 (0.0418)  classification: 0.3435 (0.3829)\n",
            "Epoch: [32] [170/289]  eta: 0:00:09  time: 0.0826  loss: 0.3957 (0.4135)  bbox_regression: 0.0509 (0.0495)  classification: 0.3448 (0.3640)\n",
            "Epoch: [32] [180/289]  eta: 0:00:08  time: 0.0824  loss: 0.3886 (0.3468)  bbox_regression: 0.0498 (0.0464)  classification: 0.3387 (0.3004)\n",
            "Epoch: [32] [190/289]  eta: 0:00:08  time: 0.0823  loss: 0.3858 (0.3011)  bbox_regression: 0.0494 (0.0361)  classification: 0.3364 (0.2650)\n",
            "Epoch: [32] [200/289]  eta: 0:00:07  time: 0.0824  loss: 0.3940 (0.4426)  bbox_regression: 0.0528 (0.0794)  classification: 0.3412 (0.3632)\n",
            "Epoch: [32] [210/289]  eta: 0:00:06  time: 0.0824  loss: 0.3925 (0.4567)  bbox_regression: 0.0533 (0.0904)  classification: 0.3392 (0.3663)\n",
            "Epoch: [32] [220/289]  eta: 0:00:05  time: 0.0823  loss: 0.3896 (0.3459)  bbox_regression: 0.0528 (0.0526)  classification: 0.3368 (0.2933)\n",
            "Epoch: [32] [230/289]  eta: 0:00:04  time: 0.0823  loss: 0.3933 (0.4020)  bbox_regression: 0.0535 (0.0563)  classification: 0.3398 (0.3458)\n",
            "Epoch: [32] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.3915 (0.4129)  bbox_regression: 0.0529 (0.0549)  classification: 0.3386 (0.3580)\n",
            "Epoch: [32] [250/289]  eta: 0:00:03  time: 0.0821  loss: 0.3905 (0.3579)  bbox_regression: 0.0523 (0.0375)  classification: 0.3383 (0.3205)\n",
            "Epoch: [32] [260/289]  eta: 0:00:02  time: 0.0821  loss: 0.3889 (0.3569)  bbox_regression: 0.0515 (0.0342)  classification: 0.3374 (0.3227)\n",
            "Epoch: [32] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.3920 (0.4108)  bbox_regression: 0.0513 (0.0390)  classification: 0.3407 (0.3718)\n",
            "Epoch: [32] [280/289]  eta: 0:00:00  time: 0.0819  loss: 0.3908 (0.4152)  bbox_regression: 0.0511 (0.0464)  classification: 0.3396 (0.3687)\n",
            "Epoch: [32] [288/289]  eta: 0:00:00  time: 0.0819  loss: 0.3920 (0.3879)  bbox_regression: 0.0503 (0.0360)  classification: 0.3417 (0.3519)\n",
            "Epoch: [32] Time: 0:00:23 (0.0819 s / it)\n",
            "Epoch: [33]\n",
            "Epoch: [33] [  0/289]  eta: 0:00:22  time: 0.0770  loss: 0.1146 (0.1146)  bbox_regression: 0.0155 (0.0155)  classification: 0.0992 (0.0992)\n",
            "Epoch: [33] [ 10/289]  eta: 0:00:22  time: 0.0802  loss: 0.3643 (0.3643)  bbox_regression: 0.0466 (0.0466)  classification: 0.3177 (0.3177)\n",
            "Epoch: [33] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.3466 (0.3582)  bbox_regression: 0.0398 (0.0411)  classification: 0.3068 (0.3171)\n",
            "Epoch: [33] [ 30/289]  eta: 0:00:21  time: 0.0819  loss: 0.3189 (0.2940)  bbox_regression: 0.0386 (0.0342)  classification: 0.2804 (0.2598)\n",
            "Epoch: [33] [ 40/289]  eta: 0:00:20  time: 0.0818  loss: 0.3219 (0.2960)  bbox_regression: 0.0396 (0.0393)  classification: 0.2823 (0.2567)\n",
            "Epoch: [33] [ 50/289]  eta: 0:00:19  time: 0.0828  loss: 0.3294 (0.3457)  bbox_regression: 0.0400 (0.0422)  classification: 0.2895 (0.3036)\n",
            "Epoch: [33] [ 60/289]  eta: 0:00:18  time: 0.0826  loss: 0.3516 (0.4125)  bbox_regression: 0.0424 (0.0482)  classification: 0.3092 (0.3643)\n",
            "Epoch: [33] [ 70/289]  eta: 0:00:18  time: 0.0830  loss: 0.3772 (0.4990)  bbox_regression: 0.0462 (0.0621)  classification: 0.3310 (0.4370)\n",
            "Epoch: [33] [ 80/289]  eta: 0:00:17  time: 0.0829  loss: 0.3823 (0.4760)  bbox_regression: 0.0470 (0.0612)  classification: 0.3353 (0.4148)\n",
            "Epoch: [33] [ 90/289]  eta: 0:00:16  time: 0.0829  loss: 0.3784 (0.3826)  bbox_regression: 0.0470 (0.0498)  classification: 0.3314 (0.3327)\n",
            "Epoch: [33] [100/289]  eta: 0:00:15  time: 0.0825  loss: 0.3728 (0.3344)  bbox_regression: 0.0480 (0.0519)  classification: 0.3248 (0.2824)\n",
            "Epoch: [33] [110/289]  eta: 0:00:14  time: 0.0825  loss: 0.3757 (0.3634)  bbox_regression: 0.0480 (0.0523)  classification: 0.3277 (0.3111)\n",
            "Epoch: [33] [120/289]  eta: 0:00:13  time: 0.0821  loss: 0.3700 (0.3558)  bbox_regression: 0.0489 (0.0536)  classification: 0.3211 (0.3022)\n",
            "Epoch: [33] [130/289]  eta: 0:00:13  time: 0.0821  loss: 0.3658 (0.3107)  bbox_regression: 0.0477 (0.0464)  classification: 0.3180 (0.2643)\n",
            "Epoch: [33] [140/289]  eta: 0:00:12  time: 0.0821  loss: 0.3679 (0.3552)  bbox_regression: 0.0471 (0.0358)  classification: 0.3208 (0.3194)\n",
            "Epoch: [33] [150/289]  eta: 0:00:11  time: 0.0819  loss: 0.3681 (0.3836)  bbox_regression: 0.0460 (0.0351)  classification: 0.3221 (0.3485)\n",
            "Epoch: [33] [160/289]  eta: 0:00:10  time: 0.0820  loss: 0.3713 (0.3952)  bbox_regression: 0.0461 (0.0396)  classification: 0.3252 (0.3556)\n",
            "Epoch: [33] [170/289]  eta: 0:00:09  time: 0.0823  loss: 0.3754 (0.4302)  bbox_regression: 0.0474 (0.0580)  classification: 0.3279 (0.3723)\n",
            "Epoch: [33] [180/289]  eta: 0:00:08  time: 0.0824  loss: 0.3720 (0.3775)  bbox_regression: 0.0476 (0.0591)  classification: 0.3244 (0.3184)\n",
            "Epoch: [33] [190/289]  eta: 0:00:08  time: 0.0825  loss: 0.3701 (0.3252)  bbox_regression: 0.0477 (0.0498)  classification: 0.3224 (0.2754)\n",
            "Epoch: [33] [200/289]  eta: 0:00:07  time: 0.0825  loss: 0.3745 (0.3973)  bbox_regression: 0.0478 (0.0498)  classification: 0.3267 (0.3475)\n",
            "Epoch: [33] [210/289]  eta: 0:00:06  time: 0.0824  loss: 0.3750 (0.4214)  bbox_regression: 0.0494 (0.0655)  classification: 0.3256 (0.3559)\n",
            "Epoch: [33] [220/289]  eta: 0:00:05  time: 0.0823  loss: 0.3789 (0.4230)  bbox_regression: 0.0489 (0.0602)  classification: 0.3300 (0.3628)\n",
            "Epoch: [33] [230/289]  eta: 0:00:04  time: 0.0822  loss: 0.3773 (0.4019)  bbox_regression: 0.0486 (0.0404)  classification: 0.3287 (0.3615)\n",
            "Epoch: [33] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.3806 (0.3991)  bbox_regression: 0.0487 (0.0460)  classification: 0.3319 (0.3531)\n",
            "Epoch: [33] [250/289]  eta: 0:00:03  time: 0.0821  loss: 0.3771 (0.3740)  bbox_regression: 0.0488 (0.0514)  classification: 0.3282 (0.3226)\n",
            "Epoch: [33] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.3758 (0.3190)  bbox_regression: 0.0487 (0.0490)  classification: 0.3271 (0.2700)\n",
            "Epoch: [33] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.3736 (0.3306)  bbox_regression: 0.0483 (0.0418)  classification: 0.3253 (0.2887)\n",
            "Epoch: [33] [280/289]  eta: 0:00:00  time: 0.0819  loss: 0.3787 (0.4165)  bbox_regression: 0.0511 (0.0827)  classification: 0.3276 (0.3338)\n",
            "Epoch: [33] [288/289]  eta: 0:00:00  time: 0.0818  loss: 0.3776 (0.4166)  bbox_regression: 0.0505 (0.0795)  classification: 0.3271 (0.3371)\n",
            "Epoch: [33] Time: 0:00:23 (0.0818 s / it)\n",
            "Epoch: [34]\n",
            "Epoch: [34] [  0/289]  eta: 0:00:23  time: 0.0813  loss: 0.1550 (0.1550)  bbox_regression: 0.0241 (0.0241)  classification: 0.1309 (0.1309)\n",
            "Epoch: [34] [ 10/289]  eta: 0:00:22  time: 0.0818  loss: 0.3696 (0.3696)  bbox_regression: 0.0505 (0.0505)  classification: 0.3191 (0.3191)\n",
            "Epoch: [34] [ 20/289]  eta: 0:00:22  time: 0.0821  loss: 0.3702 (0.3809)  bbox_regression: 0.0437 (0.0447)  classification: 0.3265 (0.3363)\n",
            "Epoch: [34] [ 30/289]  eta: 0:00:21  time: 0.0820  loss: 0.3766 (0.3804)  bbox_regression: 0.0408 (0.0354)  classification: 0.3358 (0.3450)\n",
            "Epoch: [34] [ 40/289]  eta: 0:00:20  time: 0.0813  loss: 0.3642 (0.3579)  bbox_regression: 0.0422 (0.0406)  classification: 0.3220 (0.3173)\n",
            "Epoch: [34] [ 50/289]  eta: 0:00:19  time: 0.0813  loss: 0.3415 (0.2870)  bbox_regression: 0.0391 (0.0366)  classification: 0.3023 (0.2504)\n",
            "Epoch: [34] [ 60/289]  eta: 0:00:18  time: 0.0814  loss: 0.3579 (0.3451)  bbox_regression: 0.0486 (0.0617)  classification: 0.3093 (0.2834)\n",
            "Epoch: [34] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 0.3659 (0.4283)  bbox_regression: 0.0485 (0.0724)  classification: 0.3174 (0.3559)\n",
            "Epoch: [34] [ 80/289]  eta: 0:00:17  time: 0.0815  loss: 0.3610 (0.3704)  bbox_regression: 0.0468 (0.0414)  classification: 0.3142 (0.3290)\n",
            "Epoch: [34] [ 90/289]  eta: 0:00:16  time: 0.0814  loss: 0.3477 (0.2829)  bbox_regression: 0.0456 (0.0354)  classification: 0.3021 (0.2476)\n",
            "Epoch: [34] [100/289]  eta: 0:00:15  time: 0.0817  loss: 0.3560 (0.3357)  bbox_regression: 0.0487 (0.0560)  classification: 0.3074 (0.2797)\n",
            "Epoch: [34] [110/289]  eta: 0:00:14  time: 0.0814  loss: 0.3571 (0.4000)  bbox_regression: 0.0497 (0.0683)  classification: 0.3074 (0.3317)\n",
            "Epoch: [34] [120/289]  eta: 0:00:13  time: 0.0816  loss: 0.3531 (0.3385)  bbox_regression: 0.0487 (0.0489)  classification: 0.3044 (0.2897)\n",
            "Epoch: [34] [130/289]  eta: 0:00:12  time: 0.0815  loss: 0.3610 (0.3828)  bbox_regression: 0.0498 (0.0505)  classification: 0.3112 (0.3322)\n",
            "Epoch: [34] [140/289]  eta: 0:00:12  time: 0.0813  loss: 0.3622 (0.4173)  bbox_regression: 0.0483 (0.0456)  classification: 0.3140 (0.3717)\n",
            "Epoch: [34] [150/289]  eta: 0:00:11  time: 0.0816  loss: 0.3574 (0.3338)  bbox_regression: 0.0483 (0.0386)  classification: 0.3091 (0.2952)\n",
            "Epoch: [34] [160/289]  eta: 0:00:10  time: 0.0817  loss: 0.3619 (0.3597)  bbox_regression: 0.0526 (0.0831)  classification: 0.3093 (0.2766)\n",
            "Epoch: [34] [170/289]  eta: 0:00:09  time: 0.0821  loss: 0.3616 (0.3932)  bbox_regression: 0.0525 (0.0835)  classification: 0.3092 (0.3097)\n",
            "Epoch: [34] [180/289]  eta: 0:00:08  time: 0.0821  loss: 0.3577 (0.3237)  bbox_regression: 0.0514 (0.0418)  classification: 0.3063 (0.2819)\n",
            "Epoch: [34] [190/289]  eta: 0:00:08  time: 0.0824  loss: 0.3570 (0.3176)  bbox_regression: 0.0518 (0.0463)  classification: 0.3052 (0.2712)\n",
            "Epoch: [34] [200/289]  eta: 0:00:07  time: 0.0824  loss: 0.3596 (0.3773)  bbox_regression: 0.0518 (0.0558)  classification: 0.3078 (0.3215)\n",
            "Epoch: [34] [210/289]  eta: 0:00:06  time: 0.0824  loss: 0.3540 (0.3257)  bbox_regression: 0.0513 (0.0463)  classification: 0.3027 (0.2794)\n",
            "Epoch: [34] [220/289]  eta: 0:00:05  time: 0.0824  loss: 0.3586 (0.3486)  bbox_regression: 0.0518 (0.0515)  classification: 0.3068 (0.2970)\n",
            "Epoch: [34] [230/289]  eta: 0:00:04  time: 0.0822  loss: 0.3531 (0.3438)  bbox_regression: 0.0508 (0.0455)  classification: 0.3024 (0.2983)\n",
            "Epoch: [34] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.3602 (0.3770)  bbox_regression: 0.0511 (0.0432)  classification: 0.3091 (0.3338)\n",
            "Epoch: [34] [250/289]  eta: 0:00:03  time: 0.0820  loss: 0.3572 (0.4041)  bbox_regression: 0.0504 (0.0464)  classification: 0.3068 (0.3577)\n",
            "Epoch: [34] [260/289]  eta: 0:00:02  time: 0.0821  loss: 0.3575 (0.3260)  bbox_regression: 0.0510 (0.0494)  classification: 0.3066 (0.2766)\n",
            "Epoch: [34] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.3549 (0.3262)  bbox_regression: 0.0506 (0.0529)  classification: 0.3043 (0.2733)\n",
            "Epoch: [34] [280/289]  eta: 0:00:00  time: 0.0820  loss: 0.3609 (0.4048)  bbox_regression: 0.0500 (0.0381)  classification: 0.3109 (0.3667)\n",
            "Epoch: [34] [288/289]  eta: 0:00:00  time: 0.0819  loss: 0.3612 (0.4547)  bbox_regression: 0.0493 (0.0367)  classification: 0.3119 (0.4180)\n",
            "Epoch: [34] Time: 0:00:23 (0.0819 s / it)\n",
            "Validation: [34]\n",
            "Validation: [34] [ 0/62]  eta: 0:00:04  time: 0.0706  \n",
            "Validation: [34] [10/62]  eta: 0:00:03  time: 0.0693  \n",
            "Validation: [34] [20/62]  eta: 0:00:02  time: 0.0684  \n",
            "Validation: [34] [30/62]  eta: 0:00:02  time: 0.0695  \n",
            "Validation: [34] [40/62]  eta: 0:00:01  time: 0.0701  \n",
            "Validation: [34] [50/62]  eta: 0:00:00  time: 0.0702  \n",
            "Validation: [34] [60/62]  eta: 0:00:00  time: 0.0702  \n",
            "Validation: [34] [61/62]  eta: 0:00:00  time: 0.0697  \n",
            "Validation: [34] Time: 0:00:04 (0.0698 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_35/mAP_vs_threshold_epoch_34.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_35/pr_curves_epoch_34.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_35/per_class_ap_epoch_34.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_35/confusion_matrix_epoch_34.png\n",
            "Epoch 34: mAP@0.5 = 0.4993\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6203\n",
            "  Bacterial-Black-spot: 0.5951\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.2810\n",
            "  Mechanical-damage: 0.7000\n",
            "  Others: 0.7993\n",
            "Copied mAP_vs_threshold_epoch_34.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/mAP_vs_threshold_epoch_34.csv\n",
            "Copied per_class_mAP_epoch_34.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/per_class_mAP_epoch_34.csv\n",
            "Copied per_class_ap_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/per_class_ap_epoch_34.png\n",
            "Copied confusion_matrix_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/confusion_matrix_epoch_34.png\n",
            "Copied mAP_vs_threshold_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/mAP_vs_threshold_epoch_34.png\n",
            "Copied pr_curves_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/pr_curves_epoch_34.png\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [35]\n",
            "Epoch: [35] [  0/289]  eta: 0:00:24  time: 0.0843  loss: 0.6742 (0.6742)  bbox_regression: 0.0471 (0.0471)  classification: 0.6271 (0.6271)\n",
            "Epoch: [35] [ 10/289]  eta: 0:00:23  time: 0.0830  loss: 0.3779 (0.3779)  bbox_regression: 0.0511 (0.0511)  classification: 0.3268 (0.3268)\n",
            "Epoch: [35] [ 20/289]  eta: 0:00:22  time: 0.0825  loss: 0.4051 (0.3917)  bbox_regression: 0.0588 (0.0594)  classification: 0.3463 (0.3323)\n",
            "Epoch: [35] [ 30/289]  eta: 0:00:21  time: 0.0827  loss: 0.3815 (0.3835)  bbox_regression: 0.0535 (0.0548)  classification: 0.3280 (0.3287)\n",
            "Epoch: [35] [ 40/289]  eta: 0:00:20  time: 0.0825  loss: 0.3828 (0.3594)  bbox_regression: 0.0534 (0.0478)  classification: 0.3294 (0.3116)\n",
            "Epoch: [35] [ 50/289]  eta: 0:00:19  time: 0.0823  loss: 0.3626 (0.3334)  bbox_regression: 0.0512 (0.0478)  classification: 0.3114 (0.2856)\n",
            "Epoch: [35] [ 60/289]  eta: 0:00:18  time: 0.0824  loss: 0.3557 (0.3001)  bbox_regression: 0.0494 (0.0412)  classification: 0.3063 (0.2590)\n",
            "Epoch: [35] [ 70/289]  eta: 0:00:18  time: 0.0829  loss: 0.3559 (0.3387)  bbox_regression: 0.0478 (0.0389)  classification: 0.3081 (0.2998)\n",
            "Epoch: [35] [ 80/289]  eta: 0:00:17  time: 0.0830  loss: 0.3488 (0.3277)  bbox_regression: 0.0463 (0.0368)  classification: 0.3025 (0.2909)\n",
            "Epoch: [35] [ 90/289]  eta: 0:00:16  time: 0.0835  loss: 0.3491 (0.3250)  bbox_regression: 0.0458 (0.0390)  classification: 0.3033 (0.2860)\n",
            "Epoch: [35] [100/289]  eta: 0:00:15  time: 0.0833  loss: 0.3568 (0.3892)  bbox_regression: 0.0482 (0.0562)  classification: 0.3086 (0.3331)\n",
            "Epoch: [35] [110/289]  eta: 0:00:14  time: 0.0830  loss: 0.3479 (0.3424)  bbox_regression: 0.0469 (0.0519)  classification: 0.3010 (0.2905)\n",
            "Epoch: [35] [120/289]  eta: 0:00:14  time: 0.0832  loss: 0.3505 (0.3186)  bbox_regression: 0.0521 (0.0719)  classification: 0.2983 (0.2468)\n",
            "Epoch: [35] [130/289]  eta: 0:00:13  time: 0.0831  loss: 0.3451 (0.3294)  bbox_regression: 0.0514 (0.0760)  classification: 0.2937 (0.2534)\n",
            "Epoch: [35] [140/289]  eta: 0:00:12  time: 0.0830  loss: 0.3459 (0.3180)  bbox_regression: 0.0513 (0.0464)  classification: 0.2946 (0.2716)\n",
            "Epoch: [35] [150/289]  eta: 0:00:11  time: 0.0827  loss: 0.3454 (0.3475)  bbox_regression: 0.0501 (0.0415)  classification: 0.2953 (0.3060)\n",
            "Epoch: [35] [160/289]  eta: 0:00:10  time: 0.0827  loss: 0.3373 (0.2769)  bbox_regression: 0.0495 (0.0365)  classification: 0.2878 (0.2404)\n",
            "Epoch: [35] [170/289]  eta: 0:00:09  time: 0.0825  loss: 0.3407 (0.3055)  bbox_regression: 0.0500 (0.0497)  classification: 0.2907 (0.2558)\n",
            "Epoch: [35] [180/289]  eta: 0:00:09  time: 0.0826  loss: 0.3415 (0.3753)  bbox_regression: 0.0489 (0.0438)  classification: 0.2927 (0.3314)\n",
            "Epoch: [35] [190/289]  eta: 0:00:08  time: 0.0825  loss: 0.3408 (0.3413)  bbox_regression: 0.0485 (0.0358)  classification: 0.2923 (0.3055)\n",
            "Epoch: [35] [200/289]  eta: 0:00:07  time: 0.0825  loss: 0.3455 (0.3815)  bbox_regression: 0.0479 (0.0396)  classification: 0.2976 (0.3419)\n",
            "Epoch: [35] [210/289]  eta: 0:00:06  time: 0.0826  loss: 0.3498 (0.4360)  bbox_regression: 0.0493 (0.0569)  classification: 0.3005 (0.3791)\n",
            "Epoch: [35] [220/289]  eta: 0:00:05  time: 0.0829  loss: 0.3505 (0.4007)  bbox_regression: 0.0494 (0.0640)  classification: 0.3011 (0.3368)\n",
            "Epoch: [35] [230/289]  eta: 0:00:04  time: 0.0829  loss: 0.3495 (0.3464)  bbox_regression: 0.0492 (0.0478)  classification: 0.3003 (0.2986)\n",
            "Epoch: [35] [240/289]  eta: 0:00:04  time: 0.0830  loss: 0.3465 (0.3027)  bbox_regression: 0.0486 (0.0402)  classification: 0.2979 (0.2624)\n",
            "Epoch: [35] [250/289]  eta: 0:00:03  time: 0.0831  loss: 0.3445 (0.2863)  bbox_regression: 0.0486 (0.0415)  classification: 0.2959 (0.2448)\n",
            "Epoch: [35] [260/289]  eta: 0:00:02  time: 0.0829  loss: 0.3436 (0.3083)  bbox_regression: 0.0486 (0.0483)  classification: 0.2950 (0.2600)\n",
            "Epoch: [35] [270/289]  eta: 0:00:01  time: 0.0827  loss: 0.3550 (0.4868)  bbox_regression: 0.0518 (0.0918)  classification: 0.3032 (0.3951)\n",
            "Epoch: [35] [280/289]  eta: 0:00:00  time: 0.0826  loss: 0.3522 (0.4639)  bbox_regression: 0.0513 (0.0860)  classification: 0.3009 (0.3779)\n",
            "Epoch: [35] [288/289]  eta: 0:00:00  time: 0.0824  loss: 0.3519 (0.3824)  bbox_regression: 0.0507 (0.0757)  classification: 0.3012 (0.3068)\n",
            "Epoch: [35] Time: 0:00:23 (0.0825 s / it)\n",
            "Epoch: [36]\n",
            "Epoch: [36] [  0/289]  eta: 0:00:23  time: 0.0810  loss: 0.1876 (0.1876)  bbox_regression: 0.0245 (0.0245)  classification: 0.1631 (0.1631)\n",
            "Epoch: [36] [ 10/289]  eta: 0:00:21  time: 0.0787  loss: 0.2952 (0.2952)  bbox_regression: 0.0520 (0.0520)  classification: 0.2432 (0.2432)\n",
            "Epoch: [36] [ 20/289]  eta: 0:00:21  time: 0.0790  loss: 0.2981 (0.3036)  bbox_regression: 0.0513 (0.0526)  classification: 0.2468 (0.2510)\n",
            "Epoch: [36] [ 30/289]  eta: 0:00:20  time: 0.0799  loss: 0.3095 (0.3174)  bbox_regression: 0.0524 (0.0526)  classification: 0.2571 (0.2648)\n",
            "Epoch: [36] [ 40/289]  eta: 0:00:19  time: 0.0798  loss: 0.2954 (0.2926)  bbox_regression: 0.0487 (0.0460)  classification: 0.2467 (0.2466)\n",
            "Epoch: [36] [ 50/289]  eta: 0:00:19  time: 0.0803  loss: 0.2902 (0.2604)  bbox_regression: 0.0450 (0.0335)  classification: 0.2453 (0.2269)\n",
            "Epoch: [36] [ 60/289]  eta: 0:00:18  time: 0.0800  loss: 0.2973 (0.3011)  bbox_regression: 0.0445 (0.0357)  classification: 0.2528 (0.2654)\n",
            "Epoch: [36] [ 70/289]  eta: 0:00:17  time: 0.0804  loss: 0.2955 (0.3089)  bbox_regression: 0.0453 (0.0460)  classification: 0.2502 (0.2629)\n",
            "Epoch: [36] [ 80/289]  eta: 0:00:16  time: 0.0808  loss: 0.2941 (0.2846)  bbox_regression: 0.0446 (0.0450)  classification: 0.2496 (0.2396)\n",
            "Epoch: [36] [ 90/289]  eta: 0:00:16  time: 0.0809  loss: 0.2960 (0.2977)  bbox_regression: 0.0454 (0.0459)  classification: 0.2506 (0.2518)\n",
            "Epoch: [36] [100/289]  eta: 0:00:15  time: 0.0816  loss: 0.2954 (0.3004)  bbox_regression: 0.0437 (0.0403)  classification: 0.2516 (0.2601)\n",
            "Epoch: [36] [110/289]  eta: 0:00:14  time: 0.0813  loss: 0.3042 (0.3417)  bbox_regression: 0.0458 (0.0478)  classification: 0.2584 (0.2939)\n",
            "Epoch: [36] [120/289]  eta: 0:00:13  time: 0.0813  loss: 0.3216 (0.4540)  bbox_regression: 0.0479 (0.0689)  classification: 0.2737 (0.3851)\n",
            "Epoch: [36] [130/289]  eta: 0:00:12  time: 0.0814  loss: 0.3271 (0.4543)  bbox_regression: 0.0478 (0.0588)  classification: 0.2793 (0.3956)\n",
            "Epoch: [36] [140/289]  eta: 0:00:12  time: 0.0813  loss: 0.3229 (0.3306)  bbox_regression: 0.0471 (0.0422)  classification: 0.2758 (0.2885)\n",
            "Epoch: [36] [150/289]  eta: 0:00:11  time: 0.0814  loss: 0.3275 (0.3301)  bbox_regression: 0.0484 (0.0521)  classification: 0.2792 (0.2780)\n",
            "Epoch: [36] [160/289]  eta: 0:00:10  time: 0.0814  loss: 0.3249 (0.3388)  bbox_regression: 0.0477 (0.0521)  classification: 0.2772 (0.2867)\n",
            "Epoch: [36] [170/289]  eta: 0:00:09  time: 0.0816  loss: 0.3231 (0.2895)  bbox_regression: 0.0478 (0.0435)  classification: 0.2753 (0.2459)\n",
            "Epoch: [36] [180/289]  eta: 0:00:08  time: 0.0816  loss: 0.3319 (0.3887)  bbox_regression: 0.0474 (0.0451)  classification: 0.2845 (0.3436)\n",
            "Epoch: [36] [190/289]  eta: 0:00:08  time: 0.0818  loss: 0.3296 (0.3854)  bbox_regression: 0.0479 (0.0482)  classification: 0.2818 (0.3372)\n",
            "Epoch: [36] [200/289]  eta: 0:00:07  time: 0.0817  loss: 0.3356 (0.3686)  bbox_regression: 0.0488 (0.0617)  classification: 0.2867 (0.3069)\n",
            "Epoch: [36] [210/289]  eta: 0:00:06  time: 0.0820  loss: 0.3293 (0.3265)  bbox_regression: 0.0485 (0.0546)  classification: 0.2808 (0.2719)\n",
            "Epoch: [36] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.3298 (0.2717)  bbox_regression: 0.0492 (0.0523)  classification: 0.2806 (0.2194)\n",
            "Epoch: [36] [230/289]  eta: 0:00:04  time: 0.0821  loss: 0.3282 (0.3160)  bbox_regression: 0.0487 (0.0510)  classification: 0.2795 (0.2650)\n",
            "Epoch: [36] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.3286 (0.3160)  bbox_regression: 0.0487 (0.0436)  classification: 0.2800 (0.2725)\n",
            "Epoch: [36] [250/289]  eta: 0:00:03  time: 0.0820  loss: 0.3280 (0.3260)  bbox_regression: 0.0481 (0.0415)  classification: 0.2799 (0.2845)\n",
            "Epoch: [36] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.3277 (0.3168)  bbox_regression: 0.0475 (0.0336)  classification: 0.2802 (0.2832)\n",
            "Epoch: [36] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.3305 (0.3623)  bbox_regression: 0.0471 (0.0335)  classification: 0.2835 (0.3288)\n",
            "Epoch: [36] [280/289]  eta: 0:00:00  time: 0.0820  loss: 0.3315 (0.3805)  bbox_regression: 0.0470 (0.0397)  classification: 0.2845 (0.3408)\n",
            "Epoch: [36] [288/289]  eta: 0:00:00  time: 0.0818  loss: 0.3411 (0.4890)  bbox_regression: 0.0502 (0.0900)  classification: 0.2909 (0.3990)\n",
            "Epoch: [36] Time: 0:00:23 (0.0818 s / it)\n",
            "Epoch: [37]\n",
            "Epoch: [37] [  0/289]  eta: 0:00:21  time: 0.0749  loss: 0.3643 (0.3643)  bbox_regression: 0.0312 (0.0312)  classification: 0.3330 (0.3330)\n",
            "Epoch: [37] [ 10/289]  eta: 0:00:22  time: 0.0814  loss: 0.3517 (0.3517)  bbox_regression: 0.0623 (0.0623)  classification: 0.2894 (0.2894)\n",
            "Epoch: [37] [ 20/289]  eta: 0:00:22  time: 0.0820  loss: 0.4026 (0.4046)  bbox_regression: 0.0681 (0.0700)  classification: 0.3345 (0.3346)\n",
            "Epoch: [37] [ 30/289]  eta: 0:00:21  time: 0.0821  loss: 0.3536 (0.3547)  bbox_regression: 0.0545 (0.0502)  classification: 0.2991 (0.3045)\n",
            "Epoch: [37] [ 40/289]  eta: 0:00:20  time: 0.0823  loss: 0.3501 (0.2950)  bbox_regression: 0.0507 (0.0325)  classification: 0.2994 (0.2625)\n",
            "Epoch: [37] [ 50/289]  eta: 0:00:19  time: 0.0821  loss: 0.3548 (0.3567)  bbox_regression: 0.0539 (0.0528)  classification: 0.3010 (0.3038)\n",
            "Epoch: [37] [ 60/289]  eta: 0:00:18  time: 0.0816  loss: 0.3411 (0.3225)  bbox_regression: 0.0514 (0.0529)  classification: 0.2897 (0.2697)\n",
            "Epoch: [37] [ 70/289]  eta: 0:00:17  time: 0.0818  loss: 0.3567 (0.3614)  bbox_regression: 0.0497 (0.0392)  classification: 0.3069 (0.3222)\n",
            "Epoch: [37] [ 80/289]  eta: 0:00:17  time: 0.0818  loss: 0.3689 (0.4535)  bbox_regression: 0.0627 (0.0970)  classification: 0.3062 (0.3566)\n",
            "Epoch: [37] [ 90/289]  eta: 0:00:16  time: 0.0820  loss: 0.3733 (0.4325)  bbox_regression: 0.0625 (0.1078)  classification: 0.3108 (0.3247)\n",
            "Epoch: [37] [100/289]  eta: 0:00:15  time: 0.0823  loss: 0.3624 (0.3362)  bbox_regression: 0.0626 (0.0625)  classification: 0.2997 (0.2737)\n",
            "Epoch: [37] [110/289]  eta: 0:00:14  time: 0.0830  loss: 0.3555 (0.2745)  bbox_regression: 0.0615 (0.0570)  classification: 0.2940 (0.2175)\n",
            "Epoch: [37] [120/289]  eta: 0:00:14  time: 0.0831  loss: 0.3509 (0.2927)  bbox_regression: 0.0603 (0.0487)  classification: 0.2905 (0.2440)\n",
            "Epoch: [37] [130/289]  eta: 0:00:13  time: 0.0831  loss: 0.3531 (0.3399)  bbox_regression: 0.0598 (0.0501)  classification: 0.2934 (0.2898)\n",
            "Epoch: [37] [140/289]  eta: 0:00:12  time: 0.0830  loss: 0.3525 (0.3626)  bbox_regression: 0.0580 (0.0440)  classification: 0.2945 (0.3186)\n",
            "Epoch: [37] [150/289]  eta: 0:00:11  time: 0.0828  loss: 0.3467 (0.3046)  bbox_regression: 0.0570 (0.0386)  classification: 0.2897 (0.2660)\n",
            "Epoch: [37] [160/289]  eta: 0:00:10  time: 0.0826  loss: 0.3385 (0.2396)  bbox_regression: 0.0555 (0.0379)  classification: 0.2830 (0.2017)\n",
            "Epoch: [37] [170/289]  eta: 0:00:09  time: 0.0824  loss: 0.3352 (0.2482)  bbox_regression: 0.0550 (0.0400)  classification: 0.2802 (0.2082)\n",
            "Epoch: [37] [180/289]  eta: 0:00:08  time: 0.0823  loss: 0.3296 (0.2577)  bbox_regression: 0.0538 (0.0397)  classification: 0.2758 (0.2180)\n",
            "Epoch: [37] [190/289]  eta: 0:00:08  time: 0.0823  loss: 0.3364 (0.3470)  bbox_regression: 0.0543 (0.0486)  classification: 0.2821 (0.2985)\n",
            "Epoch: [37] [200/289]  eta: 0:00:07  time: 0.0823  loss: 0.3365 (0.3994)  bbox_regression: 0.0535 (0.0514)  classification: 0.2830 (0.3479)\n",
            "Epoch: [37] [210/289]  eta: 0:00:06  time: 0.0822  loss: 0.3348 (0.3190)  bbox_regression: 0.0532 (0.0423)  classification: 0.2816 (0.2766)\n",
            "Epoch: [37] [220/289]  eta: 0:00:05  time: 0.0822  loss: 0.3395 (0.3696)  bbox_regression: 0.0525 (0.0424)  classification: 0.2870 (0.3272)\n",
            "Epoch: [37] [230/289]  eta: 0:00:04  time: 0.0823  loss: 0.3409 (0.4049)  bbox_regression: 0.0522 (0.0420)  classification: 0.2886 (0.3629)\n",
            "Epoch: [37] [240/289]  eta: 0:00:04  time: 0.0824  loss: 0.3387 (0.3292)  bbox_regression: 0.0516 (0.0408)  classification: 0.2871 (0.2884)\n",
            "Epoch: [37] [250/289]  eta: 0:00:03  time: 0.0824  loss: 0.3355 (0.2739)  bbox_regression: 0.0517 (0.0454)  classification: 0.2839 (0.2285)\n",
            "Epoch: [37] [260/289]  eta: 0:00:02  time: 0.0823  loss: 0.3312 (0.2411)  bbox_regression: 0.0508 (0.0414)  classification: 0.2804 (0.1997)\n",
            "Epoch: [37] [270/289]  eta: 0:00:01  time: 0.0823  loss: 0.3327 (0.2979)  bbox_regression: 0.0508 (0.0395)  classification: 0.2820 (0.2584)\n",
            "Epoch: [37] [280/289]  eta: 0:00:00  time: 0.0823  loss: 0.3292 (0.3030)  bbox_regression: 0.0501 (0.0410)  classification: 0.2791 (0.2620)\n",
            "Epoch: [37] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.3276 (0.2630)  bbox_regression: 0.0495 (0.0349)  classification: 0.2781 (0.2281)\n",
            "Epoch: [37] Time: 0:00:23 (0.0822 s / it)\n",
            "Epoch: [38]\n",
            "Epoch: [38] [  0/289]  eta: 0:00:23  time: 0.0815  loss: 0.1361 (0.1361)  bbox_regression: 0.0413 (0.0413)  classification: 0.0948 (0.0948)\n",
            "Epoch: [38] [ 10/289]  eta: 0:00:22  time: 0.0811  loss: 0.3498 (0.3498)  bbox_regression: 0.0381 (0.0381)  classification: 0.3117 (0.3117)\n",
            "Epoch: [38] [ 20/289]  eta: 0:00:21  time: 0.0817  loss: 0.2866 (0.2941)  bbox_regression: 0.0406 (0.0406)  classification: 0.2460 (0.2535)\n",
            "Epoch: [38] [ 30/289]  eta: 0:00:21  time: 0.0811  loss: 0.2975 (0.2687)  bbox_regression: 0.0476 (0.0527)  classification: 0.2499 (0.2159)\n",
            "Epoch: [38] [ 40/289]  eta: 0:00:20  time: 0.0812  loss: 0.2959 (0.3056)  bbox_regression: 0.0441 (0.0478)  classification: 0.2517 (0.2578)\n",
            "Epoch: [38] [ 50/289]  eta: 0:00:19  time: 0.0814  loss: 0.2972 (0.2969)  bbox_regression: 0.0444 (0.0395)  classification: 0.2528 (0.2573)\n",
            "Epoch: [38] [ 60/289]  eta: 0:00:18  time: 0.0811  loss: 0.2989 (0.3052)  bbox_regression: 0.0436 (0.0424)  classification: 0.2554 (0.2628)\n",
            "Epoch: [38] [ 70/289]  eta: 0:00:17  time: 0.0809  loss: 0.3198 (0.3774)  bbox_regression: 0.0545 (0.0804)  classification: 0.2653 (0.2970)\n",
            "Epoch: [38] [ 80/289]  eta: 0:00:16  time: 0.0806  loss: 0.3190 (0.3803)  bbox_regression: 0.0528 (0.0810)  classification: 0.2662 (0.2993)\n",
            "Epoch: [38] [ 90/289]  eta: 0:00:16  time: 0.0805  loss: 0.3180 (0.3113)  bbox_regression: 0.0540 (0.0523)  classification: 0.2639 (0.2590)\n",
            "Epoch: [38] [100/289]  eta: 0:00:15  time: 0.0809  loss: 0.3204 (0.3259)  bbox_regression: 0.0528 (0.0527)  classification: 0.2676 (0.2733)\n",
            "Epoch: [38] [110/289]  eta: 0:00:14  time: 0.0809  loss: 0.3196 (0.3274)  bbox_regression: 0.0510 (0.0369)  classification: 0.2687 (0.2904)\n",
            "Epoch: [38] [120/289]  eta: 0:00:13  time: 0.0811  loss: 0.3290 (0.3723)  bbox_regression: 0.0524 (0.0507)  classification: 0.2765 (0.3216)\n",
            "Epoch: [38] [130/289]  eta: 0:00:12  time: 0.0811  loss: 0.3297 (0.3852)  bbox_regression: 0.0531 (0.0647)  classification: 0.2766 (0.3205)\n",
            "Epoch: [38] [140/289]  eta: 0:00:12  time: 0.0811  loss: 0.3371 (0.3865)  bbox_regression: 0.0546 (0.0680)  classification: 0.2825 (0.3185)\n",
            "Epoch: [38] [150/289]  eta: 0:00:11  time: 0.0811  loss: 0.3320 (0.3475)  bbox_regression: 0.0535 (0.0561)  classification: 0.2786 (0.2914)\n",
            "Epoch: [38] [160/289]  eta: 0:00:10  time: 0.0812  loss: 0.3303 (0.2824)  bbox_regression: 0.0525 (0.0372)  classification: 0.2779 (0.2452)\n",
            "Epoch: [38] [170/289]  eta: 0:00:09  time: 0.0813  loss: 0.3206 (0.2341)  bbox_regression: 0.0510 (0.0326)  classification: 0.2695 (0.2015)\n",
            "Epoch: [38] [180/289]  eta: 0:00:08  time: 0.0815  loss: 0.3199 (0.2356)  bbox_regression: 0.0507 (0.0363)  classification: 0.2692 (0.1993)\n",
            "Epoch: [38] [190/289]  eta: 0:00:08  time: 0.0815  loss: 0.3170 (0.2865)  bbox_regression: 0.0500 (0.0412)  classification: 0.2670 (0.2454)\n",
            "Epoch: [38] [200/289]  eta: 0:00:07  time: 0.0816  loss: 0.3171 (0.2918)  bbox_regression: 0.0495 (0.0389)  classification: 0.2676 (0.2528)\n",
            "Epoch: [38] [210/289]  eta: 0:00:06  time: 0.0815  loss: 0.3116 (0.2600)  bbox_regression: 0.0487 (0.0361)  classification: 0.2629 (0.2239)\n",
            "Epoch: [38] [220/289]  eta: 0:00:05  time: 0.0817  loss: 0.3115 (0.2555)  bbox_regression: 0.0495 (0.0492)  classification: 0.2620 (0.2064)\n",
            "Epoch: [38] [230/289]  eta: 0:00:04  time: 0.0818  loss: 0.3102 (0.2957)  bbox_regression: 0.0498 (0.0618)  classification: 0.2604 (0.2340)\n",
            "Epoch: [38] [240/289]  eta: 0:00:04  time: 0.0819  loss: 0.3092 (0.2841)  bbox_regression: 0.0497 (0.0527)  classification: 0.2595 (0.2314)\n",
            "Epoch: [38] [250/289]  eta: 0:00:03  time: 0.0818  loss: 0.3151 (0.3711)  bbox_regression: 0.0509 (0.0634)  classification: 0.2642 (0.3078)\n",
            "Epoch: [38] [260/289]  eta: 0:00:02  time: 0.0819  loss: 0.3160 (0.3982)  bbox_regression: 0.0508 (0.0635)  classification: 0.2652 (0.3347)\n",
            "Epoch: [38] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.3164 (0.3330)  bbox_regression: 0.0507 (0.0488)  classification: 0.2657 (0.2841)\n",
            "Epoch: [38] [280/289]  eta: 0:00:00  time: 0.0819  loss: 0.3192 (0.3606)  bbox_regression: 0.0510 (0.0534)  classification: 0.2682 (0.3071)\n",
            "Epoch: [38] [288/289]  eta: 0:00:00  time: 0.0817  loss: 0.3207 (0.3679)  bbox_regression: 0.0509 (0.0508)  classification: 0.2698 (0.3170)\n",
            "Epoch: [38] Time: 0:00:23 (0.0817 s / it)\n",
            "Epoch: [39]\n",
            "Epoch: [39] [  0/289]  eta: 0:00:25  time: 0.0873  loss: 0.3860 (0.3860)  bbox_regression: 0.0285 (0.0285)  classification: 0.3575 (0.3575)\n",
            "Epoch: [39] [ 10/289]  eta: 0:00:22  time: 0.0791  loss: 0.2673 (0.2673)  bbox_regression: 0.0386 (0.0386)  classification: 0.2286 (0.2286)\n",
            "Epoch: [39] [ 20/289]  eta: 0:00:21  time: 0.0798  loss: 0.3291 (0.3262)  bbox_regression: 0.0445 (0.0453)  classification: 0.2846 (0.2810)\n",
            "Epoch: [39] [ 30/289]  eta: 0:00:20  time: 0.0799  loss: 0.3194 (0.3481)  bbox_regression: 0.0496 (0.0557)  classification: 0.2698 (0.2924)\n",
            "Epoch: [39] [ 40/289]  eta: 0:00:19  time: 0.0795  loss: 0.2939 (0.2570)  bbox_regression: 0.0454 (0.0464)  classification: 0.2485 (0.2106)\n",
            "Epoch: [39] [ 50/289]  eta: 0:00:19  time: 0.0804  loss: 0.2977 (0.2641)  bbox_regression: 0.0439 (0.0349)  classification: 0.2538 (0.2292)\n",
            "Epoch: [39] [ 60/289]  eta: 0:00:18  time: 0.0806  loss: 0.3166 (0.3632)  bbox_regression: 0.0505 (0.0608)  classification: 0.2662 (0.3024)\n",
            "Epoch: [39] [ 70/289]  eta: 0:00:17  time: 0.0807  loss: 0.3092 (0.3385)  bbox_regression: 0.0481 (0.0587)  classification: 0.2612 (0.2798)\n",
            "Epoch: [39] [ 80/289]  eta: 0:00:16  time: 0.0808  loss: 0.3070 (0.2776)  bbox_regression: 0.0486 (0.0429)  classification: 0.2584 (0.2347)\n",
            "Epoch: [39] [ 90/289]  eta: 0:00:16  time: 0.0812  loss: 0.3066 (0.2973)  bbox_regression: 0.0497 (0.0557)  classification: 0.2569 (0.2416)\n",
            "Epoch: [39] [100/289]  eta: 0:00:15  time: 0.0813  loss: 0.3030 (0.2866)  bbox_regression: 0.0491 (0.0512)  classification: 0.2539 (0.2355)\n",
            "Epoch: [39] [110/289]  eta: 0:00:14  time: 0.0815  loss: 0.3079 (0.3136)  bbox_regression: 0.0500 (0.0510)  classification: 0.2579 (0.2626)\n",
            "Epoch: [39] [120/289]  eta: 0:00:13  time: 0.0817  loss: 0.3115 (0.3548)  bbox_regression: 0.0524 (0.0691)  classification: 0.2591 (0.2857)\n",
            "Epoch: [39] [130/289]  eta: 0:00:13  time: 0.0818  loss: 0.3193 (0.3831)  bbox_regression: 0.0549 (0.0825)  classification: 0.2644 (0.3006)\n",
            "Epoch: [39] [140/289]  eta: 0:00:12  time: 0.0822  loss: 0.3211 (0.3790)  bbox_regression: 0.0544 (0.0663)  classification: 0.2667 (0.3127)\n",
            "Epoch: [39] [150/289]  eta: 0:00:11  time: 0.0820  loss: 0.3185 (0.3128)  bbox_regression: 0.0531 (0.0415)  classification: 0.2653 (0.2712)\n",
            "Epoch: [39] [160/289]  eta: 0:00:10  time: 0.0819  loss: 0.3163 (0.2822)  bbox_regression: 0.0523 (0.0380)  classification: 0.2639 (0.2442)\n",
            "Epoch: [39] [170/289]  eta: 0:00:09  time: 0.0818  loss: 0.3188 (0.3214)  bbox_regression: 0.0521 (0.0442)  classification: 0.2667 (0.2772)\n",
            "Epoch: [39] [180/289]  eta: 0:00:08  time: 0.0820  loss: 0.3138 (0.2941)  bbox_regression: 0.0506 (0.0366)  classification: 0.2632 (0.2575)\n",
            "Epoch: [39] [190/289]  eta: 0:00:08  time: 0.0820  loss: 0.3124 (0.2578)  bbox_regression: 0.0501 (0.0327)  classification: 0.2623 (0.2250)\n",
            "Epoch: [39] [200/289]  eta: 0:00:07  time: 0.0819  loss: 0.3106 (0.2818)  bbox_regression: 0.0499 (0.0436)  classification: 0.2607 (0.2382)\n",
            "Epoch: [39] [210/289]  eta: 0:00:06  time: 0.0818  loss: 0.3085 (0.2707)  bbox_regression: 0.0492 (0.0407)  classification: 0.2593 (0.2300)\n",
            "Epoch: [39] [220/289]  eta: 0:00:05  time: 0.0818  loss: 0.3143 (0.3512)  bbox_regression: 0.0503 (0.0539)  classification: 0.2640 (0.2973)\n",
            "Epoch: [39] [230/289]  eta: 0:00:04  time: 0.0818  loss: 0.3173 (0.4102)  bbox_regression: 0.0505 (0.0646)  classification: 0.2668 (0.3456)\n",
            "Epoch: [39] [240/289]  eta: 0:00:04  time: 0.0818  loss: 0.3157 (0.3310)  bbox_regression: 0.0498 (0.0447)  classification: 0.2659 (0.2863)\n",
            "Epoch: [39] [250/289]  eta: 0:00:03  time: 0.0819  loss: 0.3204 (0.3566)  bbox_regression: 0.0529 (0.0803)  classification: 0.2675 (0.2763)\n",
            "Epoch: [39] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.3173 (0.3368)  bbox_regression: 0.0524 (0.0840)  classification: 0.2649 (0.2528)\n",
            "Epoch: [39] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.3157 (0.2567)  bbox_regression: 0.0518 (0.0377)  classification: 0.2639 (0.2190)\n",
            "Epoch: [39] [280/289]  eta: 0:00:00  time: 0.0822  loss: 0.3129 (0.2553)  bbox_regression: 0.0512 (0.0348)  classification: 0.2617 (0.2205)\n",
            "Epoch: [39] [288/289]  eta: 0:00:00  time: 0.0820  loss: 0.3131 (0.2620)  bbox_regression: 0.0507 (0.0357)  classification: 0.2624 (0.2263)\n",
            "Epoch: [39] Time: 0:00:23 (0.0820 s / it)\n",
            "Validation: [39]\n",
            "Validation: [39] [ 0/62]  eta: 0:00:04  time: 0.0689  \n",
            "Validation: [39] [10/62]  eta: 0:00:03  time: 0.0696  \n",
            "Validation: [39] [20/62]  eta: 0:00:02  time: 0.0688  \n",
            "Validation: [39] [30/62]  eta: 0:00:02  time: 0.0690  \n",
            "Validation: [39] [40/62]  eta: 0:00:01  time: 0.0692  \n",
            "Validation: [39] [50/62]  eta: 0:00:00  time: 0.0695  \n",
            "Validation: [39] [60/62]  eta: 0:00:00  time: 0.0694  \n",
            "Validation: [39] [61/62]  eta: 0:00:00  time: 0.0690  \n",
            "Validation: [39] Time: 0:00:04 (0.0690 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_40/mAP_vs_threshold_epoch_39.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_40/pr_curves_epoch_39.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_40/per_class_ap_epoch_39.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_40/confusion_matrix_epoch_39.png\n",
            "Epoch 39: mAP@0.5 = 0.5146\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6203\n",
            "  Bacterial-Black-spot: 0.6026\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.3149\n",
            "  Mechanical-damage: 0.7571\n",
            "  Others: 0.7928\n",
            "Saved best model with mAP: 0.5146\n",
            "Copied best model to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied confusion_matrix_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/confusion_matrix_epoch_39.png\n",
            "Copied per_class_mAP_epoch_39.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/per_class_mAP_epoch_39.csv\n",
            "Copied per_class_ap_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/per_class_ap_epoch_39.png\n",
            "Copied pr_curves_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/pr_curves_epoch_39.png\n",
            "Copied mAP_vs_threshold_epoch_39.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/mAP_vs_threshold_epoch_39.csv\n",
            "Copied mAP_vs_threshold_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/mAP_vs_threshold_epoch_39.png\n",
            "Saved checkpoint at epoch 40\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [40]\n",
            "Epoch: [40] [  0/289]  eta: 0:00:23  time: 0.0816  loss: 0.7143 (0.7143)  bbox_regression: 0.0299 (0.0299)  classification: 0.6844 (0.6844)\n",
            "Epoch: [40] [ 10/289]  eta: 0:00:24  time: 0.0878  loss: 0.3528 (0.3528)  bbox_regression: 0.0493 (0.0493)  classification: 0.3035 (0.3035)\n",
            "Epoch: [40] [ 20/289]  eta: 0:00:23  time: 0.0892  loss: 0.3480 (0.3297)  bbox_regression: 0.0418 (0.0424)  classification: 0.3062 (0.2873)\n",
            "Epoch: [40] [ 30/289]  eta: 0:00:22  time: 0.0868  loss: 0.3079 (0.2832)  bbox_regression: 0.0396 (0.0343)  classification: 0.2683 (0.2489)\n",
            "Epoch: [40] [ 40/289]  eta: 0:00:21  time: 0.0849  loss: 0.2947 (0.2388)  bbox_regression: 0.0388 (0.0357)  classification: 0.2559 (0.2031)\n",
            "Epoch: [40] [ 50/289]  eta: 0:00:20  time: 0.0843  loss: 0.2844 (0.2480)  bbox_regression: 0.0406 (0.0420)  classification: 0.2438 (0.2060)\n",
            "Epoch: [40] [ 60/289]  eta: 0:00:19  time: 0.0832  loss: 0.2760 (0.2376)  bbox_regression: 0.0386 (0.0382)  classification: 0.2374 (0.1995)\n",
            "Epoch: [40] [ 70/289]  eta: 0:00:18  time: 0.0825  loss: 0.3059 (0.3608)  bbox_regression: 0.0470 (0.0635)  classification: 0.2589 (0.2972)\n",
            "Epoch: [40] [ 80/289]  eta: 0:00:17  time: 0.0822  loss: 0.3231 (0.4667)  bbox_regression: 0.0492 (0.0815)  classification: 0.2739 (0.3853)\n",
            "Epoch: [40] [ 90/289]  eta: 0:00:16  time: 0.0823  loss: 0.3105 (0.3269)  bbox_regression: 0.0478 (0.0507)  classification: 0.2627 (0.2761)\n",
            "Epoch: [40] [100/289]  eta: 0:00:15  time: 0.0828  loss: 0.3000 (0.2066)  bbox_regression: 0.0466 (0.0364)  classification: 0.2534 (0.1703)\n",
            "Epoch: [40] [110/289]  eta: 0:00:14  time: 0.0832  loss: 0.2975 (0.2384)  bbox_regression: 0.0465 (0.0404)  classification: 0.2510 (0.1980)\n",
            "Epoch: [40] [120/289]  eta: 0:00:14  time: 0.0831  loss: 0.2922 (0.2524)  bbox_regression: 0.0455 (0.0400)  classification: 0.2466 (0.2124)\n",
            "Epoch: [40] [130/289]  eta: 0:00:13  time: 0.0830  loss: 0.2878 (0.2340)  bbox_regression: 0.0451 (0.0373)  classification: 0.2427 (0.1967)\n",
            "Epoch: [40] [140/289]  eta: 0:00:12  time: 0.0829  loss: 0.2867 (0.2535)  bbox_regression: 0.0441 (0.0352)  classification: 0.2426 (0.2183)\n",
            "Epoch: [40] [150/289]  eta: 0:00:11  time: 0.0829  loss: 0.2917 (0.3170)  bbox_regression: 0.0443 (0.0391)  classification: 0.2474 (0.2779)\n",
            "Epoch: [40] [160/289]  eta: 0:00:10  time: 0.0829  loss: 0.2997 (0.3916)  bbox_regression: 0.0454 (0.0551)  classification: 0.2543 (0.3365)\n",
            "Epoch: [40] [170/289]  eta: 0:00:09  time: 0.0828  loss: 0.2958 (0.3270)  bbox_regression: 0.0450 (0.0506)  classification: 0.2508 (0.2763)\n",
            "Epoch: [40] [180/289]  eta: 0:00:09  time: 0.0829  loss: 0.2911 (0.2221)  bbox_regression: 0.0449 (0.0403)  classification: 0.2463 (0.1818)\n",
            "Epoch: [40] [190/289]  eta: 0:00:08  time: 0.0830  loss: 0.2906 (0.2461)  bbox_regression: 0.0446 (0.0412)  classification: 0.2460 (0.2049)\n",
            "Epoch: [40] [200/289]  eta: 0:00:07  time: 0.0830  loss: 0.2932 (0.3119)  bbox_regression: 0.0462 (0.0582)  classification: 0.2470 (0.2537)\n",
            "Epoch: [40] [210/289]  eta: 0:00:06  time: 0.0828  loss: 0.2945 (0.3317)  bbox_regression: 0.0469 (0.0680)  classification: 0.2477 (0.2637)\n",
            "Epoch: [40] [220/289]  eta: 0:00:05  time: 0.0828  loss: 0.2973 (0.3387)  bbox_regression: 0.0475 (0.0601)  classification: 0.2499 (0.2786)\n",
            "Epoch: [40] [230/289]  eta: 0:00:04  time: 0.0826  loss: 0.2944 (0.2928)  bbox_regression: 0.0473 (0.0518)  classification: 0.2471 (0.2410)\n",
            "Epoch: [40] [240/289]  eta: 0:00:04  time: 0.0827  loss: 0.3004 (0.3350)  bbox_regression: 0.0510 (0.0904)  classification: 0.2494 (0.2446)\n",
            "Epoch: [40] [250/289]  eta: 0:00:03  time: 0.0827  loss: 0.3034 (0.4080)  bbox_regression: 0.0509 (0.0926)  classification: 0.2525 (0.3154)\n",
            "Epoch: [40] [260/289]  eta: 0:00:02  time: 0.0826  loss: 0.3022 (0.3229)  bbox_regression: 0.0507 (0.0474)  classification: 0.2514 (0.2756)\n",
            "Epoch: [40] [270/289]  eta: 0:00:01  time: 0.0824  loss: 0.3027 (0.2936)  bbox_regression: 0.0509 (0.0511)  classification: 0.2518 (0.2425)\n",
            "Epoch: [40] [280/289]  eta: 0:00:00  time: 0.0823  loss: 0.3020 (0.2996)  bbox_regression: 0.0509 (0.0531)  classification: 0.2511 (0.2465)\n",
            "Epoch: [40] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.3026 (0.3336)  bbox_regression: 0.0508 (0.0561)  classification: 0.2518 (0.2775)\n",
            "Epoch: [40] Time: 0:00:23 (0.0822 s / it)\n",
            "Epoch: [41]\n",
            "Epoch: [41] [  0/289]  eta: 0:00:24  time: 0.0851  loss: 0.0925 (0.0925)  bbox_regression: 0.0171 (0.0171)  classification: 0.0754 (0.0754)\n",
            "Epoch: [41] [ 10/289]  eta: 0:00:23  time: 0.0825  loss: 0.2684 (0.2684)  bbox_regression: 0.0968 (0.0968)  classification: 0.1716 (0.1716)\n",
            "Epoch: [41] [ 20/289]  eta: 0:00:23  time: 0.0868  loss: 0.2698 (0.2787)  bbox_regression: 0.0736 (0.0764)  classification: 0.1962 (0.2023)\n",
            "Epoch: [41] [ 30/289]  eta: 0:00:22  time: 0.0864  loss: 0.2704 (0.2715)  bbox_regression: 0.0633 (0.0449)  classification: 0.2071 (0.2266)\n",
            "Epoch: [41] [ 40/289]  eta: 0:00:21  time: 0.0852  loss: 0.2593 (0.2483)  bbox_regression: 0.0583 (0.0423)  classification: 0.2010 (0.2060)\n",
            "Epoch: [41] [ 50/289]  eta: 0:00:20  time: 0.0846  loss: 0.2478 (0.2128)  bbox_regression: 0.0532 (0.0376)  classification: 0.1946 (0.1752)\n",
            "Epoch: [41] [ 60/289]  eta: 0:00:19  time: 0.0843  loss: 0.2489 (0.2276)  bbox_regression: 0.0494 (0.0312)  classification: 0.1995 (0.1965)\n",
            "Epoch: [41] [ 70/289]  eta: 0:00:18  time: 0.0836  loss: 0.2616 (0.2967)  bbox_regression: 0.0504 (0.0433)  classification: 0.2111 (0.2533)\n",
            "Epoch: [41] [ 80/289]  eta: 0:00:17  time: 0.0832  loss: 0.2672 (0.3229)  bbox_regression: 0.0507 (0.0546)  classification: 0.2165 (0.2683)\n",
            "Epoch: [41] [ 90/289]  eta: 0:00:16  time: 0.0830  loss: 0.2700 (0.2998)  bbox_regression: 0.0509 (0.0524)  classification: 0.2191 (0.2474)\n",
            "Epoch: [41] [100/289]  eta: 0:00:15  time: 0.0828  loss: 0.2747 (0.3053)  bbox_regression: 0.0509 (0.0520)  classification: 0.2238 (0.2533)\n",
            "Epoch: [41] [110/289]  eta: 0:00:14  time: 0.0828  loss: 0.2689 (0.2637)  bbox_regression: 0.0501 (0.0463)  classification: 0.2188 (0.2174)\n",
            "Epoch: [41] [120/289]  eta: 0:00:13  time: 0.0828  loss: 0.2673 (0.2300)  bbox_regression: 0.0492 (0.0405)  classification: 0.2181 (0.1895)\n",
            "Epoch: [41] [130/289]  eta: 0:00:13  time: 0.0825  loss: 0.2607 (0.2152)  bbox_regression: 0.0480 (0.0367)  classification: 0.2127 (0.1786)\n",
            "Epoch: [41] [140/289]  eta: 0:00:12  time: 0.0823  loss: 0.2692 (0.2804)  bbox_regression: 0.0476 (0.0378)  classification: 0.2216 (0.2426)\n",
            "Epoch: [41] [150/289]  eta: 0:00:11  time: 0.0822  loss: 0.2759 (0.3759)  bbox_regression: 0.0482 (0.0492)  classification: 0.2278 (0.3267)\n",
            "Epoch: [41] [160/289]  eta: 0:00:10  time: 0.0822  loss: 0.2756 (0.3206)  bbox_regression: 0.0480 (0.0511)  classification: 0.2275 (0.2695)\n",
            "Epoch: [41] [170/289]  eta: 0:00:09  time: 0.0823  loss: 0.2725 (0.2464)  bbox_regression: 0.0475 (0.0425)  classification: 0.2250 (0.2039)\n",
            "Epoch: [41] [180/289]  eta: 0:00:08  time: 0.0824  loss: 0.2713 (0.2372)  bbox_regression: 0.0468 (0.0367)  classification: 0.2246 (0.2005)\n",
            "Epoch: [41] [190/289]  eta: 0:00:08  time: 0.0823  loss: 0.2694 (0.2429)  bbox_regression: 0.0461 (0.0339)  classification: 0.2233 (0.2090)\n",
            "Epoch: [41] [200/289]  eta: 0:00:07  time: 0.0826  loss: 0.2730 (0.2876)  bbox_regression: 0.0486 (0.0647)  classification: 0.2244 (0.2229)\n",
            "Epoch: [41] [210/289]  eta: 0:00:06  time: 0.0825  loss: 0.2755 (0.3343)  bbox_regression: 0.0494 (0.0814)  classification: 0.2261 (0.2529)\n",
            "Epoch: [41] [220/289]  eta: 0:00:05  time: 0.0823  loss: 0.2751 (0.2970)  bbox_regression: 0.0502 (0.0664)  classification: 0.2249 (0.2306)\n",
            "Epoch: [41] [230/289]  eta: 0:00:04  time: 0.0824  loss: 0.2809 (0.3381)  bbox_regression: 0.0502 (0.0588)  classification: 0.2307 (0.2793)\n",
            "Epoch: [41] [240/289]  eta: 0:00:04  time: 0.0824  loss: 0.2800 (0.3342)  bbox_regression: 0.0498 (0.0450)  classification: 0.2303 (0.2892)\n",
            "Epoch: [41] [250/289]  eta: 0:00:03  time: 0.0823  loss: 0.2833 (0.3105)  bbox_regression: 0.0499 (0.0457)  classification: 0.2334 (0.2649)\n",
            "Epoch: [41] [260/289]  eta: 0:00:02  time: 0.0823  loss: 0.2855 (0.3507)  bbox_regression: 0.0505 (0.0595)  classification: 0.2349 (0.2912)\n",
            "Epoch: [41] [270/289]  eta: 0:00:01  time: 0.0823  loss: 0.2903 (0.3779)  bbox_regression: 0.0502 (0.0546)  classification: 0.2401 (0.3233)\n",
            "Epoch: [41] [280/289]  eta: 0:00:00  time: 0.0822  loss: 0.2893 (0.3390)  bbox_regression: 0.0506 (0.0518)  classification: 0.2387 (0.2873)\n",
            "Epoch: [41] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.2911 (0.3367)  bbox_regression: 0.0506 (0.0550)  classification: 0.2405 (0.2817)\n",
            "Epoch: [41] Time: 0:00:23 (0.0821 s / it)\n",
            "Epoch: [42]\n",
            "Epoch: [42] [  0/289]  eta: 0:00:26  time: 0.0912  loss: 0.4691 (0.4691)  bbox_regression: 0.0423 (0.0423)  classification: 0.4269 (0.4269)\n",
            "Epoch: [42] [ 10/289]  eta: 0:00:22  time: 0.0818  loss: 0.3959 (0.3959)  bbox_regression: 0.0521 (0.0521)  classification: 0.3438 (0.3438)\n",
            "Epoch: [42] [ 20/289]  eta: 0:00:22  time: 0.0826  loss: 0.3770 (0.3724)  bbox_regression: 0.0614 (0.0624)  classification: 0.3156 (0.3100)\n",
            "Epoch: [42] [ 30/289]  eta: 0:00:21  time: 0.0825  loss: 0.3153 (0.2710)  bbox_regression: 0.0519 (0.0518)  classification: 0.2634 (0.2192)\n",
            "Epoch: [42] [ 40/289]  eta: 0:00:20  time: 0.0817  loss: 0.2821 (0.1825)  bbox_regression: 0.0478 (0.0334)  classification: 0.2343 (0.1490)\n",
            "Epoch: [42] [ 50/289]  eta: 0:00:19  time: 0.0813  loss: 0.2743 (0.2107)  bbox_regression: 0.0478 (0.0415)  classification: 0.2265 (0.1692)\n",
            "Epoch: [42] [ 60/289]  eta: 0:00:18  time: 0.0814  loss: 0.2710 (0.2484)  bbox_regression: 0.0478 (0.0478)  classification: 0.2233 (0.2006)\n",
            "Epoch: [42] [ 70/289]  eta: 0:00:17  time: 0.0820  loss: 0.2795 (0.2928)  bbox_regression: 0.0482 (0.0493)  classification: 0.2313 (0.2435)\n",
            "Epoch: [42] [ 80/289]  eta: 0:00:17  time: 0.0818  loss: 0.2822 (0.3163)  bbox_regression: 0.0469 (0.0441)  classification: 0.2354 (0.2722)\n",
            "Epoch: [42] [ 90/289]  eta: 0:00:16  time: 0.0819  loss: 0.2738 (0.2535)  bbox_regression: 0.0450 (0.0335)  classification: 0.2288 (0.2201)\n",
            "Epoch: [42] [100/289]  eta: 0:00:15  time: 0.0819  loss: 0.2790 (0.2661)  bbox_regression: 0.0459 (0.0420)  classification: 0.2331 (0.2241)\n",
            "Epoch: [42] [110/289]  eta: 0:00:14  time: 0.0822  loss: 0.2700 (0.2526)  bbox_regression: 0.0454 (0.0472)  classification: 0.2246 (0.2053)\n",
            "Epoch: [42] [120/289]  eta: 0:00:13  time: 0.0820  loss: 0.2665 (0.2033)  bbox_regression: 0.0458 (0.0455)  classification: 0.2207 (0.1578)\n",
            "Epoch: [42] [130/289]  eta: 0:00:13  time: 0.0821  loss: 0.2719 (0.2828)  bbox_regression: 0.0460 (0.0497)  classification: 0.2259 (0.2332)\n",
            "Epoch: [42] [140/289]  eta: 0:00:12  time: 0.0823  loss: 0.2699 (0.2902)  bbox_regression: 0.0456 (0.0445)  classification: 0.2242 (0.2457)\n",
            "Epoch: [42] [150/289]  eta: 0:00:11  time: 0.0822  loss: 0.2701 (0.2579)  bbox_regression: 0.0455 (0.0422)  classification: 0.2245 (0.2156)\n",
            "Epoch: [42] [160/289]  eta: 0:00:10  time: 0.0821  loss: 0.2717 (0.2846)  bbox_regression: 0.0464 (0.0515)  classification: 0.2253 (0.2331)\n",
            "Epoch: [42] [170/289]  eta: 0:00:09  time: 0.0822  loss: 0.2686 (0.2578)  bbox_regression: 0.0464 (0.0528)  classification: 0.2222 (0.2049)\n",
            "Epoch: [42] [180/289]  eta: 0:00:08  time: 0.0823  loss: 0.2754 (0.3048)  bbox_regression: 0.0501 (0.0801)  classification: 0.2253 (0.2247)\n",
            "Epoch: [42] [190/289]  eta: 0:00:08  time: 0.0822  loss: 0.2744 (0.3238)  bbox_regression: 0.0494 (0.0750)  classification: 0.2250 (0.2489)\n",
            "Epoch: [42] [200/289]  eta: 0:00:07  time: 0.0821  loss: 0.2806 (0.3276)  bbox_regression: 0.0507 (0.0561)  classification: 0.2299 (0.2715)\n",
            "Epoch: [42] [210/289]  eta: 0:00:06  time: 0.0821  loss: 0.2761 (0.2922)  bbox_regression: 0.0499 (0.0545)  classification: 0.2262 (0.2377)\n",
            "Epoch: [42] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.2782 (0.2549)  bbox_regression: 0.0497 (0.0392)  classification: 0.2286 (0.2157)\n",
            "Epoch: [42] [230/289]  eta: 0:00:04  time: 0.0820  loss: 0.2810 (0.3327)  bbox_regression: 0.0493 (0.0436)  classification: 0.2317 (0.2890)\n",
            "Epoch: [42] [240/289]  eta: 0:00:04  time: 0.0819  loss: 0.2837 (0.3446)  bbox_regression: 0.0503 (0.0577)  classification: 0.2334 (0.2869)\n",
            "Epoch: [42] [250/289]  eta: 0:00:03  time: 0.0818  loss: 0.2840 (0.3186)  bbox_regression: 0.0507 (0.0666)  classification: 0.2333 (0.2520)\n",
            "Epoch: [42] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.2823 (0.2643)  bbox_regression: 0.0505 (0.0531)  classification: 0.2317 (0.2112)\n",
            "Epoch: [42] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.2817 (0.2524)  bbox_regression: 0.0503 (0.0446)  classification: 0.2314 (0.2078)\n",
            "Epoch: [42] [280/289]  eta: 0:00:00  time: 0.0819  loss: 0.2841 (0.3086)  bbox_regression: 0.0504 (0.0491)  classification: 0.2337 (0.2595)\n",
            "Epoch: [42] [288/289]  eta: 0:00:00  time: 0.0817  loss: 0.2833 (0.3134)  bbox_regression: 0.0505 (0.0539)  classification: 0.2328 (0.2595)\n",
            "Epoch: [42] Time: 0:00:23 (0.0817 s / it)\n",
            "Epoch: [43]\n",
            "Epoch: [43] [  0/289]  eta: 0:00:26  time: 0.0906  loss: 0.5630 (0.5630)  bbox_regression: 0.0580 (0.0580)  classification: 0.5050 (0.5050)\n",
            "Epoch: [43] [ 10/289]  eta: 0:00:22  time: 0.0811  loss: 0.2619 (0.2619)  bbox_regression: 0.0525 (0.0525)  classification: 0.2094 (0.2094)\n",
            "Epoch: [43] [ 20/289]  eta: 0:00:21  time: 0.0802  loss: 0.2762 (0.2618)  bbox_regression: 0.0688 (0.0693)  classification: 0.2074 (0.1925)\n",
            "Epoch: [43] [ 30/289]  eta: 0:00:20  time: 0.0808  loss: 0.2729 (0.2790)  bbox_regression: 0.0553 (0.0568)  classification: 0.2176 (0.2222)\n",
            "Epoch: [43] [ 40/289]  eta: 0:00:20  time: 0.0813  loss: 0.2646 (0.2525)  bbox_regression: 0.0511 (0.0326)  classification: 0.2135 (0.2199)\n",
            "Epoch: [43] [ 50/289]  eta: 0:00:19  time: 0.0813  loss: 0.2821 (0.2963)  bbox_regression: 0.0525 (0.0481)  classification: 0.2296 (0.2482)\n",
            "Epoch: [43] [ 60/289]  eta: 0:00:18  time: 0.0815  loss: 0.2728 (0.2894)  bbox_regression: 0.0498 (0.0471)  classification: 0.2230 (0.2423)\n",
            "Epoch: [43] [ 70/289]  eta: 0:00:17  time: 0.0812  loss: 0.2633 (0.2154)  bbox_regression: 0.0482 (0.0372)  classification: 0.2151 (0.1782)\n",
            "Epoch: [43] [ 80/289]  eta: 0:00:16  time: 0.0810  loss: 0.2572 (0.2096)  bbox_regression: 0.0477 (0.0412)  classification: 0.2095 (0.1684)\n",
            "Epoch: [43] [ 90/289]  eta: 0:00:16  time: 0.0809  loss: 0.2572 (0.2353)  bbox_regression: 0.0472 (0.0438)  classification: 0.2100 (0.1916)\n",
            "Epoch: [43] [100/289]  eta: 0:00:15  time: 0.0810  loss: 0.2590 (0.2663)  bbox_regression: 0.0472 (0.0452)  classification: 0.2118 (0.2211)\n",
            "Epoch: [43] [110/289]  eta: 0:00:14  time: 0.0811  loss: 0.2636 (0.2928)  bbox_regression: 0.0464 (0.0426)  classification: 0.2172 (0.2502)\n",
            "Epoch: [43] [120/289]  eta: 0:00:13  time: 0.0811  loss: 0.2609 (0.2704)  bbox_regression: 0.0461 (0.0405)  classification: 0.2148 (0.2298)\n",
            "Epoch: [43] [130/289]  eta: 0:00:12  time: 0.0811  loss: 0.2577 (0.2248)  bbox_regression: 0.0452 (0.0385)  classification: 0.2125 (0.1863)\n",
            "Epoch: [43] [140/289]  eta: 0:00:12  time: 0.0812  loss: 0.2551 (0.2204)  bbox_regression: 0.0456 (0.0424)  classification: 0.2096 (0.1780)\n",
            "Epoch: [43] [150/289]  eta: 0:00:11  time: 0.0814  loss: 0.2558 (0.2439)  bbox_regression: 0.0456 (0.0484)  classification: 0.2102 (0.1955)\n",
            "Epoch: [43] [160/289]  eta: 0:00:10  time: 0.0813  loss: 0.2611 (0.3037)  bbox_regression: 0.0470 (0.0568)  classification: 0.2142 (0.2469)\n",
            "Epoch: [43] [170/289]  eta: 0:00:09  time: 0.0813  loss: 0.2654 (0.3376)  bbox_regression: 0.0474 (0.0611)  classification: 0.2180 (0.2765)\n",
            "Epoch: [43] [180/289]  eta: 0:00:08  time: 0.0814  loss: 0.2624 (0.2724)  bbox_regression: 0.0468 (0.0453)  classification: 0.2156 (0.2271)\n",
            "Epoch: [43] [190/289]  eta: 0:00:08  time: 0.0816  loss: 0.2624 (0.2370)  bbox_regression: 0.0468 (0.0414)  classification: 0.2156 (0.1956)\n",
            "Epoch: [43] [200/289]  eta: 0:00:07  time: 0.0818  loss: 0.2607 (0.2454)  bbox_regression: 0.0459 (0.0381)  classification: 0.2148 (0.2073)\n",
            "Epoch: [43] [210/289]  eta: 0:00:06  time: 0.0818  loss: 0.2652 (0.2914)  bbox_regression: 0.0472 (0.0513)  classification: 0.2180 (0.2402)\n",
            "Epoch: [43] [220/289]  eta: 0:00:05  time: 0.0819  loss: 0.2666 (0.3258)  bbox_regression: 0.0478 (0.0670)  classification: 0.2188 (0.2588)\n",
            "Epoch: [43] [230/289]  eta: 0:00:04  time: 0.0819  loss: 0.2665 (0.2804)  bbox_regression: 0.0485 (0.0621)  classification: 0.2180 (0.2183)\n",
            "Epoch: [43] [240/289]  eta: 0:00:04  time: 0.0819  loss: 0.2650 (0.2474)  bbox_regression: 0.0478 (0.0481)  classification: 0.2172 (0.1992)\n",
            "Epoch: [43] [250/289]  eta: 0:00:03  time: 0.0819  loss: 0.2670 (0.2730)  bbox_regression: 0.0481 (0.0437)  classification: 0.2189 (0.2292)\n",
            "Epoch: [43] [260/289]  eta: 0:00:02  time: 0.0819  loss: 0.2695 (0.3234)  bbox_regression: 0.0485 (0.0567)  classification: 0.2209 (0.2667)\n",
            "Epoch: [43] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.2675 (0.2731)  bbox_regression: 0.0483 (0.0510)  classification: 0.2191 (0.2221)\n",
            "Epoch: [43] [280/289]  eta: 0:00:00  time: 0.0818  loss: 0.2748 (0.3437)  bbox_regression: 0.0510 (0.0830)  classification: 0.2238 (0.2607)\n",
            "Epoch: [43] [288/289]  eta: 0:00:00  time: 0.0817  loss: 0.2746 (0.3593)  bbox_regression: 0.0505 (0.0797)  classification: 0.2241 (0.2796)\n",
            "Epoch: [43] Time: 0:00:23 (0.0817 s / it)\n",
            "Epoch: [44]\n",
            "Epoch: [44] [  0/289]  eta: 0:00:21  time: 0.0734  loss: 0.5604 (0.5604)  bbox_regression: 0.1594 (0.1594)  classification: 0.4010 (0.4010)\n",
            "Epoch: [44] [ 10/289]  eta: 0:00:22  time: 0.0824  loss: 0.2635 (0.2635)  bbox_regression: 0.0543 (0.0543)  classification: 0.2092 (0.2092)\n",
            "Epoch: [44] [ 20/289]  eta: 0:00:22  time: 0.0833  loss: 0.2642 (0.2494)  bbox_regression: 0.0620 (0.0571)  classification: 0.2022 (0.1923)\n",
            "Epoch: [44] [ 30/289]  eta: 0:00:21  time: 0.0827  loss: 0.2432 (0.2320)  bbox_regression: 0.0518 (0.0504)  classification: 0.1913 (0.1815)\n",
            "Epoch: [44] [ 40/289]  eta: 0:00:20  time: 0.0829  loss: 0.2310 (0.1961)  bbox_regression: 0.0469 (0.0311)  classification: 0.1841 (0.1650)\n",
            "Epoch: [44] [ 50/289]  eta: 0:00:19  time: 0.0831  loss: 0.2163 (0.1746)  bbox_regression: 0.0435 (0.0307)  classification: 0.1727 (0.1439)\n",
            "Epoch: [44] [ 60/289]  eta: 0:00:18  time: 0.0825  loss: 0.2210 (0.2004)  bbox_regression: 0.0429 (0.0347)  classification: 0.1780 (0.1657)\n",
            "Epoch: [44] [ 70/289]  eta: 0:00:18  time: 0.0825  loss: 0.2186 (0.2246)  bbox_regression: 0.0421 (0.0384)  classification: 0.1765 (0.1862)\n",
            "Epoch: [44] [ 80/289]  eta: 0:00:17  time: 0.0824  loss: 0.2325 (0.2679)  bbox_regression: 0.0436 (0.0456)  classification: 0.1890 (0.2223)\n",
            "Epoch: [44] [ 90/289]  eta: 0:00:16  time: 0.0832  loss: 0.2409 (0.3201)  bbox_regression: 0.0442 (0.0517)  classification: 0.1967 (0.2684)\n",
            "Epoch: [44] [100/289]  eta: 0:00:15  time: 0.0832  loss: 0.2526 (0.3339)  bbox_regression: 0.0446 (0.0491)  classification: 0.2080 (0.2848)\n",
            "Epoch: [44] [110/289]  eta: 0:00:14  time: 0.0828  loss: 0.2528 (0.3068)  bbox_regression: 0.0446 (0.0465)  classification: 0.2082 (0.2603)\n",
            "Epoch: [44] [120/289]  eta: 0:00:14  time: 0.0830  loss: 0.2542 (0.2622)  bbox_regression: 0.0448 (0.0456)  classification: 0.2094 (0.2166)\n",
            "Epoch: [44] [130/289]  eta: 0:00:13  time: 0.0832  loss: 0.2545 (0.2639)  bbox_regression: 0.0448 (0.0457)  classification: 0.2097 (0.2181)\n",
            "Epoch: [44] [140/289]  eta: 0:00:12  time: 0.0830  loss: 0.2468 (0.2022)  bbox_regression: 0.0442 (0.0408)  classification: 0.2026 (0.1615)\n",
            "Epoch: [44] [150/289]  eta: 0:00:11  time: 0.0827  loss: 0.2560 (0.2662)  bbox_regression: 0.0480 (0.0690)  classification: 0.2080 (0.1972)\n",
            "Epoch: [44] [160/289]  eta: 0:00:10  time: 0.0827  loss: 0.2585 (0.3410)  bbox_regression: 0.0476 (0.0712)  classification: 0.2109 (0.2699)\n",
            "Epoch: [44] [170/289]  eta: 0:00:09  time: 0.0826  loss: 0.2600 (0.2900)  bbox_regression: 0.0484 (0.0512)  classification: 0.2116 (0.2388)\n",
            "Epoch: [44] [180/289]  eta: 0:00:08  time: 0.0824  loss: 0.2587 (0.2600)  bbox_regression: 0.0480 (0.0513)  classification: 0.2107 (0.2087)\n",
            "Epoch: [44] [190/289]  eta: 0:00:08  time: 0.0826  loss: 0.2621 (0.2805)  bbox_regression: 0.0499 (0.0632)  classification: 0.2122 (0.2173)\n",
            "Epoch: [44] [200/289]  eta: 0:00:07  time: 0.0825  loss: 0.2641 (0.3133)  bbox_regression: 0.0497 (0.0655)  classification: 0.2144 (0.2478)\n",
            "Epoch: [44] [210/289]  eta: 0:00:06  time: 0.0824  loss: 0.2650 (0.2919)  bbox_regression: 0.0492 (0.0419)  classification: 0.2158 (0.2501)\n",
            "Epoch: [44] [220/289]  eta: 0:00:05  time: 0.0823  loss: 0.2674 (0.3007)  bbox_regression: 0.0485 (0.0360)  classification: 0.2189 (0.2646)\n",
            "Epoch: [44] [230/289]  eta: 0:00:04  time: 0.0824  loss: 0.2703 (0.3268)  bbox_regression: 0.0485 (0.0416)  classification: 0.2218 (0.2852)\n",
            "Epoch: [44] [240/289]  eta: 0:00:04  time: 0.0824  loss: 0.2682 (0.2771)  bbox_regression: 0.0494 (0.0595)  classification: 0.2188 (0.2176)\n",
            "Epoch: [44] [250/289]  eta: 0:00:03  time: 0.0822  loss: 0.2653 (0.2067)  bbox_regression: 0.0491 (0.0567)  classification: 0.2161 (0.1500)\n",
            "Epoch: [44] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.2620 (0.1865)  bbox_regression: 0.0485 (0.0379)  classification: 0.2134 (0.1486)\n",
            "Epoch: [44] [270/289]  eta: 0:00:01  time: 0.0821  loss: 0.2654 (0.2675)  bbox_regression: 0.0486 (0.0419)  classification: 0.2168 (0.2256)\n",
            "Epoch: [44] [280/289]  eta: 0:00:00  time: 0.0821  loss: 0.2620 (0.2629)  bbox_regression: 0.0481 (0.0426)  classification: 0.2139 (0.2204)\n",
            "Epoch: [44] [288/289]  eta: 0:00:00  time: 0.0818  loss: 0.2655 (0.2566)  bbox_regression: 0.0500 (0.0680)  classification: 0.2155 (0.1886)\n",
            "Epoch: [44] Time: 0:00:23 (0.0818 s / it)\n",
            "Validation: [44]\n",
            "Validation: [44] [ 0/62]  eta: 0:00:04  time: 0.0682  \n",
            "Validation: [44] [10/62]  eta: 0:00:03  time: 0.0690  \n",
            "Validation: [44] [20/62]  eta: 0:00:02  time: 0.0681  \n",
            "Validation: [44] [30/62]  eta: 0:00:02  time: 0.0685  \n",
            "Validation: [44] [40/62]  eta: 0:00:01  time: 0.0695  \n",
            "Validation: [44] [50/62]  eta: 0:00:00  time: 0.0703  \n",
            "Validation: [44] [60/62]  eta: 0:00:00  time: 0.0711  \n",
            "Validation: [44] [61/62]  eta: 0:00:00  time: 0.0707  \n",
            "Validation: [44] Time: 0:00:04 (0.0707 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_45/mAP_vs_threshold_epoch_44.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_45/pr_curves_epoch_44.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_45/per_class_ap_epoch_44.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_45/confusion_matrix_epoch_44.png\n",
            "Epoch 44: mAP@0.5 = 0.5140\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6641\n",
            "  Bacterial-Black-spot: 0.5951\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.3169\n",
            "  Mechanical-damage: 0.7286\n",
            "  Others: 0.7796\n",
            "Copied per_class_mAP_epoch_44.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/per_class_mAP_epoch_44.csv\n",
            "Copied confusion_matrix_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/confusion_matrix_epoch_44.png\n",
            "Copied mAP_vs_threshold_epoch_44.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/mAP_vs_threshold_epoch_44.csv\n",
            "Copied pr_curves_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/pr_curves_epoch_44.png\n",
            "Copied per_class_ap_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/per_class_ap_epoch_44.png\n",
            "Copied mAP_vs_threshold_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/mAP_vs_threshold_epoch_44.png\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "Epoch: [45]\n",
            "Epoch: [45] [  0/289]  eta: 0:00:25  time: 0.0892  loss: 0.1475 (0.1475)  bbox_regression: 0.0582 (0.0582)  classification: 0.0893 (0.0893)\n",
            "Epoch: [45] [ 10/289]  eta: 0:00:23  time: 0.0828  loss: 0.1977 (0.1977)  bbox_regression: 0.0366 (0.0366)  classification: 0.1611 (0.1611)\n",
            "Epoch: [45] [ 20/289]  eta: 0:00:21  time: 0.0811  loss: 0.2035 (0.2063)  bbox_regression: 0.0322 (0.0309)  classification: 0.1713 (0.1754)\n",
            "Epoch: [45] [ 30/289]  eta: 0:00:21  time: 0.0816  loss: 0.2092 (0.2156)  bbox_regression: 0.0361 (0.0358)  classification: 0.1731 (0.1797)\n",
            "Epoch: [45] [ 40/289]  eta: 0:00:20  time: 0.0827  loss: 0.2278 (0.2534)  bbox_regression: 0.0423 (0.0529)  classification: 0.1855 (0.2004)\n",
            "Epoch: [45] [ 50/289]  eta: 0:00:19  time: 0.0824  loss: 0.2291 (0.2600)  bbox_regression: 0.0415 (0.0499)  classification: 0.1876 (0.2101)\n",
            "Epoch: [45] [ 60/289]  eta: 0:00:18  time: 0.0821  loss: 0.2304 (0.2356)  bbox_regression: 0.0431 (0.0448)  classification: 0.1872 (0.1908)\n",
            "Epoch: [45] [ 70/289]  eta: 0:00:17  time: 0.0822  loss: 0.2415 (0.2731)  bbox_regression: 0.0437 (0.0492)  classification: 0.1979 (0.2240)\n",
            "Epoch: [45] [ 80/289]  eta: 0:00:17  time: 0.0818  loss: 0.2411 (0.2738)  bbox_regression: 0.0447 (0.0496)  classification: 0.1964 (0.2242)\n",
            "Epoch: [45] [ 90/289]  eta: 0:00:16  time: 0.0823  loss: 0.2347 (0.2103)  bbox_regression: 0.0450 (0.0498)  classification: 0.1897 (0.1605)\n",
            "Epoch: [45] [100/289]  eta: 0:00:15  time: 0.0826  loss: 0.2443 (0.2570)  bbox_regression: 0.0441 (0.0416)  classification: 0.2001 (0.2154)\n",
            "Epoch: [45] [110/289]  eta: 0:00:14  time: 0.0826  loss: 0.2535 (0.3390)  bbox_regression: 0.0467 (0.0541)  classification: 0.2068 (0.2849)\n",
            "Epoch: [45] [120/289]  eta: 0:00:13  time: 0.0826  loss: 0.2537 (0.3013)  bbox_regression: 0.0467 (0.0600)  classification: 0.2069 (0.2413)\n",
            "Epoch: [45] [130/289]  eta: 0:00:13  time: 0.0825  loss: 0.2609 (0.3021)  bbox_regression: 0.0507 (0.0729)  classification: 0.2102 (0.2292)\n",
            "Epoch: [45] [140/289]  eta: 0:00:12  time: 0.0825  loss: 0.2618 (0.3111)  bbox_regression: 0.0514 (0.0798)  classification: 0.2104 (0.2314)\n",
            "Epoch: [45] [150/289]  eta: 0:00:11  time: 0.0826  loss: 0.2563 (0.2263)  bbox_regression: 0.0505 (0.0494)  classification: 0.2058 (0.1768)\n",
            "Epoch: [45] [160/289]  eta: 0:00:10  time: 0.0825  loss: 0.2543 (0.2014)  bbox_regression: 0.0497 (0.0374)  classification: 0.2046 (0.1640)\n",
            "Epoch: [45] [170/289]  eta: 0:00:09  time: 0.0825  loss: 0.2497 (0.1999)  bbox_regression: 0.0488 (0.0360)  classification: 0.2009 (0.1639)\n",
            "Epoch: [45] [180/289]  eta: 0:00:08  time: 0.0826  loss: 0.2466 (0.1840)  bbox_regression: 0.0477 (0.0317)  classification: 0.1989 (0.1523)\n",
            "Epoch: [45] [190/289]  eta: 0:00:08  time: 0.0825  loss: 0.2593 (0.3409)  bbox_regression: 0.0522 (0.0809)  classification: 0.2071 (0.2601)\n",
            "Epoch: [45] [200/289]  eta: 0:00:07  time: 0.0823  loss: 0.2594 (0.3753)  bbox_regression: 0.0517 (0.0879)  classification: 0.2077 (0.2874)\n",
            "Epoch: [45] [210/289]  eta: 0:00:06  time: 0.0822  loss: 0.2586 (0.2527)  bbox_regression: 0.0514 (0.0437)  classification: 0.2073 (0.2090)\n",
            "Epoch: [45] [220/289]  eta: 0:00:05  time: 0.0821  loss: 0.2584 (0.2486)  bbox_regression: 0.0508 (0.0413)  classification: 0.2076 (0.2073)\n",
            "Epoch: [45] [230/289]  eta: 0:00:04  time: 0.0820  loss: 0.2596 (0.2694)  bbox_regression: 0.0514 (0.0515)  classification: 0.2082 (0.2179)\n",
            "Epoch: [45] [240/289]  eta: 0:00:04  time: 0.0820  loss: 0.2577 (0.2506)  bbox_regression: 0.0505 (0.0471)  classification: 0.2073 (0.2034)\n",
            "Epoch: [45] [250/289]  eta: 0:00:03  time: 0.0820  loss: 0.2582 (0.2422)  bbox_regression: 0.0500 (0.0347)  classification: 0.2081 (0.2074)\n",
            "Epoch: [45] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.2558 (0.2318)  bbox_regression: 0.0496 (0.0389)  classification: 0.2062 (0.1929)\n",
            "Epoch: [45] [270/289]  eta: 0:00:01  time: 0.0820  loss: 0.2578 (0.2527)  bbox_regression: 0.0499 (0.0485)  classification: 0.2078 (0.2042)\n",
            "Epoch: [45] [280/289]  eta: 0:00:00  time: 0.0820  loss: 0.2573 (0.2777)  bbox_regression: 0.0498 (0.0532)  classification: 0.2075 (0.2245)\n",
            "Epoch: [45] [288/289]  eta: 0:00:00  time: 0.0818  loss: 0.2566 (0.2417)  bbox_regression: 0.0493 (0.0389)  classification: 0.2073 (0.2028)\n",
            "Epoch: [45] Time: 0:00:23 (0.0819 s / it)\n",
            "Epoch: [46]\n",
            "Epoch: [46] [  0/289]  eta: 0:00:25  time: 0.0883  loss: 0.0686 (0.0686)  bbox_regression: 0.0313 (0.0313)  classification: 0.0373 (0.0373)\n",
            "Epoch: [46] [ 10/289]  eta: 0:00:22  time: 0.0800  loss: 0.2348 (0.2348)  bbox_regression: 0.0484 (0.0484)  classification: 0.1864 (0.1864)\n",
            "Epoch: [46] [ 20/289]  eta: 0:00:21  time: 0.0803  loss: 0.2249 (0.2327)  bbox_regression: 0.0400 (0.0404)  classification: 0.1849 (0.1923)\n",
            "Epoch: [46] [ 30/289]  eta: 0:00:21  time: 0.0821  loss: 0.2215 (0.2142)  bbox_regression: 0.0461 (0.0448)  classification: 0.1754 (0.1694)\n",
            "Epoch: [46] [ 40/289]  eta: 0:00:20  time: 0.0824  loss: 0.2338 (0.2432)  bbox_regression: 0.0455 (0.0512)  classification: 0.1884 (0.1920)\n",
            "Epoch: [46] [ 50/289]  eta: 0:00:19  time: 0.0821  loss: 0.2331 (0.2511)  bbox_regression: 0.0419 (0.0354)  classification: 0.1912 (0.2157)\n",
            "Epoch: [46] [ 60/289]  eta: 0:00:18  time: 0.0816  loss: 0.2342 (0.2349)  bbox_regression: 0.0417 (0.0339)  classification: 0.1925 (0.2010)\n",
            "Epoch: [46] [ 70/289]  eta: 0:00:17  time: 0.0815  loss: 0.2409 (0.2608)  bbox_regression: 0.0450 (0.0529)  classification: 0.1959 (0.2079)\n",
            "Epoch: [46] [ 80/289]  eta: 0:00:16  time: 0.0811  loss: 0.2534 (0.3119)  bbox_regression: 0.0450 (0.0553)  classification: 0.2083 (0.2566)\n",
            "Epoch: [46] [ 90/289]  eta: 0:00:16  time: 0.0812  loss: 0.2531 (0.2962)  bbox_regression: 0.0471 (0.0543)  classification: 0.2060 (0.2419)\n",
            "Epoch: [46] [100/289]  eta: 0:00:15  time: 0.0813  loss: 0.2431 (0.2014)  bbox_regression: 0.0449 (0.0446)  classification: 0.1981 (0.1568)\n",
            "Epoch: [46] [110/289]  eta: 0:00:14  time: 0.0817  loss: 0.2445 (0.2057)  bbox_regression: 0.0454 (0.0380)  classification: 0.1991 (0.1677)\n",
            "Epoch: [46] [120/289]  eta: 0:00:13  time: 0.0817  loss: 0.2398 (0.2233)  bbox_regression: 0.0445 (0.0422)  classification: 0.1953 (0.1811)\n",
            "Epoch: [46] [130/289]  eta: 0:00:13  time: 0.0820  loss: 0.2453 (0.2498)  bbox_regression: 0.0450 (0.0425)  classification: 0.2004 (0.2073)\n",
            "Epoch: [46] [140/289]  eta: 0:00:12  time: 0.0821  loss: 0.2464 (0.2863)  bbox_regression: 0.0456 (0.0521)  classification: 0.2008 (0.2342)\n",
            "Epoch: [46] [150/289]  eta: 0:00:11  time: 0.0822  loss: 0.2435 (0.2317)  bbox_regression: 0.0457 (0.0502)  classification: 0.1979 (0.1814)\n",
            "Epoch: [46] [160/289]  eta: 0:00:10  time: 0.0821  loss: 0.2389 (0.1864)  bbox_regression: 0.0449 (0.0402)  classification: 0.1941 (0.1462)\n",
            "Epoch: [46] [170/289]  eta: 0:00:09  time: 0.0820  loss: 0.2509 (0.3066)  bbox_regression: 0.0516 (0.0962)  classification: 0.1993 (0.2105)\n",
            "Epoch: [46] [180/289]  eta: 0:00:08  time: 0.0820  loss: 0.2509 (0.3472)  bbox_regression: 0.0523 (0.1119)  classification: 0.1986 (0.2353)\n",
            "Epoch: [46] [190/289]  eta: 0:00:08  time: 0.0819  loss: 0.2537 (0.2780)  bbox_regression: 0.0527 (0.0620)  classification: 0.2011 (0.2160)\n",
            "Epoch: [46] [200/289]  eta: 0:00:07  time: 0.0820  loss: 0.2489 (0.2309)  bbox_regression: 0.0516 (0.0450)  classification: 0.1973 (0.1859)\n",
            "Epoch: [46] [210/289]  eta: 0:00:06  time: 0.0820  loss: 0.2471 (0.1840)  bbox_regression: 0.0512 (0.0369)  classification: 0.1960 (0.1471)\n",
            "Epoch: [46] [220/289]  eta: 0:00:05  time: 0.0820  loss: 0.2456 (0.2123)  bbox_regression: 0.0515 (0.0506)  classification: 0.1941 (0.1617)\n",
            "Epoch: [46] [230/289]  eta: 0:00:04  time: 0.0821  loss: 0.2471 (0.2462)  bbox_regression: 0.0510 (0.0486)  classification: 0.1961 (0.1975)\n",
            "Epoch: [46] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.2432 (0.2171)  bbox_regression: 0.0503 (0.0372)  classification: 0.1929 (0.1798)\n",
            "Epoch: [46] [250/289]  eta: 0:00:03  time: 0.0822  loss: 0.2502 (0.2864)  bbox_regression: 0.0502 (0.0418)  classification: 0.2000 (0.2446)\n",
            "Epoch: [46] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.2523 (0.3614)  bbox_regression: 0.0504 (0.0514)  classification: 0.2019 (0.3100)\n",
            "Epoch: [46] [270/289]  eta: 0:00:01  time: 0.0824  loss: 0.2520 (0.2751)  bbox_regression: 0.0498 (0.0444)  classification: 0.2022 (0.2307)\n",
            "Epoch: [46] [280/289]  eta: 0:00:00  time: 0.0823  loss: 0.2522 (0.2506)  bbox_regression: 0.0491 (0.0320)  classification: 0.2031 (0.2186)\n",
            "Epoch: [46] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.2523 (0.2543)  bbox_regression: 0.0488 (0.0336)  classification: 0.2036 (0.2207)\n",
            "Epoch: [46] Time: 0:00:23 (0.0821 s / it)\n",
            "Epoch: [47]\n",
            "Epoch: [47] [  0/289]  eta: 0:00:22  time: 0.0790  loss: 0.0726 (0.0726)  bbox_regression: 0.0203 (0.0203)  classification: 0.0523 (0.0523)\n",
            "Epoch: [47] [ 10/289]  eta: 0:00:22  time: 0.0805  loss: 0.2023 (0.2023)  bbox_regression: 0.0315 (0.0315)  classification: 0.1708 (0.1708)\n",
            "Epoch: [47] [ 20/289]  eta: 0:00:21  time: 0.0805  loss: 0.1794 (0.1848)  bbox_regression: 0.0323 (0.0329)  classification: 0.1472 (0.1519)\n",
            "Epoch: [47] [ 30/289]  eta: 0:00:20  time: 0.0811  loss: 0.1971 (0.1942)  bbox_regression: 0.0347 (0.0364)  classification: 0.1624 (0.1578)\n",
            "Epoch: [47] [ 40/289]  eta: 0:00:20  time: 0.0816  loss: 0.2287 (0.2803)  bbox_regression: 0.0438 (0.0559)  classification: 0.1849 (0.2244)\n",
            "Epoch: [47] [ 50/289]  eta: 0:00:19  time: 0.0819  loss: 0.2408 (0.3085)  bbox_regression: 0.0451 (0.0611)  classification: 0.1957 (0.2473)\n",
            "Epoch: [47] [ 60/289]  eta: 0:00:18  time: 0.0816  loss: 0.2513 (0.2977)  bbox_regression: 0.0561 (0.0815)  classification: 0.1951 (0.2162)\n",
            "Epoch: [47] [ 70/289]  eta: 0:00:17  time: 0.0821  loss: 0.2586 (0.3040)  bbox_regression: 0.0564 (0.0852)  classification: 0.2022 (0.2188)\n",
            "Epoch: [47] [ 80/289]  eta: 0:00:17  time: 0.0820  loss: 0.2576 (0.2770)  bbox_regression: 0.0556 (0.0540)  classification: 0.2020 (0.2230)\n",
            "Epoch: [47] [ 90/289]  eta: 0:00:16  time: 0.0818  loss: 0.2534 (0.2350)  bbox_regression: 0.0540 (0.0458)  classification: 0.1993 (0.1892)\n",
            "Epoch: [47] [100/289]  eta: 0:00:15  time: 0.0816  loss: 0.2540 (0.2392)  bbox_regression: 0.0551 (0.0531)  classification: 0.1989 (0.1861)\n",
            "Epoch: [47] [110/289]  eta: 0:00:14  time: 0.0816  loss: 0.2507 (0.2386)  bbox_regression: 0.0529 (0.0476)  classification: 0.1978 (0.1910)\n",
            "Epoch: [47] [120/289]  eta: 0:00:13  time: 0.0821  loss: 0.2462 (0.2068)  bbox_regression: 0.0512 (0.0316)  classification: 0.1950 (0.1752)\n",
            "Epoch: [47] [130/289]  eta: 0:00:13  time: 0.0824  loss: 0.2483 (0.2350)  bbox_regression: 0.0514 (0.0434)  classification: 0.1969 (0.1916)\n",
            "Epoch: [47] [140/289]  eta: 0:00:12  time: 0.0826  loss: 0.2555 (0.3122)  bbox_regression: 0.0525 (0.0603)  classification: 0.2030 (0.2519)\n",
            "Epoch: [47] [150/289]  eta: 0:00:11  time: 0.0827  loss: 0.2569 (0.3130)  bbox_regression: 0.0527 (0.0613)  classification: 0.2041 (0.2517)\n",
            "Epoch: [47] [160/289]  eta: 0:00:10  time: 0.0825  loss: 0.2589 (0.2827)  bbox_regression: 0.0529 (0.0556)  classification: 0.2060 (0.2271)\n",
            "Epoch: [47] [170/289]  eta: 0:00:09  time: 0.0826  loss: 0.2564 (0.2526)  bbox_regression: 0.0516 (0.0426)  classification: 0.2048 (0.2100)\n",
            "Epoch: [47] [180/289]  eta: 0:00:09  time: 0.0826  loss: 0.2583 (0.2535)  bbox_regression: 0.0513 (0.0389)  classification: 0.2070 (0.2146)\n",
            "Epoch: [47] [190/289]  eta: 0:00:08  time: 0.0825  loss: 0.2554 (0.2473)  bbox_regression: 0.0505 (0.0412)  classification: 0.2050 (0.2061)\n",
            "Epoch: [47] [200/289]  eta: 0:00:07  time: 0.0824  loss: 0.2540 (0.2150)  bbox_regression: 0.0496 (0.0337)  classification: 0.2044 (0.1812)\n",
            "Epoch: [47] [210/289]  eta: 0:00:06  time: 0.0823  loss: 0.2510 (0.2085)  bbox_regression: 0.0492 (0.0371)  classification: 0.2018 (0.1714)\n",
            "Epoch: [47] [220/289]  eta: 0:00:05  time: 0.0822  loss: 0.2480 (0.1877)  bbox_regression: 0.0490 (0.0435)  classification: 0.1990 (0.1442)\n",
            "Epoch: [47] [230/289]  eta: 0:00:04  time: 0.0822  loss: 0.2528 (0.2714)  bbox_regression: 0.0501 (0.0598)  classification: 0.2026 (0.2116)\n",
            "Epoch: [47] [240/289]  eta: 0:00:04  time: 0.0823  loss: 0.2534 (0.3133)  bbox_regression: 0.0500 (0.0610)  classification: 0.2034 (0.2523)\n",
            "Epoch: [47] [250/289]  eta: 0:00:03  time: 0.0822  loss: 0.2505 (0.2240)  bbox_regression: 0.0495 (0.0418)  classification: 0.2010 (0.1822)\n",
            "Epoch: [47] [260/289]  eta: 0:00:02  time: 0.0822  loss: 0.2514 (0.2274)  bbox_regression: 0.0490 (0.0363)  classification: 0.2025 (0.1911)\n",
            "Epoch: [47] [270/289]  eta: 0:00:01  time: 0.0823  loss: 0.2531 (0.2866)  bbox_regression: 0.0495 (0.0502)  classification: 0.2036 (0.2364)\n",
            "Epoch: [47] [280/289]  eta: 0:00:00  time: 0.0823  loss: 0.2527 (0.2686)  bbox_regression: 0.0495 (0.0557)  classification: 0.2032 (0.2129)\n",
            "Epoch: [47] [288/289]  eta: 0:00:00  time: 0.0821  loss: 0.2516 (0.2460)  bbox_regression: 0.0490 (0.0479)  classification: 0.2026 (0.1981)\n",
            "Epoch: [47] Time: 0:00:23 (0.0821 s / it)\n",
            "Epoch: [48]\n",
            "Epoch: [48] [  0/289]  eta: 0:00:21  time: 0.0757  loss: 0.1474 (0.1474)  bbox_regression: 0.0308 (0.0308)  classification: 0.1166 (0.1166)\n",
            "Epoch: [48] [ 10/289]  eta: 0:00:22  time: 0.0798  loss: 0.3128 (0.3128)  bbox_regression: 0.0495 (0.0495)  classification: 0.2633 (0.2633)\n",
            "Epoch: [48] [ 20/289]  eta: 0:00:21  time: 0.0814  loss: 0.2796 (0.2862)  bbox_regression: 0.0464 (0.0472)  classification: 0.2331 (0.2390)\n",
            "Epoch: [48] [ 30/289]  eta: 0:00:21  time: 0.0819  loss: 0.2714 (0.2486)  bbox_regression: 0.0572 (0.0614)  classification: 0.2142 (0.1871)\n",
            "Epoch: [48] [ 40/289]  eta: 0:00:20  time: 0.0829  loss: 0.2749 (0.2700)  bbox_regression: 0.0555 (0.0651)  classification: 0.2194 (0.2050)\n",
            "Epoch: [48] [ 50/289]  eta: 0:00:19  time: 0.0835  loss: 0.2755 (0.2819)  bbox_regression: 0.0537 (0.0482)  classification: 0.2218 (0.2337)\n",
            "Epoch: [48] [ 60/289]  eta: 0:00:19  time: 0.0831  loss: 0.2636 (0.2403)  bbox_regression: 0.0526 (0.0465)  classification: 0.2110 (0.1938)\n",
            "Epoch: [48] [ 70/289]  eta: 0:00:18  time: 0.0832  loss: 0.2699 (0.2556)  bbox_regression: 0.0529 (0.0508)  classification: 0.2170 (0.2049)\n",
            "Epoch: [48] [ 80/289]  eta: 0:00:17  time: 0.0827  loss: 0.2549 (0.2283)  bbox_regression: 0.0498 (0.0413)  classification: 0.2051 (0.1870)\n",
            "Epoch: [48] [ 90/289]  eta: 0:00:16  time: 0.0826  loss: 0.2550 (0.2023)  bbox_regression: 0.0475 (0.0284)  classification: 0.2076 (0.1739)\n",
            "Epoch: [48] [100/289]  eta: 0:00:15  time: 0.0826  loss: 0.2520 (0.2406)  bbox_regression: 0.0475 (0.0384)  classification: 0.2045 (0.2022)\n",
            "Epoch: [48] [110/289]  eta: 0:00:14  time: 0.0826  loss: 0.2460 (0.2048)  bbox_regression: 0.0464 (0.0415)  classification: 0.1996 (0.1633)\n",
            "Epoch: [48] [120/289]  eta: 0:00:13  time: 0.0824  loss: 0.2523 (0.2537)  bbox_regression: 0.0518 (0.0733)  classification: 0.2005 (0.1803)\n",
            "Epoch: [48] [130/289]  eta: 0:00:13  time: 0.0825  loss: 0.2502 (0.2734)  bbox_regression: 0.0514 (0.0790)  classification: 0.1988 (0.1944)\n",
            "Epoch: [48] [140/289]  eta: 0:00:12  time: 0.0823  loss: 0.2508 (0.2419)  bbox_regression: 0.0504 (0.0421)  classification: 0.2004 (0.1999)\n",
            "Epoch: [48] [150/289]  eta: 0:00:11  time: 0.0823  loss: 0.2523 (0.2664)  bbox_regression: 0.0504 (0.0443)  classification: 0.2019 (0.2221)\n",
            "Epoch: [48] [160/289]  eta: 0:00:10  time: 0.0824  loss: 0.2517 (0.2579)  bbox_regression: 0.0495 (0.0427)  classification: 0.2023 (0.2152)\n",
            "Epoch: [48] [170/289]  eta: 0:00:09  time: 0.0825  loss: 0.2504 (0.2362)  bbox_regression: 0.0501 (0.0475)  classification: 0.2003 (0.1887)\n",
            "Epoch: [48] [180/289]  eta: 0:00:08  time: 0.0824  loss: 0.2519 (0.2532)  bbox_regression: 0.0494 (0.0486)  classification: 0.2025 (0.2046)\n",
            "Epoch: [48] [190/289]  eta: 0:00:08  time: 0.0825  loss: 0.2494 (0.2403)  bbox_regression: 0.0488 (0.0374)  classification: 0.2006 (0.2028)\n",
            "Epoch: [48] [200/289]  eta: 0:00:07  time: 0.0826  loss: 0.2477 (0.2102)  bbox_regression: 0.0482 (0.0377)  classification: 0.1995 (0.1724)\n",
            "Epoch: [48] [210/289]  eta: 0:00:06  time: 0.0825  loss: 0.2468 (0.2221)  bbox_regression: 0.0479 (0.0391)  classification: 0.1989 (0.1830)\n",
            "Epoch: [48] [220/289]  eta: 0:00:05  time: 0.0826  loss: 0.2486 (0.2570)  bbox_regression: 0.0481 (0.0466)  classification: 0.2005 (0.2104)\n",
            "Epoch: [48] [230/289]  eta: 0:00:04  time: 0.0826  loss: 0.2475 (0.2549)  bbox_regression: 0.0485 (0.0554)  classification: 0.1990 (0.1995)\n",
            "Epoch: [48] [240/289]  eta: 0:00:04  time: 0.0826  loss: 0.2451 (0.2071)  bbox_regression: 0.0483 (0.0509)  classification: 0.1968 (0.1562)\n",
            "Epoch: [48] [250/289]  eta: 0:00:03  time: 0.0824  loss: 0.2450 (0.2156)  bbox_regression: 0.0484 (0.0473)  classification: 0.1965 (0.1683)\n",
            "Epoch: [48] [260/289]  eta: 0:00:02  time: 0.0823  loss: 0.2465 (0.2637)  bbox_regression: 0.0489 (0.0559)  classification: 0.1977 (0.2078)\n",
            "Epoch: [48] [270/289]  eta: 0:00:01  time: 0.0823  loss: 0.2530 (0.3541)  bbox_regression: 0.0492 (0.0592)  classification: 0.2038 (0.2949)\n",
            "Epoch: [48] [280/289]  eta: 0:00:00  time: 0.0823  loss: 0.2508 (0.3058)  bbox_regression: 0.0489 (0.0488)  classification: 0.2019 (0.2570)\n",
            "Epoch: [48] [288/289]  eta: 0:00:00  time: 0.0823  loss: 0.2513 (0.2468)  bbox_regression: 0.0492 (0.0534)  classification: 0.2021 (0.1935)\n",
            "Epoch: [48] Time: 0:00:23 (0.0823 s / it)\n",
            "Epoch: [49]\n",
            "Epoch: [49] [  0/289]  eta: 0:00:22  time: 0.0777  loss: 0.3239 (0.3239)  bbox_regression: 0.0323 (0.0323)  classification: 0.2916 (0.2916)\n",
            "Epoch: [49] [ 10/289]  eta: 0:00:24  time: 0.0862  loss: 0.2819 (0.2819)  bbox_regression: 0.0502 (0.0502)  classification: 0.2317 (0.2317)\n",
            "Epoch: [49] [ 20/289]  eta: 0:00:22  time: 0.0834  loss: 0.2579 (0.2546)  bbox_regression: 0.0413 (0.0418)  classification: 0.2166 (0.2128)\n",
            "Epoch: [49] [ 30/289]  eta: 0:00:21  time: 0.0834  loss: 0.2477 (0.2289)  bbox_regression: 0.0406 (0.0353)  classification: 0.2071 (0.1936)\n",
            "Epoch: [49] [ 40/289]  eta: 0:00:20  time: 0.0825  loss: 0.2559 (0.2538)  bbox_regression: 0.0403 (0.0392)  classification: 0.2157 (0.2147)\n",
            "Epoch: [49] [ 50/289]  eta: 0:00:19  time: 0.0821  loss: 0.2630 (0.2868)  bbox_regression: 0.0416 (0.0433)  classification: 0.2214 (0.2435)\n",
            "Epoch: [49] [ 60/289]  eta: 0:00:18  time: 0.0821  loss: 0.2597 (0.2675)  bbox_regression: 0.0406 (0.0413)  classification: 0.2191 (0.2262)\n",
            "Epoch: [49] [ 70/289]  eta: 0:00:17  time: 0.0821  loss: 0.2490 (0.2133)  bbox_regression: 0.0425 (0.0449)  classification: 0.2065 (0.1684)\n",
            "Epoch: [49] [ 80/289]  eta: 0:00:17  time: 0.0819  loss: 0.2462 (0.2051)  bbox_regression: 0.0428 (0.0495)  classification: 0.2034 (0.1556)\n",
            "Epoch: [49] [ 90/289]  eta: 0:00:16  time: 0.0818  loss: 0.2415 (0.2146)  bbox_regression: 0.0427 (0.0432)  classification: 0.1988 (0.1714)\n",
            "Epoch: [49] [100/289]  eta: 0:00:15  time: 0.0818  loss: 0.2537 (0.2839)  bbox_regression: 0.0455 (0.0565)  classification: 0.2082 (0.2274)\n",
            "Epoch: [49] [110/289]  eta: 0:00:14  time: 0.0817  loss: 0.2452 (0.2620)  bbox_regression: 0.0443 (0.0517)  classification: 0.2008 (0.2103)\n",
            "Epoch: [49] [120/289]  eta: 0:00:13  time: 0.0821  loss: 0.2652 (0.3232)  bbox_regression: 0.0509 (0.0782)  classification: 0.2143 (0.2450)\n",
            "Epoch: [49] [130/289]  eta: 0:00:13  time: 0.0822  loss: 0.2537 (0.3009)  bbox_regression: 0.0491 (0.0756)  classification: 0.2046 (0.2253)\n",
            "Epoch: [49] [140/289]  eta: 0:00:12  time: 0.0824  loss: 0.2526 (0.1762)  bbox_regression: 0.0477 (0.0285)  classification: 0.2048 (0.1477)\n",
            "Epoch: [49] [150/289]  eta: 0:00:11  time: 0.0821  loss: 0.2504 (0.2292)  bbox_regression: 0.0481 (0.0417)  classification: 0.2023 (0.1875)\n",
            "Epoch: [49] [160/289]  eta: 0:00:10  time: 0.0821  loss: 0.2551 (0.2729)  bbox_regression: 0.0489 (0.0571)  classification: 0.2062 (0.2158)\n",
            "Epoch: [49] [170/289]  eta: 0:00:09  time: 0.0820  loss: 0.2552 (0.2916)  bbox_regression: 0.0492 (0.0572)  classification: 0.2061 (0.2344)\n",
            "Epoch: [49] [180/289]  eta: 0:00:08  time: 0.0820  loss: 0.2583 (0.2845)  bbox_regression: 0.0488 (0.0482)  classification: 0.2095 (0.2362)\n",
            "Epoch: [49] [190/289]  eta: 0:00:08  time: 0.0820  loss: 0.2554 (0.2570)  bbox_regression: 0.0485 (0.0429)  classification: 0.2069 (0.2141)\n",
            "Epoch: [49] [200/289]  eta: 0:00:07  time: 0.0822  loss: 0.2510 (0.1851)  bbox_regression: 0.0478 (0.0381)  classification: 0.2033 (0.1470)\n",
            "Epoch: [49] [210/289]  eta: 0:00:06  time: 0.0824  loss: 0.2469 (0.1653)  bbox_regression: 0.0471 (0.0331)  classification: 0.1998 (0.1322)\n",
            "Epoch: [49] [220/289]  eta: 0:00:05  time: 0.0823  loss: 0.2481 (0.2190)  bbox_regression: 0.0480 (0.0506)  classification: 0.2001 (0.1684)\n",
            "Epoch: [49] [230/289]  eta: 0:00:04  time: 0.0823  loss: 0.2472 (0.2503)  bbox_regression: 0.0482 (0.0597)  classification: 0.1990 (0.1906)\n",
            "Epoch: [49] [240/289]  eta: 0:00:04  time: 0.0821  loss: 0.2478 (0.2434)  bbox_regression: 0.0480 (0.0474)  classification: 0.1998 (0.1960)\n",
            "Epoch: [49] [250/289]  eta: 0:00:03  time: 0.0821  loss: 0.2479 (0.2558)  bbox_regression: 0.0476 (0.0406)  classification: 0.2003 (0.2152)\n",
            "Epoch: [49] [260/289]  eta: 0:00:02  time: 0.0820  loss: 0.2473 (0.2417)  bbox_regression: 0.0477 (0.0446)  classification: 0.1996 (0.1971)\n",
            "Epoch: [49] [270/289]  eta: 0:00:01  time: 0.0819  loss: 0.2474 (0.2411)  bbox_regression: 0.0475 (0.0464)  classification: 0.1999 (0.1947)\n",
            "Epoch: [49] [280/289]  eta: 0:00:00  time: 0.0820  loss: 0.2491 (0.2725)  bbox_regression: 0.0487 (0.0610)  classification: 0.2004 (0.2115)\n",
            "Epoch: [49] [288/289]  eta: 0:00:00  time: 0.0819  loss: 0.2512 (0.3107)  bbox_regression: 0.0494 (0.0734)  classification: 0.2018 (0.2373)\n",
            "Epoch: [49] Time: 0:00:23 (0.0819 s / it)\n",
            "Validation: [49]\n",
            "Validation: [49] [ 0/62]  eta: 0:00:04  time: 0.0731  \n",
            "Validation: [49] [10/62]  eta: 0:00:03  time: 0.0704  \n",
            "Validation: [49] [20/62]  eta: 0:00:02  time: 0.0691  \n",
            "Validation: [49] [30/62]  eta: 0:00:02  time: 0.0691  \n",
            "Validation: [49] [40/62]  eta: 0:00:01  time: 0.0691  \n",
            "Validation: [49] [50/62]  eta: 0:00:00  time: 0.0690  \n",
            "Validation: [49] [60/62]  eta: 0:00:00  time: 0.0689  \n",
            "Validation: [49] [61/62]  eta: 0:00:00  time: 0.0685  \n",
            "Validation: [49] Time: 0:00:04 (0.0685 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/epoch_50/mAP_vs_threshold_epoch_49.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/epoch_50/pr_curves_epoch_49.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/epoch_50/per_class_ap_epoch_49.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/epoch_50/confusion_matrix_epoch_49.png\n",
            "Epoch 49: mAP@0.5 = 0.5144\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6516\n",
            "  Bacterial-Black-spot: 0.6101\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.3169\n",
            "  Mechanical-damage: 0.7286\n",
            "  Others: 0.7796\n",
            "Copied per_class_mAP_epoch_49.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/per_class_mAP_epoch_49.csv\n",
            "Copied per_class_ap_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/per_class_ap_epoch_49.png\n",
            "Copied mAP_vs_threshold_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/mAP_vs_threshold_epoch_49.png\n",
            "Copied confusion_matrix_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/confusion_matrix_epoch_49.png\n",
            "Copied mAP_vs_threshold_epoch_49.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/mAP_vs_threshold_epoch_49.csv\n",
            "Copied pr_curves_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/pr_curves_epoch_49.png\n",
            "Saved checkpoint at epoch 50\n",
            "Saved mAP threshold curves to /content/ssd_model/mAP_threshold_curves.png\n",
            "\n",
            "Training complete in 23.97 minutes\n",
            "Best validation mAP: 0.5146\n",
            "Loaded best model for final evaluation\n",
            "Validation: [50]\n",
            "Validation: [50] [ 0/62]  eta: 0:00:04  time: 0.0709  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-4e708d5fe050>:1452: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [50] [10/62]  eta: 0:00:03  time: 0.0713  \n",
            "Validation: [50] [20/62]  eta: 0:00:02  time: 0.0703  \n",
            "Validation: [50] [30/62]  eta: 0:00:02  time: 0.0706  \n",
            "Validation: [50] [40/62]  eta: 0:00:01  time: 0.0705  \n",
            "Validation: [50] [50/62]  eta: 0:00:00  time: 0.0712  \n",
            "Validation: [50] [60/62]  eta: 0:00:00  time: 0.0716  \n",
            "Validation: [50] [61/62]  eta: 0:00:00  time: 0.0711  \n",
            "Validation: [50] Time: 0:00:04 (0.0712 s / it)\n",
            "Saved mAP vs threshold plot to /content/ssd_model/evaluation/final/mAP_vs_threshold_epoch_50.png\n",
            "Saved PR curves to /content/ssd_model/evaluation/final/pr_curves_epoch_50.png\n",
            "Saved per-class AP plot to /content/ssd_model/evaluation/final/per_class_ap_epoch_50.png\n",
            "Saved confusion matrix to /content/ssd_model/evaluation/final/confusion_matrix_epoch_50.png\n",
            "Epoch 50: mAP@0.5 = 0.5146\n",
            "\n",
            "Per-class Average Precision:\n",
            "  Anthracnose: 0.6203\n",
            "  Bacterial-Black-spot: 0.6026\n",
            "  Damaged-mango: 0.0000\n",
            "  Fruitly: 0.3149\n",
            "  Mechanical-damage: 0.7571\n",
            "  Others: 0.7928\n",
            "Final validation mAP: 0.5146\n",
            "Generating enhanced prediction visualizations...\n",
            "Enhanced prediction visualization and metrics saved to /content/ssd_model/evaluation/final/conf_0.3\n",
            "Enhanced prediction visualization and metrics saved to /content/ssd_model/evaluation/final/conf_0.5\n",
            "Enhanced prediction visualization and metrics saved to /content/ssd_model/evaluation/final/conf_0.7\n",
            "Copied mAP_vs_threshold_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/mAP_vs_threshold_epoch_50.png\n",
            "Copied pr_curves_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/pr_curves_epoch_50.png\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/detection_metrics.csv\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/detection_metrics.csv\n",
            "Copied per_class_ap_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/per_class_ap_epoch_50.png\n",
            "Copied confusion_matrix_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/confusion_matrix_epoch_50.png\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/detection_metrics.csv\n",
            "Copied mAP_vs_threshold_epoch_50.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/mAP_vs_threshold_epoch_50.csv\n",
            "Copied per_class_mAP_epoch_50.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/per_class_mAP_epoch_50.csv\n",
            "Enhanced training report saved to /content/ssd_model/training_report.txt\n",
            "Copied training report to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/training_report.txt\n",
            "Copied checkpoint_10.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/checkpoint_10.pth\n",
            "Copied checkpoint_20.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/checkpoint_20.pth\n",
            "Copied checkpoint_30.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/checkpoint_30.pth\n",
            "Copied best_model.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n",
            "Copied checkpoint_50.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/checkpoint_50.pth\n",
            "Copied checkpoint_40.pth to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/checkpoint_40.pth\n",
            "Copied mAP_threshold_curves.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/mAP_threshold_curves.png\n",
            "Copied mAP_vs_threshold_epoch_4.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/mAP_vs_threshold_epoch_4.csv\n",
            "Copied per_class_ap_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/per_class_ap_epoch_4.png\n",
            "Copied confusion_matrix_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/confusion_matrix_epoch_4.png\n",
            "Copied mAP_vs_threshold_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/mAP_vs_threshold_epoch_4.png\n",
            "Copied pr_curves_epoch_4.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/pr_curves_epoch_4.png\n",
            "Copied per_class_mAP_epoch_4.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_5/per_class_mAP_epoch_4.csv\n",
            "Copied per_class_mAP_epoch_19.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/per_class_mAP_epoch_19.csv\n",
            "Copied per_class_ap_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/per_class_ap_epoch_19.png\n",
            "Copied mAP_vs_threshold_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/mAP_vs_threshold_epoch_19.png\n",
            "Copied mAP_vs_threshold_epoch_19.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/mAP_vs_threshold_epoch_19.csv\n",
            "Copied confusion_matrix_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/confusion_matrix_epoch_19.png\n",
            "Copied pr_curves_epoch_19.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_20/pr_curves_epoch_19.png\n",
            "Copied confusion_matrix_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/confusion_matrix_epoch_39.png\n",
            "Copied per_class_mAP_epoch_39.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/per_class_mAP_epoch_39.csv\n",
            "Copied per_class_ap_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/per_class_ap_epoch_39.png\n",
            "Copied pr_curves_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/pr_curves_epoch_39.png\n",
            "Copied mAP_vs_threshold_epoch_39.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/mAP_vs_threshold_epoch_39.csv\n",
            "Copied mAP_vs_threshold_epoch_39.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_40/mAP_vs_threshold_epoch_39.png\n",
            "Copied per_class_ap_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/per_class_ap_epoch_24.png\n",
            "Copied mAP_vs_threshold_epoch_24.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/mAP_vs_threshold_epoch_24.csv\n",
            "Copied pr_curves_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/pr_curves_epoch_24.png\n",
            "Copied mAP_vs_threshold_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/mAP_vs_threshold_epoch_24.png\n",
            "Copied per_class_mAP_epoch_24.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/per_class_mAP_epoch_24.csv\n",
            "Copied confusion_matrix_epoch_24.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_25/confusion_matrix_epoch_24.png\n",
            "Copied per_class_mAP_epoch_44.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/per_class_mAP_epoch_44.csv\n",
            "Copied confusion_matrix_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/confusion_matrix_epoch_44.png\n",
            "Copied mAP_vs_threshold_epoch_44.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/mAP_vs_threshold_epoch_44.csv\n",
            "Copied pr_curves_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/pr_curves_epoch_44.png\n",
            "Copied per_class_ap_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/per_class_ap_epoch_44.png\n",
            "Copied mAP_vs_threshold_epoch_44.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_45/mAP_vs_threshold_epoch_44.png\n",
            "Copied mAP_vs_threshold_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/mAP_vs_threshold_epoch_50.png\n",
            "Copied pr_curves_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/pr_curves_epoch_50.png\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.7/detection_metrics.csv\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.5/detection_metrics.csv\n",
            "Copied per_class_ap_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/per_class_ap_epoch_50.png\n",
            "Copied confusion_matrix_epoch_50.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/confusion_matrix_epoch_50.png\n",
            "Copied per_class_metrics.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/per_class_metrics.png\n",
            "Copied enhanced_predictions.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/enhanced_predictions.png\n",
            "Copied detection_metrics.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/conf_0.3/detection_metrics.csv\n",
            "Copied mAP_vs_threshold_epoch_50.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/mAP_vs_threshold_epoch_50.csv\n",
            "Copied per_class_mAP_epoch_50.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/final/per_class_mAP_epoch_50.csv\n",
            "Copied confusion_matrix_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/confusion_matrix_epoch_14.png\n",
            "Copied per_class_mAP_epoch_14.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/per_class_mAP_epoch_14.csv\n",
            "Copied per_class_ap_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/per_class_ap_epoch_14.png\n",
            "Copied mAP_vs_threshold_epoch_14.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/mAP_vs_threshold_epoch_14.csv\n",
            "Copied mAP_vs_threshold_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/mAP_vs_threshold_epoch_14.png\n",
            "Copied pr_curves_epoch_14.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_15/pr_curves_epoch_14.png\n",
            "Copied per_class_mAP_epoch_49.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/per_class_mAP_epoch_49.csv\n",
            "Copied per_class_ap_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/per_class_ap_epoch_49.png\n",
            "Copied mAP_vs_threshold_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/mAP_vs_threshold_epoch_49.png\n",
            "Copied confusion_matrix_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/confusion_matrix_epoch_49.png\n",
            "Copied mAP_vs_threshold_epoch_49.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/mAP_vs_threshold_epoch_49.csv\n",
            "Copied pr_curves_epoch_49.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_50/pr_curves_epoch_49.png\n",
            "Copied pr_curves_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/pr_curves_epoch_29.png\n",
            "Copied mAP_vs_threshold_epoch_29.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/mAP_vs_threshold_epoch_29.csv\n",
            "Copied per_class_mAP_epoch_29.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/per_class_mAP_epoch_29.csv\n",
            "Copied mAP_vs_threshold_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/mAP_vs_threshold_epoch_29.png\n",
            "Copied confusion_matrix_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/confusion_matrix_epoch_29.png\n",
            "Copied per_class_ap_epoch_29.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_30/per_class_ap_epoch_29.png\n",
            "Copied mAP_vs_threshold_epoch_34.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/mAP_vs_threshold_epoch_34.csv\n",
            "Copied per_class_mAP_epoch_34.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/per_class_mAP_epoch_34.csv\n",
            "Copied per_class_ap_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/per_class_ap_epoch_34.png\n",
            "Copied confusion_matrix_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/confusion_matrix_epoch_34.png\n",
            "Copied mAP_vs_threshold_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/mAP_vs_threshold_epoch_34.png\n",
            "Copied pr_curves_epoch_34.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_35/pr_curves_epoch_34.png\n",
            "Copied confusion_matrix_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/confusion_matrix_epoch_9.png\n",
            "Copied mAP_vs_threshold_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/mAP_vs_threshold_epoch_9.png\n",
            "Copied pr_curves_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/pr_curves_epoch_9.png\n",
            "Copied per_class_ap_epoch_9.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/per_class_ap_epoch_9.png\n",
            "Copied per_class_mAP_epoch_9.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/per_class_mAP_epoch_9.csv\n",
            "Copied mAP_vs_threshold_epoch_9.csv to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation/epoch_10/mAP_vs_threshold_epoch_9.csv\n",
            "Copied training_report.txt to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/training_report.txt\n",
            "Copied training_curves.png to Google Drive: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/training_curves.png\n",
            "\n",
            "==== SSD MODEL TRAINING WITH ENHANCED EVALUATION COMPLETE ====\n",
            "SSD model training completed successfully.\n",
            "\n",
            "==== ALL STEPS COMPLETED SUCCESSFULLY ====\n",
            "SSD model trained and saved to /content/ssd_model/best_model.pth\n",
            "Model also backed up to Google Drive at /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import sys\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab environment\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"ERROR: This script must be run in Google Colab\")\n",
        "    sys.exit(1)\n",
        "\n",
        "def copy_with_progress(src_dir, dst_dir):\n",
        "    \"\"\"Copy files with progress bar\"\"\"\n",
        "    # Get list of all files to copy\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(src_dir):\n",
        "        for file in files:\n",
        "            src_path = os.path.join(root, file)\n",
        "            rel_path = os.path.relpath(src_path, src_dir)\n",
        "            dst_path = os.path.join(dst_dir, rel_path)\n",
        "            all_files.append((src_path, dst_path))\n",
        "\n",
        "    # Create progress bar\n",
        "    with tqdm(total=len(all_files), desc=\"Copying files\") as pbar:\n",
        "        for src_path, dst_path in all_files:\n",
        "            # Create destination directory if it doesn't exist\n",
        "            os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "            # Copy the file\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            pbar.update(1)\n",
        "\n",
        "def push_evaluation_to_drive(local_eval_dir, drive_base_dir, model_name=\"ssd_model\"):\n",
        "    \"\"\"Push evaluation folder to Google Drive\"\"\"\n",
        "\n",
        "    if not os.path.exists(local_eval_dir):\n",
        "        print(f\"ERROR: Local evaluation directory not found: {local_eval_dir}\")\n",
        "        return False\n",
        "\n",
        "    # Mount Google Drive if not already mounted\n",
        "    drive_mounted = os.path.exists(\"/content/drive\")\n",
        "    if not drive_mounted:\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Google Drive mounted successfully\")\n",
        "\n",
        "    # Create target directory\n",
        "    drive_eval_dir = os.path.join(drive_base_dir, model_name, \"evaluation\")\n",
        "    os.makedirs(drive_eval_dir, exist_ok=True)\n",
        "    print(f\"Target directory: {drive_eval_dir}\")\n",
        "\n",
        "    # Count files to copy\n",
        "    file_count = sum([len(files) for _, _, files in os.walk(local_eval_dir)])\n",
        "    dir_count = sum([len(dirs) for _, dirs, _ in os.walk(local_eval_dir)])\n",
        "    print(f\"Found {file_count} files in {dir_count} directories to copy\")\n",
        "\n",
        "    # Copy files\n",
        "    print(f\"Copying evaluation results to Google Drive...\")\n",
        "    copy_with_progress(local_eval_dir, drive_eval_dir)\n",
        "\n",
        "    # Verify copy\n",
        "    drive_file_count = sum([len(files) for _, _, files in os.walk(drive_eval_dir)])\n",
        "    if drive_file_count == file_count:\n",
        "        print(f\"SUCCESS: {drive_file_count} files copied to Google Drive\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"WARNING: Only {drive_file_count} of {file_count} files were copied\")\n",
        "        return False\n",
        "\n",
        "# Configure these variables to customize the backup\n",
        "LOCAL_EVAL_DIR = '/content/ssd_model/evaluation'  # Source directory\n",
        "DRIVE_BASE_DIR = '/content/drive/MyDrive/MANGO/PROJECT'  # Destination base directory\n",
        "MODEL_NAME = 'mango_ssd_enhanced'  # Model name subfolder\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"PUSHING EVALUATION RESULTS TO GOOGLE DRIVE\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Source: {LOCAL_EVAL_DIR}\")\n",
        "print(f\"Destination: {DRIVE_BASE_DIR}/{MODEL_NAME}/evaluation\")\n",
        "\n",
        "success = push_evaluation_to_drive(\n",
        "    LOCAL_EVAL_DIR,\n",
        "    DRIVE_BASE_DIR,\n",
        "    MODEL_NAME\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"\\nAll evaluation results successfully copied to Google Drive!\")\n",
        "    print(\"You can safely close this notebook or continue with other tasks.\")\n",
        "else:\n",
        "    print(\"\\nWARNING: There may have been issues copying the evaluation results.\")\n",
        "    print(\"Please check the logs above for more details.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "17d0ac95445848bb88f13a4d9f32f63f",
            "1610f81d34c44f43b955db88bf3d68dd",
            "c44097cfe6f04f7ea85d95e9b4b86dcf",
            "22caaf2bc33b4d8ba20efe835a2e5128",
            "f429d1bf2d0249699a30386890ee8e97",
            "c061618aea0b44939a88b8dac49b6e7e",
            "e7d8db68ad654b898ddabdf7837f9970",
            "f351e39394e54c1b9335453f3f7a6243",
            "5458e9754dd7483787a35ee9173b55d7",
            "dd74c110b5b94732b5b47c9a024c6b77",
            "4132b87a94854a5897df58597b1c896f"
          ]
        },
        "id": "Soty-Hk56bxV",
        "outputId": "f1f09c63-c0df-4595-9f4b-d17cc1f185d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab environment\n",
            "==================================================\n",
            "PUSHING EVALUATION RESULTS TO GOOGLE DRIVE\n",
            "==================================================\n",
            "Source: /content/ssd_model/evaluation\n",
            "Destination: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation\n",
            "Target directory: /content/drive/MyDrive/MANGO/PROJECT/mango_ssd_enhanced/evaluation\n",
            "Found 75 files in 14 directories to copy\n",
            "Copying evaluation results to Google Drive...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Copying files:   0%|          | 0/75 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17d0ac95445848bb88f13a4d9f32f63f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: 75 files copied to Google Drive\n",
            "\n",
            "All evaluation results successfully copied to Google Drive!\n",
            "You can safely close this notebook or continue with other tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.models.detection.ssd import SSDHead\n",
        "from torchvision.models.detection.anchor_utils import DefaultBoxGenerator\n",
        "from torchvision.ops import box_iou, nms\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score\n",
        "\n",
        "# ===========================\n",
        "# INCEPTION V2 BACKBONE\n",
        "# ===========================\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    \"\"\"Basic convolution module used in Inception networks\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return self.relu(x)\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Inception module with BatchNorm (InceptionV2 style)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # 1x1 branch\n",
        "        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        # 3x3 branch\n",
        "        self.branch2 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, ch3x3red, kernel_size=1),\n",
        "            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # 5x5 branch (implemented as two 3x3 convs for efficiency)\n",
        "        self.branch3 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, ch5x5red, kernel_size=1),\n",
        "            BasicConv2d(ch5x5red, ch5x5, kernel_size=3, padding=1),\n",
        "            BasicConv2d(ch5x5, ch5x5, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Pooling branch\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            BasicConv2d(in_channels, pool_proj, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
        "\n",
        "class InceptionV2Backbone(nn.Module):\n",
        "    \"\"\"\n",
        "    InceptionV2 backbone network for SSD\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(InceptionV2Backbone, self).__init__()\n",
        "\n",
        "        # Initial layers similar to InceptionV2\n",
        "        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n",
        "        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Inception blocks\n",
        "        self.inception3a = InceptionModule(192, 64, 64, 64, 64, 96, 32)\n",
        "        self.inception3b = InceptionModule(256, 64, 64, 96, 64, 96, 64)\n",
        "        self.inception3c = InceptionModule(320, 128, 64, 96, 64, 96, 64)\n",
        "\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception4a = InceptionModule(384, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        # If using pretrained weights, load from torchvision's Inception model\n",
        "        if pretrained:\n",
        "            try:\n",
        "                inception_model = torchvision.models.inception_v3(pretrained=True)\n",
        "                # We can't use direct loading as architectures differ, so we'll do a partial transfer\n",
        "                print(\"Loading pretrained Inception weights and adapting to InceptionV2...\")\n",
        "                # This would require mapping between layers, which is complex\n",
        "                # In a real implementation, you might want to use a pretrained checkpoint specifically for InceptionV2\n",
        "            except Exception as e:\n",
        "                print(f\"Could not load pretrained weights: {e}\")\n",
        "                print(\"Using randomly initialized weights.\")\n",
        "\n",
        "        # Initialize weights if not using pretrained\n",
        "        if not pretrained:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feature extraction and return intermediate features for SSD\n",
        "        features = []\n",
        "\n",
        "        # Initial convolutions\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Inception blocks with feature collection\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.inception3c(x)\n",
        "\n",
        "        # Save feature after Inception block 3\n",
        "        features.append(x)  # feature 1 (~similar to conv4_3 in VGG16)\n",
        "\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        x = self.inception4e(x)\n",
        "\n",
        "        # Save feature after Inception block 4\n",
        "        features.append(x)  # feature 2 (~similar to conv7 in SSD with VGG16)\n",
        "\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        # Save feature after Inception block 5\n",
        "        features.append(x)  # feature 3\n",
        "\n",
        "        return features\n",
        "\n",
        "# ===========================\n",
        "# ENHANCED ANCHOR BOX GENERATION\n",
        "# ===========================\n",
        "\n",
        "class CustomBoxGenerator(DefaultBoxGenerator):\n",
        "    \"\"\"Enhanced anchor box generator with better aspect ratios and scales\"\"\"\n",
        "\n",
        "    def __init__(self, aspect_ratios=None, min_ratio=0.05, max_ratio=0.95, scales=None):\n",
        "        # Use more diverse aspect ratios to better capture different object shapes\n",
        "        if aspect_ratios is None:\n",
        "            aspect_ratios = [[2, 3, 1/2, 1/3], [2, 3, 1/2, 1/3],\n",
        "                             [2, 3, 1/2, 1/3], [2, 3, 1/2, 1/3],\n",
        "                             [2, 3, 1/2, 1/3], [2, 3, 1/2, 1/3]]\n",
        "\n",
        "        # Use finer scale steps for better coverage\n",
        "        if scales is None:\n",
        "            scales = [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9]\n",
        "\n",
        "        super().__init__(aspect_ratios=aspect_ratios, scales=scales)\n",
        "\n",
        "# ===========================\n",
        "# FOCAL LOSS FOR SSD\n",
        "# ===========================\n",
        "\n",
        "class FocalLossForSSD(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Focal Loss for SSD object detection.\n",
        "    Helps address class imbalance between foreground and background.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='sum'):\n",
        "        super(FocalLossForSSD, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, classifications, targets):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            classifications (batch_size, num_anchors, num_classes)\n",
        "            targets (batch_size, num_anchors)\n",
        "        \"\"\"\n",
        "        batch_size = classifications.size(0)\n",
        "        classification_losses = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            classification = classifications[i, :, :]  # (num_anchors, num_classes)\n",
        "            target = targets[i, :]  # (num_anchors)\n",
        "\n",
        "            alpha_factor = torch.ones_like(target) * self.alpha\n",
        "            alpha_factor = torch.where(target > 0, alpha_factor, 1 - alpha_factor)\n",
        "\n",
        "            # One-hot encode targets\n",
        "            num_classes = classifications.size(2)\n",
        "            target_onehot = F.one_hot(target.long(), num_classes=num_classes)\n",
        "\n",
        "            # Apply sigmoid to get probabilities\n",
        "            prob = torch.sigmoid(classification)\n",
        "\n",
        "            # Calculate focal weight\n",
        "            focal_weight = torch.where(target_onehot > 0, 1 - prob, prob)\n",
        "            focal_weight = alpha_factor * focal_weight.pow(self.gamma)\n",
        "\n",
        "            # Calculate binary cross entropy\n",
        "            bce = F.binary_cross_entropy_with_logits(\n",
        "                classification,\n",
        "                target_onehot.float(),\n",
        "                reduction='none'\n",
        "            )\n",
        "\n",
        "            # Apply focal weight to loss\n",
        "            cls_loss = focal_weight * bce\n",
        "\n",
        "            # Normalize by positive samples if needed\n",
        "            if self.reduction == 'sum':\n",
        "                cls_loss = cls_loss.sum()\n",
        "            elif self.reduction == 'mean':\n",
        "                cls_loss = cls_loss.mean()\n",
        "\n",
        "            classification_losses.append(cls_loss)\n",
        "\n",
        "        return torch.stack(classification_losses).mean()\n",
        "\n",
        "# ===========================\n",
        "# L2Norm Module\n",
        "# ===========================\n",
        "\n",
        "class L2Norm(nn.Module):\n",
        "    \"\"\"\n",
        "    L2 normalization module as used in SSD\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels, scale=20):\n",
        "        super(L2Norm, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.scale = scale\n",
        "        self.eps = 1e-10\n",
        "        self.weight = nn.Parameter(torch.ones(n_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # L2 norm across channel dimension\n",
        "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() + self.eps\n",
        "        x = x / norm\n",
        "        # Scale the output - fixed the dimension mismatch\n",
        "        out = x * self.weight.view(1, -1, 1, 1)\n",
        "        return out\n",
        "\n",
        "# ===========================\n",
        "# SSD Classification and Regression Head\n",
        "# ===========================\n",
        "\n",
        "class SSDClassificationHead(nn.Module):\n",
        "    \"\"\"Classification head for SSD\"\"\"\n",
        "    def __init__(self, in_channels, num_anchors, num_classes):\n",
        "        super(SSDClassificationHead, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.cls_heads = nn.ModuleList()\n",
        "        for channels, anchors in zip(in_channels, num_anchors):\n",
        "            self.cls_heads.append(\n",
        "                nn.Conv2d(channels, anchors * num_classes, kernel_size=3, padding=1)\n",
        "            )\n",
        "\n",
        "    def forward(self, features):\n",
        "        \"\"\"Forward pass through classification head\"\"\"\n",
        "        cls_logits = []\n",
        "        for feature, head in zip(features, self.cls_heads):\n",
        "            cls_logits.append(head(feature).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "        batch_size = features[0].shape[0]\n",
        "        return torch.cat([c.view(batch_size, -1, self.num_classes) for c in cls_logits], dim=1)\n",
        "\n",
        "class SSDRegressionHead(nn.Module):\n",
        "    \"\"\"Regression head for SSD\"\"\"\n",
        "    def __init__(self, in_channels, num_anchors):\n",
        "        super(SSDRegressionHead, self).__init__()\n",
        "\n",
        "        self.reg_heads = nn.ModuleList()\n",
        "        for channels, anchors in zip(in_channels, num_anchors):\n",
        "            self.reg_heads.append(\n",
        "                nn.Conv2d(channels, anchors * 4, kernel_size=3, padding=1)\n",
        "            )\n",
        "\n",
        "    def forward(self, features):\n",
        "        \"\"\"Forward pass through regression head\"\"\"\n",
        "        bbox_regression = []\n",
        "        for feature, head in zip(features, self.reg_heads):\n",
        "            bbox_regression.append(head(feature).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "        batch_size = features[0].shape[0]\n",
        "        return torch.cat([b.view(batch_size, -1, 4) for b in bbox_regression], dim=1)\n",
        "\n",
        "# ===========================\n",
        "# SSD WITH INCEPTION V2 BACKBONE\n",
        "# ===========================\n",
        "\n",
        "class SSD300_InceptionV2(nn.Module):\n",
        "    \"\"\"\n",
        "    SSD300 model with InceptionV2 backbone\n",
        "\n",
        "    Key improvements:\n",
        "    1. InceptionV2 backbone instead of VGG16\n",
        "    2. Feature pyramid connections for better scale handling\n",
        "    3. Focal loss for class imbalance\n",
        "    4. Custom anchor boxes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(SSD300_InceptionV2, self).__init__()\n",
        "\n",
        "        # Create InceptionV2 backbone\n",
        "        self.backbone = InceptionV2Backbone(pretrained=pretrained)\n",
        "\n",
        "        # Determine feature output channels - Fixed to match actual outputs\n",
        "        self.backbone_out_channels = [384, 832, 1024]  # [inception3c, inception4e, inception5b]\n",
        "\n",
        "        # Additional SSD detection layers (conv layers to extend feature hierarchy)\n",
        "        self.additional_blocks = nn.ModuleList([\n",
        "            # Additional feature layers decreasing in size\n",
        "            # Format: (input_channels, output_channels, kernel_size, stride, padding)\n",
        "            BasicConv2d(1024, 512, kernel_size=1),  # Reduction layer\n",
        "            BasicConv2d(512, 512, kernel_size=3, stride=2, padding=1),  # conv8_2\n",
        "\n",
        "            BasicConv2d(512, 256, kernel_size=1),   # Reduction layer\n",
        "            BasicConv2d(256, 512, kernel_size=3, stride=2, padding=1),  # conv9_2\n",
        "\n",
        "            BasicConv2d(512, 128, kernel_size=1),   # Reduction layer\n",
        "            BasicConv2d(128, 256, kernel_size=3, stride=2, padding=1),  # conv10_2\n",
        "\n",
        "            BasicConv2d(256, 128, kernel_size=1),   # Reduction layer\n",
        "            BasicConv2d(128, 256, kernel_size=3, stride=2, padding=1),  # conv11_2\n",
        "        ])\n",
        "\n",
        "        # Lateral connections for feature pyramid (similar to FPN)\n",
        "        self.lateral_connections = nn.ModuleList([\n",
        "            nn.Conv2d(384, 256, kernel_size=1),    # For inception3c - Fixed to match actual channel count\n",
        "            nn.Conv2d(832, 256, kernel_size=1),    # For inception4e\n",
        "            nn.Conv2d(1024, 256, kernel_size=1),   # For inception5b\n",
        "            nn.Conv2d(512, 256, kernel_size=1),    # For conv8_2\n",
        "            nn.Conv2d(512, 256, kernel_size=1),    # For conv9_2\n",
        "            nn.Conv2d(256, 256, kernel_size=1),    # For conv10_2\n",
        "        ])\n",
        "\n",
        "        # L2 Normalization for the first feature map (inception3c) - Fixed to match actual channel count\n",
        "        self.l2_norm = L2Norm(384, scale=20)\n",
        "\n",
        "        # Use custom anchor box generator\n",
        "        self.anchor_generator = CustomBoxGenerator()\n",
        "\n",
        "        # Define the number of anchors per location for each feature map\n",
        "        self.num_anchors = [4, 6, 6, 6, 4, 4]  # Adjusted for our aspect ratios\n",
        "\n",
        "        # Create detection heads\n",
        "        # Classification head (predicts classes)\n",
        "        self.classification_head = SSDClassificationHead(\n",
        "            in_channels=[256] * 6,  # All feature maps have 256 channels after lateral connections\n",
        "            num_anchors=self.num_anchors,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "        # Regression head (predicts bounding box offsets)\n",
        "        self.regression_head = SSDRegressionHead(\n",
        "            in_channels=[256] * 6,\n",
        "            num_anchors=self.num_anchors\n",
        "        )\n",
        "\n",
        "        # Initialize the weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "        # Use focal loss\n",
        "        self.focal_loss = FocalLossForSSD(alpha=0.25, gamma=2.0)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # Initialize the additional blocks and detection heads\n",
        "        for module in [self.additional_blocks, self.lateral_connections,\n",
        "                      self.classification_head, self.regression_head]:\n",
        "            for m in module.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                    if m.bias is not None:\n",
        "                        nn.init.zeros_(m.bias)\n",
        "                elif isinstance(m, nn.BatchNorm2d):\n",
        "                    nn.init.ones_(m.weight)\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        \"\"\"Extract and process feature maps for SSD\"\"\"\n",
        "        # Get backbone features\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # Apply L2 norm to the first feature map\n",
        "        features[0] = self.l2_norm(features[0])\n",
        "\n",
        "        # Additional SSD feature maps\n",
        "        x = features[-1]  # Start from the last backbone feature\n",
        "\n",
        "        # Apply additional blocks in pairs (reduction + conv)\n",
        "        for i in range(0, len(self.additional_blocks), 2):\n",
        "            x = self.additional_blocks[i](x)\n",
        "            x = self.additional_blocks[i+1](x)\n",
        "            features.append(x)\n",
        "\n",
        "        # Apply lateral connections to all feature maps\n",
        "        enhanced_features = []\n",
        "        for i, feature in enumerate(features):\n",
        "            if i < len(self.lateral_connections):\n",
        "                lateral = self.lateral_connections[i](feature)\n",
        "                enhanced_features.append(lateral)\n",
        "\n",
        "        return enhanced_features\n",
        "\n",
        "    def forward(self, images, targets=None):\n",
        "        \"\"\"Forward pass for SSD model\"\"\"\n",
        "        # Check if list or tensor\n",
        "        if isinstance(images, list):\n",
        "            images = torch.stack(images)\n",
        "\n",
        "        # Get image sizes for anchor generation\n",
        "        image_sizes = [(img.shape[-2], img.shape[-1]) for img in images]\n",
        "\n",
        "        # Extract features\n",
        "        features = self.extract_features(images)\n",
        "\n",
        "        # Get predictions from detection heads\n",
        "        cls_logits = self.classification_head(features)\n",
        "        bbox_regression = self.regression_head(features)\n",
        "\n",
        "        # Generate anchors\n",
        "        anchors = self.anchor_generator(features, image_sizes)\n",
        "\n",
        "        if self.training and targets is not None:\n",
        "            # Training mode with actual loss calculation\n",
        "            matched_idxs = []\n",
        "            matched_labels = []\n",
        "\n",
        "            for anchors_per_image, targets_per_image in zip(anchors, targets):\n",
        "                if targets_per_image[\"boxes\"].numel() == 0:\n",
        "                    matched_idxs.append(torch.zeros_like(anchors_per_image[:, 0], dtype=torch.int64))\n",
        "                    matched_labels.append(torch.zeros_like(anchors_per_image[:, 0], dtype=torch.int64))\n",
        "                    continue\n",
        "\n",
        "                # Calculate IoU between targets and anchors\n",
        "                match_quality_matrix = box_iou(targets_per_image[\"boxes\"], anchors_per_image)\n",
        "\n",
        "                # Match each anchor to the target with highest IoU\n",
        "                matched_vals, matches = match_quality_matrix.max(dim=0)\n",
        "\n",
        "                # Assign labels to anchors\n",
        "                matched_labels_per_image = targets_per_image[\"labels\"][matches]\n",
        "\n",
        "                # Background (negative) if IoU < 0.4\n",
        "                bg_indices = matched_vals < 0.4\n",
        "                matched_labels_per_image[bg_indices] = 0\n",
        "\n",
        "                # Ignore anchors if 0.4 <= IoU < 0.5\n",
        "                ignore_indices = (matched_vals >= 0.4) & (matched_vals < 0.5)\n",
        "                matched_labels_per_image[ignore_indices] = -1\n",
        "\n",
        "                matched_idxs.append(matches)\n",
        "                matched_labels.append(matched_labels_per_image)\n",
        "\n",
        "            # Compute regression targets\n",
        "            regression_targets = []\n",
        "            for anchors_per_image, matched_idxs_per_image, targets_per_image in zip(\n",
        "                anchors, matched_idxs, targets):\n",
        "\n",
        "                if targets_per_image[\"boxes\"].numel() == 0:\n",
        "                    regression_targets.append(torch.zeros_like(anchors_per_image))\n",
        "                    continue\n",
        "\n",
        "                matched_gt_boxes = targets_per_image[\"boxes\"][matched_idxs_per_image]\n",
        "\n",
        "                # Encode regression targets\n",
        "                regression_targets.append(self.encode_boxes(matched_gt_boxes, anchors_per_image))\n",
        "\n",
        "            regression_targets = torch.stack(regression_targets)\n",
        "            matched_labels = torch.stack(matched_labels)\n",
        "\n",
        "            # Calculate losses\n",
        "            # Use hard negative mining for classification loss\n",
        "            N = cls_logits.size(0)\n",
        "            cls_logits_reshape = cls_logits.reshape(N, -1, self.classification_head.num_classes)\n",
        "\n",
        "            # Apply focal loss for classification\n",
        "            cls_loss = self.focal_loss(cls_logits_reshape, matched_labels)\n",
        "\n",
        "            # Regression loss - only for positive anchors\n",
        "            positive_mask = matched_labels > 0\n",
        "            if positive_mask.sum() > 0:\n",
        "                reg_loss = F.smooth_l1_loss(\n",
        "                    bbox_regression[positive_mask],\n",
        "                    regression_targets[positive_mask],\n",
        "                    reduction='sum'\n",
        "                ) / positive_mask.sum().float()\n",
        "            else:\n",
        "                reg_loss = torch.tensor(0.0, device=cls_loss.device)\n",
        "\n",
        "            return {\n",
        "                'classification': cls_loss,\n",
        "                'bbox_regression': reg_loss,\n",
        "                'total_loss': cls_loss + reg_loss\n",
        "            }\n",
        "        else:\n",
        "            # Inference mode\n",
        "            # Apply NMS and return detections\n",
        "\n",
        "            # Create detection dictionaries\n",
        "            detections = []\n",
        "\n",
        "            # For each image in the batch\n",
        "            for img_idx in range(len(images)):\n",
        "                # Run NMS and format detections for this image\n",
        "                boxes, scores, labels = self.postprocess_detections(\n",
        "                    cls_logits[img_idx],\n",
        "                    bbox_regression[img_idx],\n",
        "                    anchors[img_idx],\n",
        "                    image_sizes[img_idx]\n",
        "                )\n",
        "\n",
        "                detections.append({\n",
        "                    'boxes': boxes,\n",
        "                    'scores': scores,\n",
        "                    'labels': labels\n",
        "                })\n",
        "\n",
        "            return detections\n",
        "\n",
        "    def encode_boxes(self, gt_boxes, anchors):\n",
        "        \"\"\"\n",
        "        Encode ground-truth boxes to regression targets\n",
        "\n",
        "        Args:\n",
        "            gt_boxes: Tensor of shape (N, 4) with ground-truth boxes\n",
        "            anchors: Tensor of shape (N, 4) with anchor boxes\n",
        "\n",
        "        Returns:\n",
        "            Encoded regression targets\n",
        "        \"\"\"\n",
        "        # Extract coordinates\n",
        "        anchor_widths = anchors[:, 2] - anchors[:, 0]\n",
        "        anchor_heights = anchors[:, 3] - anchors[:, 1]\n",
        "        anchor_ctr_x = anchors[:, 0] + 0.5 * anchor_widths\n",
        "        anchor_ctr_y = anchors[:, 1] + 0.5 * anchor_heights\n",
        "\n",
        "        gt_widths = gt_boxes[:, 2] - gt_boxes[:, 0]\n",
        "        gt_heights = gt_boxes[:, 3] - gt_boxes[:, 1]\n",
        "        gt_ctr_x = gt_boxes[:, 0] + 0.5 * gt_widths\n",
        "        gt_ctr_y = gt_boxes[:, 1] + 0.5 * gt_heights\n",
        "\n",
        "        # Prevent division by zero\n",
        "        eps = 1e-7\n",
        "        anchor_widths = torch.clamp(anchor_widths, min=eps)\n",
        "        anchor_heights = torch.clamp(anchor_heights, min=eps)\n",
        "\n",
        "        # Calculate targets\n",
        "        targets_dx = (gt_ctr_x - anchor_ctr_x) / anchor_widths\n",
        "        targets_dy = (gt_ctr_y - anchor_ctr_y) / anchor_heights\n",
        "        targets_dw = torch.log(gt_widths / anchor_widths)\n",
        "        targets_dh = torch.log(gt_heights / anchor_heights)\n",
        "\n",
        "        targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh), dim=1)\n",
        "        return targets\n",
        "\n",
        "    def postprocess_detections(self, cls_logits, bbox_regression, anchors, image_size):\n",
        "        \"\"\"Post-process detections including NMS\"\"\"\n",
        "        # Apply softmax to get class probabilities\n",
        "        scores = F.softmax(cls_logits, dim=1)\n",
        "\n",
        "        # Get highest scoring class (excluding background class 0)\n",
        "        scores, labels = scores[:, 1:].max(dim=1)\n",
        "        labels = labels + 1  # Adjust labels (add 1) because we excluded background\n",
        "\n",
        "        # Decode regression values to bounding boxes\n",
        "        boxes = self.decode_boxes(bbox_regression, anchors)\n",
        "\n",
        "        # Filter out low scoring boxes\n",
        "        keep_idxs = scores > 0.05  # Confidence threshold\n",
        "        boxes = boxes[keep_idxs]\n",
        "        scores = scores[keep_idxs]\n",
        "        labels = labels[keep_idxs]\n",
        "\n",
        "        # Clip boxes to image boundaries\n",
        "        boxes[:, 0].clamp_(min=0, max=image_size[1])\n",
        "        boxes[:, 1].clamp_(min=0, max=image_size[0])\n",
        "        boxes[:, 2].clamp_(min=0, max=image_size[1])\n",
        "        boxes[:, 3].clamp_(min=0, max=image_size[0])\n",
        "\n",
        "        # Non-maximum suppression\n",
        "        keep = nms(boxes, scores, iou_threshold=0.5)\n",
        "\n",
        "        # Get final detections\n",
        "        boxes = boxes[keep]\n",
        "        scores = scores[keep]\n",
        "        labels = labels[keep]\n",
        "\n",
        "        return boxes, scores, labels\n",
        "\n",
        "    def decode_boxes(self, box_regression, anchors):\n",
        "        \"\"\"\n",
        "        Decode regression values to box coordinates\n",
        "\n",
        "        Args:\n",
        "            box_regression: Tensor of shape (N, 4) with encoded offsets\n",
        "            anchors: Tensor of shape (N, 4) with anchor boxes\n",
        "\n",
        "        Returns:\n",
        "            Decoded boxes in (x1, y1, x2, y2) format\n",
        "        \"\"\"\n",
        "        # Extract anchor coordinates\n",
        "        anchor_widths = anchors[:, 2] - anchors[:, 0]\n",
        "        anchor_heights = anchors[:, 3] - anchors[:, 1]\n",
        "        anchor_ctr_x = anchors[:, 0] + 0.5 * anchor_widths\n",
        "        anchor_ctr_y = anchors[:, 1] + 0.5 * anchor_heights\n",
        "\n",
        "        # Get predicted offsets\n",
        "        dx = box_regression[:, 0]\n",
        "        dy = box_regression[:, 1]\n",
        "        dw = box_regression[:, 2]\n",
        "        dh = box_regression[:, 3]\n",
        "\n",
        "        # Convert predictions to center, width, height format\n",
        "        pred_ctr_x = dx * anchor_widths + anchor_ctr_x\n",
        "        pred_ctr_y = dy * anchor_heights + anchor_ctr_y\n",
        "        pred_w = torch.exp(dw) * anchor_widths\n",
        "        pred_h = torch.exp(dh) * anchor_heights\n",
        "\n",
        "        # Convert back to (x1, y1, x2, y2) format\n",
        "        pred_boxes = torch.zeros_like(box_regression)\n",
        "        pred_boxes[:, 0] = pred_ctr_x - 0.5 * pred_w\n",
        "        pred_boxes[:, 1] = pred_ctr_y - 0.5 * pred_h\n",
        "        pred_boxes[:, 2] = pred_ctr_x + 0.5 * pred_w\n",
        "        pred_boxes[:, 3] = pred_ctr_y + 0.5 * pred_h\n",
        "\n",
        "        return pred_boxes\n",
        "\n",
        "# ===========================\n",
        "# DATA LOADING AND PREPROCESSING\n",
        "# ===========================\n",
        "\n",
        "class VOCDataset(Dataset):\n",
        "    \"\"\"\n",
        "    VOC Dataset for SSD training\n",
        "    \"\"\"\n",
        "    def __init__(self, root, year='2012', image_set='train', transform=None):\n",
        "        self.root = os.path.join(root, f'VOC{year}')\n",
        "        self.image_set = image_set\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load class names\n",
        "        self.classes = [\n",
        "            'background',  # Explicitly include background class (index 0)\n",
        "            'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
        "            'bus', 'car', 'cat', 'chair', 'cow',\n",
        "            'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
        "            'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
        "        ]\n",
        "\n",
        "        # Create class to index mapping\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        # Get image and annotation paths\n",
        "        self.images = []\n",
        "        self.annotations = []\n",
        "\n",
        "        # Path to image set file\n",
        "        image_set_file = os.path.join(self.root, 'ImageSets', 'Main', f'{image_set}.txt')\n",
        "\n",
        "        # Read image ids\n",
        "        with open(image_set_file, 'r') as f:\n",
        "            file_ids = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        # Get full paths\n",
        "        for file_id in file_ids:\n",
        "            self.images.append(os.path.join(self.root, 'JPEGImages', f'{file_id}.jpg'))\n",
        "            self.annotations.append(os.path.join(self.root, 'Annotations', f'{file_id}.xml'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load image\n",
        "        img_path = self.images[index]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        # Load annotations\n",
        "        ann_path = self.annotations[index]\n",
        "        boxes, labels = self._parse_voc_xml(ann_path)\n",
        "        # Convert to tensors\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        # Create target dictionary\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([index]),\n",
        "            'orig_size': torch.as_tensor([img.height, img.width])\n",
        "        }\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img, target = self.transform(img, target)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "    def _parse_voc_xml(self, xml_path):\n",
        "        \"\"\"Parse Pascal VOC XML annotation file\"\"\"\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            # Get class label\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name in self.class_to_idx:\n",
        "                label = self.class_to_idx[class_name]\n",
        "            else:\n",
        "                continue  # Skip objects with unknown class\n",
        "\n",
        "            # Get bounding box\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = float(bbox.find('xmin').text)\n",
        "            ymin = float(bbox.find('ymin').text)\n",
        "            xmax = float(bbox.find('xmax').text)\n",
        "            ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "            # Skip invalid boxes\n",
        "            if xmax <= xmin or ymax <= ymin:\n",
        "                continue\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label)\n",
        "\n",
        "        return boxes, labels\n",
        "\n",
        "# ===========================\n",
        "# TRANSFORMS FOR SSD TRAINING\n",
        "# ===========================\n",
        "\n",
        "\n",
        "class Compose:\n",
        "    \"\"\"Compose multiple transforms\"\"\"\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "class ToTensor:\n",
        "    \"\"\"Convert PIL Image to Tensor\"\"\"\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.ToTensor()(image)\n",
        "        return image, target\n",
        "\n",
        "class Resize:\n",
        "    \"\"\"Resize image and adjust bounding boxes accordingly\"\"\"\n",
        "    def __init__(self, size):\n",
        "        self.size = size  # (height, width)\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        # Original size\n",
        "        orig_width, orig_height = image.size\n",
        "\n",
        "        # Resize image\n",
        "        image = transforms.Resize(self.size)(image)\n",
        "\n",
        "        # Adjust boxes\n",
        "        if target['boxes'].shape[0] > 0:\n",
        "            # Scale factors\n",
        "            width_scale = self.size[1] / orig_width\n",
        "            height_scale = self.size[0] / orig_height\n",
        "\n",
        "            # Scale boxes\n",
        "            boxes = target['boxes'].clone()\n",
        "            boxes[:, 0] *= width_scale\n",
        "            boxes[:, 2] *= width_scale\n",
        "            boxes[:, 1] *= height_scale\n",
        "            boxes[:, 3] *= height_scale\n",
        "\n",
        "            target['boxes'] = boxes\n",
        "\n",
        "        return image, target\n",
        "\n",
        "class RandomHorizontalFlip:\n",
        "    \"\"\"Randomly flip image horizontally\"\"\"\n",
        "    def __init__(self, prob=0.5):\n",
        "        self.prob = prob\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        if random.random() < self.prob:\n",
        "            # Flip image\n",
        "            image = transforms.functional.hflip(image)\n",
        "\n",
        "            # Flip boxes\n",
        "            if target['boxes'].shape[0] > 0:\n",
        "                width = image.width\n",
        "                boxes = target['boxes'].clone()\n",
        "                boxes[:, [0, 2]] = width - boxes[:, [2, 0]]\n",
        "                target['boxes'] = boxes\n",
        "\n",
        "        return image, target\n",
        "\n",
        "class ColorJitter:\n",
        "    \"\"\"Apply color jitter to image\"\"\"\n",
        "    def __init__(self, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1):\n",
        "        self.transform = transforms.ColorJitter(\n",
        "            brightness=brightness,\n",
        "            contrast=contrast,\n",
        "            saturation=saturation,\n",
        "            hue=hue\n",
        "        )\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "class Normalize:\n",
        "    \"\"\"Normalize image\"\"\"\n",
        "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        image = transforms.functional.normalize(image, mean=self.mean, std=self.std)\n",
        "        return image, target\n",
        "\n",
        "# ===========================\n",
        "# DATA LOADERS\n",
        "# ===========================\n",
        "\n",
        "def create_data_loaders(args):\n",
        "    \"\"\"Create data loaders for training and validation\"\"\"\n",
        "\n",
        "    # Define transforms\n",
        "    train_transform = Compose([\n",
        "        Resize((args.image_size, args.image_size)),\n",
        "        RandomHorizontalFlip(),\n",
        "        ColorJitter(),\n",
        "        ToTensor(),\n",
        "        Normalize()\n",
        "    ])\n",
        "\n",
        "    val_transform = Compose([\n",
        "        Resize((args.image_size, args.image_size)),\n",
        "        ToTensor(),\n",
        "        Normalize()\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    try:\n",
        "        # Try to load from specified path\n",
        "        train_dataset = VOCDataset(\n",
        "            root=args.voc_path,\n",
        "            image_set='train',\n",
        "            transform=train_transform\n",
        "        )\n",
        "\n",
        "        val_dataset = VOCDataset(\n",
        "            root=args.voc_path,\n",
        "            image_set='val',\n",
        "            transform=val_transform\n",
        "        )\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Could not find VOC dataset at {args.voc_path}\")\n",
        "        print(\"Using dummy dataset for testing purposes...\")\n",
        "\n",
        "        # Create dummy datasets for testing\n",
        "        train_dataset = create_dummy_dataset(num_samples=100, image_size=args.image_size, transform=train_transform)\n",
        "        val_dataset = create_dummy_dataset(num_samples=20, image_size=args.image_size, transform=val_transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, len(train_dataset.classes)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Custom collate function for object detection batches\"\"\"\n",
        "    images = []\n",
        "    targets = []\n",
        "\n",
        "    for img, target in batch:\n",
        "        images.append(img)\n",
        "        targets.append(target)\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "def create_dummy_dataset(num_samples=100, image_size=300, transform=None):\n",
        "    \"\"\"Create a dummy dataset for testing\"\"\"\n",
        "    class DummyDataset(Dataset):\n",
        "        def __init__(self, num_samples, image_size, transform):\n",
        "            self.num_samples = num_samples\n",
        "            self.image_size = image_size\n",
        "            self.transform = transform\n",
        "\n",
        "            # Define classes\n",
        "            self.classes = [\n",
        "                'background',\n",
        "                'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
        "                'bus', 'car', 'cat', 'chair', 'cow',\n",
        "                'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
        "                'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
        "            ]\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.num_samples\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            # Create random image\n",
        "            img = torch.rand(3, self.image_size, self.image_size)\n",
        "            img = transforms.ToPILImage()(img)\n",
        "\n",
        "            # Create random boxes (1-3 boxes per image)\n",
        "            num_boxes = random.randint(1, 3)\n",
        "            boxes = []\n",
        "\n",
        "            for _ in range(num_boxes):\n",
        "                # Random box dimensions\n",
        "                x1 = random.uniform(0, self.image_size - 100)\n",
        "                y1 = random.uniform(0, self.image_size - 100)\n",
        "                x2 = random.uniform(x1 + 50, min(x1 + 150, self.image_size))\n",
        "                y2 = random.uniform(y1 + 50, min(y1 + 150, self.image_size))\n",
        "\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "            # Random labels (excluding background class 0)\n",
        "            labels = [random.randint(1, len(self.classes) - 1) for _ in range(num_boxes)]\n",
        "\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "            # Create target dictionary\n",
        "            target = {\n",
        "                'boxes': boxes,\n",
        "                'labels': labels,\n",
        "                'image_id': torch.tensor([index]),\n",
        "                'orig_size': torch.as_tensor([self.image_size, self.image_size])\n",
        "            }\n",
        "\n",
        "            # Apply transformations\n",
        "            if self.transform:\n",
        "                img, target = self.transform(img, target)\n",
        "\n",
        "            return img, target\n",
        "\n",
        "    return DummyDataset(num_samples, image_size, transform)\n",
        "\n",
        "# ===========================\n",
        "# EVALUATION METRICS\n",
        "# ===========================\n",
        "\n",
        "def calculate_mAP(predictions, targets, iou_threshold=0.5, confidence_threshold=0.05, return_per_class=False):\n",
        "    \"\"\"\n",
        "    Calculate mean Average Precision (mAP) for object detection\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        iou_threshold: IoU threshold for considering a detection as correct\n",
        "        confidence_threshold: Confidence threshold for filtering detections\n",
        "        return_per_class: Whether to return per-class AP\n",
        "\n",
        "    Returns:\n",
        "        mAP: Mean Average Precision\n",
        "        class_aps: List of per-class AP if return_per_class=True\n",
        "    \"\"\"\n",
        "    # Get all classes (excluding background class 0)\n",
        "    all_labels = set()\n",
        "    for target in targets:\n",
        "        if len(target['labels']) > 0:\n",
        "            all_labels.update(target['labels'].tolist())\n",
        "\n",
        "    # Filter out background class\n",
        "    all_labels = [label for label in all_labels if label > 0]\n",
        "    num_classes = max(all_labels) + 1\n",
        "\n",
        "    # Initialize per-class metrics\n",
        "    class_metrics = {cls: {'tp': [], 'fp': [], 'scores': [], 'num_gt': 0} for cls in range(1, num_classes)}\n",
        "\n",
        "    # Process each image\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # Count ground truth instances per class\n",
        "        for cls in range(1, num_classes):\n",
        "            class_metrics[cls]['num_gt'] += (target_labels == cls).sum().item()\n",
        "\n",
        "        # Filter by confidence threshold\n",
        "        keep = pred_scores > confidence_threshold\n",
        "        pred_boxes = pred_boxes[keep]\n",
        "        pred_scores = pred_scores[keep]\n",
        "        pred_labels = pred_labels[keep]\n",
        "\n",
        "        # Process each class\n",
        "        for cls in range(1, num_classes):\n",
        "            # Filter predictions by class\n",
        "            cls_pred_mask = pred_labels == cls\n",
        "            cls_pred_boxes = pred_boxes[cls_pred_mask]\n",
        "            cls_pred_scores = pred_scores[cls_pred_mask]\n",
        "\n",
        "            # Filter targets by class\n",
        "            cls_target_mask = target_labels == cls\n",
        "            cls_target_boxes = target_boxes[cls_target_mask]\n",
        "\n",
        "            # Sort predictions by score (descending)\n",
        "            if len(cls_pred_scores) > 0:\n",
        "                sort_idx = torch.argsort(cls_pred_scores, descending=True)\n",
        "                cls_pred_boxes = cls_pred_boxes[sort_idx]\n",
        "                cls_pred_scores = cls_pred_scores[sort_idx]\n",
        "\n",
        "            # Initialize target flags (used to track matched targets)\n",
        "            target_flags = [False] * len(cls_target_boxes)\n",
        "\n",
        "            # For each prediction, find if it matches any ground truth\n",
        "            for i, pred_box in enumerate(cls_pred_boxes):\n",
        "                # Store the score\n",
        "                class_metrics[cls]['scores'].append(cls_pred_scores[i].item())\n",
        "\n",
        "                if len(cls_target_boxes) == 0:\n",
        "                    # No ground truth, all predictions are false positives\n",
        "                    class_metrics[cls]['tp'].append(0)\n",
        "                    class_metrics[cls]['fp'].append(1)\n",
        "                    continue\n",
        "\n",
        "                # Calculate IoU with all ground truths\n",
        "                ious = box_iou(pred_box.unsqueeze(0), cls_target_boxes)[0]\n",
        "\n",
        "                # Get maximum IoU and corresponding index\n",
        "                max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "                if max_iou >= iou_threshold and not target_flags[max_idx]:\n",
        "                    # True positive - matched with a ground truth that hasn't been matched before\n",
        "                    class_metrics[cls]['tp'].append(1)\n",
        "                    class_metrics[cls]['fp'].append(0)\n",
        "                    target_flags[max_idx] = True\n",
        "                else:\n",
        "                    # False positive - either doesn't match any ground truth or matches one that's already been matched\n",
        "                    class_metrics[cls]['tp'].append(0)\n",
        "                    class_metrics[cls]['fp'].append(1)\n",
        "\n",
        "    # Calculate AP for each class\n",
        "    class_aps = []\n",
        "\n",
        "    for cls in range(1, num_classes):\n",
        "        if class_metrics[cls]['num_gt'] == 0:\n",
        "            class_aps.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        scores = np.array(class_metrics[cls]['scores'])\n",
        "        tp = np.array(class_metrics[cls]['tp'])\n",
        "        fp = np.array(class_metrics[cls]['fp'])\n",
        "\n",
        "        if len(scores) == 0:\n",
        "            class_aps.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Sort by score\n",
        "        indices = np.argsort(-scores)\n",
        "        tp = tp[indices]\n",
        "        fp = fp[indices]\n",
        "\n",
        "        # Compute cumulative sum\n",
        "        tp_cumsum = np.cumsum(tp)\n",
        "        fp_cumsum = np.cumsum(fp)\n",
        "\n",
        "        # Calculate precision and recall\n",
        "        precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
        "        recall = tp_cumsum / class_metrics[cls]['num_gt']\n",
        "\n",
        "        # Add sentinel values\n",
        "        precision = np.concatenate(([1.0], precision))\n",
        "        recall = np.concatenate(([0.0], recall))\n",
        "\n",
        "        # Compute average precision using 11-point interpolation\n",
        "        ap = 0.0\n",
        "        for t in np.linspace(0, 1, 11):\n",
        "            mask = recall >= t\n",
        "            if mask.any():\n",
        "                p = precision[mask].max()\n",
        "            else:\n",
        "                p = 0.0\n",
        "            ap += p / 11.0\n",
        "\n",
        "        class_aps.append(ap)\n",
        "\n",
        "    # Calculate mAP\n",
        "    mAP = sum(class_aps) / len(class_aps) if class_aps else 0.0\n",
        "\n",
        "    if return_per_class:\n",
        "        return mAP, class_aps\n",
        "    else:\n",
        "        return mAP\n",
        "\n",
        "def calculate_confusion_matrix(predictions, targets, num_classes, iou_threshold=0.5, confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate confusion matrix for object detection\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        num_classes: Number of classes (including background)\n",
        "        iou_threshold: IoU threshold for considering a detection as correct\n",
        "        confidence_threshold: Confidence threshold for filtering detections\n",
        "\n",
        "    Returns:\n",
        "        Confusion matrix: (num_classes, num_classes) tensor\n",
        "    \"\"\"\n",
        "    # Initialize confusion matrix (rows=ground truth, cols=prediction)\n",
        "    conf_matrix = torch.zeros((num_classes, num_classes), dtype=torch.int64)\n",
        "\n",
        "    # Initialize counter for unmatched ground truth (misses)\n",
        "    misses = torch.zeros(num_classes, dtype=torch.int64)\n",
        "\n",
        "    # Process each image\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # Filter by confidence threshold\n",
        "        keep = pred_scores > confidence_threshold\n",
        "        pred_boxes = pred_boxes[keep]\n",
        "        pred_labels = pred_labels[keep]\n",
        "\n",
        "        # Initialize target flags (used to track matched targets)\n",
        "        target_flags = [False] * len(target_boxes)\n",
        "\n",
        "        # For each prediction, find matching ground truth\n",
        "        for i, (pred_box, pred_label) in enumerate(zip(pred_boxes, pred_labels)):\n",
        "            if len(target_boxes) == 0:\n",
        "                # No ground truth, all predictions are false positives (class 0 = background)\n",
        "                conf_matrix[0, pred_label] += 1\n",
        "                continue\n",
        "\n",
        "            # Calculate IoU with all ground truths\n",
        "            ious = box_iou(pred_box.unsqueeze(0), target_boxes)[0]\n",
        "\n",
        "            # Get maximum IoU and corresponding index\n",
        "            max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "            if max_iou >= iou_threshold and not target_flags[max_idx]:\n",
        "                # Prediction matches a ground truth\n",
        "                gt_label = target_labels[max_idx]\n",
        "                conf_matrix[gt_label, pred_label] += 1\n",
        "                target_flags[max_idx] = True\n",
        "            else:\n",
        "                # No match, false positive (class 0 = background)\n",
        "                conf_matrix[0, pred_label] += 1\n",
        "\n",
        "        # Count unmatched ground truths (misses)\n",
        "        for i, (flag, label) in enumerate(zip(target_flags, target_labels)):\n",
        "            if not flag:\n",
        "                # Missed detection, counted as predicting background\n",
        "                conf_matrix[label, 0] += 1\n",
        "\n",
        "    return conf_matrix\n",
        "\n",
        "def calculate_precision_recall_curve(predictions, targets, class_idx, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate precision-recall curve for a specific class\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        class_idx: Class index to calculate PR curve for\n",
        "        iou_threshold: IoU threshold for considering a detection as correct\n",
        "\n",
        "    Returns:\n",
        "        precision: List of precision values\n",
        "        recall: List of recall values\n",
        "        thresholds: List of score thresholds\n",
        "    \"\"\"\n",
        "    # Collect all predictions and ground truths for this class\n",
        "    all_scores = []\n",
        "    all_tp = []\n",
        "    all_fp = []\n",
        "    num_gt = 0\n",
        "\n",
        "    # Process each image\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # Count ground truth for this class\n",
        "        num_gt += (target_labels == class_idx).sum().item()\n",
        "\n",
        "        # Filter predictions by class\n",
        "        cls_pred_mask = pred_labels == class_idx\n",
        "        cls_pred_boxes = pred_boxes[cls_pred_mask]\n",
        "        cls_pred_scores = pred_scores[cls_pred_mask]\n",
        "\n",
        "        # Filter targets by class\n",
        "        cls_target_mask = target_labels == class_idx\n",
        "        cls_target_boxes = target_boxes[cls_target_mask]\n",
        "\n",
        "        # Sort predictions by score (descending)\n",
        "        if len(cls_pred_scores) > 0:\n",
        "            sort_idx = torch.argsort(cls_pred_scores, descending=True)\n",
        "            cls_pred_boxes = cls_pred_boxes[sort_idx]\n",
        "            cls_pred_scores = cls_pred_scores[sort_idx]\n",
        "\n",
        "        # Initialize target flags (used to track matched targets)\n",
        "        target_flags = [False] * len(cls_target_boxes)\n",
        "\n",
        "        # For each prediction, find if it matches any ground truth\n",
        "        for i, pred_box in enumerate(cls_pred_boxes):\n",
        "            # Store the score\n",
        "            all_scores.append(cls_pred_scores[i].item())\n",
        "\n",
        "            if len(cls_target_boxes) == 0:\n",
        "                # No ground truth, all predictions are false positives\n",
        "                all_tp.append(0)\n",
        "                all_fp.append(1)\n",
        "                continue\n",
        "\n",
        "            # Calculate IoU with all ground truths\n",
        "            ious = box_iou(pred_box.unsqueeze(0), cls_target_boxes)[0]\n",
        "\n",
        "            # Get maximum IoU and corresponding index\n",
        "            max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "            if max_iou >= iou_threshold and not target_flags[max_idx]:\n",
        "                # True positive\n",
        "                all_tp.append(1)\n",
        "                all_fp.append(0)\n",
        "                target_flags[max_idx] = True\n",
        "            else:\n",
        "                # False positive\n",
        "                all_tp.append(0)\n",
        "                all_fp.append(1)\n",
        "\n",
        "    # Calculate precision-recall curve\n",
        "    if len(all_scores) == 0 or num_gt == 0:\n",
        "        return [], [], []\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    scores = np.array(all_scores)\n",
        "    tp = np.array(all_tp)\n",
        "    fp = np.array(all_fp)\n",
        "\n",
        "    # Sort by score\n",
        "    indices = np.argsort(-scores)\n",
        "    tp = tp[indices]\n",
        "    fp = fp[indices]\n",
        "    thresholds = scores[indices]\n",
        "\n",
        "    # Compute cumulative sum\n",
        "    tp_cumsum = np.cumsum(tp)\n",
        "    fp_cumsum = np.cumsum(fp)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
        "    recall = tp_cumsum / num_gt\n",
        "\n",
        "    return precision, recall, thresholds\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5, output_dir=None):\n",
        "    \"\"\"\n",
        "    Visualize model predictions on sample images\n",
        "\n",
        "    Args:\n",
        "        model: Trained SSD model\n",
        "        dataset: Dataset to sample images from\n",
        "        device: Device to run model on\n",
        "        num_images: Number of images to visualize\n",
        "        output_dir: Directory to save visualizations\n",
        "    \"\"\"\n",
        "    # Sample indices\n",
        "    indices = random.sample(range(len(dataset)), min(num_images, len(dataset)))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            # Get image and target\n",
        "            img, target = dataset[idx]\n",
        "\n",
        "            # Run model\n",
        "            pred = model([img.to(device)])[0]\n",
        "\n",
        "            # Convert tensor to PIL image for drawing\n",
        "            img_np = img.permute(1, 2, 0).cpu().numpy()\n",
        "            img_np = (img_np * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]) * 255\n",
        "            img_np = img_np.astype(np.uint8)\n",
        "            img_pil = Image.fromarray(img_np)\n",
        "\n",
        "            # Create drawing context\n",
        "            draw = ImageDraw.Draw(img_pil)\n",
        "\n",
        "            # Draw ground truth boxes (green)\n",
        "            for box, label in zip(target['boxes'], target['labels']):\n",
        "                box = box.tolist()\n",
        "                label_text = dataset.classes[label.item()]\n",
        "                draw.rectangle(box, outline='green', width=2)\n",
        "                draw.text((box[0], box[1]), label_text, fill='green')\n",
        "\n",
        "            # Draw predicted boxes (red)\n",
        "            for box, score, label in zip(pred['boxes'], pred['scores'], pred['labels']):\n",
        "                if score > 0.5:  # Only draw high-confidence predictions\n",
        "                    box = box.tolist()\n",
        "                    label_text = f\"{dataset.classes[label.item()]}: {score:.2f}\"\n",
        "                    draw.rectangle(box, outline='red', width=2)\n",
        "                    draw.text((box[0], box[3] + 10), label_text, fill='red')\n",
        "\n",
        "            # Save visualization\n",
        "            if output_dir:\n",
        "                img_pil.save(os.path.join(output_dir, f'viz_{i}.png'))\n",
        "\n",
        "# ===========================\n",
        "# TEST-TIME AUGMENTATION\n",
        "# ===========================\n",
        "\n",
        "class TestTimeAugmentation:\n",
        "    \"\"\"\n",
        "    Apply test-time augmentation to improve detection performance\n",
        "    without modifying the training procedure.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, device, num_augmentations=5):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.num_augmentations = num_augmentations\n",
        "\n",
        "    def __call__(self, images):\n",
        "        \"\"\"\n",
        "        Apply multiple augmentations to the input images and ensemble the results\n",
        "\n",
        "        Args:\n",
        "            images: List of input images\n",
        "\n",
        "        Returns:\n",
        "            List of detection results after ensembling\n",
        "        \"\"\"\n",
        "        # Store original images\n",
        "        original_images = images\n",
        "        all_detections = []\n",
        "\n",
        "        # Original prediction (no augmentation)\n",
        "        with torch.no_grad():\n",
        "            original_detections = self.model(original_images)\n",
        "\n",
        "        all_detections.append(original_detections)\n",
        "\n",
        "        # Apply various augmentations\n",
        "        augmentations = [\n",
        "            # Horizontal flip\n",
        "            lambda img: torch.flip(img, dims=[2]),\n",
        "\n",
        "            # Slight rotation (convert to PIL, rotate, convert back)\n",
        "            lambda img: torchvision.transforms.functional.to_tensor(\n",
        "                torchvision.transforms.functional.rotate(\n",
        "                    torchvision.transforms.functional.to_pil_image(img),\n",
        "                    angle=5.0\n",
        "                )\n",
        "            ),\n",
        "\n",
        "            # Brightness adjustment\n",
        "            lambda img: torchvision.transforms.functional.adjust_brightness(img, brightness_factor=0.9),\n",
        "\n",
        "            # Contrast adjustment\n",
        "            lambda img: torchvision.transforms.functional.adjust_contrast(img, contrast_factor=1.1),\n",
        "\n",
        "            # Small translation (shift)\n",
        "            lambda img: torch.nn.functional.pad(\n",
        "                img[:, :, :-1, :], (0, 0, 1, 0), mode='replicate'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Apply each augmentation and get predictions\n",
        "        for aug_fn in augmentations[:self.num_augmentations]:\n",
        "            # Apply augmentation to each image\n",
        "            aug_images = [aug_fn(img) for img in original_images]\n",
        "\n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                aug_detections = self.model(aug_images)\n",
        "\n",
        "            # For horizontal flip, adjust bounding box coordinates\n",
        "            if aug_fn == augmentations[0]:  # Horizontal flip\n",
        "                for det in aug_detections:\n",
        "                    if len(det['boxes']) > 0:\n",
        "                        # Flip back the coordinates\n",
        "                        img_width = original_images[0].shape[2]\n",
        "                        boxes = det['boxes']\n",
        "                        flipped_boxes = boxes.clone()\n",
        "                        flipped_boxes[:, 0] = img_width - boxes[:, 2]\n",
        "                        flipped_boxes[:, 2] = img_width - boxes[:, 0]\n",
        "                        det['boxes'] = flipped_boxes\n",
        "\n",
        "            all_detections.append(aug_detections)\n",
        "\n",
        "        # Merge detections from all augmentations\n",
        "        merged_detections = self._merge_detections(all_detections)\n",
        "\n",
        "        return merged_detections\n",
        "\n",
        "    def _merge_detections(self, all_detections):\n",
        "        \"\"\"Merge detections from multiple augmentations\"\"\"\n",
        "        merged_detections = []\n",
        "\n",
        "        # Process each image separately\n",
        "        for img_idx in range(len(all_detections[0])):\n",
        "            # Collect all boxes, scores and labels for this image\n",
        "            boxes = []\n",
        "            scores = []\n",
        "            labels = []\n",
        "\n",
        "            for aug_detections in all_detections:\n",
        "                det = aug_detections[img_idx]\n",
        "                boxes.append(det['boxes'])\n",
        "                scores.append(det['scores'])\n",
        "                labels.append(det['labels'])\n",
        "\n",
        "            # Concatenate all predictions if not empty\n",
        "            if all(len(b) > 0 for b in boxes):\n",
        "                boxes = torch.cat(boxes, dim=0)\n",
        "                scores = torch.cat(scores, dim=0)\n",
        "                labels = torch.cat(labels, dim=0)\n",
        "\n",
        "                # Apply weighted NMS per class\n",
        "                result = {}\n",
        "                result_boxes = []\n",
        "                result_scores = []\n",
        "                result_labels = []\n",
        "\n",
        "                # Process each class separately\n",
        "                unique_labels = torch.unique(labels)\n",
        "                for cls in unique_labels:\n",
        "                    cls_mask = (labels == cls)\n",
        "                    cls_boxes = boxes[cls_mask]\n",
        "                    cls_scores = scores[cls_mask]\n",
        "\n",
        "                    # Apply NMS\n",
        "                    keep = nms(cls_boxes, cls_scores, iou_threshold=0.5)\n",
        "\n",
        "                    result_boxes.append(cls_boxes[keep])\n",
        "                    result_scores.append(cls_scores[keep])\n",
        "                    result_labels.append(torch.full_like(cls_scores[keep], cls, dtype=torch.int64))\n",
        "\n",
        "                # Combine results\n",
        "                if result_boxes:\n",
        "                    result['boxes'] = torch.cat(result_boxes, dim=0)\n",
        "                    result['scores'] = torch.cat(result_scores, dim=0)\n",
        "                    result['labels'] = torch.cat(result_labels, dim=0)\n",
        "                else:\n",
        "                    result['boxes'] = torch.empty((0, 4), device=boxes.device)\n",
        "                    result['scores'] = torch.empty((0,), device=boxes.device)\n",
        "                    result['labels'] = torch.empty((0,), device=boxes.device, dtype=torch.int64)\n",
        "            else:\n",
        "                # Handle the case where some detections are empty\n",
        "                result = {'boxes': torch.empty((0, 4)), 'scores': torch.empty(0), 'labels': torch.empty(0, dtype=torch.int64)}\n",
        "\n",
        "            merged_detections.append(result)\n",
        "\n",
        "        return merged_detections\n",
        "\n",
        "# ===========================\n",
        "# ENHANCED OPTIMIZER AND SCHEDULER\n",
        "# ===========================\n",
        "\n",
        "\n",
        "def create_enhanced_optimizer(model, lr=0.0005, weight_decay=0.0001):\n",
        "    \"\"\"Create an enhanced optimizer with parameter-specific learning rates\"\"\"\n",
        "    # Separate backbone and detection head parameters for different learning rates\n",
        "    backbone_params = []\n",
        "    head_params = []\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'backbone' in name:\n",
        "            backbone_params.append(param)\n",
        "        else:\n",
        "            head_params.append(param)\n",
        "\n",
        "    # Create optimizer with different learning rates\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': lr * 0.1},  # Lower LR for backbone\n",
        "        {'params': head_params, 'lr': lr}\n",
        "    ], weight_decay=weight_decay)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, cycles=0.5):\n",
        "    \"\"\"\n",
        "    Create a schedule with a learning rate that decreases following the\n",
        "    values of the cosine function between the initial lr and 0, after\n",
        "    a warmup period during which it increases linearly from 0 to the initial lr.\n",
        "    \"\"\"\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(cycles) * 2.0 * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "# ===========================\n",
        "# HARD NEGATIVE MINING\n",
        "# ===========================\n",
        "\n",
        "def hard_negative_mining(cls_loss, pos_mask, neg_pos_ratio=3):\n",
        "    \"\"\"\n",
        "    Hard negative mining to select the most difficult background examples.\n",
        "\n",
        "    Args:\n",
        "        cls_loss: Classification loss per anchor\n",
        "        pos_mask: Boolean mask indicating positive (foreground) anchors\n",
        "        neg_pos_ratio: Ratio of negative (background) to positive examples\n",
        "\n",
        "    Returns:\n",
        "        Boolean mask indicating which negative anchors to keep\n",
        "    \"\"\"\n",
        "    # Count positives\n",
        "    pos_count = pos_mask.sum().item()\n",
        "\n",
        "    # Number of negatives to sample\n",
        "    neg_count = int(pos_count * neg_pos_ratio)\n",
        "\n",
        "    # If no positives, sample a fixed number of negatives\n",
        "    if pos_count == 0:\n",
        "        neg_count = 100\n",
        "\n",
        "    # Get loss for negative anchors\n",
        "    neg_mask = ~pos_mask\n",
        "    neg_losses = cls_loss * neg_mask.float()\n",
        "\n",
        "    # Sort negative losses from highest to lowest\n",
        "    _, indices = neg_losses.sort(descending=True)\n",
        "    _, orders = indices.sort()\n",
        "\n",
        "    # Select the top K negatives\n",
        "    neg_mask_top_k = orders < neg_count\n",
        "\n",
        "    # Combine with positive mask\n",
        "    hard_mining_mask = pos_mask | (neg_mask & neg_mask_top_k)\n",
        "\n",
        "    return hard_mining_mask\n",
        "\n",
        "# ===========================\n",
        "# ADVANCED EVALUATION METRICS\n",
        "# ===========================\n",
        "\n",
        "def calculate_ap_per_iou(predictions, targets, class_idx, iou_thresholds=None):\n",
        "    \"\"\"\n",
        "    Calculate Average Precision across multiple IoU thresholds (COCO-style)\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        class_idx: Class index to calculate AP for\n",
        "        iou_thresholds: List of IoU thresholds, defaults to [0.5, 0.55, 0.6, ..., 0.95]\n",
        "\n",
        "    Returns:\n",
        "        AP: Average Precision across multiple IoU thresholds\n",
        "    \"\"\"\n",
        "    if iou_thresholds is None:\n",
        "        iou_thresholds = np.linspace(0.5, 0.95, 10)\n",
        "\n",
        "    # Calculate AP for each IoU threshold\n",
        "    aps = []\n",
        "    for iou_threshold in iou_thresholds:\n",
        "        # Collect all predictions and ground truths for this class\n",
        "        all_scores = []\n",
        "        all_tp = []\n",
        "        all_fp = []\n",
        "        num_gt = 0\n",
        "\n",
        "        # Process each image\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            pred_boxes = pred['boxes']\n",
        "            pred_scores = pred['scores']\n",
        "            pred_labels = pred['labels']\n",
        "\n",
        "            target_boxes = target['boxes']\n",
        "            target_labels = target['labels']\n",
        "\n",
        "            # Count ground truth for this class\n",
        "            num_gt += (target_labels == class_idx).sum().item()\n",
        "\n",
        "            # Filter predictions by class\n",
        "            cls_pred_mask = pred_labels == class_idx\n",
        "            cls_pred_boxes = pred_boxes[cls_pred_mask]\n",
        "            cls_pred_scores = pred_scores[cls_pred_mask]\n",
        "\n",
        "            # Filter targets by class\n",
        "            cls_target_mask = target_labels == class_idx\n",
        "            cls_target_boxes = target_boxes[cls_target_mask]\n",
        "\n",
        "            # Sort predictions by score (descending)\n",
        "            if len(cls_pred_scores) > 0:\n",
        "                sort_idx = torch.argsort(cls_pred_scores, descending=True)\n",
        "                cls_pred_boxes = cls_pred_boxes[sort_idx]\n",
        "                cls_pred_scores = cls_pred_scores[sort_idx]\n",
        "\n",
        "            # Initialize target flags (used to track matched targets)\n",
        "            target_flags = [False] * len(cls_target_boxes)\n",
        "\n",
        "            # For each prediction, find if it matches any ground truth\n",
        "            for i, pred_box in enumerate(cls_pred_boxes):\n",
        "                # Store the score\n",
        "                all_scores.append(cls_pred_scores[i].item())\n",
        "\n",
        "                if len(cls_target_boxes) == 0:\n",
        "                    # No ground truth, all predictions are false positives\n",
        "                    all_tp.append(0)\n",
        "                    all_fp.append(1)\n",
        "                    continue\n",
        "\n",
        "                # Calculate IoU with all ground truths\n",
        "                ious = box_iou(pred_box.unsqueeze(0), cls_target_boxes)[0]\n",
        "\n",
        "                # Get maximum IoU and corresponding index\n",
        "                max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "                if max_iou >= iou_threshold and not target_flags[max_idx]:\n",
        "                    # True positive\n",
        "                    all_tp.append(1)\n",
        "                    all_fp.append(0)\n",
        "                    target_flags[max_idx] = True\n",
        "                else:\n",
        "                    # False positive\n",
        "                    all_tp.append(0)\n",
        "                    all_fp.append(1)\n",
        "\n",
        "        # Calculate AP for this IoU threshold\n",
        "        if len(all_scores) == 0 or num_gt == 0:\n",
        "            aps.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        scores = np.array(all_scores)\n",
        "        tp = np.array(all_tp)\n",
        "        fp = np.array(all_fp)\n",
        "\n",
        "        # Sort by score\n",
        "        indices = np.argsort(-scores)\n",
        "        tp = tp[indices]\n",
        "        fp = fp[indices]\n",
        "\n",
        "        # Compute cumulative sum\n",
        "        tp_cumsum = np.cumsum(tp)\n",
        "        fp_cumsum = np.cumsum(fp)\n",
        "\n",
        "        # Calculate precision and recall\n",
        "        precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
        "        recall = tp_cumsum / num_gt\n",
        "\n",
        "        # Add sentinel values\n",
        "        precision = np.concatenate(([1.0], precision))\n",
        "        recall = np.concatenate(([0.0], recall))\n",
        "\n",
        "        # Compute average precision using 11-point interpolation\n",
        "        ap = 0.0\n",
        "        for t in np.linspace(0, 1, 11):\n",
        "            mask = recall >= t\n",
        "            if mask.any():\n",
        "                p = precision[mask].max()\n",
        "            else:\n",
        "                p = 0.0\n",
        "            ap += p / 11.0\n",
        "\n",
        "        aps.append(ap)\n",
        "\n",
        "    # Return mean AP across IoU thresholds\n",
        "    return np.mean(aps)\n",
        "\n",
        "def calculate_coco_metrics(predictions, targets, num_classes):\n",
        "    \"\"\"\n",
        "    Calculate COCO-style metrics including:\n",
        "    - mAP@[0.5:0.95]\n",
        "    - mAP@0.5\n",
        "    - mAP@0.75\n",
        "    - mAP for small, medium, large objects\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        num_classes: Number of classes (including background)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of COCO metrics\n",
        "    \"\"\"\n",
        "    # Initialize metrics\n",
        "    metrics = {\n",
        "        'mAP': 0.0,\n",
        "        'mAP_50': 0.0,\n",
        "        'mAP_75': 0.0,\n",
        "        'mAP_small': 0.0,\n",
        "        'mAP_medium': 0.0,\n",
        "        'mAP_large': 0.0\n",
        "    }\n",
        "    # Calculate AP for each class at various IoU thresholds\n",
        "    class_aps = []\n",
        "    class_aps_50 = []\n",
        "    class_aps_75 = []\n",
        "\n",
        "    # AP by object size\n",
        "    class_aps_small = []\n",
        "    class_aps_medium = []\n",
        "    class_aps_large = []\n",
        "\n",
        "    for cls in range(1, num_classes):  # Skip background class\n",
        "        # Calculate AP across IoU thresholds [0.5:0.95]\n",
        "        ap = calculate_ap_per_iou(predictions, targets, cls)\n",
        "        class_aps.append(ap)\n",
        "        # Calculate AP at IoU 0.5\n",
        "        ap_50 = calculate_ap_per_iou(predictions, targets, cls, [0.5])\n",
        "        class_aps_50.append(ap_50)\n",
        "        # Calculate AP at IoU 0.75\n",
        "        ap_75 = calculate_ap_per_iou(predictions, targets, cls, [0.75])\n",
        "        class_aps_75.append(ap_75)\n",
        "        # Calculate AP by object size\n",
        "        ap_small, ap_medium, ap_large = calculate_ap_by_size(predictions, targets, cls)\n",
        "        class_aps_small.append(ap_small)\n",
        "        class_aps_medium.append(ap_medium)\n",
        "        class_aps_large.append(ap_large)\n",
        "    # Calculate mean metrics\n",
        "    metrics['mAP'] = np.mean(class_aps) if class_aps else 0.0\n",
        "    metrics['mAP_50'] = np.mean(class_aps_50) if class_aps_50 else 0.0\n",
        "    metrics['mAP_75'] = np.mean(class_aps_75) if class_aps_75 else 0.0\n",
        "    metrics['mAP_small'] = np.mean(class_aps_small) if class_aps_small else 0.0\n",
        "    metrics['mAP_medium'] = np.mean(class_aps_medium) if class_aps_medium else 0.0\n",
        "    metrics['mAP_large'] = np.mean(class_aps_large) if class_aps_large else 0.0\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def calculate_ap_by_size(predictions, targets, class_idx, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate Average Precision for different object sizes:\n",
        "    - Small: area < 32²\n",
        "    - Medium: 32² <= area < 96²\n",
        "    - Large: area >= 96²\n",
        "\n",
        "    Args:\n",
        "        predictions: List of prediction dictionaries with 'boxes', 'scores', 'labels'\n",
        "        targets: List of target dictionaries with 'boxes', 'labels'\n",
        "        class_idx: Class index to calculate AP for\n",
        "        iou_threshold: IoU threshold for considering a detection as correct\n",
        "\n",
        "    Returns:\n",
        "        ap_small, ap_medium, ap_large: AP for each size category\n",
        "    \"\"\"\n",
        "    # Define size thresholds\n",
        "    small_threshold = 32 * 32\n",
        "    medium_threshold = 96 * 96\n",
        "\n",
        "    # Initialize metrics for each size category\n",
        "    small_metrics = {'tp': [], 'fp': [], 'scores': [], 'num_gt': 0}\n",
        "    medium_metrics = {'tp': [], 'fp': [], 'scores': [], 'num_gt': 0}\n",
        "    large_metrics = {'tp': [], 'fp': [], 'scores': [], 'num_gt': 0}\n",
        "\n",
        "    # Process each image\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        pred_scores = pred['scores']\n",
        "        pred_labels = pred['labels']\n",
        "\n",
        "        target_boxes = target['boxes']\n",
        "        target_labels = target['labels']\n",
        "\n",
        "        # Filter predictions by class\n",
        "        cls_pred_mask = pred_labels == class_idx\n",
        "        cls_pred_boxes = pred_boxes[cls_pred_mask]\n",
        "        cls_pred_scores = pred_scores[cls_pred_mask]\n",
        "\n",
        "        # Filter targets by class\n",
        "        cls_target_mask = target_labels == class_idx\n",
        "        cls_target_boxes = target_boxes[cls_target_mask]\n",
        "\n",
        "        # Calculate areas\n",
        "        if len(cls_target_boxes) > 0:\n",
        "            target_areas = (cls_target_boxes[:, 2] - cls_target_boxes[:, 0]) * (cls_target_boxes[:, 3] - cls_target_boxes[:, 1])\n",
        "\n",
        "            # Count ground truths by size\n",
        "            small_metrics['num_gt'] += (target_areas < small_threshold).sum().item()\n",
        "            medium_metrics['num_gt'] += ((target_areas >= small_threshold) & (target_areas < medium_threshold)).sum().item()\n",
        "            large_metrics['num_gt'] += (target_areas >= medium_threshold).sum().item()\n",
        "\n",
        "            # Create size masks for targets\n",
        "            small_targets_mask = target_areas < small_threshold\n",
        "            medium_targets_mask = (target_areas >= small_threshold) & (target_areas < medium_threshold)\n",
        "            large_targets_mask = target_areas >= medium_threshold\n",
        "\n",
        "            # Get target boxes by size\n",
        "            small_targets = cls_target_boxes[small_targets_mask]\n",
        "            medium_targets = cls_target_boxes[medium_targets_mask]\n",
        "            large_targets = cls_target_boxes[large_targets_mask]\n",
        "\n",
        "            # Initialize target flags\n",
        "            small_flags = [False] * len(small_targets)\n",
        "            medium_flags = [False] * len(medium_targets)\n",
        "            large_flags = [False] * len(large_targets)\n",
        "\n",
        "            # For each prediction, find if it matches any ground truth\n",
        "            for i, pred_box in enumerate(cls_pred_boxes):\n",
        "                pred_score = cls_pred_scores[i].item()\n",
        "\n",
        "                # Calculate area of prediction (to categorize it)\n",
        "                pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
        "\n",
        "                # Small predictions\n",
        "                if pred_area < small_threshold:\n",
        "                    # Add score\n",
        "                    small_metrics['scores'].append(pred_score)\n",
        "\n",
        "                    if len(small_targets) == 0:\n",
        "                        # No small ground truths, count as false positive\n",
        "                        small_metrics['tp'].append(0)\n",
        "                        small_metrics['fp'].append(1)\n",
        "                    else:\n",
        "                        # Calculate IoU with small ground truths\n",
        "                        ious = box_iou(pred_box.unsqueeze(0), small_targets)[0]\n",
        "                        max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "                        if max_iou >= iou_threshold and not small_flags[max_idx]:\n",
        "                            # True positive\n",
        "                            small_metrics['tp'].append(1)\n",
        "                            small_metrics['fp'].append(0)\n",
        "                            small_flags[max_idx] = True\n",
        "                        else:\n",
        "                            # False positive\n",
        "                            small_metrics['tp'].append(0)\n",
        "                            small_metrics['fp'].append(1)\n",
        "\n",
        "                # Medium predictions\n",
        "                elif pred_area < medium_threshold:\n",
        "                    # Add score\n",
        "                    medium_metrics['scores'].append(pred_score)\n",
        "\n",
        "                    if len(medium_targets) == 0:\n",
        "                        # No medium ground truths, count as false positive\n",
        "                        medium_metrics['tp'].append(0)\n",
        "                        medium_metrics['fp'].append(1)\n",
        "                    else:\n",
        "                        # Calculate IoU with medium ground truths\n",
        "                        ious = box_iou(pred_box.unsqueeze(0), medium_targets)[0]\n",
        "                        max_iou, max_idx = torch.max(ious, dim=0)\n",
        "                        if max_iou >= iou_threshold and not medium_flags[max_idx]:\n",
        "                            # True positive\n",
        "                            medium_metrics['tp'].append(1)\n",
        "                            medium_metrics['fp'].append(0)\n",
        "                            medium_flags[max_idx] = True\n",
        "                        else:\n",
        "                            # False positive\n",
        "                            medium_metrics['tp'].append(0)\n",
        "                            medium_metrics['fp'].append(1)\n",
        "                # Large predictions\n",
        "                else:\n",
        "                    # Add score\n",
        "                    large_metrics['scores'].append(pred_score)\n",
        "\n",
        "                    if len(large_targets) == 0:\n",
        "                        # No large ground truths, count as false positive\n",
        "                        large_metrics['tp'].append(0)\n",
        "                        large_metrics['fp'].append(1)\n",
        "                    else:\n",
        "                        # Calculate IoU with large ground truths\n",
        "                        ious = box_iou(pred_box.unsqueeze(0), large_targets)[0]\n",
        "                        max_iou, max_idx = torch.max(ious, dim=0)\n",
        "\n",
        "                        if max_iou >= iou_threshold and not large_flags[max_idx]:\n",
        "                            # True positive\n",
        "                            large_metrics['tp'].append(1)\n",
        "                            large_metrics['fp'].append(0)\n",
        "                            large_flags[max_idx] = True\n",
        "                        else:\n",
        "                            # False positive\n",
        "                            large_metrics['tp'].append(0)\n",
        "                            large_metrics['fp'].append(1)\n",
        "\n",
        "    # Calculate AP for each size category\n",
        "    ap_small = calculate_ap_from_metrics(small_metrics)\n",
        "    ap_medium = calculate_ap_from_metrics(medium_metrics)\n",
        "    ap_large = calculate_ap_from_metrics(large_metrics)\n",
        "    return ap_small, ap_medium, ap_large\n",
        "def calculate_ap_from_metrics(metrics):\n",
        "    \"\"\"Helper function to calculate AP from metrics dictionary\"\"\"\n",
        "    if metrics['num_gt'] == 0 or len(metrics['scores']) == 0:\n",
        "        return 0.0\n",
        "    # Convert to numpy arrays\n",
        "    scores = np.array(metrics['scores'])\n",
        "    tp = np.array(metrics['tp'])\n",
        "    fp = np.array(metrics['fp'])\n",
        "    # Sort by score\n",
        "    indices = np.argsort(-scores)\n",
        "    tp = tp[indices]\n",
        "    fp = fp[indices]\n",
        "    # Compute cumulative sum\n",
        "    tp_cumsum = np.cumsum(tp)\n",
        "    fp_cumsum = np.cumsum(fp)\n",
        "    # Calculate precision and recall\n",
        "    precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
        "    recall = tp_cumsum / metrics['num_gt']\n",
        "    # Add sentinel values\n",
        "    precision = np.concatenate(([1.0], precision))\n",
        "    recall = np.concatenate(([0.0], recall))\n",
        "    # Compute average precision using 11-point interpolation\n",
        "    ap = 0.0\n",
        "    for t in np.linspace(0, 1, 11):\n",
        "        mask = recall >= t\n",
        "        if mask.any():\n",
        "            p = precision[mask].max()\n",
        "        else:\n",
        "            p = 0.0\n",
        "        ap += p / 11.0\n",
        "    return ap"
      ],
      "metadata": {
        "id": "UBNzaI4IjqAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}